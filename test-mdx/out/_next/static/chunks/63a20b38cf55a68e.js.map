{"version":3,"sources":["turbopack:///[project]/node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/ral.js","turbopack:///[project]/node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/is.js","turbopack:///[project]/node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/events.js","turbopack:///[project]/node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/cancellation.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_stackHas.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_stackDelete.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_stackGet.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_listCacheClear.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/eq.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_objectToString.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isObject.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_toSource.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_getValue.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_hashDelete.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_isKeyable.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_arrayEach.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseTimes.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isObjectLike.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isArray.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/stubFalse.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_isIndex.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isLength.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseUnary.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_isPrototype.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_overArg.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_nativeKeysIn.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_copyArray.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_arrayFilter.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/stubArray.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_arrayPush.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_initCloneArray.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_cloneRegExp.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_createBaseFor.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/identity.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseHas.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_arrayMap.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_setCacheAdd.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_setCacheHas.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_arraySome.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_cacheHas.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_mapToArray.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_setToArray.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_matchesStrictComparable.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseHasIn.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseProperty.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseSlice.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_trimmedEndIndex.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_apply.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/constant.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_shortOut.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_arrayEvery.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseFindIndex.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseIsNaN.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_strictIndexOf.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_arrayIncludesWith.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/noop.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isUndefined.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/compact.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/head.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_arrayReduce.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseReduce.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/negate.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/last.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_arrayAggregator.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.22/node_modules/lodash-es/flatMap.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.22/node_modules/lodash-es/uniqBy.js","turbopack:///[project]/node_modules/.pnpm/@mermaid-js+parser@0.6.3/node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-FPAJGGOC.mjs","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_freeGlobal.js","turbopack:///[project]/node_modules/.pnpm/@chevrotain+utils@11.0.3/node_modules/@chevrotain/utils/src/timer.ts","webpack://LIB/./node_modules/path-browserify/index.js","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/checks.ts","turbopack:///[project]/node_modules/.pnpm/@chevrotain+gast@11.0.3/node_modules/@chevrotain/gast/src/api.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/scan/lexer_public.ts","turbopack:///[project]/node_modules/.pnpm/@chevrotain+gast@11.0.3/node_modules/@chevrotain/gast/src/visitor.ts","webpack://LIB/webpack/bootstrap","webpack://LIB/webpack/runtime/define property getters","webpack://LIB/webpack/runtime/hasOwnProperty shorthand","webpack://LIB/webpack/runtime/make namespace object","webpack://LIB/./src/platform.ts","webpack://LIB/./src/uri.ts","webpack://LIB/./src/utils.ts","turbopack:///[project]/node_modules/.pnpm/@chevrotain+regexp-to-ast@11.0.3/node_modules/@chevrotain/regexp-to-ast/src/utils.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/tree_builder.ts","turbopack:///[project]/node_modules/.pnpm/@chevrotain+cst-dts-gen@11.0.3/node_modules/@chevrotain/cst-dts-gen/src/generate.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/scan/tokens.ts","turbopack:///[project]/node_modules/.pnpm/@chevrotain+gast@11.0.3/node_modules/@chevrotain/gast/src/model.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/first.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/diagrams/render_public.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/recognizer_engine.ts","turbopack:///[project]/node_modules/.pnpm/@chevrotain+gast@11.0.3/node_modules/@chevrotain/gast/src/helpers.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/gast_recorder.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/rest.ts","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_Uint8Array.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/clone.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseFor.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_createBaseEach.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_castFunction.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_nativeKeys.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/memoize.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_memoizeCapped.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_stringToPath.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/toString.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_toKey.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_equalObjects.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_isStrictComparable.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/get.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_basePropertyDeep.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseValues.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseTrim.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/toFinite.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/toInteger.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_overRest.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseEvery.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseSome.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/flatten.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_arrayIncludes.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/uniq.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_cloneBuffer.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseFilter.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_getPrototype.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseCreate.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_cloneArrayBuffer.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_cloneDataView.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_cloneSymbol.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_cloneTypedArray.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseAggregator.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_assocIndexOf.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_listCacheDelete.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_listCacheGet.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_listCacheHas.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_listCacheSet.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_stackClear.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_root.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_Symbol.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_getRawTag.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_coreJsData.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_isMasked.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_nativeCreate.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_hashClear.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_hashGet.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_hashHas.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_hashSet.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_getMapData.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_mapCacheDelete.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_mapCacheGet.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_mapCacheHas.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_mapCacheSet.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_defineProperty.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseAssignValue.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_nodeUtil.js","turbopack:///[project]/node_modules/.pnpm/@chevrotain+regexp-to-ast@11.0.3/node_modules/@chevrotain/regexp-to-ast/src/character-classes.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/lang/lang_extensions.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/scan/reg_exp_parser.ts","turbopack:///[project]/node_modules/.pnpm/@chevrotain+cst-dts-gen@11.0.3/node_modules/@chevrotain/cst-dts-gen/src/api.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/follow.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/gast/gast_resolver_public.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/api.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/scan/lexer_errors_public.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/scan/tokens_public.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/error_handler.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/scan/lexer.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/looksahead.ts","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseMap.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/values.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_copySymbolsIn.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseGetAllKeys.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_DataView.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_Promise.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_Set.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_WeakMap.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/drop.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseKeys.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_setToString.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_createAssigner.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseIsRegExp.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isArrayLike.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseFlatten.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseAssign.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseAssignIn.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isArrayLikeObject.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/find.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/indexOf.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseIsMap.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseIsSet.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseForOwn.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseEach.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/dropRight.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/flatMap.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/groupBy.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/hasIn.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isSymbol.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_isKey.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isFunction.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_getSymbols.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_getNative.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_Map.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/has.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_copySymbols.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseIsEqual.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseIsMatch.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_assignValue.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_copyObject.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseIsArguments.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isArguments.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isBuffer.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_getMatchData.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseGet.js","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/recoverable.ts","turbopack:///[project]/node_modules/.pnpm/@chevrotain+cst-dts-gen@11.0.3/node_modules/@chevrotain/cst-dts-gen/src/model.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/utils/apply_mixins.ts","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_initCloneObject.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isMap.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_basePickBy.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_getAllKeys.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseGetTag.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isSet.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseKeysIn.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/keysIn.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/toNumber.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_getAllKeysIn.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseRest.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_createFind.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/findIndex.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_SetCache.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_mapCacheClear.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_equalArrays.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_stackSet.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseIndexOf.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_isFlattenable.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/keys.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseIsTypedArray.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseMatches.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_createSet.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseSetToString.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isTypedArray.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isRegExp.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isString.js","turbopack:///[project]/node_modules/.pnpm/@chevrotain+regexp-to-ast@11.0.3/node_modules/@chevrotain/regexp-to-ast/src/regexp-parser.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/errors_public.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/resolver.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/interpreter.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/lookahead.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/parser.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/scan/reg_exp.ts","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/pickBy.js","turbopack:///[project]/node_modules/.pnpm/vscode-languageserver-textdocument@1.0.12/node_modules/vscode-languageserver-textdocument/lib/esm/main.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_castPath.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseToString.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseIsNative.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/defaults.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/difference.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/filter.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_createAggregator.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/property.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/map.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_getSymbolsIn.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/forEach.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_isIterateeCall.js","turbopack:///[project]/node_modules/.pnpm/vscode-languageserver-types@3.17.5/node_modules/vscode-languageserver-types/lib/esm/main.js","turbopack:///[project]/node_modules/.pnpm/@chevrotain+regexp-to-ast@11.0.3/node_modules/@chevrotain/regexp-to-ast/src/base-regexp-visitor.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/context_assist.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/grammar-loader.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/documentation/comment-provider.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/serializer/hydrator.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain-allstar@0.3.1_chevrotain@11.0.3/node_modules/chevrotain-allstar/src/all-star-lookahead.ts","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseIteratee.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_Hash.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_MapCache.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/reduce.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/reject.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseSet.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/every.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/includes.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/some.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_ListCache.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_initCloneByTag.js","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/syntax-tree.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/documentation/jsdoc.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/default-module.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/regexp-utils.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/workspace-lock.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/serializer/json-serializer.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/value-converter.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/references/linker.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/validation/document-validator.ts","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_hasPath.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseDifference.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_arrayLikeKeys.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_Stack.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseUniq.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/assign.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_equalByTag.js","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/file-system-provider.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/errors.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain-allstar@0.3.1_chevrotain@11.0.3/node_modules/chevrotain-allstar/src/atn.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/validation/validation-registry.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/lexer.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/cst/cst.ts","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_getTag.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseMatchesProperty.js","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/dependency-injection.ts","turbopack:///[project]/node_modules/.pnpm/@chevrotain+utils@11.0.3/node_modules/@chevrotain/utils/src/print.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/perf_tracer.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/index-manager.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/parser-builder-base.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/document-builder.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/references/references.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/grammar-utils.ts","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isEmpty.js","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseIsEqualDeep.js","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/documentation/documentation-provider.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/llk_lookahead.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/token-builder.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/keys.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/completion-parser-builder.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/references/scope-provider.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/ast-node-locator.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/promise-utils.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/disposable.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/cst/cst_visitor.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/collections.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/workspace-manager.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/cst-node-builder.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/ast-descriptions.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/uri-utils.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/configuration.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/references/scope.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/langium-parser.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/lexer_adapter.ts","turbopack:///[project]/node_modules/.pnpm/@chevrotain+utils@11.0.3/node_modules/@chevrotain/utils/src/to-fast-properties.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/languages/grammar-config.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/recognizer_api.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/stream.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/service-registry.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/documents.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain-allstar@0.3.1_chevrotain@11.0.3/node_modules/chevrotain-allstar/src/dfa.ts","turbopack:///[project]/node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseClone.js","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/languages/generated/ast.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/caching.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/async-parser.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/references/scope-computation.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/cst-utils.ts","turbopack:///[project]/node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/exceptions_public.ts","turbopack:///[project]/node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/ast-utils.ts"],"sourcesContent":["\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nlet _ral;\nfunction RAL() {\n    if (_ral === undefined) {\n        throw new Error(`No runtime abstraction layer installed`);\n    }\n    return _ral;\n}\n(function (RAL) {\n    function install(ral) {\n        if (ral === undefined) {\n            throw new Error(`No runtime abstraction layer provided`);\n        }\n        _ral = ral;\n    }\n    RAL.install = install;\n})(RAL || (RAL = {}));\nexports.default = RAL;\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.stringArray = exports.array = exports.func = exports.error = exports.number = exports.string = exports.boolean = void 0;\nfunction boolean(value) {\n    return value === true || value === false;\n}\nexports.boolean = boolean;\nfunction string(value) {\n    return typeof value === 'string' || value instanceof String;\n}\nexports.string = string;\nfunction number(value) {\n    return typeof value === 'number' || value instanceof Number;\n}\nexports.number = number;\nfunction error(value) {\n    return value instanceof Error;\n}\nexports.error = error;\nfunction func(value) {\n    return typeof value === 'function';\n}\nexports.func = func;\nfunction array(value) {\n    return Array.isArray(value);\n}\nexports.array = array;\nfunction stringArray(value) {\n    return array(value) && value.every(elem => string(elem));\n}\nexports.stringArray = stringArray;\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Emitter = exports.Event = void 0;\nconst ral_1 = require(\"./ral\");\nvar Event;\n(function (Event) {\n    const _disposable = { dispose() { } };\n    Event.None = function () { return _disposable; };\n})(Event || (exports.Event = Event = {}));\nclass CallbackList {\n    add(callback, context = null, bucket) {\n        if (!this._callbacks) {\n            this._callbacks = [];\n            this._contexts = [];\n        }\n        this._callbacks.push(callback);\n        this._contexts.push(context);\n        if (Array.isArray(bucket)) {\n            bucket.push({ dispose: () => this.remove(callback, context) });\n        }\n    }\n    remove(callback, context = null) {\n        if (!this._callbacks) {\n            return;\n        }\n        let foundCallbackWithDifferentContext = false;\n        for (let i = 0, len = this._callbacks.length; i < len; i++) {\n            if (this._callbacks[i] === callback) {\n                if (this._contexts[i] === context) {\n                    // callback & context match => remove it\n                    this._callbacks.splice(i, 1);\n                    this._contexts.splice(i, 1);\n                    return;\n                }\n                else {\n                    foundCallbackWithDifferentContext = true;\n                }\n            }\n        }\n        if (foundCallbackWithDifferentContext) {\n            throw new Error('When adding a listener with a context, you should remove it with the same context');\n        }\n    }\n    invoke(...args) {\n        if (!this._callbacks) {\n            return [];\n        }\n        const ret = [], callbacks = this._callbacks.slice(0), contexts = this._contexts.slice(0);\n        for (let i = 0, len = callbacks.length; i < len; i++) {\n            try {\n                ret.push(callbacks[i].apply(contexts[i], args));\n            }\n            catch (e) {\n                // eslint-disable-next-line no-console\n                (0, ral_1.default)().console.error(e);\n            }\n        }\n        return ret;\n    }\n    isEmpty() {\n        return !this._callbacks || this._callbacks.length === 0;\n    }\n    dispose() {\n        this._callbacks = undefined;\n        this._contexts = undefined;\n    }\n}\nclass Emitter {\n    constructor(_options) {\n        this._options = _options;\n    }\n    /**\n     * For the public to allow to subscribe\n     * to events from this Emitter\n     */\n    get event() {\n        if (!this._event) {\n            this._event = (listener, thisArgs, disposables) => {\n                if (!this._callbacks) {\n                    this._callbacks = new CallbackList();\n                }\n                if (this._options && this._options.onFirstListenerAdd && this._callbacks.isEmpty()) {\n                    this._options.onFirstListenerAdd(this);\n                }\n                this._callbacks.add(listener, thisArgs);\n                const result = {\n                    dispose: () => {\n                        if (!this._callbacks) {\n                            // disposable is disposed after emitter is disposed.\n                            return;\n                        }\n                        this._callbacks.remove(listener, thisArgs);\n                        result.dispose = Emitter._noop;\n                        if (this._options && this._options.onLastListenerRemove && this._callbacks.isEmpty()) {\n                            this._options.onLastListenerRemove(this);\n                        }\n                    }\n                };\n                if (Array.isArray(disposables)) {\n                    disposables.push(result);\n                }\n                return result;\n            };\n        }\n        return this._event;\n    }\n    /**\n     * To be kept private to fire an event to\n     * subscribers\n     */\n    fire(event) {\n        if (this._callbacks) {\n            this._callbacks.invoke.call(this._callbacks, event);\n        }\n    }\n    dispose() {\n        if (this._callbacks) {\n            this._callbacks.dispose();\n            this._callbacks = undefined;\n        }\n    }\n}\nexports.Emitter = Emitter;\nEmitter._noop = function () { };\n","\"use strict\";\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.CancellationTokenSource = exports.CancellationToken = void 0;\nconst ral_1 = require(\"./ral\");\nconst Is = require(\"./is\");\nconst events_1 = require(\"./events\");\nvar CancellationToken;\n(function (CancellationToken) {\n    CancellationToken.None = Object.freeze({\n        isCancellationRequested: false,\n        onCancellationRequested: events_1.Event.None\n    });\n    CancellationToken.Cancelled = Object.freeze({\n        isCancellationRequested: true,\n        onCancellationRequested: events_1.Event.None\n    });\n    function is(value) {\n        const candidate = value;\n        return candidate && (candidate === CancellationToken.None\n            || candidate === CancellationToken.Cancelled\n            || (Is.boolean(candidate.isCancellationRequested) && !!candidate.onCancellationRequested));\n    }\n    CancellationToken.is = is;\n})(CancellationToken || (exports.CancellationToken = CancellationToken = {}));\nconst shortcutEvent = Object.freeze(function (callback, context) {\n    const handle = (0, ral_1.default)().timer.setTimeout(callback.bind(context), 0);\n    return { dispose() { handle.dispose(); } };\n});\nclass MutableToken {\n    constructor() {\n        this._isCancelled = false;\n    }\n    cancel() {\n        if (!this._isCancelled) {\n            this._isCancelled = true;\n            if (this._emitter) {\n                this._emitter.fire(undefined);\n                this.dispose();\n            }\n        }\n    }\n    get isCancellationRequested() {\n        return this._isCancelled;\n    }\n    get onCancellationRequested() {\n        if (this._isCancelled) {\n            return shortcutEvent;\n        }\n        if (!this._emitter) {\n            this._emitter = new events_1.Emitter();\n        }\n        return this._emitter.event;\n    }\n    dispose() {\n        if (this._emitter) {\n            this._emitter.dispose();\n            this._emitter = undefined;\n        }\n    }\n}\nclass CancellationTokenSource {\n    get token() {\n        if (!this._token) {\n            // be lazy and create the token only when\n            // actually needed\n            this._token = new MutableToken();\n        }\n        return this._token;\n    }\n    cancel() {\n        if (!this._token) {\n            // save an object by returning the default\n            // cancelled token when cancellation happens\n            // before someone asks for the token\n            this._token = CancellationToken.Cancelled;\n        }\n        else {\n            this._token.cancel();\n        }\n    }\n    dispose() {\n        if (!this._token) {\n            // ensure to initialize with an empty token if we had none\n            this._token = CancellationToken.None;\n        }\n        else if (this._token instanceof MutableToken) {\n            // actually dispose\n            this._token.dispose();\n        }\n    }\n}\nexports.CancellationTokenSource = CancellationTokenSource;\n","/**\n * Checks if a stack value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Stack\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction stackHas(key) {\n  return this.__data__.has(key);\n}\n\nexport default stackHas;\n","/**\n * Removes `key` and its value from the stack.\n *\n * @private\n * @name delete\n * @memberOf Stack\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction stackDelete(key) {\n  var data = this.__data__,\n      result = data['delete'](key);\n\n  this.size = data.size;\n  return result;\n}\n\nexport default stackDelete;\n","/**\n * Gets the stack value for `key`.\n *\n * @private\n * @name get\n * @memberOf Stack\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction stackGet(key) {\n  return this.__data__.get(key);\n}\n\nexport default stackGet;\n","/**\n * Removes all key-value entries from the list cache.\n *\n * @private\n * @name clear\n * @memberOf ListCache\n */\nfunction listCacheClear() {\n  this.__data__ = [];\n  this.size = 0;\n}\n\nexport default listCacheClear;\n","/**\n * Performs a\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * comparison between two values to determine if they are equivalent.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @returns {boolean} Returns `true` if the values are equivalent, else `false`.\n * @example\n *\n * var object = { 'a': 1 };\n * var other = { 'a': 1 };\n *\n * _.eq(object, object);\n * // => true\n *\n * _.eq(object, other);\n * // => false\n *\n * _.eq('a', 'a');\n * // => true\n *\n * _.eq('a', Object('a'));\n * // => false\n *\n * _.eq(NaN, NaN);\n * // => true\n */\nfunction eq(value, other) {\n  return value === other || (value !== value && other !== other);\n}\n\nexport default eq;\n","/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar nativeObjectToString = objectProto.toString;\n\n/**\n * Converts `value` to a string using `Object.prototype.toString`.\n *\n * @private\n * @param {*} value The value to convert.\n * @returns {string} Returns the converted string.\n */\nfunction objectToString(value) {\n  return nativeObjectToString.call(value);\n}\n\nexport default objectToString;\n","/**\n * Checks if `value` is the\n * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)\n * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an object, else `false`.\n * @example\n *\n * _.isObject({});\n * // => true\n *\n * _.isObject([1, 2, 3]);\n * // => true\n *\n * _.isObject(_.noop);\n * // => true\n *\n * _.isObject(null);\n * // => false\n */\nfunction isObject(value) {\n  var type = typeof value;\n  return value != null && (type == 'object' || type == 'function');\n}\n\nexport default isObject;\n","/** Used for built-in method references. */\nvar funcProto = Function.prototype;\n\n/** Used to resolve the decompiled source of functions. */\nvar funcToString = funcProto.toString;\n\n/**\n * Converts `func` to its source code.\n *\n * @private\n * @param {Function} func The function to convert.\n * @returns {string} Returns the source code.\n */\nfunction toSource(func) {\n  if (func != null) {\n    try {\n      return funcToString.call(func);\n    } catch (e) {}\n    try {\n      return (func + '');\n    } catch (e) {}\n  }\n  return '';\n}\n\nexport default toSource;\n","/**\n * Gets the value at `key` of `object`.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {string} key The key of the property to get.\n * @returns {*} Returns the property value.\n */\nfunction getValue(object, key) {\n  return object == null ? undefined : object[key];\n}\n\nexport default getValue;\n","/**\n * Removes `key` and its value from the hash.\n *\n * @private\n * @name delete\n * @memberOf Hash\n * @param {Object} hash The hash to modify.\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction hashDelete(key) {\n  var result = this.has(key) && delete this.__data__[key];\n  this.size -= result ? 1 : 0;\n  return result;\n}\n\nexport default hashDelete;\n","/**\n * Checks if `value` is suitable for use as unique object key.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is suitable, else `false`.\n */\nfunction isKeyable(value) {\n  var type = typeof value;\n  return (type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean')\n    ? (value !== '__proto__')\n    : (value === null);\n}\n\nexport default isKeyable;\n","/**\n * A specialized version of `_.forEach` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns `array`.\n */\nfunction arrayEach(array, iteratee) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    if (iteratee(array[index], index, array) === false) {\n      break;\n    }\n  }\n  return array;\n}\n\nexport default arrayEach;\n","/**\n * The base implementation of `_.times` without support for iteratee shorthands\n * or max array length checks.\n *\n * @private\n * @param {number} n The number of times to invoke `iteratee`.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the array of results.\n */\nfunction baseTimes(n, iteratee) {\n  var index = -1,\n      result = Array(n);\n\n  while (++index < n) {\n    result[index] = iteratee(index);\n  }\n  return result;\n}\n\nexport default baseTimes;\n","/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return value != null && typeof value == 'object';\n}\n\nexport default isObjectLike;\n","/**\n * Checks if `value` is classified as an `Array` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array, else `false`.\n * @example\n *\n * _.isArray([1, 2, 3]);\n * // => true\n *\n * _.isArray(document.body.children);\n * // => false\n *\n * _.isArray('abc');\n * // => false\n *\n * _.isArray(_.noop);\n * // => false\n */\nvar isArray = Array.isArray;\n\nexport default isArray;\n","/**\n * This method returns `false`.\n *\n * @static\n * @memberOf _\n * @since 4.13.0\n * @category Util\n * @returns {boolean} Returns `false`.\n * @example\n *\n * _.times(2, _.stubFalse);\n * // => [false, false]\n */\nfunction stubFalse() {\n  return false;\n}\n\nexport default stubFalse;\n","/** Used as references for various `Number` constants. */\nvar MAX_SAFE_INTEGER = 9007199254740991;\n\n/** Used to detect unsigned integer values. */\nvar reIsUint = /^(?:0|[1-9]\\d*)$/;\n\n/**\n * Checks if `value` is a valid array-like index.\n *\n * @private\n * @param {*} value The value to check.\n * @param {number} [length=MAX_SAFE_INTEGER] The upper bounds of a valid index.\n * @returns {boolean} Returns `true` if `value` is a valid index, else `false`.\n */\nfunction isIndex(value, length) {\n  var type = typeof value;\n  length = length == null ? MAX_SAFE_INTEGER : length;\n\n  return !!length &&\n    (type == 'number' ||\n      (type != 'symbol' && reIsUint.test(value))) &&\n        (value > -1 && value % 1 == 0 && value < length);\n}\n\nexport default isIndex;\n","/** Used as references for various `Number` constants. */\nvar MAX_SAFE_INTEGER = 9007199254740991;\n\n/**\n * Checks if `value` is a valid array-like length.\n *\n * **Note:** This method is loosely based on\n * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a valid length, else `false`.\n * @example\n *\n * _.isLength(3);\n * // => true\n *\n * _.isLength(Number.MIN_VALUE);\n * // => false\n *\n * _.isLength(Infinity);\n * // => false\n *\n * _.isLength('3');\n * // => false\n */\nfunction isLength(value) {\n  return typeof value == 'number' &&\n    value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;\n}\n\nexport default isLength;\n","/**\n * The base implementation of `_.unary` without support for storing metadata.\n *\n * @private\n * @param {Function} func The function to cap arguments for.\n * @returns {Function} Returns the new capped function.\n */\nfunction baseUnary(func) {\n  return function(value) {\n    return func(value);\n  };\n}\n\nexport default baseUnary;\n","/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/**\n * Checks if `value` is likely a prototype object.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a prototype, else `false`.\n */\nfunction isPrototype(value) {\n  var Ctor = value && value.constructor,\n      proto = (typeof Ctor == 'function' && Ctor.prototype) || objectProto;\n\n  return value === proto;\n}\n\nexport default isPrototype;\n","/**\n * Creates a unary function that invokes `func` with its argument transformed.\n *\n * @private\n * @param {Function} func The function to wrap.\n * @param {Function} transform The argument transform.\n * @returns {Function} Returns the new function.\n */\nfunction overArg(func, transform) {\n  return function(arg) {\n    return func(transform(arg));\n  };\n}\n\nexport default overArg;\n","/**\n * This function is like\n * [`Object.keys`](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)\n * except that it includes inherited enumerable properties.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction nativeKeysIn(object) {\n  var result = [];\n  if (object != null) {\n    for (var key in Object(object)) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\nexport default nativeKeysIn;\n","/**\n * Copies the values of `source` to `array`.\n *\n * @private\n * @param {Array} source The array to copy values from.\n * @param {Array} [array=[]] The array to copy values to.\n * @returns {Array} Returns `array`.\n */\nfunction copyArray(source, array) {\n  var index = -1,\n      length = source.length;\n\n  array || (array = Array(length));\n  while (++index < length) {\n    array[index] = source[index];\n  }\n  return array;\n}\n\nexport default copyArray;\n","/**\n * A specialized version of `_.filter` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {Array} Returns the new filtered array.\n */\nfunction arrayFilter(array, predicate) {\n  var index = -1,\n      length = array == null ? 0 : array.length,\n      resIndex = 0,\n      result = [];\n\n  while (++index < length) {\n    var value = array[index];\n    if (predicate(value, index, array)) {\n      result[resIndex++] = value;\n    }\n  }\n  return result;\n}\n\nexport default arrayFilter;\n","/**\n * This method returns a new empty array.\n *\n * @static\n * @memberOf _\n * @since 4.13.0\n * @category Util\n * @returns {Array} Returns the new empty array.\n * @example\n *\n * var arrays = _.times(2, _.stubArray);\n *\n * console.log(arrays);\n * // => [[], []]\n *\n * console.log(arrays[0] === arrays[1]);\n * // => false\n */\nfunction stubArray() {\n  return [];\n}\n\nexport default stubArray;\n","/**\n * Appends the elements of `values` to `array`.\n *\n * @private\n * @param {Array} array The array to modify.\n * @param {Array} values The values to append.\n * @returns {Array} Returns `array`.\n */\nfunction arrayPush(array, values) {\n  var index = -1,\n      length = values.length,\n      offset = array.length;\n\n  while (++index < length) {\n    array[offset + index] = values[index];\n  }\n  return array;\n}\n\nexport default arrayPush;\n","/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Initializes an array clone.\n *\n * @private\n * @param {Array} array The array to clone.\n * @returns {Array} Returns the initialized clone.\n */\nfunction initCloneArray(array) {\n  var length = array.length,\n      result = new array.constructor(length);\n\n  // Add properties assigned by `RegExp#exec`.\n  if (length && typeof array[0] == 'string' && hasOwnProperty.call(array, 'index')) {\n    result.index = array.index;\n    result.input = array.input;\n  }\n  return result;\n}\n\nexport default initCloneArray;\n","/** Used to match `RegExp` flags from their coerced string values. */\nvar reFlags = /\\w*$/;\n\n/**\n * Creates a clone of `regexp`.\n *\n * @private\n * @param {Object} regexp The regexp to clone.\n * @returns {Object} Returns the cloned regexp.\n */\nfunction cloneRegExp(regexp) {\n  var result = new regexp.constructor(regexp.source, reFlags.exec(regexp));\n  result.lastIndex = regexp.lastIndex;\n  return result;\n}\n\nexport default cloneRegExp;\n","/**\n * Creates a base function for methods like `_.forIn` and `_.forOwn`.\n *\n * @private\n * @param {boolean} [fromRight] Specify iterating from right to left.\n * @returns {Function} Returns the new base function.\n */\nfunction createBaseFor(fromRight) {\n  return function(object, iteratee, keysFunc) {\n    var index = -1,\n        iterable = Object(object),\n        props = keysFunc(object),\n        length = props.length;\n\n    while (length--) {\n      var key = props[fromRight ? length : ++index];\n      if (iteratee(iterable[key], key, iterable) === false) {\n        break;\n      }\n    }\n    return object;\n  };\n}\n\nexport default createBaseFor;\n","/**\n * This method returns the first argument it receives.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Util\n * @param {*} value Any value.\n * @returns {*} Returns `value`.\n * @example\n *\n * var object = { 'a': 1 };\n *\n * console.log(_.identity(object) === object);\n * // => true\n */\nfunction identity(value) {\n  return value;\n}\n\nexport default identity;\n","/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * The base implementation of `_.has` without support for deep paths.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {Array|string} key The key to check.\n * @returns {boolean} Returns `true` if `key` exists, else `false`.\n */\nfunction baseHas(object, key) {\n  return object != null && hasOwnProperty.call(object, key);\n}\n\nexport default baseHas;\n","/**\n * A specialized version of `_.map` for arrays without support for iteratee\n * shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the new mapped array.\n */\nfunction arrayMap(array, iteratee) {\n  var index = -1,\n      length = array == null ? 0 : array.length,\n      result = Array(length);\n\n  while (++index < length) {\n    result[index] = iteratee(array[index], index, array);\n  }\n  return result;\n}\n\nexport default arrayMap;\n","/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/**\n * Adds `value` to the array cache.\n *\n * @private\n * @name add\n * @memberOf SetCache\n * @alias push\n * @param {*} value The value to cache.\n * @returns {Object} Returns the cache instance.\n */\nfunction setCacheAdd(value) {\n  this.__data__.set(value, HASH_UNDEFINED);\n  return this;\n}\n\nexport default setCacheAdd;\n","/**\n * Checks if `value` is in the array cache.\n *\n * @private\n * @name has\n * @memberOf SetCache\n * @param {*} value The value to search for.\n * @returns {number} Returns `true` if `value` is found, else `false`.\n */\nfunction setCacheHas(value) {\n  return this.__data__.has(value);\n}\n\nexport default setCacheHas;\n","/**\n * A specialized version of `_.some` for arrays without support for iteratee\n * shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if any element passes the predicate check,\n *  else `false`.\n */\nfunction arraySome(array, predicate) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    if (predicate(array[index], index, array)) {\n      return true;\n    }\n  }\n  return false;\n}\n\nexport default arraySome;\n","/**\n * Checks if a `cache` value for `key` exists.\n *\n * @private\n * @param {Object} cache The cache to query.\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction cacheHas(cache, key) {\n  return cache.has(key);\n}\n\nexport default cacheHas;\n","/**\n * Converts `map` to its key-value pairs.\n *\n * @private\n * @param {Object} map The map to convert.\n * @returns {Array} Returns the key-value pairs.\n */\nfunction mapToArray(map) {\n  var index = -1,\n      result = Array(map.size);\n\n  map.forEach(function(value, key) {\n    result[++index] = [key, value];\n  });\n  return result;\n}\n\nexport default mapToArray;\n","/**\n * Converts `set` to an array of its values.\n *\n * @private\n * @param {Object} set The set to convert.\n * @returns {Array} Returns the values.\n */\nfunction setToArray(set) {\n  var index = -1,\n      result = Array(set.size);\n\n  set.forEach(function(value) {\n    result[++index] = value;\n  });\n  return result;\n}\n\nexport default setToArray;\n","/**\n * A specialized version of `matchesProperty` for source values suitable\n * for strict equality comparisons, i.e. `===`.\n *\n * @private\n * @param {string} key The key of the property to get.\n * @param {*} srcValue The value to match.\n * @returns {Function} Returns the new spec function.\n */\nfunction matchesStrictComparable(key, srcValue) {\n  return function(object) {\n    if (object == null) {\n      return false;\n    }\n    return object[key] === srcValue &&\n      (srcValue !== undefined || (key in Object(object)));\n  };\n}\n\nexport default matchesStrictComparable;\n","/**\n * The base implementation of `_.hasIn` without support for deep paths.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {Array|string} key The key to check.\n * @returns {boolean} Returns `true` if `key` exists, else `false`.\n */\nfunction baseHasIn(object, key) {\n  return object != null && key in Object(object);\n}\n\nexport default baseHasIn;\n","/**\n * The base implementation of `_.property` without support for deep paths.\n *\n * @private\n * @param {string} key The key of the property to get.\n * @returns {Function} Returns the new accessor function.\n */\nfunction baseProperty(key) {\n  return function(object) {\n    return object == null ? undefined : object[key];\n  };\n}\n\nexport default baseProperty;\n","/**\n * The base implementation of `_.slice` without an iteratee call guard.\n *\n * @private\n * @param {Array} array The array to slice.\n * @param {number} [start=0] The start position.\n * @param {number} [end=array.length] The end position.\n * @returns {Array} Returns the slice of `array`.\n */\nfunction baseSlice(array, start, end) {\n  var index = -1,\n      length = array.length;\n\n  if (start < 0) {\n    start = -start > length ? 0 : (length + start);\n  }\n  end = end > length ? length : end;\n  if (end < 0) {\n    end += length;\n  }\n  length = start > end ? 0 : ((end - start) >>> 0);\n  start >>>= 0;\n\n  var result = Array(length);\n  while (++index < length) {\n    result[index] = array[index + start];\n  }\n  return result;\n}\n\nexport default baseSlice;\n","/** Used to match a single whitespace character. */\nvar reWhitespace = /\\s/;\n\n/**\n * Used by `_.trim` and `_.trimEnd` to get the index of the last non-whitespace\n * character of `string`.\n *\n * @private\n * @param {string} string The string to inspect.\n * @returns {number} Returns the index of the last non-whitespace character.\n */\nfunction trimmedEndIndex(string) {\n  var index = string.length;\n\n  while (index-- && reWhitespace.test(string.charAt(index))) {}\n  return index;\n}\n\nexport default trimmedEndIndex;\n","/**\n * A faster alternative to `Function#apply`, this function invokes `func`\n * with the `this` binding of `thisArg` and the arguments of `args`.\n *\n * @private\n * @param {Function} func The function to invoke.\n * @param {*} thisArg The `this` binding of `func`.\n * @param {Array} args The arguments to invoke `func` with.\n * @returns {*} Returns the result of `func`.\n */\nfunction apply(func, thisArg, args) {\n  switch (args.length) {\n    case 0: return func.call(thisArg);\n    case 1: return func.call(thisArg, args[0]);\n    case 2: return func.call(thisArg, args[0], args[1]);\n    case 3: return func.call(thisArg, args[0], args[1], args[2]);\n  }\n  return func.apply(thisArg, args);\n}\n\nexport default apply;\n","/**\n * Creates a function that returns `value`.\n *\n * @static\n * @memberOf _\n * @since 2.4.0\n * @category Util\n * @param {*} value The value to return from the new function.\n * @returns {Function} Returns the new constant function.\n * @example\n *\n * var objects = _.times(2, _.constant({ 'a': 1 }));\n *\n * console.log(objects);\n * // => [{ 'a': 1 }, { 'a': 1 }]\n *\n * console.log(objects[0] === objects[1]);\n * // => true\n */\nfunction constant(value) {\n  return function() {\n    return value;\n  };\n}\n\nexport default constant;\n","/** Used to detect hot functions by number of calls within a span of milliseconds. */\nvar HOT_COUNT = 800,\n    HOT_SPAN = 16;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeNow = Date.now;\n\n/**\n * Creates a function that'll short out and invoke `identity` instead\n * of `func` when it's called `HOT_COUNT` or more times in `HOT_SPAN`\n * milliseconds.\n *\n * @private\n * @param {Function} func The function to restrict.\n * @returns {Function} Returns the new shortable function.\n */\nfunction shortOut(func) {\n  var count = 0,\n      lastCalled = 0;\n\n  return function() {\n    var stamp = nativeNow(),\n        remaining = HOT_SPAN - (stamp - lastCalled);\n\n    lastCalled = stamp;\n    if (remaining > 0) {\n      if (++count >= HOT_COUNT) {\n        return arguments[0];\n      }\n    } else {\n      count = 0;\n    }\n    return func.apply(undefined, arguments);\n  };\n}\n\nexport default shortOut;\n","/**\n * A specialized version of `_.every` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`.\n */\nfunction arrayEvery(array, predicate) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    if (!predicate(array[index], index, array)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport default arrayEvery;\n","/**\n * The base implementation of `_.findIndex` and `_.findLastIndex` without\n * support for iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Function} predicate The function invoked per iteration.\n * @param {number} fromIndex The index to search from.\n * @param {boolean} [fromRight] Specify iterating from right to left.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction baseFindIndex(array, predicate, fromIndex, fromRight) {\n  var length = array.length,\n      index = fromIndex + (fromRight ? 1 : -1);\n\n  while ((fromRight ? index-- : ++index < length)) {\n    if (predicate(array[index], index, array)) {\n      return index;\n    }\n  }\n  return -1;\n}\n\nexport default baseFindIndex;\n","/**\n * The base implementation of `_.isNaN` without support for number objects.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is `NaN`, else `false`.\n */\nfunction baseIsNaN(value) {\n  return value !== value;\n}\n\nexport default baseIsNaN;\n","/**\n * A specialized version of `_.indexOf` which performs strict equality\n * comparisons of values, i.e. `===`.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} value The value to search for.\n * @param {number} fromIndex The index to search from.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction strictIndexOf(array, value, fromIndex) {\n  var index = fromIndex - 1,\n      length = array.length;\n\n  while (++index < length) {\n    if (array[index] === value) {\n      return index;\n    }\n  }\n  return -1;\n}\n\nexport default strictIndexOf;\n","/**\n * This function is like `arrayIncludes` except that it accepts a comparator.\n *\n * @private\n * @param {Array} [array] The array to inspect.\n * @param {*} target The value to search for.\n * @param {Function} comparator The comparator invoked per element.\n * @returns {boolean} Returns `true` if `target` is found, else `false`.\n */\nfunction arrayIncludesWith(array, value, comparator) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    if (comparator(value, array[index])) {\n      return true;\n    }\n  }\n  return false;\n}\n\nexport default arrayIncludesWith;\n","/**\n * This method returns `undefined`.\n *\n * @static\n * @memberOf _\n * @since 2.3.0\n * @category Util\n * @example\n *\n * _.times(2, _.noop);\n * // => [undefined, undefined]\n */\nfunction noop() {\n  // No operation performed.\n}\n\nexport default noop;\n","/**\n * Checks if `value` is `undefined`.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is `undefined`, else `false`.\n * @example\n *\n * _.isUndefined(void 0);\n * // => true\n *\n * _.isUndefined(null);\n * // => false\n */\nfunction isUndefined(value) {\n  return value === undefined;\n}\n\nexport default isUndefined;\n","/**\n * Creates an array with all falsey values removed. The values `false`, `null`,\n * `0`, `\"\"`, `undefined`, and `NaN` are falsey.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to compact.\n * @returns {Array} Returns the new array of filtered values.\n * @example\n *\n * _.compact([0, 1, false, 2, '', 3]);\n * // => [1, 2, 3]\n */\nfunction compact(array) {\n  var index = -1,\n      length = array == null ? 0 : array.length,\n      resIndex = 0,\n      result = [];\n\n  while (++index < length) {\n    var value = array[index];\n    if (value) {\n      result[resIndex++] = value;\n    }\n  }\n  return result;\n}\n\nexport default compact;\n","/**\n * Gets the first element of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @alias first\n * @category Array\n * @param {Array} array The array to query.\n * @returns {*} Returns the first element of `array`.\n * @example\n *\n * _.head([1, 2, 3]);\n * // => 1\n *\n * _.head([]);\n * // => undefined\n */\nfunction head(array) {\n  return (array && array.length) ? array[0] : undefined;\n}\n\nexport default head;\n","/**\n * A specialized version of `_.reduce` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @param {*} [accumulator] The initial value.\n * @param {boolean} [initAccum] Specify using the first element of `array` as\n *  the initial value.\n * @returns {*} Returns the accumulated value.\n */\nfunction arrayReduce(array, iteratee, accumulator, initAccum) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  if (initAccum && length) {\n    accumulator = array[++index];\n  }\n  while (++index < length) {\n    accumulator = iteratee(accumulator, array[index], index, array);\n  }\n  return accumulator;\n}\n\nexport default arrayReduce;\n","/**\n * The base implementation of `_.reduce` and `_.reduceRight`, without support\n * for iteratee shorthands, which iterates over `collection` using `eachFunc`.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @param {*} accumulator The initial value.\n * @param {boolean} initAccum Specify using the first or last element of\n *  `collection` as the initial value.\n * @param {Function} eachFunc The function to iterate over `collection`.\n * @returns {*} Returns the accumulated value.\n */\nfunction baseReduce(collection, iteratee, accumulator, initAccum, eachFunc) {\n  eachFunc(collection, function(value, index, collection) {\n    accumulator = initAccum\n      ? (initAccum = false, value)\n      : iteratee(accumulator, value, index, collection);\n  });\n  return accumulator;\n}\n\nexport default baseReduce;\n","/** Error message constants. */\nvar FUNC_ERROR_TEXT = 'Expected a function';\n\n/**\n * Creates a function that negates the result of the predicate `func`. The\n * `func` predicate is invoked with the `this` binding and arguments of the\n * created function.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Function\n * @param {Function} predicate The predicate to negate.\n * @returns {Function} Returns the new negated function.\n * @example\n *\n * function isEven(n) {\n *   return n % 2 == 0;\n * }\n *\n * _.filter([1, 2, 3, 4, 5, 6], _.negate(isEven));\n * // => [1, 3, 5]\n */\nfunction negate(predicate) {\n  if (typeof predicate != 'function') {\n    throw new TypeError(FUNC_ERROR_TEXT);\n  }\n  return function() {\n    var args = arguments;\n    switch (args.length) {\n      case 0: return !predicate.call(this);\n      case 1: return !predicate.call(this, args[0]);\n      case 2: return !predicate.call(this, args[0], args[1]);\n      case 3: return !predicate.call(this, args[0], args[1], args[2]);\n    }\n    return !predicate.apply(this, args);\n  };\n}\n\nexport default negate;\n","/**\n * Gets the last element of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to query.\n * @returns {*} Returns the last element of `array`.\n * @example\n *\n * _.last([1, 2, 3]);\n * // => 3\n */\nfunction last(array) {\n  var length = array == null ? 0 : array.length;\n  return length ? array[length - 1] : undefined;\n}\n\nexport default last;\n","/**\n * A specialized version of `baseAggregator` for arrays.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} setter The function to set `accumulator` values.\n * @param {Function} iteratee The iteratee to transform keys.\n * @param {Object} accumulator The initial aggregated object.\n * @returns {Function} Returns `accumulator`.\n */\nfunction arrayAggregator(array, setter, iteratee, accumulator) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    var value = array[index];\n    setter(accumulator, value, iteratee(value), array);\n  }\n  return accumulator;\n}\n\nexport default arrayAggregator;\n","import baseFlatten from './_baseFlatten.js';\nimport map from './map.js';\n\n/**\n * Creates a flattened array of values by running each element in `collection`\n * thru `iteratee` and flattening the mapped results. The iteratee is invoked\n * with three arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new flattened array.\n * @example\n *\n * function duplicate(n) {\n *   return [n, n];\n * }\n *\n * _.flatMap([1, 2], duplicate);\n * // => [1, 1, 2, 2]\n */\nfunction flatMap(collection, iteratee) {\n  return baseFlatten(map(collection, iteratee), 1);\n}\n\nexport default flatMap;\n","import baseIteratee from './_baseIteratee.js';\nimport baseUniq from './_baseUniq.js';\n\n/**\n * This method is like `_.uniq` except that it accepts `iteratee` which is\n * invoked for each element in `array` to generate the criterion by which\n * uniqueness is computed. The order of result values is determined by the\n * order they occur in the array. The iteratee is invoked with one argument:\n * (value).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {Function} [iteratee=_.identity] The iteratee invoked per element.\n * @returns {Array} Returns the new duplicate free array.\n * @example\n *\n * _.uniqBy([2.1, 1.2, 2.3], Math.floor);\n * // => [2.1, 1.2]\n *\n * // The `_.property` iteratee shorthand.\n * _.uniqBy([{ 'x': 1 }, { 'x': 2 }, { 'x': 1 }], 'x');\n * // => [{ 'x': 1 }, { 'x': 2 }]\n */\nfunction uniqBy(array, iteratee) {\n  return (array && array.length) ? baseUniq(array, baseIteratee(iteratee, 2)) : [];\n}\n\nexport default uniqBy;\n","var __defProp = Object.defineProperty;\nvar __name = (target, value) => __defProp(target, \"name\", { value, configurable: true });\n\n// src/language/generated/ast.ts\nimport { AbstractAstReflection } from \"langium\";\nvar Statement = \"Statement\";\nvar Architecture = \"Architecture\";\nfunction isArchitecture(item) {\n  return reflection.isInstance(item, Architecture);\n}\n__name(isArchitecture, \"isArchitecture\");\nvar Axis = \"Axis\";\nvar Branch = \"Branch\";\nfunction isBranch(item) {\n  return reflection.isInstance(item, Branch);\n}\n__name(isBranch, \"isBranch\");\nvar Checkout = \"Checkout\";\nvar CherryPicking = \"CherryPicking\";\nvar ClassDefStatement = \"ClassDefStatement\";\nvar Commit = \"Commit\";\nfunction isCommit(item) {\n  return reflection.isInstance(item, Commit);\n}\n__name(isCommit, \"isCommit\");\nvar Curve = \"Curve\";\nvar Edge = \"Edge\";\nvar Entry = \"Entry\";\nvar GitGraph = \"GitGraph\";\nfunction isGitGraph(item) {\n  return reflection.isInstance(item, GitGraph);\n}\n__name(isGitGraph, \"isGitGraph\");\nvar Group = \"Group\";\nvar Info = \"Info\";\nfunction isInfo(item) {\n  return reflection.isInstance(item, Info);\n}\n__name(isInfo, \"isInfo\");\nvar Item = \"Item\";\nvar Junction = \"Junction\";\nvar Merge = \"Merge\";\nfunction isMerge(item) {\n  return reflection.isInstance(item, Merge);\n}\n__name(isMerge, \"isMerge\");\nvar Option = \"Option\";\nvar Packet = \"Packet\";\nfunction isPacket(item) {\n  return reflection.isInstance(item, Packet);\n}\n__name(isPacket, \"isPacket\");\nvar PacketBlock = \"PacketBlock\";\nfunction isPacketBlock(item) {\n  return reflection.isInstance(item, PacketBlock);\n}\n__name(isPacketBlock, \"isPacketBlock\");\nvar Pie = \"Pie\";\nfunction isPie(item) {\n  return reflection.isInstance(item, Pie);\n}\n__name(isPie, \"isPie\");\nvar PieSection = \"PieSection\";\nfunction isPieSection(item) {\n  return reflection.isInstance(item, PieSection);\n}\n__name(isPieSection, \"isPieSection\");\nvar Radar = \"Radar\";\nvar Service = \"Service\";\nvar Treemap = \"Treemap\";\nfunction isTreemap(item) {\n  return reflection.isInstance(item, Treemap);\n}\n__name(isTreemap, \"isTreemap\");\nvar TreemapRow = \"TreemapRow\";\nvar Direction = \"Direction\";\nvar Leaf = \"Leaf\";\nvar Section = \"Section\";\nvar MermaidAstReflection = class extends AbstractAstReflection {\n  static {\n    __name(this, \"MermaidAstReflection\");\n  }\n  getAllTypes() {\n    return [Architecture, Axis, Branch, Checkout, CherryPicking, ClassDefStatement, Commit, Curve, Direction, Edge, Entry, GitGraph, Group, Info, Item, Junction, Leaf, Merge, Option, Packet, PacketBlock, Pie, PieSection, Radar, Section, Service, Statement, Treemap, TreemapRow];\n  }\n  computeIsSubtype(subtype, supertype) {\n    switch (subtype) {\n      case Branch:\n      case Checkout:\n      case CherryPicking:\n      case Commit:\n      case Merge: {\n        return this.isSubtype(Statement, supertype);\n      }\n      case Direction: {\n        return this.isSubtype(GitGraph, supertype);\n      }\n      case Leaf:\n      case Section: {\n        return this.isSubtype(Item, supertype);\n      }\n      default: {\n        return false;\n      }\n    }\n  }\n  getReferenceType(refInfo) {\n    const referenceId = `${refInfo.container.$type}:${refInfo.property}`;\n    switch (referenceId) {\n      case \"Entry:axis\": {\n        return Axis;\n      }\n      default: {\n        throw new Error(`${referenceId} is not a valid reference id.`);\n      }\n    }\n  }\n  getTypeMetaData(type) {\n    switch (type) {\n      case Architecture: {\n        return {\n          name: Architecture,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"edges\", defaultValue: [] },\n            { name: \"groups\", defaultValue: [] },\n            { name: \"junctions\", defaultValue: [] },\n            { name: \"services\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Axis: {\n        return {\n          name: Axis,\n          properties: [\n            { name: \"label\" },\n            { name: \"name\" }\n          ]\n        };\n      }\n      case Branch: {\n        return {\n          name: Branch,\n          properties: [\n            { name: \"name\" },\n            { name: \"order\" }\n          ]\n        };\n      }\n      case Checkout: {\n        return {\n          name: Checkout,\n          properties: [\n            { name: \"branch\" }\n          ]\n        };\n      }\n      case CherryPicking: {\n        return {\n          name: CherryPicking,\n          properties: [\n            { name: \"id\" },\n            { name: \"parent\" },\n            { name: \"tags\", defaultValue: [] }\n          ]\n        };\n      }\n      case ClassDefStatement: {\n        return {\n          name: ClassDefStatement,\n          properties: [\n            { name: \"className\" },\n            { name: \"styleText\" }\n          ]\n        };\n      }\n      case Commit: {\n        return {\n          name: Commit,\n          properties: [\n            { name: \"id\" },\n            { name: \"message\" },\n            { name: \"tags\", defaultValue: [] },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case Curve: {\n        return {\n          name: Curve,\n          properties: [\n            { name: \"entries\", defaultValue: [] },\n            { name: \"label\" },\n            { name: \"name\" }\n          ]\n        };\n      }\n      case Edge: {\n        return {\n          name: Edge,\n          properties: [\n            { name: \"lhsDir\" },\n            { name: \"lhsGroup\", defaultValue: false },\n            { name: \"lhsId\" },\n            { name: \"lhsInto\", defaultValue: false },\n            { name: \"rhsDir\" },\n            { name: \"rhsGroup\", defaultValue: false },\n            { name: \"rhsId\" },\n            { name: \"rhsInto\", defaultValue: false },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Entry: {\n        return {\n          name: Entry,\n          properties: [\n            { name: \"axis\" },\n            { name: \"value\" }\n          ]\n        };\n      }\n      case GitGraph: {\n        return {\n          name: GitGraph,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"statements\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Group: {\n        return {\n          name: Group,\n          properties: [\n            { name: \"icon\" },\n            { name: \"id\" },\n            { name: \"in\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Info: {\n        return {\n          name: Info,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Item: {\n        return {\n          name: Item,\n          properties: [\n            { name: \"classSelector\" },\n            { name: \"name\" }\n          ]\n        };\n      }\n      case Junction: {\n        return {\n          name: Junction,\n          properties: [\n            { name: \"id\" },\n            { name: \"in\" }\n          ]\n        };\n      }\n      case Merge: {\n        return {\n          name: Merge,\n          properties: [\n            { name: \"branch\" },\n            { name: \"id\" },\n            { name: \"tags\", defaultValue: [] },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case Option: {\n        return {\n          name: Option,\n          properties: [\n            { name: \"name\" },\n            { name: \"value\", defaultValue: false }\n          ]\n        };\n      }\n      case Packet: {\n        return {\n          name: Packet,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"blocks\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case PacketBlock: {\n        return {\n          name: PacketBlock,\n          properties: [\n            { name: \"bits\" },\n            { name: \"end\" },\n            { name: \"label\" },\n            { name: \"start\" }\n          ]\n        };\n      }\n      case Pie: {\n        return {\n          name: Pie,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"sections\", defaultValue: [] },\n            { name: \"showData\", defaultValue: false },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case PieSection: {\n        return {\n          name: PieSection,\n          properties: [\n            { name: \"label\" },\n            { name: \"value\" }\n          ]\n        };\n      }\n      case Radar: {\n        return {\n          name: Radar,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"axes\", defaultValue: [] },\n            { name: \"curves\", defaultValue: [] },\n            { name: \"options\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Service: {\n        return {\n          name: Service,\n          properties: [\n            { name: \"icon\" },\n            { name: \"iconText\" },\n            { name: \"id\" },\n            { name: \"in\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Treemap: {\n        return {\n          name: Treemap,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"title\" },\n            { name: \"TreemapRows\", defaultValue: [] }\n          ]\n        };\n      }\n      case TreemapRow: {\n        return {\n          name: TreemapRow,\n          properties: [\n            { name: \"indent\" },\n            { name: \"item\" }\n          ]\n        };\n      }\n      case Direction: {\n        return {\n          name: Direction,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"dir\" },\n            { name: \"statements\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Leaf: {\n        return {\n          name: Leaf,\n          properties: [\n            { name: \"classSelector\" },\n            { name: \"name\" },\n            { name: \"value\" }\n          ]\n        };\n      }\n      case Section: {\n        return {\n          name: Section,\n          properties: [\n            { name: \"classSelector\" },\n            { name: \"name\" }\n          ]\n        };\n      }\n      default: {\n        return {\n          name: type,\n          properties: []\n        };\n      }\n    }\n  }\n};\nvar reflection = new MermaidAstReflection();\n\n// src/language/generated/grammar.ts\nimport { loadGrammarFromJson } from \"langium\";\nvar loadedInfoGrammar;\nvar InfoGrammar = /* @__PURE__ */ __name(() => loadedInfoGrammar ?? (loadedInfoGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Info\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Info\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"info\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"showInfo\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[],\"cardinality\":\"*\"}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"?\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"}},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[],\"types\":[],\"usedGrammars\":[]}`)), \"InfoGrammar\");\nvar loadedPacketGrammar;\nvar PacketGrammar = /* @__PURE__ */ __name(() => loadedPacketGrammar ?? (loadedPacketGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Packet\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Packet\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"packet\"},{\"$type\":\"Keyword\",\"value\":\"packet-beta\"}]},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"blocks\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}],\"cardinality\":\"*\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"PacketBlock\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"start\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"-\"},{\"$type\":\"Assignment\",\"feature\":\"end\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}],\"cardinality\":\"?\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"+\"},{\"$type\":\"Assignment\",\"feature\":\"bits\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]}]},{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"}},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[],\"types\":[],\"usedGrammars\":[]}`)), \"PacketGrammar\");\nvar loadedPieGrammar;\nvar PieGrammar = /* @__PURE__ */ __name(() => loadedPieGrammar ?? (loadedPieGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Pie\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Pie\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"pie\"},{\"$type\":\"Assignment\",\"feature\":\"showData\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"showData\"},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"sections\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}],\"cardinality\":\"*\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"PieSection\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT_PIE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/-?[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT_PIE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/-?(0|[1-9][0-9]*)(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER_PIE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"}},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"}},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[],\"types\":[],\"usedGrammars\":[]}`)), \"PieGrammar\");\nvar loadedArchitectureGrammar;\nvar ArchitectureGrammar = /* @__PURE__ */ __name(() => loadedArchitectureGrammar ?? (loadedArchitectureGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Architecture\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Architecture\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"architecture-beta\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}],\"cardinality\":\"*\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Statement\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"groups\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"services\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"junctions\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"edges\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"LeftPort\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"lhsDir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"RightPort\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"rhsDir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\":\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Arrow\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"lhsInto\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"--\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"-\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@29\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\"-\"}]}]},{\"$type\":\"Assignment\",\"feature\":\"rhsInto\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Group\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"group\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"icon\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@28\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@29\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Service\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"service\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"iconText\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"icon\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@28\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@29\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Junction\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"junction\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Edge\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"lhsId\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"lhsGroup\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"rhsId\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"rhsGroup\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_DIRECTION\",\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"L\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"R\"}}]},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"T\"}}]},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"B\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_GROUP\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\{group\\\\\\\\}/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_INTO\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/<|>/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"}},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_ICON\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\([\\\\\\\\w-:]+\\\\\\\\)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\[[\\\\\\\\w ]+\\\\\\\\]/\"},\"fragment\":false,\"hidden\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[],\"types\":[],\"usedGrammars\":[]}`)), \"ArchitectureGrammar\");\nvar loadedGitGraphGrammar;\nvar GitGraphGrammar = /* @__PURE__ */ __name(() => loadedGitGraphGrammar ?? (loadedGitGraphGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"GitGraph\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"GitGraph\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"Keyword\",\"value\":\":\"}]},{\"$type\":\"Keyword\",\"value\":\"gitGraph:\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]},{\"$type\":\"Keyword\",\"value\":\":\"}]}]},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"statements\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Statement\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Direction\",\"definition\":{\"$type\":\"Assignment\",\"feature\":\"dir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"LR\"},{\"$type\":\"Keyword\",\"value\":\"TB\"},{\"$type\":\"Keyword\",\"value\":\"BT\"}]}},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Commit\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"commit\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"msg:\",\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"message\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"type:\"},{\"$type\":\"Assignment\",\"feature\":\"type\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"NORMAL\"},{\"$type\":\"Keyword\",\"value\":\"REVERSE\"},{\"$type\":\"Keyword\",\"value\":\"HIGHLIGHT\"}]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Branch\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"branch\"},{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@24\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"order:\"},{\"$type\":\"Assignment\",\"feature\":\"order\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Merge\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"merge\"},{\"$type\":\"Assignment\",\"feature\":\"branch\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@24\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]}},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"type:\"},{\"$type\":\"Assignment\",\"feature\":\"type\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"NORMAL\"},{\"$type\":\"Keyword\",\"value\":\"REVERSE\"},{\"$type\":\"Keyword\",\"value\":\"HIGHLIGHT\"}]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Checkout\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"checkout\"},{\"$type\":\"Keyword\",\"value\":\"switch\"}]},{\"$type\":\"Assignment\",\"feature\":\"branch\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@24\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"CherryPicking\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"cherry-pick\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"parent:\"},{\"$type\":\"Assignment\",\"feature\":\"parent\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"}},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"name\":\"REFERENCE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\w([-\\\\\\\\./\\\\\\\\w]*[-\\\\\\\\w])?/\"},\"fragment\":false,\"hidden\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[],\"types\":[],\"usedGrammars\":[]}`)), \"GitGraphGrammar\");\nvar loadedRadarGrammar;\nvar RadarGrammar = /* @__PURE__ */ __name(() => loadedRadarGrammar ?? (loadedRadarGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Radar\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Radar\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"radar-beta\"},{\"$type\":\"Keyword\",\"value\":\"radar-beta:\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"radar-beta\"},{\"$type\":\"Keyword\",\"value\":\":\"}]}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"axis\"},{\"$type\":\"Assignment\",\"feature\":\"axes\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"axes\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"curve\"},{\"$type\":\"Assignment\",\"feature\":\"curves\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"curves\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"options\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"options\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}],\"cardinality\":\"*\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Label\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"[\"},{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\"]\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Axis\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[],\"cardinality\":\"?\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Curve\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[],\"cardinality\":\"?\"},{\"$type\":\"Keyword\",\"value\":\"{\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Keyword\",\"value\":\"}\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Entries\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"DetailedEntry\",\"returnType\":{\"$ref\":\"#/interfaces@0\"},\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"axis\",\"operator\":\"=\",\"terminal\":{\"$type\":\"CrossReference\",\"type\":{\"$ref\":\"#/rules@2\"},\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},\"deprecatedSyntax\":false}},{\"$type\":\"Keyword\",\"value\":\":\",\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"NumberEntry\",\"returnType\":{\"$ref\":\"#/interfaces@0\"},\"definition\":{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Option\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"showLegend\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"ticks\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"max\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"min\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"graticule\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}}]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"GRATICULE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"circle\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"polygon\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"}},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Entry\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"axis\",\"isOptional\":true,\"type\":{\"$type\":\"ReferenceType\",\"referenceType\":{\"$type\":\"SimpleType\",\"typeRef\":{\"$ref\":\"#/rules@2\"}}}},{\"$type\":\"TypeAttribute\",\"name\":\"value\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"number\"},\"isOptional\":false}],\"superTypes\":[]}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"types\":[],\"usedGrammars\":[]}`)), \"RadarGrammar\");\nvar loadedTreemapGrammar;\nvar TreemapGrammar = /* @__PURE__ */ __name(() => loadedTreemapGrammar ?? (loadedTreemapGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Treemap\",\"rules\":[{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Treemap\",\"returnType\":{\"$ref\":\"#/interfaces@4\"},\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@0\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"TreemapRows\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"TREEMAP_KEYWORD\",\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"treemap-beta\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"treemap\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"CLASS_DEF\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/classDef\\\\\\\\s+([a-zA-Z_][a-zA-Z0-9_]+)(?:\\\\\\\\s+([^;\\\\\\\\r\\\\\\\\n]*))?(?:;)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STYLE_SEPARATOR\",\"definition\":{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\":::\"}},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"SEPARATOR\",\"definition\":{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\":\"}},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"COMMA\",\"definition\":{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\",\"}},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WS\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[ \\\\\\\\t]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"ML_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\%\\\\\\\\%[^\\\\\\\\n]*/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"NL\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false},{\"$type\":\"ParserRule\",\"name\":\"TreemapRow\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"indent\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"item\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]}]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"ClassDef\",\"dataType\":\"string\",\"definition\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Item\",\"returnType\":{\"$ref\":\"#/interfaces@0\"},\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Section\",\"returnType\":{\"$ref\":\"#/interfaces@1\"},\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"classSelector\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}],\"cardinality\":\"?\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Leaf\",\"returnType\":{\"$ref\":\"#/interfaces@2\"},\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[],\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[],\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"classSelector\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}],\"cardinality\":\"?\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"INDENTATION\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[ \\\\\\\\t]{1,}/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID2\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[a-zA-Z_][a-zA-Z0-9_]*/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER2\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9_\\\\\\\\.\\\\\\\\,]+/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"name\":\"MyNumber\",\"dataType\":\"number\",\"definition\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING2\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"[^\\\\\"]*\\\\\"|'[^']*'/\"},\"fragment\":false,\"hidden\":false}],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Item\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"name\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"},\"isOptional\":false},{\"$type\":\"TypeAttribute\",\"name\":\"classSelector\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]},{\"$type\":\"Interface\",\"name\":\"Section\",\"superTypes\":[{\"$ref\":\"#/interfaces@0\"}],\"attributes\":[]},{\"$type\":\"Interface\",\"name\":\"Leaf\",\"superTypes\":[{\"$ref\":\"#/interfaces@0\"}],\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"value\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"number\"},\"isOptional\":false}]},{\"$type\":\"Interface\",\"name\":\"ClassDefStatement\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"className\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"},\"isOptional\":false},{\"$type\":\"TypeAttribute\",\"name\":\"styleText\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"},\"isOptional\":false}],\"superTypes\":[]},{\"$type\":\"Interface\",\"name\":\"Treemap\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"TreemapRows\",\"type\":{\"$type\":\"ArrayType\",\"elementType\":{\"$type\":\"SimpleType\",\"typeRef\":{\"$ref\":\"#/rules@14\"}}},\"isOptional\":false},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"imports\":[],\"types\":[],\"usedGrammars\":[],\"$comment\":\"/**\\\\n * Treemap grammar for Langium\\\\n * Converted from mindmap grammar\\\\n *\\\\n * The ML_COMMENT and NL hidden terminals handle whitespace, comments, and newlines\\\\n * before the treemap keyword, allowing for empty lines and comments before the\\\\n * treemap declaration.\\\\n */\"}`)), \"TreemapGrammar\");\n\n// src/language/generated/module.ts\nvar InfoLanguageMetaData = {\n  languageId: \"info\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar PacketLanguageMetaData = {\n  languageId: \"packet\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar PieLanguageMetaData = {\n  languageId: \"pie\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar ArchitectureLanguageMetaData = {\n  languageId: \"architecture\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar GitGraphLanguageMetaData = {\n  languageId: \"gitGraph\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar RadarLanguageMetaData = {\n  languageId: \"radar\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar TreemapLanguageMetaData = {\n  languageId: \"treemap\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar MermaidGeneratedSharedModule = {\n  AstReflection: /* @__PURE__ */ __name(() => new MermaidAstReflection(), \"AstReflection\")\n};\nvar InfoGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => InfoGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => InfoLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar PacketGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => PacketGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => PacketLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar PieGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => PieGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => PieLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar ArchitectureGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => ArchitectureGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => ArchitectureLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar GitGraphGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => GitGraphGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => GitGraphLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar RadarGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => RadarGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => RadarLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar TreemapGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => TreemapGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => TreemapLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\n\n// src/language/common/valueConverter.ts\nimport { DefaultValueConverter } from \"langium\";\n\n// src/language/common/matcher.ts\nvar accessibilityDescrRegex = /accDescr(?:[\\t ]*:([^\\n\\r]*)|\\s*{([^}]*)})/;\nvar accessibilityTitleRegex = /accTitle[\\t ]*:([^\\n\\r]*)/;\nvar titleRegex = /title([\\t ][^\\n\\r]*|)/;\n\n// src/language/common/valueConverter.ts\nvar rulesRegexes = {\n  ACC_DESCR: accessibilityDescrRegex,\n  ACC_TITLE: accessibilityTitleRegex,\n  TITLE: titleRegex\n};\nvar AbstractMermaidValueConverter = class extends DefaultValueConverter {\n  static {\n    __name(this, \"AbstractMermaidValueConverter\");\n  }\n  runConverter(rule, input, cstNode) {\n    let value = this.runCommonConverter(rule, input, cstNode);\n    if (value === void 0) {\n      value = this.runCustomConverter(rule, input, cstNode);\n    }\n    if (value === void 0) {\n      return super.runConverter(rule, input, cstNode);\n    }\n    return value;\n  }\n  runCommonConverter(rule, input, _cstNode) {\n    const regex = rulesRegexes[rule.name];\n    if (regex === void 0) {\n      return void 0;\n    }\n    const match = regex.exec(input);\n    if (match === null) {\n      return void 0;\n    }\n    if (match[1] !== void 0) {\n      return match[1].trim().replace(/[\\t ]{2,}/gm, \" \");\n    }\n    if (match[2] !== void 0) {\n      return match[2].replace(/^\\s*/gm, \"\").replace(/\\s+$/gm, \"\").replace(/[\\t ]{2,}/gm, \" \").replace(/[\\n\\r]{2,}/gm, \"\\n\");\n    }\n    return void 0;\n  }\n};\nvar CommonValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"CommonValueConverter\");\n  }\n  runCustomConverter(_rule, _input, _cstNode) {\n    return void 0;\n  }\n};\n\n// src/language/common/tokenBuilder.ts\nimport { DefaultTokenBuilder } from \"langium\";\nvar AbstractMermaidTokenBuilder = class extends DefaultTokenBuilder {\n  static {\n    __name(this, \"AbstractMermaidTokenBuilder\");\n  }\n  constructor(keywords) {\n    super();\n    this.keywords = new Set(keywords);\n  }\n  buildKeywordTokens(rules, terminalTokens, options) {\n    const tokenTypes = super.buildKeywordTokens(rules, terminalTokens, options);\n    tokenTypes.forEach((tokenType) => {\n      if (this.keywords.has(tokenType.name) && tokenType.PATTERN !== void 0) {\n        tokenType.PATTERN = new RegExp(tokenType.PATTERN.toString() + \"(?:(?=%%)|(?!\\\\S))\");\n      }\n    });\n    return tokenTypes;\n  }\n};\nvar CommonTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"CommonTokenBuilder\");\n  }\n};\n\nexport {\n  __name,\n  Statement,\n  Architecture,\n  isArchitecture,\n  Branch,\n  isBranch,\n  Commit,\n  isCommit,\n  GitGraph,\n  isGitGraph,\n  Info,\n  isInfo,\n  Merge,\n  isMerge,\n  Packet,\n  isPacket,\n  PacketBlock,\n  isPacketBlock,\n  Pie,\n  isPie,\n  PieSection,\n  isPieSection,\n  Radar,\n  Treemap,\n  isTreemap,\n  MermaidGeneratedSharedModule,\n  InfoGeneratedModule,\n  PacketGeneratedModule,\n  PieGeneratedModule,\n  ArchitectureGeneratedModule,\n  GitGraphGeneratedModule,\n  RadarGeneratedModule,\n  TreemapGeneratedModule,\n  AbstractMermaidValueConverter,\n  CommonValueConverter,\n  AbstractMermaidTokenBuilder,\n  CommonTokenBuilder\n};\n","/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof global == 'object' && global && global.Object === Object && global;\n\nexport default freeGlobal;\n","export function timer<T>(func: () => T): { time: number; value: T } {\n  const start = new Date().getTime();\n  const val = func();\n  const end = new Date().getTime();\n  const total = end - start;\n  return { time: total, value: val };\n}\n","// 'path' module extracted from Node.js v8.11.1 (only the posix part)\n// transplited with Babel\n\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\nfunction assertPath(path) {\n  if (typeof path !== 'string') {\n    throw new TypeError('Path must be a string. Received ' + JSON.stringify(path));\n  }\n}\n\n// Resolves . and .. elements in a path with directory names\nfunction normalizeStringPosix(path, allowAboveRoot) {\n  var res = '';\n  var lastSegmentLength = 0;\n  var lastSlash = -1;\n  var dots = 0;\n  var code;\n  for (var i = 0; i <= path.length; ++i) {\n    if (i < path.length)\n      code = path.charCodeAt(i);\n    else if (code === 47 /*/*/)\n      break;\n    else\n      code = 47 /*/*/;\n    if (code === 47 /*/*/) {\n      if (lastSlash === i - 1 || dots === 1) {\n        // NOOP\n      } else if (lastSlash !== i - 1 && dots === 2) {\n        if (res.length < 2 || lastSegmentLength !== 2 || res.charCodeAt(res.length - 1) !== 46 /*.*/ || res.charCodeAt(res.length - 2) !== 46 /*.*/) {\n          if (res.length > 2) {\n            var lastSlashIndex = res.lastIndexOf('/');\n            if (lastSlashIndex !== res.length - 1) {\n              if (lastSlashIndex === -1) {\n                res = '';\n                lastSegmentLength = 0;\n              } else {\n                res = res.slice(0, lastSlashIndex);\n                lastSegmentLength = res.length - 1 - res.lastIndexOf('/');\n              }\n              lastSlash = i;\n              dots = 0;\n              continue;\n            }\n          } else if (res.length === 2 || res.length === 1) {\n            res = '';\n            lastSegmentLength = 0;\n            lastSlash = i;\n            dots = 0;\n            continue;\n          }\n        }\n        if (allowAboveRoot) {\n          if (res.length > 0)\n            res += '/..';\n          else\n            res = '..';\n          lastSegmentLength = 2;\n        }\n      } else {\n        if (res.length > 0)\n          res += '/' + path.slice(lastSlash + 1, i);\n        else\n          res = path.slice(lastSlash + 1, i);\n        lastSegmentLength = i - lastSlash - 1;\n      }\n      lastSlash = i;\n      dots = 0;\n    } else if (code === 46 /*.*/ && dots !== -1) {\n      ++dots;\n    } else {\n      dots = -1;\n    }\n  }\n  return res;\n}\n\nfunction _format(sep, pathObject) {\n  var dir = pathObject.dir || pathObject.root;\n  var base = pathObject.base || (pathObject.name || '') + (pathObject.ext || '');\n  if (!dir) {\n    return base;\n  }\n  if (dir === pathObject.root) {\n    return dir + base;\n  }\n  return dir + sep + base;\n}\n\nvar posix = {\n  // path.resolve([from ...], to)\n  resolve: function resolve() {\n    var resolvedPath = '';\n    var resolvedAbsolute = false;\n    var cwd;\n\n    for (var i = arguments.length - 1; i >= -1 && !resolvedAbsolute; i--) {\n      var path;\n      if (i >= 0)\n        path = arguments[i];\n      else {\n        if (cwd === undefined)\n          cwd = process.cwd();\n        path = cwd;\n      }\n\n      assertPath(path);\n\n      // Skip empty entries\n      if (path.length === 0) {\n        continue;\n      }\n\n      resolvedPath = path + '/' + resolvedPath;\n      resolvedAbsolute = path.charCodeAt(0) === 47 /*/*/;\n    }\n\n    // At this point the path should be resolved to a full absolute path, but\n    // handle relative paths to be safe (might happen when process.cwd() fails)\n\n    // Normalize the path\n    resolvedPath = normalizeStringPosix(resolvedPath, !resolvedAbsolute);\n\n    if (resolvedAbsolute) {\n      if (resolvedPath.length > 0)\n        return '/' + resolvedPath;\n      else\n        return '/';\n    } else if (resolvedPath.length > 0) {\n      return resolvedPath;\n    } else {\n      return '.';\n    }\n  },\n\n  normalize: function normalize(path) {\n    assertPath(path);\n\n    if (path.length === 0) return '.';\n\n    var isAbsolute = path.charCodeAt(0) === 47 /*/*/;\n    var trailingSeparator = path.charCodeAt(path.length - 1) === 47 /*/*/;\n\n    // Normalize the path\n    path = normalizeStringPosix(path, !isAbsolute);\n\n    if (path.length === 0 && !isAbsolute) path = '.';\n    if (path.length > 0 && trailingSeparator) path += '/';\n\n    if (isAbsolute) return '/' + path;\n    return path;\n  },\n\n  isAbsolute: function isAbsolute(path) {\n    assertPath(path);\n    return path.length > 0 && path.charCodeAt(0) === 47 /*/*/;\n  },\n\n  join: function join() {\n    if (arguments.length === 0)\n      return '.';\n    var joined;\n    for (var i = 0; i < arguments.length; ++i) {\n      var arg = arguments[i];\n      assertPath(arg);\n      if (arg.length > 0) {\n        if (joined === undefined)\n          joined = arg;\n        else\n          joined += '/' + arg;\n      }\n    }\n    if (joined === undefined)\n      return '.';\n    return posix.normalize(joined);\n  },\n\n  relative: function relative(from, to) {\n    assertPath(from);\n    assertPath(to);\n\n    if (from === to) return '';\n\n    from = posix.resolve(from);\n    to = posix.resolve(to);\n\n    if (from === to) return '';\n\n    // Trim any leading backslashes\n    var fromStart = 1;\n    for (; fromStart < from.length; ++fromStart) {\n      if (from.charCodeAt(fromStart) !== 47 /*/*/)\n        break;\n    }\n    var fromEnd = from.length;\n    var fromLen = fromEnd - fromStart;\n\n    // Trim any leading backslashes\n    var toStart = 1;\n    for (; toStart < to.length; ++toStart) {\n      if (to.charCodeAt(toStart) !== 47 /*/*/)\n        break;\n    }\n    var toEnd = to.length;\n    var toLen = toEnd - toStart;\n\n    // Compare paths to find the longest common path from root\n    var length = fromLen < toLen ? fromLen : toLen;\n    var lastCommonSep = -1;\n    var i = 0;\n    for (; i <= length; ++i) {\n      if (i === length) {\n        if (toLen > length) {\n          if (to.charCodeAt(toStart + i) === 47 /*/*/) {\n            // We get here if `from` is the exact base path for `to`.\n            // For example: from='/foo/bar'; to='/foo/bar/baz'\n            return to.slice(toStart + i + 1);\n          } else if (i === 0) {\n            // We get here if `from` is the root\n            // For example: from='/'; to='/foo'\n            return to.slice(toStart + i);\n          }\n        } else if (fromLen > length) {\n          if (from.charCodeAt(fromStart + i) === 47 /*/*/) {\n            // We get here if `to` is the exact base path for `from`.\n            // For example: from='/foo/bar/baz'; to='/foo/bar'\n            lastCommonSep = i;\n          } else if (i === 0) {\n            // We get here if `to` is the root.\n            // For example: from='/foo'; to='/'\n            lastCommonSep = 0;\n          }\n        }\n        break;\n      }\n      var fromCode = from.charCodeAt(fromStart + i);\n      var toCode = to.charCodeAt(toStart + i);\n      if (fromCode !== toCode)\n        break;\n      else if (fromCode === 47 /*/*/)\n        lastCommonSep = i;\n    }\n\n    var out = '';\n    // Generate the relative path based on the path difference between `to`\n    // and `from`\n    for (i = fromStart + lastCommonSep + 1; i <= fromEnd; ++i) {\n      if (i === fromEnd || from.charCodeAt(i) === 47 /*/*/) {\n        if (out.length === 0)\n          out += '..';\n        else\n          out += '/..';\n      }\n    }\n\n    // Lastly, append the rest of the destination (`to`) path that comes after\n    // the common path parts\n    if (out.length > 0)\n      return out + to.slice(toStart + lastCommonSep);\n    else {\n      toStart += lastCommonSep;\n      if (to.charCodeAt(toStart) === 47 /*/*/)\n        ++toStart;\n      return to.slice(toStart);\n    }\n  },\n\n  _makeLong: function _makeLong(path) {\n    return path;\n  },\n\n  dirname: function dirname(path) {\n    assertPath(path);\n    if (path.length === 0) return '.';\n    var code = path.charCodeAt(0);\n    var hasRoot = code === 47 /*/*/;\n    var end = -1;\n    var matchedSlash = true;\n    for (var i = path.length - 1; i >= 1; --i) {\n      code = path.charCodeAt(i);\n      if (code === 47 /*/*/) {\n          if (!matchedSlash) {\n            end = i;\n            break;\n          }\n        } else {\n        // We saw the first non-path separator\n        matchedSlash = false;\n      }\n    }\n\n    if (end === -1) return hasRoot ? '/' : '.';\n    if (hasRoot && end === 1) return '//';\n    return path.slice(0, end);\n  },\n\n  basename: function basename(path, ext) {\n    if (ext !== undefined && typeof ext !== 'string') throw new TypeError('\"ext\" argument must be a string');\n    assertPath(path);\n\n    var start = 0;\n    var end = -1;\n    var matchedSlash = true;\n    var i;\n\n    if (ext !== undefined && ext.length > 0 && ext.length <= path.length) {\n      if (ext.length === path.length && ext === path) return '';\n      var extIdx = ext.length - 1;\n      var firstNonSlashEnd = -1;\n      for (i = path.length - 1; i >= 0; --i) {\n        var code = path.charCodeAt(i);\n        if (code === 47 /*/*/) {\n            // If we reached a path separator that was not part of a set of path\n            // separators at the end of the string, stop now\n            if (!matchedSlash) {\n              start = i + 1;\n              break;\n            }\n          } else {\n          if (firstNonSlashEnd === -1) {\n            // We saw the first non-path separator, remember this index in case\n            // we need it if the extension ends up not matching\n            matchedSlash = false;\n            firstNonSlashEnd = i + 1;\n          }\n          if (extIdx >= 0) {\n            // Try to match the explicit extension\n            if (code === ext.charCodeAt(extIdx)) {\n              if (--extIdx === -1) {\n                // We matched the extension, so mark this as the end of our path\n                // component\n                end = i;\n              }\n            } else {\n              // Extension does not match, so our result is the entire path\n              // component\n              extIdx = -1;\n              end = firstNonSlashEnd;\n            }\n          }\n        }\n      }\n\n      if (start === end) end = firstNonSlashEnd;else if (end === -1) end = path.length;\n      return path.slice(start, end);\n    } else {\n      for (i = path.length - 1; i >= 0; --i) {\n        if (path.charCodeAt(i) === 47 /*/*/) {\n            // If we reached a path separator that was not part of a set of path\n            // separators at the end of the string, stop now\n            if (!matchedSlash) {\n              start = i + 1;\n              break;\n            }\n          } else if (end === -1) {\n          // We saw the first non-path separator, mark this as the end of our\n          // path component\n          matchedSlash = false;\n          end = i + 1;\n        }\n      }\n\n      if (end === -1) return '';\n      return path.slice(start, end);\n    }\n  },\n\n  extname: function extname(path) {\n    assertPath(path);\n    var startDot = -1;\n    var startPart = 0;\n    var end = -1;\n    var matchedSlash = true;\n    // Track the state of characters (if any) we see before our first dot and\n    // after any path separator we find\n    var preDotState = 0;\n    for (var i = path.length - 1; i >= 0; --i) {\n      var code = path.charCodeAt(i);\n      if (code === 47 /*/*/) {\n          // If we reached a path separator that was not part of a set of path\n          // separators at the end of the string, stop now\n          if (!matchedSlash) {\n            startPart = i + 1;\n            break;\n          }\n          continue;\n        }\n      if (end === -1) {\n        // We saw the first non-path separator, mark this as the end of our\n        // extension\n        matchedSlash = false;\n        end = i + 1;\n      }\n      if (code === 46 /*.*/) {\n          // If this is our first dot, mark it as the start of our extension\n          if (startDot === -1)\n            startDot = i;\n          else if (preDotState !== 1)\n            preDotState = 1;\n      } else if (startDot !== -1) {\n        // We saw a non-dot and non-path separator before our dot, so we should\n        // have a good chance at having a non-empty extension\n        preDotState = -1;\n      }\n    }\n\n    if (startDot === -1 || end === -1 ||\n        // We saw a non-dot character immediately before the dot\n        preDotState === 0 ||\n        // The (right-most) trimmed path component is exactly '..'\n        preDotState === 1 && startDot === end - 1 && startDot === startPart + 1) {\n      return '';\n    }\n    return path.slice(startDot, end);\n  },\n\n  format: function format(pathObject) {\n    if (pathObject === null || typeof pathObject !== 'object') {\n      throw new TypeError('The \"pathObject\" argument must be of type Object. Received type ' + typeof pathObject);\n    }\n    return _format('/', pathObject);\n  },\n\n  parse: function parse(path) {\n    assertPath(path);\n\n    var ret = { root: '', dir: '', base: '', ext: '', name: '' };\n    if (path.length === 0) return ret;\n    var code = path.charCodeAt(0);\n    var isAbsolute = code === 47 /*/*/;\n    var start;\n    if (isAbsolute) {\n      ret.root = '/';\n      start = 1;\n    } else {\n      start = 0;\n    }\n    var startDot = -1;\n    var startPart = 0;\n    var end = -1;\n    var matchedSlash = true;\n    var i = path.length - 1;\n\n    // Track the state of characters (if any) we see before our first dot and\n    // after any path separator we find\n    var preDotState = 0;\n\n    // Get non-dir info\n    for (; i >= start; --i) {\n      code = path.charCodeAt(i);\n      if (code === 47 /*/*/) {\n          // If we reached a path separator that was not part of a set of path\n          // separators at the end of the string, stop now\n          if (!matchedSlash) {\n            startPart = i + 1;\n            break;\n          }\n          continue;\n        }\n      if (end === -1) {\n        // We saw the first non-path separator, mark this as the end of our\n        // extension\n        matchedSlash = false;\n        end = i + 1;\n      }\n      if (code === 46 /*.*/) {\n          // If this is our first dot, mark it as the start of our extension\n          if (startDot === -1) startDot = i;else if (preDotState !== 1) preDotState = 1;\n        } else if (startDot !== -1) {\n        // We saw a non-dot and non-path separator before our dot, so we should\n        // have a good chance at having a non-empty extension\n        preDotState = -1;\n      }\n    }\n\n    if (startDot === -1 || end === -1 ||\n    // We saw a non-dot character immediately before the dot\n    preDotState === 0 ||\n    // The (right-most) trimmed path component is exactly '..'\n    preDotState === 1 && startDot === end - 1 && startDot === startPart + 1) {\n      if (end !== -1) {\n        if (startPart === 0 && isAbsolute) ret.base = ret.name = path.slice(1, end);else ret.base = ret.name = path.slice(startPart, end);\n      }\n    } else {\n      if (startPart === 0 && isAbsolute) {\n        ret.name = path.slice(1, startDot);\n        ret.base = path.slice(1, end);\n      } else {\n        ret.name = path.slice(startPart, startDot);\n        ret.base = path.slice(startPart, end);\n      }\n      ret.ext = path.slice(startDot, end);\n    }\n\n    if (startPart > 0) ret.dir = path.slice(0, startPart - 1);else if (isAbsolute) ret.dir = '/';\n\n    return ret;\n  },\n\n  sep: '/',\n  delimiter: ':',\n  win32: null,\n  posix: null\n};\n\nposix.posix = posix;\n\nmodule.exports = posix;\n","import {\n  clone,\n  compact,\n  difference,\n  drop,\n  dropRight,\n  filter,\n  first,\n  flatMap,\n  flatten,\n  forEach,\n  groupBy,\n  includes,\n  isEmpty,\n  map,\n  pickBy,\n  reduce,\n  reject,\n  values,\n} from \"lodash-es\";\nimport {\n  IParserAmbiguousAlternativesDefinitionError,\n  IParserDuplicatesDefinitionError,\n  IParserEmptyAlternativeDefinitionError,\n  ParserDefinitionErrorType,\n} from \"../parser/parser.js\";\nimport {\n  Alternation,\n  Alternative as AlternativeGAST,\n  GAstVisitor,\n  getProductionDslName,\n  isOptionalProd,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport {\n  Alternative,\n  containsPath,\n  getLookaheadPathsForOptionalProd,\n  getLookaheadPathsForOr,\n  getProdType,\n  isStrictPrefixOfPath,\n} from \"./lookahead.js\";\nimport { nextPossibleTokensAfter } from \"./interpreter.js\";\nimport {\n  ILookaheadStrategy,\n  IProduction,\n  IProductionWithOccurrence,\n  Rule,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  IGrammarValidatorErrorMessageProvider,\n  IParserDefinitionError,\n} from \"./types.js\";\nimport { tokenStructuredMatcher } from \"../../scan/tokens.js\";\n\nexport function validateLookahead(options: {\n  lookaheadStrategy: ILookaheadStrategy;\n  rules: Rule[];\n  tokenTypes: TokenType[];\n  grammarName: string;\n}): IParserDefinitionError[] {\n  const lookaheadValidationErrorMessages = options.lookaheadStrategy.validate({\n    rules: options.rules,\n    tokenTypes: options.tokenTypes,\n    grammarName: options.grammarName,\n  });\n  return map(lookaheadValidationErrorMessages, (errorMessage) => ({\n    type: ParserDefinitionErrorType.CUSTOM_LOOKAHEAD_VALIDATION,\n    ...errorMessage,\n  }));\n}\n\nexport function validateGrammar(\n  topLevels: Rule[],\n  tokenTypes: TokenType[],\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n  grammarName: string,\n): IParserDefinitionError[] {\n  const duplicateErrors: IParserDefinitionError[] = flatMap(\n    topLevels,\n    (currTopLevel) =>\n      validateDuplicateProductions(currTopLevel, errMsgProvider),\n  );\n\n  const termsNamespaceConflictErrors = checkTerminalAndNoneTerminalsNameSpace(\n    topLevels,\n    tokenTypes,\n    errMsgProvider,\n  );\n\n  const tooManyAltsErrors = flatMap(topLevels, (curRule) =>\n    validateTooManyAlts(curRule, errMsgProvider),\n  );\n\n  const duplicateRulesError = flatMap(topLevels, (curRule) =>\n    validateRuleDoesNotAlreadyExist(\n      curRule,\n      topLevels,\n      grammarName,\n      errMsgProvider,\n    ),\n  );\n\n  return duplicateErrors.concat(\n    termsNamespaceConflictErrors,\n    tooManyAltsErrors,\n    duplicateRulesError,\n  );\n}\n\nfunction validateDuplicateProductions(\n  topLevelRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDuplicatesDefinitionError[] {\n  const collectorVisitor = new OccurrenceValidationCollector();\n  topLevelRule.accept(collectorVisitor);\n  const allRuleProductions = collectorVisitor.allProductions;\n\n  const productionGroups = groupBy(\n    allRuleProductions,\n    identifyProductionForDuplicates,\n  );\n\n  const duplicates: any = pickBy(productionGroups, (currGroup) => {\n    return currGroup.length > 1;\n  });\n\n  const errors = map(values(duplicates), (currDuplicates: any) => {\n    const firstProd: any = first(currDuplicates);\n    const msg = errMsgProvider.buildDuplicateFoundError(\n      topLevelRule,\n      currDuplicates,\n    );\n    const dslName = getProductionDslName(firstProd);\n    const defError: IParserDuplicatesDefinitionError = {\n      message: msg,\n      type: ParserDefinitionErrorType.DUPLICATE_PRODUCTIONS,\n      ruleName: topLevelRule.name,\n      dslName: dslName,\n      occurrence: firstProd.idx,\n    };\n\n    const param = getExtraProductionArgument(firstProd);\n    if (param) {\n      defError.parameter = param;\n    }\n\n    return defError;\n  });\n  return errors;\n}\n\nexport function identifyProductionForDuplicates(\n  prod: IProductionWithOccurrence,\n): string {\n  return `${getProductionDslName(prod)}_#_${\n    prod.idx\n  }_#_${getExtraProductionArgument(prod)}`;\n}\n\nfunction getExtraProductionArgument(prod: IProductionWithOccurrence): string {\n  if (prod instanceof Terminal) {\n    return prod.terminalType.name;\n  } else if (prod instanceof NonTerminal) {\n    return prod.nonTerminalName;\n  } else {\n    return \"\";\n  }\n}\n\nexport class OccurrenceValidationCollector extends GAstVisitor {\n  public allProductions: IProductionWithOccurrence[] = [];\n\n  public visitNonTerminal(subrule: NonTerminal): void {\n    this.allProductions.push(subrule);\n  }\n\n  public visitOption(option: Option): void {\n    this.allProductions.push(option);\n  }\n\n  public visitRepetitionWithSeparator(manySep: RepetitionWithSeparator): void {\n    this.allProductions.push(manySep);\n  }\n\n  public visitRepetitionMandatory(atLeastOne: RepetitionMandatory): void {\n    this.allProductions.push(atLeastOne);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    atLeastOneSep: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.allProductions.push(atLeastOneSep);\n  }\n\n  public visitRepetition(many: Repetition): void {\n    this.allProductions.push(many);\n  }\n\n  public visitAlternation(or: Alternation): void {\n    this.allProductions.push(or);\n  }\n\n  public visitTerminal(terminal: Terminal): void {\n    this.allProductions.push(terminal);\n  }\n}\n\nexport function validateRuleDoesNotAlreadyExist(\n  rule: Rule,\n  allRules: Rule[],\n  className: string,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const errors = [];\n  const occurrences = reduce(\n    allRules,\n    (result, curRule) => {\n      if (curRule.name === rule.name) {\n        return result + 1;\n      }\n      return result;\n    },\n    0,\n  );\n  if (occurrences > 1) {\n    const errMsg = errMsgProvider.buildDuplicateRuleNameError({\n      topLevelRule: rule,\n      grammarName: className,\n    });\n    errors.push({\n      message: errMsg,\n      type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n      ruleName: rule.name,\n    });\n  }\n\n  return errors;\n}\n\n// TODO: is there anyway to get only the rule names of rules inherited from the super grammars?\n// This is not part of the IGrammarErrorProvider because the validation cannot be performed on\n// The grammar structure, only at runtime.\nexport function validateRuleIsOverridden(\n  ruleName: string,\n  definedRulesNames: string[],\n  className: string,\n): IParserDefinitionError[] {\n  const errors = [];\n  let errMsg;\n\n  if (!includes(definedRulesNames, ruleName)) {\n    errMsg =\n      `Invalid rule override, rule: ->${ruleName}<- cannot be overridden in the grammar: ->${className}<-` +\n      `as it is not defined in any of the super grammars `;\n    errors.push({\n      message: errMsg,\n      type: ParserDefinitionErrorType.INVALID_RULE_OVERRIDE,\n      ruleName: ruleName,\n    });\n  }\n\n  return errors;\n}\n\nexport function validateNoLeftRecursion(\n  topRule: Rule,\n  currRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n  path: Rule[] = [],\n): IParserDefinitionError[] {\n  const errors: IParserDefinitionError[] = [];\n  const nextNonTerminals = getFirstNoneTerminal(currRule.definition);\n  if (isEmpty(nextNonTerminals)) {\n    return [];\n  } else {\n    const ruleName = topRule.name;\n    const foundLeftRecursion = includes(nextNonTerminals, topRule);\n    if (foundLeftRecursion) {\n      errors.push({\n        message: errMsgProvider.buildLeftRecursionError({\n          topLevelRule: topRule,\n          leftRecursionPath: path,\n        }),\n        type: ParserDefinitionErrorType.LEFT_RECURSION,\n        ruleName: ruleName,\n      });\n    }\n\n    // we are only looking for cyclic paths leading back to the specific topRule\n    // other cyclic paths are ignored, we still need this difference to avoid infinite loops...\n    const validNextSteps = difference(nextNonTerminals, path.concat([topRule]));\n    const errorsFromNextSteps = flatMap(validNextSteps, (currRefRule) => {\n      const newPath = clone(path);\n      newPath.push(currRefRule);\n      return validateNoLeftRecursion(\n        topRule,\n        currRefRule,\n        errMsgProvider,\n        newPath,\n      );\n    });\n\n    return errors.concat(errorsFromNextSteps);\n  }\n}\n\nexport function getFirstNoneTerminal(definition: IProduction[]): Rule[] {\n  let result: Rule[] = [];\n  if (isEmpty(definition)) {\n    return result;\n  }\n  const firstProd = first(definition);\n\n  /* istanbul ignore else */\n  if (firstProd instanceof NonTerminal) {\n    result.push(firstProd.referencedRule);\n  } else if (\n    firstProd instanceof AlternativeGAST ||\n    firstProd instanceof Option ||\n    firstProd instanceof RepetitionMandatory ||\n    firstProd instanceof RepetitionMandatoryWithSeparator ||\n    firstProd instanceof RepetitionWithSeparator ||\n    firstProd instanceof Repetition\n  ) {\n    result = result.concat(\n      getFirstNoneTerminal(<IProduction[]>firstProd.definition),\n    );\n  } else if (firstProd instanceof Alternation) {\n    // each sub definition in alternation is a FLAT\n    result = flatten(\n      map(firstProd.definition, (currSubDef) =>\n        getFirstNoneTerminal((<AlternativeGAST>currSubDef).definition),\n      ),\n    );\n  } else if (firstProd instanceof Terminal) {\n    // nothing to see, move along\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n\n  const isFirstOptional = isOptionalProd(firstProd);\n  const hasMore = definition.length > 1;\n  if (isFirstOptional && hasMore) {\n    const rest = drop(definition);\n    return result.concat(getFirstNoneTerminal(rest));\n  } else {\n    return result;\n  }\n}\n\nclass OrCollector extends GAstVisitor {\n  public alternations: Alternation[] = [];\n\n  public visitAlternation(node: Alternation): void {\n    this.alternations.push(node);\n  }\n}\n\nexport function validateEmptyOrAlternative(\n  topLevelRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserEmptyAlternativeDefinitionError[] {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  const ors = orCollector.alternations;\n\n  const errors = flatMap<Alternation, IParserEmptyAlternativeDefinitionError>(\n    ors,\n    (currOr) => {\n      const exceptLast = dropRight(currOr.definition);\n      return flatMap(exceptLast, (currAlternative, currAltIdx) => {\n        const possibleFirstInAlt = nextPossibleTokensAfter(\n          [currAlternative],\n          [],\n          tokenStructuredMatcher,\n          1,\n        );\n        if (isEmpty(possibleFirstInAlt)) {\n          return [\n            {\n              message: errMsgProvider.buildEmptyAlternationError({\n                topLevelRule: topLevelRule,\n                alternation: currOr,\n                emptyChoiceIdx: currAltIdx,\n              }),\n              type: ParserDefinitionErrorType.NONE_LAST_EMPTY_ALT,\n              ruleName: topLevelRule.name,\n              occurrence: currOr.idx,\n              alternative: currAltIdx + 1,\n            },\n          ];\n        } else {\n          return [];\n        }\n      });\n    },\n  );\n\n  return errors;\n}\n\nexport function validateAmbiguousAlternationAlternatives(\n  topLevelRule: Rule,\n  globalMaxLookahead: number,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserAmbiguousAlternativesDefinitionError[] {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  let ors = orCollector.alternations;\n\n  // New Handling of ignoring ambiguities\n  // - https://github.com/chevrotain/chevrotain/issues/869\n  ors = reject(ors, (currOr) => currOr.ignoreAmbiguities === true);\n\n  const errors = flatMap(ors, (currOr: Alternation) => {\n    const currOccurrence = currOr.idx;\n    const actualMaxLookahead = currOr.maxLookahead || globalMaxLookahead;\n    const alternatives = getLookaheadPathsForOr(\n      currOccurrence,\n      topLevelRule,\n      actualMaxLookahead,\n      currOr,\n    );\n    const altsAmbiguityErrors = checkAlternativesAmbiguities(\n      alternatives,\n      currOr,\n      topLevelRule,\n      errMsgProvider,\n    );\n    const altsPrefixAmbiguityErrors = checkPrefixAlternativesAmbiguities(\n      alternatives,\n      currOr,\n      topLevelRule,\n      errMsgProvider,\n    );\n\n    return altsAmbiguityErrors.concat(altsPrefixAmbiguityErrors);\n  });\n\n  return errors;\n}\n\nexport class RepetitionCollector extends GAstVisitor {\n  public allProductions: (IProductionWithOccurrence & {\n    maxLookahead?: number;\n  })[] = [];\n\n  public visitRepetitionWithSeparator(manySep: RepetitionWithSeparator): void {\n    this.allProductions.push(manySep);\n  }\n\n  public visitRepetitionMandatory(atLeastOne: RepetitionMandatory): void {\n    this.allProductions.push(atLeastOne);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    atLeastOneSep: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.allProductions.push(atLeastOneSep);\n  }\n\n  public visitRepetition(many: Repetition): void {\n    this.allProductions.push(many);\n  }\n}\n\nexport function validateTooManyAlts(\n  topLevelRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  const ors = orCollector.alternations;\n\n  const errors = flatMap(ors, (currOr) => {\n    if (currOr.definition.length > 255) {\n      return [\n        {\n          message: errMsgProvider.buildTooManyAlternativesError({\n            topLevelRule: topLevelRule,\n            alternation: currOr,\n          }),\n          type: ParserDefinitionErrorType.TOO_MANY_ALTS,\n          ruleName: topLevelRule.name,\n          occurrence: currOr.idx,\n        },\n      ];\n    } else {\n      return [];\n    }\n  });\n\n  return errors;\n}\n\nexport function validateSomeNonEmptyLookaheadPath(\n  topLevelRules: Rule[],\n  maxLookahead: number,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const errors: IParserDefinitionError[] = [];\n  forEach(topLevelRules, (currTopRule) => {\n    const collectorVisitor = new RepetitionCollector();\n    currTopRule.accept(collectorVisitor);\n    const allRuleProductions = collectorVisitor.allProductions;\n    forEach(allRuleProductions, (currProd) => {\n      const prodType = getProdType(currProd);\n      const actualMaxLookahead = currProd.maxLookahead || maxLookahead;\n      const currOccurrence = currProd.idx;\n      const paths = getLookaheadPathsForOptionalProd(\n        currOccurrence,\n        currTopRule,\n        prodType,\n        actualMaxLookahead,\n      );\n      const pathsInsideProduction = paths[0];\n      if (isEmpty(flatten(pathsInsideProduction))) {\n        const errMsg = errMsgProvider.buildEmptyRepetitionError({\n          topLevelRule: currTopRule,\n          repetition: currProd,\n        });\n        errors.push({\n          message: errMsg,\n          type: ParserDefinitionErrorType.NO_NON_EMPTY_LOOKAHEAD,\n          ruleName: currTopRule.name,\n        });\n      }\n    });\n  });\n\n  return errors;\n}\n\nexport interface IAmbiguityDescriptor {\n  alts: number[];\n  path: TokenType[];\n}\n\nfunction checkAlternativesAmbiguities(\n  alternatives: Alternative[],\n  alternation: Alternation,\n  rule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserAmbiguousAlternativesDefinitionError[] {\n  const foundAmbiguousPaths: Alternative = [];\n  const identicalAmbiguities = reduce(\n    alternatives,\n    (result, currAlt, currAltIdx) => {\n      // ignore (skip) ambiguities with this alternative\n      if (alternation.definition[currAltIdx].ignoreAmbiguities === true) {\n        return result;\n      }\n\n      forEach(currAlt, (currPath) => {\n        const altsCurrPathAppearsIn = [currAltIdx];\n        forEach(alternatives, (currOtherAlt, currOtherAltIdx) => {\n          if (\n            currAltIdx !== currOtherAltIdx &&\n            containsPath(currOtherAlt, currPath) &&\n            // ignore (skip) ambiguities with this \"other\" alternative\n            alternation.definition[currOtherAltIdx].ignoreAmbiguities !== true\n          ) {\n            altsCurrPathAppearsIn.push(currOtherAltIdx);\n          }\n        });\n\n        if (\n          altsCurrPathAppearsIn.length > 1 &&\n          !containsPath(foundAmbiguousPaths, currPath)\n        ) {\n          foundAmbiguousPaths.push(currPath);\n          result.push({\n            alts: altsCurrPathAppearsIn,\n            path: currPath,\n          });\n        }\n      });\n      return result;\n    },\n    [] as { alts: number[]; path: TokenType[] }[],\n  );\n\n  const currErrors = map(identicalAmbiguities, (currAmbDescriptor) => {\n    const ambgIndices = map(\n      currAmbDescriptor.alts,\n      (currAltIdx) => currAltIdx + 1,\n    );\n\n    const currMessage = errMsgProvider.buildAlternationAmbiguityError({\n      topLevelRule: rule,\n      alternation: alternation,\n      ambiguityIndices: ambgIndices,\n      prefixPath: currAmbDescriptor.path,\n    });\n\n    return {\n      message: currMessage,\n      type: ParserDefinitionErrorType.AMBIGUOUS_ALTS,\n      ruleName: rule.name,\n      occurrence: alternation.idx,\n      alternatives: currAmbDescriptor.alts,\n    };\n  });\n\n  return currErrors;\n}\n\nexport function checkPrefixAlternativesAmbiguities(\n  alternatives: Alternative[],\n  alternation: Alternation,\n  rule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserAmbiguousAlternativesDefinitionError[] {\n  // flatten\n  const pathsAndIndices = reduce(\n    alternatives,\n    (result, currAlt, idx) => {\n      const currPathsAndIdx = map(currAlt, (currPath) => {\n        return { idx: idx, path: currPath };\n      });\n      return result.concat(currPathsAndIdx);\n    },\n    [] as { idx: number; path: TokenType[] }[],\n  );\n\n  const errors = compact(\n    flatMap(pathsAndIndices, (currPathAndIdx) => {\n      const alternativeGast = alternation.definition[currPathAndIdx.idx];\n      // ignore (skip) ambiguities with this alternative\n      if (alternativeGast.ignoreAmbiguities === true) {\n        return [];\n      }\n      const targetIdx = currPathAndIdx.idx;\n      const targetPath = currPathAndIdx.path;\n\n      const prefixAmbiguitiesPathsAndIndices = filter(\n        pathsAndIndices,\n        (searchPathAndIdx) => {\n          // prefix ambiguity can only be created from lower idx (higher priority) path\n          return (\n            // ignore (skip) ambiguities with this \"other\" alternative\n            alternation.definition[searchPathAndIdx.idx].ignoreAmbiguities !==\n              true &&\n            searchPathAndIdx.idx < targetIdx &&\n            // checking for strict prefix because identical lookaheads\n            // will be be detected using a different validation.\n            isStrictPrefixOfPath(searchPathAndIdx.path, targetPath)\n          );\n        },\n      );\n\n      const currPathPrefixErrors = map(\n        prefixAmbiguitiesPathsAndIndices,\n        (currAmbPathAndIdx): IParserAmbiguousAlternativesDefinitionError => {\n          const ambgIndices = [currAmbPathAndIdx.idx + 1, targetIdx + 1];\n          const occurrence = alternation.idx === 0 ? \"\" : alternation.idx;\n\n          const message = errMsgProvider.buildAlternationPrefixAmbiguityError({\n            topLevelRule: rule,\n            alternation: alternation,\n            ambiguityIndices: ambgIndices,\n            prefixPath: currAmbPathAndIdx.path,\n          });\n          return {\n            message: message,\n            type: ParserDefinitionErrorType.AMBIGUOUS_PREFIX_ALTS,\n            ruleName: rule.name,\n            occurrence: occurrence,\n            alternatives: ambgIndices,\n          };\n        },\n      );\n\n      return currPathPrefixErrors;\n    }),\n  );\n\n  return errors;\n}\n\nfunction checkTerminalAndNoneTerminalsNameSpace(\n  topLevels: Rule[],\n  tokenTypes: TokenType[],\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const errors: IParserDefinitionError[] = [];\n\n  const tokenNames = map(tokenTypes, (currToken) => currToken.name);\n\n  forEach(topLevels, (currRule) => {\n    const currRuleName = currRule.name;\n    if (includes(tokenNames, currRuleName)) {\n      const errMsg = errMsgProvider.buildNamespaceConflictError(currRule);\n\n      errors.push({\n        message: errMsg,\n        type: ParserDefinitionErrorType.CONFLICT_TOKENS_RULES_NAMESPACE,\n        ruleName: currRuleName,\n      });\n    }\n  });\n\n  return errors;\n}\n","export {\n  Rule,\n  Terminal,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Alternation,\n  Alternative,\n  serializeGrammar,\n  serializeProduction,\n} from \"./model.js\";\n\nexport { GAstVisitor } from \"./visitor.js\";\n\nexport {\n  getProductionDslName,\n  isOptionalProd,\n  isBranchingProd,\n  isSequenceProd,\n} from \"./helpers.js\";\n","import {\n  analyzeTokenTypes,\n  charCodeToOptimizedIndex,\n  cloneEmptyGroups,\n  DEFAULT_MODE,\n  IAnalyzeResult,\n  IPatternConfig,\n  LineTerminatorOptimizedTester,\n  performRuntimeChecks,\n  performWarningRuntimeChecks,\n  SUPPORT_STICKY,\n  validatePatterns,\n} from \"./lexer.js\";\nimport {\n  assign,\n  clone,\n  forEach,\n  identity,\n  isArray,\n  isEmpty,\n  isUndefined,\n  keys,\n  last,\n  map,\n  noop,\n  reduce,\n  reject,\n} from \"lodash-es\";\nimport { PRINT_WARNING, timer, toFastProperties } from \"@chevrotain/utils\";\nimport { augmentTokenTypes } from \"./tokens.js\";\nimport {\n  CustomPatternMatcherFunc,\n  CustomPatternMatcherReturn,\n  ILexerConfig,\n  ILexerDefinitionError,\n  ILexingError,\n  IMultiModeLexerDefinition,\n  IToken,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { defaultLexerErrorProvider } from \"./lexer_errors_public.js\";\nimport { clearRegExpParserCache } from \"./reg_exp_parser.js\";\n\nexport interface ILexingResult {\n  tokens: IToken[];\n  groups: { [groupName: string]: IToken[] };\n  errors: ILexingError[];\n}\n\nexport enum LexerDefinitionErrorType {\n  MISSING_PATTERN,\n  INVALID_PATTERN,\n  EOI_ANCHOR_FOUND,\n  UNSUPPORTED_FLAGS_FOUND,\n  DUPLICATE_PATTERNS_FOUND,\n  INVALID_GROUP_TYPE_FOUND,\n  PUSH_MODE_DOES_NOT_EXIST,\n  MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE,\n  MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY,\n  MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST,\n  LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED,\n  SOI_ANCHOR_FOUND,\n  EMPTY_MATCH_PATTERN,\n  NO_LINE_BREAKS_FLAGS,\n  UNREACHABLE_PATTERN,\n  IDENTIFY_TERMINATOR,\n  CUSTOM_LINE_BREAK,\n  MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE,\n}\n\nexport interface IRegExpExec {\n  exec: CustomPatternMatcherFunc;\n}\n\nconst DEFAULT_LEXER_CONFIG: Required<ILexerConfig> = {\n  deferDefinitionErrorsHandling: false,\n  positionTracking: \"full\",\n  lineTerminatorsPattern: /\\n|\\r\\n?/g,\n  lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n  ensureOptimizations: false,\n  safeMode: false,\n  errorMessageProvider: defaultLexerErrorProvider,\n  traceInitPerf: false,\n  skipValidations: false,\n  recoveryEnabled: true,\n};\n\nObject.freeze(DEFAULT_LEXER_CONFIG);\n\nexport class Lexer {\n  public static SKIPPED =\n    \"This marks a skipped Token pattern, this means each token identified by it will\" +\n    \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\n\n  public static NA = /NOT_APPLICABLE/;\n  public lexerDefinitionErrors: ILexerDefinitionError[] = [];\n  public lexerDefinitionWarning: ILexerDefinitionError[] = [];\n\n  protected patternIdxToConfig: Record<string, IPatternConfig[]> = {};\n  protected charCodeToPatternIdxToConfig: {\n    [modeName: string]: { [charCode: number]: IPatternConfig[] };\n  } = {};\n\n  protected modes: string[] = [];\n  protected defaultMode!: string;\n  protected emptyGroups: { [groupName: string]: IToken } = {};\n\n  private config: Required<ILexerConfig>;\n  private trackStartLines: boolean = true;\n  private trackEndLines: boolean = true;\n  private hasCustom: boolean = false;\n  private canModeBeOptimized: Record<string, boolean> = {};\n\n  private traceInitPerf!: boolean | number;\n  private traceInitMaxIdent!: number;\n  private traceInitIndent: number;\n\n  constructor(\n    protected lexerDefinition: TokenType[] | IMultiModeLexerDefinition,\n    config: ILexerConfig = DEFAULT_LEXER_CONFIG,\n  ) {\n    if (typeof config === \"boolean\") {\n      throw Error(\n        \"The second argument to the Lexer constructor is now an ILexerConfig Object.\\n\" +\n          \"a boolean 2nd argument is no longer supported\",\n      );\n    }\n\n    // todo: defaults func?\n    this.config = assign({}, DEFAULT_LEXER_CONFIG, config) as any;\n\n    const traceInitVal = this.config.traceInitPerf;\n    if (traceInitVal === true) {\n      this.traceInitMaxIdent = Infinity;\n      this.traceInitPerf = true;\n    } else if (typeof traceInitVal === \"number\") {\n      this.traceInitMaxIdent = traceInitVal;\n      this.traceInitPerf = true;\n    }\n    this.traceInitIndent = -1;\n\n    this.TRACE_INIT(\"Lexer Constructor\", () => {\n      let actualDefinition!: IMultiModeLexerDefinition;\n      let hasOnlySingleMode = true;\n      this.TRACE_INIT(\"Lexer Config handling\", () => {\n        if (\n          this.config.lineTerminatorsPattern ===\n          DEFAULT_LEXER_CONFIG.lineTerminatorsPattern\n        ) {\n          // optimized built-in implementation for the defaults definition of lineTerminators\n          this.config.lineTerminatorsPattern = LineTerminatorOptimizedTester;\n        } else {\n          if (\n            this.config.lineTerminatorCharacters ===\n            DEFAULT_LEXER_CONFIG.lineTerminatorCharacters\n          ) {\n            throw Error(\n              \"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\" +\n                \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\",\n            );\n          }\n        }\n\n        if (config.safeMode && config.ensureOptimizations) {\n          throw Error(\n            '\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.',\n          );\n        }\n\n        this.trackStartLines = /full|onlyStart/i.test(\n          this.config.positionTracking,\n        );\n        this.trackEndLines = /full/i.test(this.config.positionTracking);\n\n        // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n        if (isArray(lexerDefinition)) {\n          actualDefinition = {\n            modes: { defaultMode: clone(lexerDefinition) },\n            defaultMode: DEFAULT_MODE,\n          };\n        } else {\n          // no conversion needed, input should already be a IMultiModeLexerDefinition\n          hasOnlySingleMode = false;\n          actualDefinition = clone(<IMultiModeLexerDefinition>lexerDefinition);\n        }\n      });\n\n      if (this.config.skipValidations === false) {\n        this.TRACE_INIT(\"performRuntimeChecks\", () => {\n          this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(\n            performRuntimeChecks(\n              actualDefinition,\n              this.trackStartLines,\n              this.config.lineTerminatorCharacters,\n            ),\n          );\n        });\n\n        this.TRACE_INIT(\"performWarningRuntimeChecks\", () => {\n          this.lexerDefinitionWarning = this.lexerDefinitionWarning.concat(\n            performWarningRuntimeChecks(\n              actualDefinition,\n              this.trackStartLines,\n              this.config.lineTerminatorCharacters,\n            ),\n          );\n        });\n      }\n\n      // for extra robustness to avoid throwing an none informative error message\n      actualDefinition.modes = actualDefinition.modes\n        ? actualDefinition.modes\n        : {};\n\n      // an error of undefined TokenTypes will be detected in \"performRuntimeChecks\" above.\n      // this transformation is to increase robustness in the case of partially invalid lexer definition.\n      forEach(actualDefinition.modes, (currModeValue, currModeName) => {\n        actualDefinition.modes[currModeName] = reject<TokenType>(\n          currModeValue,\n          (currTokType) => isUndefined(currTokType),\n        );\n      });\n\n      const allModeNames = keys(actualDefinition.modes);\n\n      forEach(\n        actualDefinition.modes,\n        (currModDef: TokenType[], currModName) => {\n          this.TRACE_INIT(`Mode: <${currModName}> processing`, () => {\n            this.modes.push(currModName);\n\n            if (this.config.skipValidations === false) {\n              this.TRACE_INIT(`validatePatterns`, () => {\n                this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(\n                  validatePatterns(currModDef, allModeNames),\n                );\n              });\n            }\n\n            // If definition errors were encountered, the analysis phase may fail unexpectedly/\n            // Considering a lexer with definition errors may never be used, there is no point\n            // to performing the analysis anyhow...\n            if (isEmpty(this.lexerDefinitionErrors)) {\n              augmentTokenTypes(currModDef);\n\n              let currAnalyzeResult!: IAnalyzeResult;\n              this.TRACE_INIT(`analyzeTokenTypes`, () => {\n                currAnalyzeResult = analyzeTokenTypes(currModDef, {\n                  lineTerminatorCharacters:\n                    this.config.lineTerminatorCharacters,\n                  positionTracking: config.positionTracking,\n                  ensureOptimizations: config.ensureOptimizations,\n                  safeMode: config.safeMode,\n                  tracer: this.TRACE_INIT,\n                });\n              });\n\n              this.patternIdxToConfig[currModName] =\n                currAnalyzeResult.patternIdxToConfig;\n\n              this.charCodeToPatternIdxToConfig[currModName] =\n                currAnalyzeResult.charCodeToPatternIdxToConfig;\n\n              this.emptyGroups = assign(\n                {},\n                this.emptyGroups,\n                currAnalyzeResult.emptyGroups,\n              ) as any;\n\n              this.hasCustom = currAnalyzeResult.hasCustom || this.hasCustom;\n\n              this.canModeBeOptimized[currModName] =\n                currAnalyzeResult.canBeOptimized;\n            }\n          });\n        },\n      );\n\n      this.defaultMode = actualDefinition.defaultMode;\n\n      if (\n        !isEmpty(this.lexerDefinitionErrors) &&\n        !this.config.deferDefinitionErrorsHandling\n      ) {\n        const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n          return error.message;\n        });\n        const allErrMessagesString = allErrMessages.join(\n          \"-----------------------\\n\",\n        );\n        throw new Error(\n          \"Errors detected in definition of Lexer:\\n\" + allErrMessagesString,\n        );\n      }\n\n      // Only print warning if there are no errors, This will avoid pl\n      forEach(this.lexerDefinitionWarning, (warningDescriptor) => {\n        PRINT_WARNING(warningDescriptor.message);\n      });\n\n      this.TRACE_INIT(\"Choosing sub-methods implementations\", () => {\n        // Choose the relevant internal implementations for this specific parser.\n        // These implementations should be in-lined by the JavaScript engine\n        // to provide optimal performance in each scenario.\n        if (SUPPORT_STICKY) {\n          this.chopInput = <any>identity;\n          this.match = this.matchWithTest;\n        } else {\n          this.updateLastIndex = noop;\n          this.match = this.matchWithExec;\n        }\n\n        if (hasOnlySingleMode) {\n          this.handleModes = noop;\n        }\n\n        if (this.trackStartLines === false) {\n          this.computeNewColumn = identity;\n        }\n\n        if (this.trackEndLines === false) {\n          this.updateTokenEndLineColumnLocation = noop;\n        }\n\n        if (/full/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createFullToken;\n        } else if (/onlyStart/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createStartOnlyToken;\n        } else if (/onlyOffset/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createOffsetOnlyToken;\n        } else {\n          throw Error(\n            `Invalid <positionTracking> config option: \"${this.config.positionTracking}\"`,\n          );\n        }\n\n        if (this.hasCustom) {\n          this.addToken = this.addTokenUsingPush;\n          this.handlePayload = this.handlePayloadWithCustom;\n        } else {\n          this.addToken = this.addTokenUsingMemberAccess;\n          this.handlePayload = this.handlePayloadNoCustom;\n        }\n      });\n\n      this.TRACE_INIT(\"Failed Optimization Warnings\", () => {\n        const unOptimizedModes = reduce(\n          this.canModeBeOptimized,\n          (cannotBeOptimized, canBeOptimized, modeName) => {\n            if (canBeOptimized === false) {\n              cannotBeOptimized.push(modeName);\n            }\n            return cannotBeOptimized;\n          },\n          [] as string[],\n        );\n\n        if (config.ensureOptimizations && !isEmpty(unOptimizedModes)) {\n          throw Error(\n            `Lexer Modes: < ${unOptimizedModes.join(\n              \", \",\n            )} > cannot be optimized.\\n` +\n              '\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n' +\n              \"\\t Or inspect the console log for details on how to resolve these issues.\",\n          );\n        }\n      });\n\n      this.TRACE_INIT(\"clearRegExpParserCache\", () => {\n        clearRegExpParserCache();\n      });\n\n      this.TRACE_INIT(\"toFastProperties\", () => {\n        toFastProperties(this);\n      });\n    });\n  }\n\n  public tokenize(\n    text: string,\n    initialMode: string = this.defaultMode,\n  ): ILexingResult {\n    if (!isEmpty(this.lexerDefinitionErrors)) {\n      const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n        return error.message;\n      });\n      const allErrMessagesString = allErrMessages.join(\n        \"-----------------------\\n\",\n      );\n      throw new Error(\n        \"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" +\n          allErrMessagesString,\n      );\n    }\n\n    return this.tokenizeInternal(text, initialMode);\n  }\n\n  // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n  // This is intentional due to performance considerations.\n  // this method also used quite a bit of `!` none null assertions because it is too optimized\n  // for `tsc` to always understand it is \"safe\"\n  private tokenizeInternal(text: string, initialMode: string): ILexingResult {\n    let i,\n      j,\n      k,\n      matchAltImage,\n      longerAlt,\n      matchedImage: string | null,\n      payload,\n      altPayload,\n      imageLength,\n      group,\n      tokType,\n      newToken: IToken,\n      errLength,\n      droppedChar,\n      msg,\n      match;\n    const orgText = text;\n    const orgLength = orgText.length;\n    let offset = 0;\n    let matchedTokensIndex = 0;\n    // initializing the tokensArray to the \"guessed\" size.\n    // guessing too little will still reduce the number of array re-sizes on pushes.\n    // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\n    // but would still have a faster runtime by avoiding (All but one) array resizing.\n    const guessedNumberOfTokens = this.hasCustom\n      ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\n      : Math.floor(text.length / 10);\n    const matchedTokens = new Array(guessedNumberOfTokens);\n    const errors: ILexingError[] = [];\n    let line = this.trackStartLines ? 1 : undefined;\n    let column = this.trackStartLines ? 1 : undefined;\n    const groups: any = cloneEmptyGroups(this.emptyGroups);\n    const trackLines = this.trackStartLines;\n    const lineTerminatorPattern = this.config.lineTerminatorsPattern;\n\n    let currModePatternsLength = 0;\n    let patternIdxToConfig: IPatternConfig[] = [];\n    let currCharCodeToPatternIdxToConfig: {\n      [charCode: number]: IPatternConfig[];\n    } = [];\n\n    const modeStack: string[] = [];\n\n    const emptyArray: IPatternConfig[] = [];\n    Object.freeze(emptyArray);\n    let getPossiblePatterns!: (charCode: number) => IPatternConfig[];\n\n    function getPossiblePatternsSlow() {\n      return patternIdxToConfig;\n    }\n\n    function getPossiblePatternsOptimized(charCode: number): IPatternConfig[] {\n      const optimizedCharIdx = charCodeToOptimizedIndex(charCode);\n      const possiblePatterns =\n        currCharCodeToPatternIdxToConfig[optimizedCharIdx];\n      if (possiblePatterns === undefined) {\n        return emptyArray;\n      } else {\n        return possiblePatterns;\n      }\n    }\n\n    const pop_mode = (popToken: IToken) => {\n      // TODO: perhaps avoid this error in the edge case there is no more input?\n      if (\n        modeStack.length === 1 &&\n        // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n        // So no error should occur.\n        popToken.tokenType.PUSH_MODE === undefined\n      ) {\n        // if we try to pop the last mode there lexer will no longer have ANY mode.\n        // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n        const msg =\n          this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(\n            popToken,\n          );\n\n        errors.push({\n          offset: popToken.startOffset,\n          line: popToken.startLine,\n          column: popToken.startColumn,\n          length: popToken.image.length,\n          message: msg,\n        });\n      } else {\n        modeStack.pop();\n        const newMode = last(modeStack)!;\n        patternIdxToConfig = this.patternIdxToConfig[newMode];\n        currCharCodeToPatternIdxToConfig =\n          this.charCodeToPatternIdxToConfig[newMode];\n        currModePatternsLength = patternIdxToConfig.length;\n        const modeCanBeOptimized =\n          this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n\n        if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n          getPossiblePatterns = getPossiblePatternsOptimized;\n        } else {\n          getPossiblePatterns = getPossiblePatternsSlow;\n        }\n      }\n    };\n\n    function push_mode(this: Lexer, newMode: string) {\n      modeStack.push(newMode);\n      currCharCodeToPatternIdxToConfig =\n        this.charCodeToPatternIdxToConfig[newMode];\n\n      patternIdxToConfig = this.patternIdxToConfig[newMode];\n      currModePatternsLength = patternIdxToConfig.length;\n\n      currModePatternsLength = patternIdxToConfig.length;\n      const modeCanBeOptimized =\n        this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n\n      if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n        getPossiblePatterns = getPossiblePatternsOptimized;\n      } else {\n        getPossiblePatterns = getPossiblePatternsSlow;\n      }\n    }\n\n    // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n    // seem to matter performance wise.\n    push_mode.call(this, initialMode);\n\n    let currConfig!: IPatternConfig;\n\n    const recoveryEnabled = this.config.recoveryEnabled;\n\n    while (offset < orgLength) {\n      matchedImage = null;\n\n      const nextCharCode = orgText.charCodeAt(offset);\n      const chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\n      const chosenPatternsLength = chosenPatternIdxToConfig.length;\n\n      for (i = 0; i < chosenPatternsLength; i++) {\n        currConfig = chosenPatternIdxToConfig[i];\n        const currPattern = currConfig.pattern;\n        payload = null;\n\n        // manually in-lined because > 600 chars won't be in-lined in V8\n        const singleCharCode = currConfig.short;\n        if (singleCharCode !== false) {\n          if (nextCharCode === singleCharCode) {\n            // single character string\n            matchedImage = currPattern as string;\n          }\n        } else if (currConfig.isCustom === true) {\n          match = (currPattern as IRegExpExec).exec(\n            orgText,\n            offset,\n            matchedTokens,\n            groups,\n          );\n          if (match !== null) {\n            matchedImage = match[0];\n            if ((match as CustomPatternMatcherReturn).payload !== undefined) {\n              payload = (match as CustomPatternMatcherReturn).payload;\n            }\n          } else {\n            matchedImage = null;\n          }\n        } else {\n          this.updateLastIndex(currPattern as RegExp, offset);\n          matchedImage = this.match(currPattern as RegExp, text, offset);\n        }\n\n        if (matchedImage !== null) {\n          // even though this pattern matched we must try a another longer alternative.\n          // this can be used to prioritize keywords over identifiers\n          longerAlt = currConfig.longerAlt;\n          if (longerAlt !== undefined) {\n            // TODO: micro optimize, avoid extra prop access\n            // by saving/linking longerAlt on the original config?\n            const longerAltLength = longerAlt.length;\n            for (k = 0; k < longerAltLength; k++) {\n              const longerAltConfig = patternIdxToConfig[longerAlt[k]];\n              const longerAltPattern = longerAltConfig.pattern;\n              altPayload = null;\n\n              // single Char can never be a longer alt so no need to test it.\n              // manually in-lined because > 600 chars won't be in-lined in V8\n              if (longerAltConfig.isCustom === true) {\n                match = (longerAltPattern as IRegExpExec).exec(\n                  orgText,\n                  offset,\n                  matchedTokens,\n                  groups,\n                );\n                if (match !== null) {\n                  matchAltImage = match[0];\n                  if (\n                    (match as CustomPatternMatcherReturn).payload !== undefined\n                  ) {\n                    altPayload = (match as CustomPatternMatcherReturn).payload;\n                  }\n                } else {\n                  matchAltImage = null;\n                }\n              } else {\n                this.updateLastIndex(longerAltPattern as RegExp, offset);\n                matchAltImage = this.match(\n                  longerAltPattern as RegExp,\n                  text,\n                  offset,\n                );\n              }\n\n              if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                matchedImage = matchAltImage;\n                payload = altPayload;\n                currConfig = longerAltConfig;\n                // Exit the loop early after matching one of the longer alternatives\n                // The first matched alternative takes precedence\n                break;\n              }\n            }\n          }\n          break;\n        }\n      }\n\n      // successful match\n      if (matchedImage !== null) {\n        imageLength = matchedImage.length;\n        group = currConfig.group;\n        if (group !== undefined) {\n          tokType = currConfig.tokenTypeIdx;\n          // TODO: \"offset + imageLength\" and the new column may be computed twice in case of \"full\" location information inside\n          // createFullToken method\n          newToken = this.createTokenInstance(\n            matchedImage,\n            offset,\n            tokType,\n            currConfig.tokenType,\n            line,\n            column,\n            imageLength,\n          );\n\n          this.handlePayload(newToken, payload);\n\n          // TODO: optimize NOOP in case there are no special groups?\n          if (group === false) {\n            matchedTokensIndex = this.addToken(\n              matchedTokens,\n              matchedTokensIndex,\n              newToken,\n            );\n          } else {\n            groups[group].push(newToken);\n          }\n        }\n        text = this.chopInput(text, imageLength);\n        offset = offset + imageLength;\n\n        // TODO: with newlines the column may be assigned twice\n        column = this.computeNewColumn(column!, imageLength);\n\n        if (trackLines === true && currConfig.canLineTerminator === true) {\n          let numOfLTsInMatch = 0;\n          let foundTerminator;\n          let lastLTEndOffset: number;\n          lineTerminatorPattern.lastIndex = 0;\n          do {\n            foundTerminator = lineTerminatorPattern.test(matchedImage);\n            if (foundTerminator === true) {\n              lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\n              numOfLTsInMatch++;\n            }\n          } while (foundTerminator === true);\n\n          if (numOfLTsInMatch !== 0) {\n            line = line! + numOfLTsInMatch;\n            column = imageLength - lastLTEndOffset!;\n            this.updateTokenEndLineColumnLocation(\n              newToken!,\n              group!,\n              lastLTEndOffset!,\n              numOfLTsInMatch,\n              line,\n              column,\n              imageLength,\n            );\n          }\n        }\n        // will be NOOP if no modes present\n        this.handleModes(currConfig, pop_mode, push_mode, newToken!);\n      } else {\n        // error recovery, drop characters until we identify a valid token's start point\n        const errorStartOffset = offset;\n        const errorLine = line;\n        const errorColumn = column;\n        let foundResyncPoint = recoveryEnabled === false;\n\n        while (foundResyncPoint === false && offset < orgLength) {\n          // Identity Func (when sticky flag is enabled)\n          text = this.chopInput(text, 1);\n          offset++;\n          for (j = 0; j < currModePatternsLength; j++) {\n            const currConfig = patternIdxToConfig[j];\n            const currPattern = currConfig.pattern;\n\n            // manually in-lined because > 600 chars won't be in-lined in V8\n            const singleCharCode = currConfig.short;\n            if (singleCharCode !== false) {\n              if (orgText.charCodeAt(offset) === singleCharCode) {\n                // single character string\n                foundResyncPoint = true;\n              }\n            } else if (currConfig.isCustom === true) {\n              foundResyncPoint =\n                (currPattern as IRegExpExec).exec(\n                  orgText,\n                  offset,\n                  matchedTokens,\n                  groups,\n                ) !== null;\n            } else {\n              this.updateLastIndex(currPattern as RegExp, offset);\n              foundResyncPoint = (currPattern as RegExp).exec(text) !== null;\n            }\n\n            if (foundResyncPoint === true) {\n              break;\n            }\n          }\n        }\n\n        errLength = offset - errorStartOffset;\n        column = this.computeNewColumn(column!, errLength);\n        // at this point we either re-synced or reached the end of the input text\n        msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(\n          orgText,\n          errorStartOffset,\n          errLength,\n          errorLine,\n          errorColumn,\n        );\n        errors.push({\n          offset: errorStartOffset,\n          line: errorLine,\n          column: errorColumn,\n          length: errLength,\n          message: msg,\n        });\n\n        if (recoveryEnabled === false) {\n          break;\n        }\n      }\n    }\n\n    // if we do have custom patterns which push directly into the\n    // TODO: custom tokens should not push directly??\n    if (!this.hasCustom) {\n      // if we guessed a too large size for the tokens array this will shrink it to the right size.\n      matchedTokens.length = matchedTokensIndex;\n    }\n\n    return {\n      tokens: matchedTokens,\n      groups: groups,\n      errors: errors,\n    };\n  }\n\n  private handleModes(\n    config: IPatternConfig,\n    pop_mode: (tok: IToken) => void,\n    push_mode: (this: Lexer, pushMode: string) => void,\n    newToken: IToken,\n  ) {\n    if (config.pop === true) {\n      // need to save the PUSH_MODE property as if the mode is popped\n      // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n      const pushMode = config.push;\n      pop_mode(newToken);\n      if (pushMode !== undefined) {\n        push_mode.call(this, pushMode);\n      }\n    } else if (config.push !== undefined) {\n      push_mode.call(this, config.push);\n    }\n  }\n\n  private chopInput(text: string, length: number): string {\n    return text.substring(length);\n  }\n\n  private updateLastIndex(regExp: RegExp, newLastIndex: number): void {\n    regExp.lastIndex = newLastIndex;\n  }\n\n  // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n  private updateTokenEndLineColumnLocation(\n    newToken: IToken,\n    group: string | false,\n    lastLTIdx: number,\n    numOfLTsInMatch: number,\n    line: number,\n    column: number,\n    imageLength: number,\n  ): void {\n    let lastCharIsLT, fixForEndingInLT;\n    if (group !== undefined) {\n      // a none skipped multi line Token, need to update endLine/endColumn\n      lastCharIsLT = lastLTIdx === imageLength - 1;\n      fixForEndingInLT = lastCharIsLT ? -1 : 0;\n      if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n        // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n        newToken.endLine = line + fixForEndingInLT;\n        // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n        // inclusive to exclusive range.\n        newToken.endColumn = column - 1 + -fixForEndingInLT;\n      }\n      // else single LT in the last character of a token, no need to modify the endLine/EndColumn\n    }\n  }\n\n  private computeNewColumn(oldColumn: number, imageLength: number) {\n    return oldColumn + imageLength;\n  }\n\n  // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\n  /* istanbul ignore next - place holder */\n  private createTokenInstance!: (...args: any[]) => IToken;\n\n  private createOffsetOnlyToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n  ) {\n    return {\n      image,\n      startOffset,\n      tokenTypeIdx,\n      tokenType,\n    };\n  }\n\n  private createStartOnlyToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n    startLine: number,\n    startColumn: number,\n  ) {\n    return {\n      image,\n      startOffset,\n      startLine,\n      startColumn,\n      tokenTypeIdx,\n      tokenType,\n    };\n  }\n\n  private createFullToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n    startLine: number,\n    startColumn: number,\n    imageLength: number,\n  ): IToken {\n    return {\n      image,\n      startOffset,\n      endOffset: startOffset + imageLength - 1,\n      startLine,\n      endLine: startLine,\n      startColumn,\n      endColumn: startColumn + imageLength - 1,\n      tokenTypeIdx,\n      tokenType,\n    };\n  }\n\n  // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\n  /* istanbul ignore next - place holder */\n  private addToken!: (\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken,\n  ) => number;\n\n  private addTokenUsingPush(\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken,\n  ): number {\n    tokenVector.push(tokenToAdd);\n    return index;\n  }\n\n  private addTokenUsingMemberAccess(\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken,\n  ): number {\n    tokenVector[index] = tokenToAdd;\n    index++;\n    return index;\n  }\n\n  // Place holder, will be replaced by the correct variant according to the hasCustom flag option at runtime.\n  private handlePayload: (token: IToken, payload: any) => void;\n\n  private handlePayloadNoCustom(token: IToken, payload: any): void {}\n\n  private handlePayloadWithCustom(token: IToken, payload: any): void {\n    if (payload !== null) {\n      token.payload = payload;\n    }\n  }\n\n  // place holder to be replaced with chosen alternative at runtime\n  private match!: (\n    pattern: RegExp,\n    text: string,\n    offset: number,\n  ) => string | null;\n\n  private matchWithTest(\n    pattern: RegExp,\n    text: string,\n    offset: number,\n  ): string | null {\n    const found = pattern.test(text);\n    if (found === true) {\n      return text.substring(offset, pattern.lastIndex);\n    }\n    return null;\n  }\n\n  private matchWithExec(pattern: RegExp, text: string): string | null {\n    const regExpArray = pattern.exec(text);\n    return regExpArray !== null ? regExpArray[0] : null;\n  }\n\n  // Duplicated from the parser's perf trace trait to allow future extraction\n  // of the lexer to a separate package.\n  TRACE_INIT = <T>(phaseDesc: string, phaseImpl: () => T): T => {\n    // No need to optimize this using NOOP pattern because\n    // It is not called in a hot spot...\n    if (this.traceInitPerf === true) {\n      this.traceInitIndent++;\n      const indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        console.log(`${indent}--> <${phaseDesc}>`);\n      }\n      const { time, value } = timer(phaseImpl);\n      /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n      const traceMethod = time > 10 ? console.warn : console.log;\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n      }\n      this.traceInitIndent--;\n      return value;\n    } else {\n      return phaseImpl();\n    }\n  };\n}\n","import {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"./model.js\";\nimport type { IProduction } from \"@chevrotain/types\";\n\nexport abstract class GAstVisitor {\n  public visit(node: IProduction): any {\n    const nodeAny: any = node;\n    switch (nodeAny.constructor) {\n      case NonTerminal:\n        return this.visitNonTerminal(nodeAny);\n      case Alternative:\n        return this.visitAlternative(nodeAny);\n      case Option:\n        return this.visitOption(nodeAny);\n      case RepetitionMandatory:\n        return this.visitRepetitionMandatory(nodeAny);\n      case RepetitionMandatoryWithSeparator:\n        return this.visitRepetitionMandatoryWithSeparator(nodeAny);\n      case RepetitionWithSeparator:\n        return this.visitRepetitionWithSeparator(nodeAny);\n      case Repetition:\n        return this.visitRepetition(nodeAny);\n      case Alternation:\n        return this.visitAlternation(nodeAny);\n      case Terminal:\n        return this.visitTerminal(nodeAny);\n      case Rule:\n        return this.visitRule(nodeAny);\n      /* c8 ignore next 2 */\n      default:\n        throw Error(\"non exhaustive match\");\n    }\n  }\n\n  /* c8 ignore next */\n  public visitNonTerminal(node: NonTerminal): any {}\n\n  /* c8 ignore next */\n  public visitAlternative(node: Alternative): any {}\n\n  /* c8 ignore next */\n  public visitOption(node: Option): any {}\n\n  /* c8 ignore next */\n  public visitRepetition(node: Repetition): any {}\n\n  /* c8 ignore next */\n  public visitRepetitionMandatory(node: RepetitionMandatory): any {}\n\n  /* c8 ignore next 3 */\n  public visitRepetitionMandatoryWithSeparator(\n    node: RepetitionMandatoryWithSeparator,\n  ): any {}\n\n  /* c8 ignore next */\n  public visitRepetitionWithSeparator(node: RepetitionWithSeparator): any {}\n\n  /* c8 ignore next */\n  public visitAlternation(node: Alternation): any {}\n\n  /* c8 ignore next */\n  public visitTerminal(node: Terminal): any {}\n\n  /* c8 ignore next */\n  public visitRule(node: Rule): any {}\n}\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n'use strict';\n\n// !!!!!\n// SEE https://github.com/microsoft/vscode/blob/master/src/vs/base/common/platform.ts\n// !!!!!\n\ndeclare const process: { platform: 'win32' };\ndeclare const navigator: { userAgent: string };\n\nexport let isWindows: boolean;\n\nif (typeof process === 'object') {\n\tisWindows = process.platform === 'win32';\n} else if (typeof navigator === 'object') {\n\tlet userAgent = navigator.userAgent;\n\tisWindows = userAgent.indexOf('Windows') >= 0;\n}\n","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n'use strict';\n\nimport { CharCode } from './charCode'\nimport { isWindows } from './platform';\n\nconst _schemePattern = /^\\w[\\w\\d+.-]*$/;\nconst _singleSlashStart = /^\\//;\nconst _doubleSlashStart = /^\\/\\//;\n\nfunction _validateUri(ret: URI, _strict?: boolean): void {\n\n\t// scheme, must be set\n\tif (!ret.scheme && _strict) {\n\t\tthrow new Error(`[UriError]: Scheme is missing: {scheme: \"\", authority: \"${ret.authority}\", path: \"${ret.path}\", query: \"${ret.query}\", fragment: \"${ret.fragment}\"}`);\n\t}\n\n\t// scheme, https://tools.ietf.org/html/rfc3986#section-3.1\n\t// ALPHA *( ALPHA / DIGIT / \"+\" / \"-\" / \".\" )\n\tif (ret.scheme && !_schemePattern.test(ret.scheme)) {\n\t\tthrow new Error('[UriError]: Scheme contains illegal characters.');\n\t}\n\n\t// path, http://tools.ietf.org/html/rfc3986#section-3.3\n\t// If a URI contains an authority component, then the path component\n\t// must either be empty or begin with a slash (\"/\") character.  If a URI\n\t// does not contain an authority component, then the path cannot begin\n\t// with two slash characters (\"//\").\n\tif (ret.path) {\n\t\tif (ret.authority) {\n\t\t\tif (!_singleSlashStart.test(ret.path)) {\n\t\t\t\tthrow new Error('[UriError]: If a URI contains an authority component, then the path component must either be empty or begin with a slash (\"/\") character');\n\t\t\t}\n\t\t} else {\n\t\t\tif (_doubleSlashStart.test(ret.path)) {\n\t\t\t\tthrow new Error('[UriError]: If a URI does not contain an authority component, then the path cannot begin with two slash characters (\"//\")');\n\t\t\t}\n\t\t}\n\t}\n}\n\n// for a while we allowed uris *without* schemes and this is the migration\n// for them, e.g. an uri without scheme and without strict-mode warns and falls\n// back to the file-scheme. that should cause the least carnage and still be a\n// clear warning\nfunction _schemeFix(scheme: string, _strict: boolean): string {\n\tif (!scheme && !_strict) {\n\t\treturn 'file';\n\t}\n\treturn scheme;\n}\n\n// implements a bit of https://tools.ietf.org/html/rfc3986#section-5\nfunction _referenceResolution(scheme: string, path: string): string {\n\n\t// the slash-character is our 'default base' as we don't\n\t// support constructing URIs relative to other URIs. This\n\t// also means that we alter and potentially break paths.\n\t// see https://tools.ietf.org/html/rfc3986#section-5.1.4\n\tswitch (scheme) {\n\t\tcase 'https':\n\t\tcase 'http':\n\t\tcase 'file':\n\t\t\tif (!path) {\n\t\t\t\tpath = _slash;\n\t\t\t} else if (path[0] !== _slash) {\n\t\t\t\tpath = _slash + path;\n\t\t\t}\n\t\t\tbreak;\n\t}\n\treturn path;\n}\n\nconst _empty = '';\nconst _slash = '/';\nconst _regexp = /^(([^:/?#]+?):)?(\\/\\/([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?/;\n\n/**\n * Uniform Resource Identifier (URI) http://tools.ietf.org/html/rfc3986.\n * This class is a simple parser which creates the basic component parts\n * (http://tools.ietf.org/html/rfc3986#section-3) with minimal validation\n * and encoding.\n *\n * ```txt\n *       foo://example.com:8042/over/there?name=ferret#nose\n *       \\_/   \\______________/\\_________/ \\_________/ \\__/\n *        |           |            |            |        |\n *     scheme     authority       path        query   fragment\n *        |   _____________________|__\n *       / \\ /                        \\\n *       urn:example:animal:ferret:nose\n * ```\n */\nexport class URI implements UriComponents {\n\n\tstatic isUri(thing: any): thing is URI {\n\t\tif (thing instanceof URI) {\n\t\t\treturn true;\n\t\t}\n\t\tif (!thing) {\n\t\t\treturn false;\n\t\t}\n\t\treturn typeof (<URI>thing).authority === 'string'\n\t\t\t&& typeof (<URI>thing).fragment === 'string'\n\t\t\t&& typeof (<URI>thing).path === 'string'\n\t\t\t&& typeof (<URI>thing).query === 'string'\n\t\t\t&& typeof (<URI>thing).scheme === 'string'\n\t\t\t&& typeof (<URI>thing).fsPath === 'string'\n\t\t\t&& typeof (<URI>thing).with === 'function'\n\t\t\t&& typeof (<URI>thing).toString === 'function';\n\t}\n\n\t/**\n\t * scheme is the 'http' part of 'http://www.example.com/some/path?query#fragment'.\n\t * The part before the first colon.\n\t */\n\treadonly scheme: string;\n\n\t/**\n\t * authority is the 'www.example.com' part of 'http://www.example.com/some/path?query#fragment'.\n\t * The part between the first double slashes and the next slash.\n\t */\n\treadonly authority: string;\n\n\t/**\n\t * path is the '/some/path' part of 'http://www.example.com/some/path?query#fragment'.\n\t */\n\treadonly path: string;\n\n\t/**\n\t * query is the 'query' part of 'http://www.example.com/some/path?query#fragment'.\n\t */\n\treadonly query: string;\n\n\t/**\n\t * fragment is the 'fragment' part of 'http://www.example.com/some/path?query#fragment'.\n\t */\n\treadonly fragment: string;\n\n\t/**\n\t * @internal\n\t */\n\tprotected constructor(scheme: string, authority?: string, path?: string, query?: string, fragment?: string, _strict?: boolean);\n\n\t/**\n\t * @internal\n\t */\n\tprotected constructor(components: UriComponents);\n\n\t/**\n\t * @internal\n\t */\n\tprotected constructor(schemeOrData: string | UriComponents, authority?: string, path?: string, query?: string, fragment?: string, _strict: boolean = false) {\n\n\t\tif (typeof schemeOrData === 'object') {\n\t\t\tthis.scheme = schemeOrData.scheme || _empty;\n\t\t\tthis.authority = schemeOrData.authority || _empty;\n\t\t\tthis.path = schemeOrData.path || _empty;\n\t\t\tthis.query = schemeOrData.query || _empty;\n\t\t\tthis.fragment = schemeOrData.fragment || _empty;\n\t\t\t// no validation because it's this URI\n\t\t\t// that creates uri components.\n\t\t\t// _validateUri(this);\n\t\t} else {\n\t\t\tthis.scheme = _schemeFix(schemeOrData, _strict);\n\t\t\tthis.authority = authority || _empty;\n\t\t\tthis.path = _referenceResolution(this.scheme, path || _empty);\n\t\t\tthis.query = query || _empty;\n\t\t\tthis.fragment = fragment || _empty;\n\n\t\t\t_validateUri(this, _strict);\n\t\t}\n\t}\n\n\t// ---- filesystem path -----------------------\n\n\t/**\n\t * Returns a string representing the corresponding file system path of this URI.\n\t * Will handle UNC paths, normalizes windows drive letters to lower-case, and uses the\n\t * platform specific path separator.\n\t *\n\t * * Will *not* validate the path for invalid characters and semantics.\n\t * * Will *not* look at the scheme of this URI.\n\t * * The result shall *not* be used for display purposes but for accessing a file on disk.\n\t *\n\t *\n\t * The *difference* to `URI#path` is the use of the platform specific separator and the handling\n\t * of UNC paths. See the below sample of a file-uri with an authority (UNC path).\n\t *\n\t * ```ts\n\t\tconst u = URI.parse('file://server/c$/folder/file.txt')\n\t\tu.authority === 'server'\n\t\tu.path === '/shares/c$/file.txt'\n\t\tu.fsPath === '\\\\server\\c$\\folder\\file.txt'\n\t```\n\t *\n\t * Using `URI#path` to read a file (using fs-apis) would not be enough because parts of the path,\n\t * namely the server name, would be missing. Therefore `URI#fsPath` exists - it's sugar to ease working\n\t * with URIs that represent files on disk (`file` scheme).\n\t */\n\tget fsPath(): string {\n\t\t// if (this.scheme !== 'file') {\n\t\t// \tconsole.warn(`[UriError] calling fsPath with scheme ${this.scheme}`);\n\t\t// }\n\t\treturn uriToFsPath(this, false);\n\t}\n\n\t// ---- modify to new -------------------------\n\n\twith(change: { scheme?: string; authority?: string | null; path?: string | null; query?: string | null; fragment?: string | null }): URI {\n\n\t\tif (!change) {\n\t\t\treturn this;\n\t\t}\n\n\t\tlet { scheme, authority, path, query, fragment } = change;\n\t\tif (scheme === undefined) {\n\t\t\tscheme = this.scheme;\n\t\t} else if (scheme === null) {\n\t\t\tscheme = _empty;\n\t\t}\n\t\tif (authority === undefined) {\n\t\t\tauthority = this.authority;\n\t\t} else if (authority === null) {\n\t\t\tauthority = _empty;\n\t\t}\n\t\tif (path === undefined) {\n\t\t\tpath = this.path;\n\t\t} else if (path === null) {\n\t\t\tpath = _empty;\n\t\t}\n\t\tif (query === undefined) {\n\t\t\tquery = this.query;\n\t\t} else if (query === null) {\n\t\t\tquery = _empty;\n\t\t}\n\t\tif (fragment === undefined) {\n\t\t\tfragment = this.fragment;\n\t\t} else if (fragment === null) {\n\t\t\tfragment = _empty;\n\t\t}\n\n\t\tif (scheme === this.scheme\n\t\t\t&& authority === this.authority\n\t\t\t&& path === this.path\n\t\t\t&& query === this.query\n\t\t\t&& fragment === this.fragment) {\n\n\t\t\treturn this;\n\t\t}\n\n\t\treturn new Uri(scheme, authority, path, query, fragment);\n\t}\n\n\t// ---- parse & validate ------------------------\n\n\t/**\n\t * Creates a new URI from a string, e.g. `http://www.example.com/some/path`,\n\t * `file:///usr/home`, or `scheme:with/path`.\n\t *\n\t * @param value A string which represents an URI (see `URI#toString`).\n\t */\n\tstatic parse(value: string, _strict: boolean = false): URI {\n\t\tconst match = _regexp.exec(value);\n\t\tif (!match) {\n\t\t\treturn new Uri(_empty, _empty, _empty, _empty, _empty);\n\t\t}\n\t\treturn new Uri(\n\t\t\tmatch[2] || _empty,\n\t\t\tpercentDecode(match[4] || _empty),\n\t\t\tpercentDecode(match[5] || _empty),\n\t\t\tpercentDecode(match[7] || _empty),\n\t\t\tpercentDecode(match[9] || _empty),\n\t\t\t_strict\n\t\t);\n\t}\n\n\t/**\n\t * Creates a new URI from a file system path, e.g. `c:\\my\\files`,\n\t * `/usr/home`, or `\\\\server\\share\\some\\path`.\n\t *\n\t * The *difference* between `URI#parse` and `URI#file` is that the latter treats the argument\n\t * as path, not as stringified-uri. E.g. `URI.file(path)` is **not the same as**\n\t * `URI.parse('file://' + path)` because the path might contain characters that are\n\t * interpreted (# and ?). See the following sample:\n\t * ```ts\n\tconst good = URI.file('/coding/c#/project1');\n\tgood.scheme === 'file';\n\tgood.path === '/coding/c#/project1';\n\tgood.fragment === '';\n\tconst bad = URI.parse('file://' + '/coding/c#/project1');\n\tbad.scheme === 'file';\n\tbad.path === '/coding/c'; // path is now broken\n\tbad.fragment === '/project1';\n\t```\n\t *\n\t * @param path A file system path (see `URI#fsPath`)\n\t */\n\tstatic file(path: string): URI {\n\n\t\tlet authority = _empty;\n\n\t\t// normalize to fwd-slashes on windows,\n\t\t// on other systems bwd-slashes are valid\n\t\t// filename character, eg /f\\oo/ba\\r.txt\n\t\tif (isWindows) {\n\t\t\tpath = path.replace(/\\\\/g, _slash);\n\t\t}\n\n\t\t// check for authority as used in UNC shares\n\t\t// or use the path as given\n\t\tif (path[0] === _slash && path[1] === _slash) {\n\t\t\tconst idx = path.indexOf(_slash, 2);\n\t\t\tif (idx === -1) {\n\t\t\t\tauthority = path.substring(2);\n\t\t\t\tpath = _slash;\n\t\t\t} else {\n\t\t\t\tauthority = path.substring(2, idx);\n\t\t\t\tpath = path.substring(idx) || _slash;\n\t\t\t}\n\t\t}\n\n\t\treturn new Uri('file', authority, path, _empty, _empty);\n\t}\n\n\tstatic from(components: { scheme: string; authority?: string; path?: string; query?: string; fragment?: string }): URI {\n\t\tconst result = new Uri(\n\t\t\tcomponents.scheme,\n\t\t\tcomponents.authority,\n\t\t\tcomponents.path,\n\t\t\tcomponents.query,\n\t\t\tcomponents.fragment,\n\t\t);\n\t\t_validateUri(result, true);\n\t\treturn result;\n\t}\n\n\t// ---- printing/externalize ---------------------------\n\n\t/**\n\t * Creates a string representation for this URI. It's guaranteed that calling\n\t * `URI.parse` with the result of this function creates an URI which is equal\n\t * to this URI.\n\t *\n\t * * The result shall *not* be used for display purposes but for externalization or transport.\n\t * * The result will be encoded using the percentage encoding and encoding happens mostly\n\t * ignore the scheme-specific encoding rules.\n\t *\n\t * @param skipEncoding Do not encode the result, default is `false`\n\t */\n\ttoString(skipEncoding: boolean = false): string {\n\t\treturn _asFormatted(this, skipEncoding);\n\t}\n\n\ttoJSON(): UriComponents {\n\t\treturn this;\n\t}\n\n\tstatic revive(data: UriComponents | URI): URI;\n\tstatic revive(data: UriComponents | URI | undefined): URI | undefined;\n\tstatic revive(data: UriComponents | URI | null): URI | null;\n\tstatic revive(data: UriComponents | URI | undefined | null): URI | undefined | null;\n\tstatic revive(data: UriComponents | URI | undefined | null): URI | undefined | null {\n\t\tif (!data) {\n\t\t\treturn <any>data;\n\t\t} else if (data instanceof URI) {\n\t\t\treturn data;\n\t\t} else {\n\t\t\tconst result = new Uri(data);\n\t\t\tresult._formatted = (<UriState>data).external;\n\t\t\tresult._fsPath = (<UriState>data)._sep === _pathSepMarker ? (<UriState>data).fsPath : null;\n\t\t\treturn result;\n\t\t}\n\t}\n}\n\nexport interface UriComponents {\n\tscheme: string;\n\tauthority: string;\n\tpath: string;\n\tquery: string;\n\tfragment: string;\n}\n\ninterface UriState extends UriComponents {\n\t$mid: number;\n\texternal: string;\n\tfsPath: string;\n\t_sep: 1 | undefined;\n}\n\nconst _pathSepMarker = isWindows ? 1 : undefined;\n\n// This class exists so that URI is compatible with vscode.Uri (API).\nclass Uri extends URI {\n\n\t_formatted: string | null = null;\n\t_fsPath: string | null = null;\n\n\toverride get fsPath(): string {\n\t\tif (!this._fsPath) {\n\t\t\tthis._fsPath = uriToFsPath(this, false);\n\t\t}\n\t\treturn this._fsPath;\n\t}\n\n\toverride toString(skipEncoding: boolean = false): string {\n\t\tif (!skipEncoding) {\n\t\t\tif (!this._formatted) {\n\t\t\t\tthis._formatted = _asFormatted(this, false);\n\t\t\t}\n\t\t\treturn this._formatted;\n\t\t} else {\n\t\t\t// we don't cache that\n\t\t\treturn _asFormatted(this, true);\n\t\t}\n\t}\n\n\toverride toJSON(): UriComponents {\n\t\tconst res = <UriState>{\n\t\t\t$mid: 1\n\t\t};\n\t\t// cached state\n\t\tif (this._fsPath) {\n\t\t\tres.fsPath = this._fsPath;\n\t\t\tres._sep = _pathSepMarker;\n\t\t}\n\t\tif (this._formatted) {\n\t\t\tres.external = this._formatted;\n\t\t}\n\t\t// uri components\n\t\tif (this.path) {\n\t\t\tres.path = this.path;\n\t\t}\n\t\tif (this.scheme) {\n\t\t\tres.scheme = this.scheme;\n\t\t}\n\t\tif (this.authority) {\n\t\t\tres.authority = this.authority;\n\t\t}\n\t\tif (this.query) {\n\t\t\tres.query = this.query;\n\t\t}\n\t\tif (this.fragment) {\n\t\t\tres.fragment = this.fragment;\n\t\t}\n\t\treturn res;\n\t}\n}\n\n// reserved characters: https://tools.ietf.org/html/rfc3986#section-2.2\nconst encodeTable: { [ch: number]: string } = {\n\t[CharCode.Colon]: '%3A', // gen-delims\n\t[CharCode.Slash]: '%2F',\n\t[CharCode.QuestionMark]: '%3F',\n\t[CharCode.Hash]: '%23',\n\t[CharCode.OpenSquareBracket]: '%5B',\n\t[CharCode.CloseSquareBracket]: '%5D',\n\t[CharCode.AtSign]: '%40',\n\n\t[CharCode.ExclamationMark]: '%21', // sub-delims\n\t[CharCode.DollarSign]: '%24',\n\t[CharCode.Ampersand]: '%26',\n\t[CharCode.SingleQuote]: '%27',\n\t[CharCode.OpenParen]: '%28',\n\t[CharCode.CloseParen]: '%29',\n\t[CharCode.Asterisk]: '%2A',\n\t[CharCode.Plus]: '%2B',\n\t[CharCode.Comma]: '%2C',\n\t[CharCode.Semicolon]: '%3B',\n\t[CharCode.Equals]: '%3D',\n\n\t[CharCode.Space]: '%20',\n};\n\nfunction encodeURIComponentFast(uriComponent: string, isPath: boolean, isAuthority: boolean): string {\n\tlet res: string | undefined = undefined;\n\tlet nativeEncodePos = -1;\n\n\tfor (let pos = 0; pos < uriComponent.length; pos++) {\n\t\tconst code = uriComponent.charCodeAt(pos);\n\n\t\t// unreserved characters: https://tools.ietf.org/html/rfc3986#section-2.3\n\t\tif (\n\t\t\t(code >= CharCode.a && code <= CharCode.z)\n\t\t\t|| (code >= CharCode.A && code <= CharCode.Z)\n\t\t\t|| (code >= CharCode.Digit0 && code <= CharCode.Digit9)\n\t\t\t|| code === CharCode.Dash\n\t\t\t|| code === CharCode.Period\n\t\t\t|| code === CharCode.Underline\n\t\t\t|| code === CharCode.Tilde\n\t\t\t|| (isPath && code === CharCode.Slash)\n\t\t\t|| (isAuthority && code === CharCode.OpenSquareBracket)\n\t\t\t|| (isAuthority && code === CharCode.CloseSquareBracket)\n\t\t\t|| (isAuthority && code === CharCode.Colon)\n\t\t) {\n\t\t\t// check if we are delaying native encode\n\t\t\tif (nativeEncodePos !== -1) {\n\t\t\t\tres += encodeURIComponent(uriComponent.substring(nativeEncodePos, pos));\n\t\t\t\tnativeEncodePos = -1;\n\t\t\t}\n\t\t\t// check if we write into a new string (by default we try to return the param)\n\t\t\tif (res !== undefined) {\n\t\t\t\tres += uriComponent.charAt(pos);\n\t\t\t}\n\n\t\t} else {\n\t\t\t// encoding needed, we need to allocate a new string\n\t\t\tif (res === undefined) {\n\t\t\t\tres = uriComponent.substr(0, pos);\n\t\t\t}\n\n\t\t\t// check with default table first\n\t\t\tconst escaped = encodeTable[code];\n\t\t\tif (escaped !== undefined) {\n\n\t\t\t\t// check if we are delaying native encode\n\t\t\t\tif (nativeEncodePos !== -1) {\n\t\t\t\t\tres += encodeURIComponent(uriComponent.substring(nativeEncodePos, pos));\n\t\t\t\t\tnativeEncodePos = -1;\n\t\t\t\t}\n\n\t\t\t\t// append escaped variant to result\n\t\t\t\tres += escaped;\n\n\t\t\t} else if (nativeEncodePos === -1) {\n\t\t\t\t// use native encode only when needed\n\t\t\t\tnativeEncodePos = pos;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (nativeEncodePos !== -1) {\n\t\tres += encodeURIComponent(uriComponent.substring(nativeEncodePos));\n\t}\n\n\treturn res !== undefined ? res : uriComponent;\n}\n\nfunction encodeURIComponentMinimal(path: string): string {\n\tlet res: string | undefined = undefined;\n\tfor (let pos = 0; pos < path.length; pos++) {\n\t\tconst code = path.charCodeAt(pos);\n\t\tif (code === CharCode.Hash || code === CharCode.QuestionMark) {\n\t\t\tif (res === undefined) {\n\t\t\t\tres = path.substr(0, pos);\n\t\t\t}\n\t\t\tres += encodeTable[code];\n\t\t} else {\n\t\t\tif (res !== undefined) {\n\t\t\t\tres += path[pos];\n\t\t\t}\n\t\t}\n\t}\n\treturn res !== undefined ? res : path;\n}\n\n/**\n * Compute `fsPath` for the given uri\n */\nexport function uriToFsPath(uri: URI, keepDriveLetterCasing: boolean): string {\n\n\tlet value: string;\n\tif (uri.authority && uri.path.length > 1 && uri.scheme === 'file') {\n\t\t// unc path: file://shares/c$/far/boo\n\t\tvalue = `//${uri.authority}${uri.path}`;\n\t} else if (\n\t\turi.path.charCodeAt(0) === CharCode.Slash\n\t\t&& (uri.path.charCodeAt(1) >= CharCode.A && uri.path.charCodeAt(1) <= CharCode.Z || uri.path.charCodeAt(1) >= CharCode.a && uri.path.charCodeAt(1) <= CharCode.z)\n\t\t&& uri.path.charCodeAt(2) === CharCode.Colon\n\t) {\n\t\tif (!keepDriveLetterCasing) {\n\t\t\t// windows drive letter: file:///c:/far/boo\n\t\t\tvalue = uri.path[1].toLowerCase() + uri.path.substr(2);\n\t\t} else {\n\t\t\tvalue = uri.path.substr(1);\n\t\t}\n\t} else {\n\t\t// other path\n\t\tvalue = uri.path;\n\t}\n\tif (isWindows) {\n\t\tvalue = value.replace(/\\//g, '\\\\');\n\t}\n\treturn value;\n}\n\n/**\n * Create the external version of a uri\n */\nfunction _asFormatted(uri: URI, skipEncoding: boolean): string {\n\n\tconst encoder = !skipEncoding\n\t\t? encodeURIComponentFast\n\t\t: encodeURIComponentMinimal;\n\n\tlet res = '';\n\tlet { scheme, authority, path, query, fragment } = uri;\n\tif (scheme) {\n\t\tres += scheme;\n\t\tres += ':';\n\t}\n\tif (authority || scheme === 'file') {\n\t\tres += _slash;\n\t\tres += _slash;\n\t}\n\tif (authority) {\n\t\tlet idx = authority.indexOf('@');\n\t\tif (idx !== -1) {\n\t\t\t// <user>@<auth>\n\t\t\tconst userinfo = authority.substr(0, idx);\n\t\t\tauthority = authority.substr(idx + 1);\n\t\t\tidx = userinfo.lastIndexOf(':');\n\t\t\tif (idx === -1) {\n\t\t\t\tres += encoder(userinfo, false, false);\n\t\t\t} else {\n\t\t\t\t// <user>:<pass>@<auth>\n\t\t\t\tres += encoder(userinfo.substr(0, idx), false, false);\n\t\t\t\tres += ':';\n\t\t\t\tres += encoder(userinfo.substr(idx + 1), false, true);\n\t\t\t}\n\t\t\tres += '@';\n\t\t}\n\t\tauthority = authority.toLowerCase();\n\t\tidx = authority.lastIndexOf(':');\n\t\tif (idx === -1) {\n\t\t\tres += encoder(authority, false, true);\n\t\t} else {\n\t\t\t// <auth>:<port>\n\t\t\tres += encoder(authority.substr(0, idx), false, true);\n\t\t\tres += authority.substr(idx);\n\t\t}\n\t}\n\tif (path) {\n\t\t// lower-case windows drive letters in /C:/fff or C:/fff\n\t\tif (path.length >= 3 && path.charCodeAt(0) === CharCode.Slash && path.charCodeAt(2) === CharCode.Colon) {\n\t\t\tconst code = path.charCodeAt(1);\n\t\t\tif (code >= CharCode.A && code <= CharCode.Z) {\n\t\t\t\tpath = `/${String.fromCharCode(code + 32)}:${path.substr(3)}`; // \"/c:\".length === 3\n\t\t\t}\n\t\t} else if (path.length >= 2 && path.charCodeAt(1) === CharCode.Colon) {\n\t\t\tconst code = path.charCodeAt(0);\n\t\t\tif (code >= CharCode.A && code <= CharCode.Z) {\n\t\t\t\tpath = `${String.fromCharCode(code + 32)}:${path.substr(2)}`; // \"/c:\".length === 3\n\t\t\t}\n\t\t}\n\t\t// encode the rest of the path\n\t\tres += encoder(path, true, false);\n\t}\n\tif (query) {\n\t\tres += '?';\n\t\tres += encoder(query, false, false);\n\t}\n\tif (fragment) {\n\t\tres += '#';\n\t\tres += !skipEncoding ? encodeURIComponentFast(fragment, false, false) : fragment;\n\t}\n\treturn res;\n}\n\n// --- decode\n\nfunction decodeURIComponentGraceful(str: string): string {\n\ttry {\n\t\treturn decodeURIComponent(str);\n\t} catch {\n\t\tif (str.length > 3) {\n\t\t\treturn str.substr(0, 3) + decodeURIComponentGraceful(str.substr(3));\n\t\t} else {\n\t\t\treturn str;\n\t\t}\n\t}\n}\n\nconst _rEncodedAsHex = /(%[0-9A-Za-z][0-9A-Za-z])+/g;\n\nfunction percentDecode(str: string): string {\n\tif (!str.match(_rEncodedAsHex)) {\n\t\treturn str;\n\t}\n\treturn str.replace(_rEncodedAsHex, (match) => decodeURIComponentGraceful(match));\n}\n\n/**\n * Mapped-type that replaces all occurrences of URI with UriComponents\n */\nexport type UriDto<T> = { [K in keyof T]: T[K] extends URI\n\t? UriComponents\n\t: UriDto<T[K]> };\n","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\n'use strict';\n\nimport { CharCode } from './charCode';\nimport { URI } from './uri';\nimport * as nodePath from 'path';\n\nconst posixPath = nodePath.posix || nodePath;\nconst slash = '/';\n\nexport namespace Utils {\n\n    /**\n     * Joins one or more input paths to the path of URI. \n     * '/' is used as the directory separation character. \n     * \n     * The resolved path will be normalized. That means:\n     *  - all '..' and '.' segments are resolved.\n     *  - multiple, sequential occurences of '/' are replaced by a single instance of '/'.\n     *  - trailing separators are preserved.\n     * \n     * @param uri The input URI.\n     * @param paths The paths to be joined with the path of URI.\n     * @returns A URI with the joined path. All other properties of the URI (scheme, authority, query, fragments, ...) will be taken from the input URI.\n     */\n    export function joinPath(uri: URI, ...paths: string[]): URI {\n        return uri.with({ path: posixPath.join(uri.path, ...paths) });\n    }\n\n\n    /**\n     * Resolves one or more paths against the path of a URI. \n     * '/' is used as the directory separation character. \n     * \n     * The resolved path will be normalized. That means:\n     *  - all '..' and '.' segments are resolved. \n     *  - multiple, sequential occurences of '/' are replaced by a single instance of '/'.\n     *  - trailing separators are removed.\n     * \n     * @param uri The input URI.\n     * @param paths The paths to resolve against the path of URI.\n     * @returns A URI with the resolved path. All other properties of the URI (scheme, authority, query, fragments, ...) will be taken from the input URI.\n     */\n    export function resolvePath(uri: URI, ...paths: string[]): URI {\n        let path = uri.path; \n        let slashAdded = false;\n        if (path[0] !== slash) {\n            path = slash + path; // make the path abstract: for posixPath.resolve the first segments has to be absolute or cwd is used.\n            slashAdded = true;\n        }\n        let resolvedPath = posixPath.resolve(path, ...paths);\n        if (slashAdded && resolvedPath[0] === slash && !uri.authority) {\n            resolvedPath = resolvedPath.substring(1);\n        }\n        return uri.with({ path: resolvedPath });\n    }\n\n    /**\n     * Returns a URI where the path is the directory name of the input uri, similar to the Unix dirname command. \n     * In the path, '/' is recognized as the directory separation character. Trailing directory separators are ignored.\n     * The orignal URI is returned if the URIs path is empty or does not contain any path segments.\n     * \n     * @param uri The input URI.\n     * @return The last segment of the URIs path.\n     */\n    export function dirname(uri: URI): URI {\n        if (uri.path.length === 0 || uri.path === slash) {\n            return uri;\n        }\n        let path = posixPath.dirname(uri.path);\n        if (path.length === 1 && path.charCodeAt(0) === CharCode.Period) {\n            path = '';\n        }\n        return uri.with({ path });\n    }\n\n    /**\n     * Returns the last segment of the path of a URI, similar to the Unix basename command. \n     * In the path, '/' is recognized as the directory separation character. Trailing directory separators are ignored.\n     * The empty string is returned if the URIs path is empty or does not contain any path segments.\n     * \n     * @param uri The input URI.\n     * @return The base name of the URIs path.\n     */\n    export function basename(uri: URI): string {\n        return posixPath.basename(uri.path);\n    }\n\n    /**\n     * Returns the extension name of the path of a URI, similar to the Unix extname command. \n     * In the path, '/' is recognized as the directory separation character. Trailing directory separators are ignored.\n     * The empty string is returned if the URIs path is empty or does not contain any path segments.\n     * \n     * @param uri The input URI.\n     * @return The extension name of the URIs path.\n     */\n    export function extname(uri: URI): string {\n        return posixPath.extname(uri.path);\n    }\n}","import type { Character, IRegExpAST, RegExpFlags } from \"../types\";\n\nexport function cc(char: string): number {\n  return char.charCodeAt(0);\n}\n\nexport function insertToSet<T>(item: T | T[], set: T[]) {\n  if (Array.isArray(item)) {\n    item.forEach(function (subItem) {\n      set.push(subItem);\n    });\n  } else {\n    set.push(item);\n  }\n}\n\nexport function addFlag(\n  flagObj: RegExpFlags,\n  flagKey: keyof Omit<RegExpFlags, keyof IRegExpAST>,\n) {\n  if (flagObj[flagKey] === true) {\n    throw \"duplicate flag \" + flagKey;\n  }\n\n  const x: boolean = flagObj[flagKey];\n  flagObj[flagKey] = true;\n}\n\nexport function ASSERT_EXISTS<T = Object>(obj: any): obj is T {\n  // istanbul ignore next\n  if (obj === undefined) {\n    throw Error(\"Internal Error - Should never get here!\");\n  }\n  return true;\n}\n\n// istanbul ignore next\nexport function ASSERT_NEVER_REACH_HERE(): any {\n  throw Error(\"Internal Error - Should never get here!\");\n}\n\nexport function isCharacter(obj: { type: string }): obj is Character {\n  return obj[\"type\"] === \"Character\";\n}\n","import {\n  addNoneTerminalToCst,\n  addTerminalToCst,\n  setNodeLocationFull,\n  setNodeLocationOnlyOffset,\n} from \"../../cst/cst.js\";\nimport { has, isUndefined, keys, noop } from \"lodash-es\";\nimport {\n  createBaseSemanticVisitorConstructor,\n  createBaseVisitorConstructorWithDefaults,\n} from \"../../cst/cst_visitor.js\";\nimport {\n  CstNode,\n  CstNodeLocation,\n  ICstVisitor,\n  IParserConfig,\n  IToken,\n  nodeLocationTrackingOptions,\n} from \"@chevrotain/types\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\n/**\n * This trait is responsible for the CST building logic.\n */\nexport class TreeBuilder {\n  outputCst: boolean;\n  CST_STACK: CstNode[];\n  baseCstVisitorConstructor: Function;\n  baseCstVisitorWithDefaultsConstructor: Function;\n\n  // dynamically assigned Methods\n  setNodeLocationFromNode: (\n    nodeLocation: CstNodeLocation,\n    locationInformation: CstNodeLocation,\n  ) => void;\n  setNodeLocationFromToken: (\n    nodeLocation: CstNodeLocation,\n    locationInformation: CstNodeLocation,\n  ) => void;\n  cstPostRule: (this: MixedInParser, ruleCstNode: CstNode) => void;\n\n  setInitialNodeLocation: (cstNode: CstNode) => void;\n  nodeLocationTracking: nodeLocationTrackingOptions;\n\n  initTreeBuilder(this: MixedInParser, config: IParserConfig) {\n    this.CST_STACK = [];\n\n    // outputCst is no longer exposed/defined in the pubic API\n    this.outputCst = (config as any).outputCst;\n\n    this.nodeLocationTracking = has(config, \"nodeLocationTracking\")\n      ? (config.nodeLocationTracking as nodeLocationTrackingOptions) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.nodeLocationTracking;\n\n    if (!this.outputCst) {\n      this.cstInvocationStateUpdate = noop;\n      this.cstFinallyStateUpdate = noop;\n      this.cstPostTerminal = noop;\n      this.cstPostNonTerminal = noop;\n      this.cstPostRule = noop;\n    } else {\n      if (/full/i.test(this.nodeLocationTracking)) {\n        if (this.recoveryEnabled) {\n          this.setNodeLocationFromToken = setNodeLocationFull;\n          this.setNodeLocationFromNode = setNodeLocationFull;\n          this.cstPostRule = noop;\n          this.setInitialNodeLocation = this.setInitialNodeLocationFullRecovery;\n        } else {\n          this.setNodeLocationFromToken = noop;\n          this.setNodeLocationFromNode = noop;\n          this.cstPostRule = this.cstPostRuleFull;\n          this.setInitialNodeLocation = this.setInitialNodeLocationFullRegular;\n        }\n      } else if (/onlyOffset/i.test(this.nodeLocationTracking)) {\n        if (this.recoveryEnabled) {\n          this.setNodeLocationFromToken = <any>setNodeLocationOnlyOffset;\n          this.setNodeLocationFromNode = <any>setNodeLocationOnlyOffset;\n          this.cstPostRule = noop;\n          this.setInitialNodeLocation =\n            this.setInitialNodeLocationOnlyOffsetRecovery;\n        } else {\n          this.setNodeLocationFromToken = noop;\n          this.setNodeLocationFromNode = noop;\n          this.cstPostRule = this.cstPostRuleOnlyOffset;\n          this.setInitialNodeLocation =\n            this.setInitialNodeLocationOnlyOffsetRegular;\n        }\n      } else if (/none/i.test(this.nodeLocationTracking)) {\n        this.setNodeLocationFromToken = noop;\n        this.setNodeLocationFromNode = noop;\n        this.cstPostRule = noop;\n        this.setInitialNodeLocation = noop;\n      } else {\n        throw Error(\n          `Invalid <nodeLocationTracking> config option: \"${config.nodeLocationTracking}\"`,\n        );\n      }\n    }\n  }\n\n  setInitialNodeLocationOnlyOffsetRecovery(\n    this: MixedInParser,\n    cstNode: any,\n  ): void {\n    cstNode.location = {\n      startOffset: NaN,\n      endOffset: NaN,\n    };\n  }\n\n  setInitialNodeLocationOnlyOffsetRegular(\n    this: MixedInParser,\n    cstNode: any,\n  ): void {\n    cstNode.location = {\n      // without error recovery the starting Location of a new CstNode is guaranteed\n      // To be the next Token's startOffset (for valid inputs).\n      // For invalid inputs there won't be any CSTOutput so this potential\n      // inaccuracy does not matter\n      startOffset: this.LA(1).startOffset,\n      endOffset: NaN,\n    };\n  }\n\n  setInitialNodeLocationFullRecovery(this: MixedInParser, cstNode: any): void {\n    cstNode.location = {\n      startOffset: NaN,\n      startLine: NaN,\n      startColumn: NaN,\n      endOffset: NaN,\n      endLine: NaN,\n      endColumn: NaN,\n    };\n  }\n\n  /**\n     *  @see setInitialNodeLocationOnlyOffsetRegular for explanation why this work\n\n     * @param cstNode\n     */\n  setInitialNodeLocationFullRegular(this: MixedInParser, cstNode: any): void {\n    const nextToken = this.LA(1);\n    cstNode.location = {\n      startOffset: nextToken.startOffset,\n      startLine: nextToken.startLine,\n      startColumn: nextToken.startColumn,\n      endOffset: NaN,\n      endLine: NaN,\n      endColumn: NaN,\n    };\n  }\n\n  cstInvocationStateUpdate(this: MixedInParser, fullRuleName: string): void {\n    const cstNode: CstNode = {\n      name: fullRuleName,\n      children: Object.create(null),\n    };\n\n    this.setInitialNodeLocation(cstNode);\n    this.CST_STACK.push(cstNode);\n  }\n\n  cstFinallyStateUpdate(this: MixedInParser): void {\n    this.CST_STACK.pop();\n  }\n\n  cstPostRuleFull(this: MixedInParser, ruleCstNode: CstNode): void {\n    // casts to `required<CstNodeLocation>` are safe because `cstPostRuleFull` should only be invoked when full location is enabled\n    const prevToken = this.LA(0) as Required<CstNodeLocation>;\n    const loc = ruleCstNode.location as Required<CstNodeLocation>;\n\n    // If this condition is true it means we consumed at least one Token\n    // In this CstNode.\n    if (loc.startOffset <= prevToken.startOffset === true) {\n      loc.endOffset = prevToken.endOffset;\n      loc.endLine = prevToken.endLine;\n      loc.endColumn = prevToken.endColumn;\n    }\n    // \"empty\" CstNode edge case\n    else {\n      loc.startOffset = NaN;\n      loc.startLine = NaN;\n      loc.startColumn = NaN;\n    }\n  }\n\n  cstPostRuleOnlyOffset(this: MixedInParser, ruleCstNode: CstNode): void {\n    const prevToken = this.LA(0);\n    // `location' is not null because `cstPostRuleOnlyOffset` will only be invoked when location tracking is enabled.\n    const loc = ruleCstNode.location!;\n\n    // If this condition is true it means we consumed at least one Token\n    // In this CstNode.\n    if (loc.startOffset <= prevToken.startOffset === true) {\n      loc.endOffset = prevToken.endOffset;\n    }\n    // \"empty\" CstNode edge case\n    else {\n      loc.startOffset = NaN;\n    }\n  }\n\n  cstPostTerminal(\n    this: MixedInParser,\n    key: string,\n    consumedToken: IToken,\n  ): void {\n    const rootCst = this.CST_STACK[this.CST_STACK.length - 1];\n    addTerminalToCst(rootCst, consumedToken, key);\n    // This is only used when **both** error recovery and CST Output are enabled.\n    this.setNodeLocationFromToken(rootCst.location!, <any>consumedToken);\n  }\n\n  cstPostNonTerminal(\n    this: MixedInParser,\n    ruleCstResult: CstNode,\n    ruleName: string,\n  ): void {\n    const preCstNode = this.CST_STACK[this.CST_STACK.length - 1];\n    addNoneTerminalToCst(preCstNode, ruleName, ruleCstResult);\n    // This is only used when **both** error recovery and CST Output are enabled.\n    this.setNodeLocationFromNode(preCstNode.location!, ruleCstResult.location!);\n  }\n\n  getBaseCstVisitorConstructor<IN = any, OUT = any>(\n    this: MixedInParser,\n  ): {\n    new (...args: any[]): ICstVisitor<IN, OUT>;\n  } {\n    if (isUndefined(this.baseCstVisitorConstructor)) {\n      const newBaseCstVisitorConstructor = createBaseSemanticVisitorConstructor(\n        this.className,\n        keys(this.gastProductionsCache),\n      );\n      this.baseCstVisitorConstructor = newBaseCstVisitorConstructor;\n      return newBaseCstVisitorConstructor;\n    }\n\n    return <any>this.baseCstVisitorConstructor;\n  }\n\n  getBaseCstVisitorConstructorWithDefaults<IN = any, OUT = any>(\n    this: MixedInParser,\n  ): {\n    new (...args: any[]): ICstVisitor<IN, OUT>;\n  } {\n    if (isUndefined(this.baseCstVisitorWithDefaultsConstructor)) {\n      const newConstructor = createBaseVisitorConstructorWithDefaults(\n        this.className,\n        keys(this.gastProductionsCache),\n        this.getBaseCstVisitorConstructor(),\n      );\n      this.baseCstVisitorWithDefaultsConstructor = newConstructor;\n      return newConstructor;\n    }\n\n    return <any>this.baseCstVisitorWithDefaultsConstructor;\n  }\n\n  getLastExplicitRuleShortName(this: MixedInParser): number {\n    const ruleStack = this.RULE_STACK;\n    return ruleStack[ruleStack.length - 1];\n  }\n\n  getPreviousExplicitRuleShortName(this: MixedInParser): number {\n    const ruleStack = this.RULE_STACK;\n    return ruleStack[ruleStack.length - 2];\n  }\n\n  getLastExplicitRuleOccurrenceIndex(this: MixedInParser): number {\n    const occurrenceStack = this.RULE_OCCURRENCE_STACK;\n    return occurrenceStack[occurrenceStack.length - 1];\n  }\n}\n","import { flatten, isArray, map, reduce, uniq, upperFirst } from \"lodash-es\";\nimport { GenerateDtsOptions } from \"@chevrotain/types\";\nimport {\n  CstNodeTypeDefinition,\n  PropertyArrayType,\n  PropertyTypeDefinition,\n  RuleArrayType,\n  TokenArrayType,\n} from \"./model.js\";\n\nexport function genDts(\n  model: CstNodeTypeDefinition[],\n  options: Required<GenerateDtsOptions>,\n): string {\n  let contentParts: string[] = [];\n\n  contentParts = contentParts.concat(\n    `import type { CstNode, ICstVisitor, IToken } from \"chevrotain\";`,\n  );\n\n  contentParts = contentParts.concat(\n    flatten(map(model, (node) => genCstNodeTypes(node))),\n  );\n\n  if (options.includeVisitorInterface) {\n    contentParts = contentParts.concat(\n      genVisitor(options.visitorInterfaceName, model),\n    );\n  }\n\n  return contentParts.join(\"\\n\\n\") + \"\\n\";\n}\n\nfunction genCstNodeTypes(node: CstNodeTypeDefinition) {\n  const nodeCstInterface = genNodeInterface(node);\n  const nodeChildrenInterface = genNodeChildrenType(node);\n\n  return [nodeCstInterface, nodeChildrenInterface];\n}\n\nfunction genNodeInterface(node: CstNodeTypeDefinition) {\n  const nodeInterfaceName = getNodeInterfaceName(node.name);\n  const childrenTypeName = getNodeChildrenTypeName(node.name);\n\n  return `export interface ${nodeInterfaceName} extends CstNode {\n  name: \"${node.name}\";\n  children: ${childrenTypeName};\n}`;\n}\n\nfunction genNodeChildrenType(node: CstNodeTypeDefinition) {\n  const typeName = getNodeChildrenTypeName(node.name);\n\n  return `export type ${typeName} = {\n  ${map(node.properties, (property) => genChildProperty(property)).join(\"\\n  \")}\n};`;\n}\n\nfunction genChildProperty(prop: PropertyTypeDefinition) {\n  const typeName = buildTypeString(prop.type);\n  return `${prop.name}${prop.optional ? \"?\" : \"\"}: ${typeName}[];`;\n}\n\nfunction genVisitor(name: string, nodes: CstNodeTypeDefinition[]) {\n  return `export interface ${name}<IN, OUT> extends ICstVisitor<IN, OUT> {\n  ${map(nodes, (node) => genVisitorFunction(node)).join(\"\\n  \")}\n}`;\n}\n\nfunction genVisitorFunction(node: CstNodeTypeDefinition) {\n  const childrenTypeName = getNodeChildrenTypeName(node.name);\n  return `${node.name}(children: ${childrenTypeName}, param?: IN): OUT;`;\n}\n\nfunction buildTypeString(type: PropertyArrayType) {\n  if (isArray(type)) {\n    const typeNames = uniq(map(type, (t) => getTypeString(t)));\n    const typeString = reduce(typeNames, (sum, t) => sum + \" | \" + t);\n    return \"(\" + typeString + \")\";\n  } else {\n    return getTypeString(type);\n  }\n}\n\nfunction getTypeString(type: TokenArrayType | RuleArrayType) {\n  if (type.kind === \"token\") {\n    return \"IToken\";\n  }\n  return getNodeInterfaceName(type.name);\n}\n\nfunction getNodeInterfaceName(ruleName: string) {\n  return upperFirst(ruleName) + \"CstNode\";\n}\n\nfunction getNodeChildrenTypeName(ruleName: string) {\n  return upperFirst(ruleName) + \"CstChildren\";\n}\n","import {\n  clone,\n  compact,\n  difference,\n  flatten,\n  forEach,\n  has,\n  includes,\n  isArray,\n  isEmpty,\n  map,\n} from \"lodash-es\";\nimport { IToken, TokenType } from \"@chevrotain/types\";\n\nexport function tokenStructuredMatcher(\n  tokInstance: IToken,\n  tokConstructor: TokenType,\n) {\n  const instanceType = tokInstance.tokenTypeIdx;\n  if (instanceType === tokConstructor.tokenTypeIdx) {\n    return true;\n  } else {\n    return (\n      tokConstructor.isParent === true &&\n      tokConstructor.categoryMatchesMap![instanceType] === true\n    );\n  }\n}\n\n// Optimized tokenMatcher in case our grammar does not use token categories\n// Being so tiny it is much more likely to be in-lined and this avoid the function call overhead\nexport function tokenStructuredMatcherNoCategories(\n  token: IToken,\n  tokType: TokenType,\n) {\n  return token.tokenTypeIdx === tokType.tokenTypeIdx;\n}\n\nexport let tokenShortNameIdx = 1;\nexport const tokenIdxToClass: { [tokenIdx: number]: TokenType } = {};\n\nexport function augmentTokenTypes(tokenTypes: TokenType[]): void {\n  // collect the parent Token Types as well.\n  const tokenTypesAndParents = expandCategories(tokenTypes);\n\n  // add required tokenType and categoryMatches properties\n  assignTokenDefaultProps(tokenTypesAndParents);\n\n  // fill up the categoryMatches\n  assignCategoriesMapProp(tokenTypesAndParents);\n  assignCategoriesTokensProp(tokenTypesAndParents);\n\n  forEach(tokenTypesAndParents, (tokType) => {\n    tokType.isParent = tokType.categoryMatches!.length > 0;\n  });\n}\n\nexport function expandCategories(tokenTypes: TokenType[]): TokenType[] {\n  let result = clone(tokenTypes);\n\n  let categories = tokenTypes;\n  let searching = true;\n  while (searching) {\n    categories = compact(\n      flatten(map(categories, (currTokType) => currTokType.CATEGORIES)),\n    );\n\n    const newCategories = difference(categories, result);\n\n    result = result.concat(newCategories);\n\n    if (isEmpty(newCategories)) {\n      searching = false;\n    } else {\n      categories = newCategories;\n    }\n  }\n  return result;\n}\n\nexport function assignTokenDefaultProps(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    if (!hasShortKeyProperty(currTokType)) {\n      tokenIdxToClass[tokenShortNameIdx] = currTokType;\n      (<any>currTokType).tokenTypeIdx = tokenShortNameIdx++;\n    }\n\n    // CATEGORIES? : TokenType | TokenType[]\n    if (\n      hasCategoriesProperty(currTokType) &&\n      !isArray(currTokType.CATEGORIES)\n      // &&\n      // !isUndefined(currTokType.CATEGORIES.PATTERN)\n    ) {\n      currTokType.CATEGORIES = [currTokType.CATEGORIES as unknown as TokenType];\n    }\n\n    if (!hasCategoriesProperty(currTokType)) {\n      currTokType.CATEGORIES = [];\n    }\n\n    if (!hasExtendingTokensTypesProperty(currTokType)) {\n      currTokType.categoryMatches = [];\n    }\n\n    if (!hasExtendingTokensTypesMapProperty(currTokType)) {\n      currTokType.categoryMatchesMap = {};\n    }\n  });\n}\n\nexport function assignCategoriesTokensProp(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    // avoid duplications\n    currTokType.categoryMatches = [];\n    forEach(currTokType.categoryMatchesMap!, (val, key) => {\n      currTokType.categoryMatches!.push(\n        tokenIdxToClass[key as unknown as number].tokenTypeIdx!,\n      );\n    });\n  });\n}\n\nexport function assignCategoriesMapProp(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    singleAssignCategoriesToksMap([], currTokType);\n  });\n}\n\nexport function singleAssignCategoriesToksMap(\n  path: TokenType[],\n  nextNode: TokenType,\n): void {\n  forEach(path, (pathNode) => {\n    nextNode.categoryMatchesMap![pathNode.tokenTypeIdx!] = true;\n  });\n\n  forEach(nextNode.CATEGORIES, (nextCategory) => {\n    const newPath = path.concat(nextNode);\n    // avoids infinite loops due to cyclic categories.\n    if (!includes(newPath, nextCategory)) {\n      singleAssignCategoriesToksMap(newPath, nextCategory);\n    }\n  });\n}\n\nexport function hasShortKeyProperty(tokType: TokenType): boolean {\n  return has(tokType, \"tokenTypeIdx\");\n}\n\nexport function hasCategoriesProperty(tokType: TokenType): boolean {\n  return has(tokType, \"CATEGORIES\");\n}\n\nexport function hasExtendingTokensTypesProperty(tokType: TokenType): boolean {\n  return has(tokType, \"categoryMatches\");\n}\n\nexport function hasExtendingTokensTypesMapProperty(\n  tokType: TokenType,\n): boolean {\n  return has(tokType, \"categoryMatchesMap\");\n}\n\nexport function isTokenType(tokType: TokenType): boolean {\n  return has(tokType, \"tokenTypeIdx\");\n}\n","import { assign, forEach, isRegExp, isString, map, pickBy } from \"lodash-es\";\nimport type {\n  IGASTVisitor,\n  IProduction,\n  IProductionWithOccurrence,\n  ISerializedGast,\n  TokenType,\n} from \"@chevrotain/types\";\n\n// TODO: duplicated code to avoid extracting another sub-package -- how to avoid?\nfunction tokenLabel(tokType: TokenType): string {\n  if (hasTokenLabel(tokType)) {\n    return tokType.LABEL;\n  } else {\n    return tokType.name;\n  }\n}\n\n// TODO: duplicated code to avoid extracting another sub-package -- how to avoid?\nfunction hasTokenLabel(\n  obj: TokenType,\n): obj is TokenType & Pick<Required<TokenType>, \"LABEL\"> {\n  return isString(obj.LABEL) && obj.LABEL !== \"\";\n}\n\nexport abstract class AbstractProduction<T extends IProduction = IProduction>\n  implements IProduction\n{\n  public get definition(): T[] {\n    return this._definition;\n  }\n  public set definition(value: T[]) {\n    this._definition = value;\n  }\n\n  constructor(protected _definition: T[]) {}\n\n  accept(visitor: IGASTVisitor): void {\n    visitor.visit(this);\n    forEach(this.definition, (prod) => {\n      prod.accept(visitor);\n    });\n  }\n}\n\nexport class NonTerminal\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public nonTerminalName!: string;\n  public label?: string;\n  public referencedRule!: Rule;\n  public idx: number = 1;\n\n  constructor(options: {\n    nonTerminalName: string;\n    label?: string;\n    referencedRule?: Rule;\n    idx?: number;\n  }) {\n    super([]);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n\n  set definition(definition: IProduction[]) {\n    // immutable\n  }\n\n  get definition(): IProduction[] {\n    if (this.referencedRule !== undefined) {\n      return this.referencedRule.definition;\n    }\n    return [];\n  }\n\n  accept(visitor: IGASTVisitor): void {\n    visitor.visit(this);\n    // don't visit children of a reference, we will get cyclic infinite loops if we do so\n  }\n}\n\nexport class Rule extends AbstractProduction {\n  public name!: string;\n  public orgText: string = \"\";\n\n  constructor(options: {\n    name: string;\n    definition: IProduction[];\n    orgText?: string;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Alternative extends AbstractProduction {\n  public ignoreAmbiguities: boolean = false;\n\n  constructor(options: {\n    definition: IProduction[];\n    ignoreAmbiguities?: boolean;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Option\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    idx?: number;\n    maxLookahead?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class RepetitionMandatory\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    idx?: number;\n    maxLookahead?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class RepetitionMandatoryWithSeparator\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public separator!: TokenType;\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    separator: TokenType;\n    idx?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Repetition\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public separator!: TokenType;\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    idx?: number;\n    maxLookahead?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class RepetitionWithSeparator\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public separator!: TokenType;\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    separator: TokenType;\n    idx?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Alternation\n  extends AbstractProduction<Alternative>\n  implements IProductionWithOccurrence\n{\n  public idx: number = 1;\n  public ignoreAmbiguities: boolean = false;\n  public hasPredicates: boolean = false;\n  public maxLookahead?: number;\n\n  public get definition(): Alternative[] {\n    return this._definition;\n  }\n  public set definition(value: Alternative[]) {\n    this._definition = value;\n  }\n\n  constructor(options: {\n    definition: Alternative[];\n    idx?: number;\n    ignoreAmbiguities?: boolean;\n    hasPredicates?: boolean;\n    maxLookahead?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Terminal implements IProductionWithOccurrence {\n  public terminalType!: TokenType;\n  public label?: string;\n  public idx: number = 1;\n\n  constructor(options: {\n    terminalType: TokenType;\n    label?: string;\n    idx?: number;\n  }) {\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n\n  accept(visitor: IGASTVisitor): void {\n    visitor.visit(this);\n  }\n}\n\nexport interface ISerializedBasic extends ISerializedGast {\n  type:\n    | \"Alternative\"\n    | \"Option\"\n    | \"RepetitionMandatory\"\n    | \"Repetition\"\n    | \"Alternation\";\n  idx?: number;\n}\n\nexport interface ISerializedGastRule extends ISerializedGast {\n  type: \"Rule\";\n  name: string;\n  orgText: string;\n}\n\nexport interface ISerializedNonTerminal extends ISerializedGast {\n  type: \"NonTerminal\";\n  name: string;\n  label?: string;\n  idx: number;\n}\n\nexport interface ISerializedTerminal extends ISerializedGast {\n  type: \"Terminal\";\n  name: string;\n  terminalLabel?: string;\n  label?: string;\n  pattern?: string;\n  idx: number;\n}\n\nexport interface ISerializedTerminalWithSeparator extends ISerializedGast {\n  type: \"RepetitionMandatoryWithSeparator\" | \"RepetitionWithSeparator\";\n  idx: number;\n  separator: ISerializedTerminal;\n}\n\nexport type ISerializedGastAny =\n  | ISerializedBasic\n  | ISerializedGastRule\n  | ISerializedNonTerminal\n  | ISerializedTerminal\n  | ISerializedTerminalWithSeparator;\n\nexport function serializeGrammar(topRules: Rule[]): ISerializedGast[] {\n  return map(topRules, serializeProduction);\n}\n\nexport function serializeProduction(node: IProduction): ISerializedGast {\n  function convertDefinition(definition: IProduction[]): ISerializedGast[] {\n    return map(definition, serializeProduction);\n  }\n  /* istanbul ignore else */\n  if (node instanceof NonTerminal) {\n    const serializedNonTerminal: ISerializedNonTerminal = {\n      type: \"NonTerminal\",\n      name: node.nonTerminalName,\n      idx: node.idx,\n    };\n\n    if (isString(node.label)) {\n      serializedNonTerminal.label = node.label;\n    }\n\n    return serializedNonTerminal;\n  } else if (node instanceof Alternative) {\n    return <ISerializedBasic>{\n      type: \"Alternative\",\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof Option) {\n    return <ISerializedBasic>{\n      type: \"Option\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof RepetitionMandatory) {\n    return <ISerializedBasic>{\n      type: \"RepetitionMandatory\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof RepetitionMandatoryWithSeparator) {\n    return <ISerializedTerminalWithSeparator>{\n      type: \"RepetitionMandatoryWithSeparator\",\n      idx: node.idx,\n      separator: <ISerializedTerminal>(\n        serializeProduction(new Terminal({ terminalType: node.separator }))\n      ),\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof RepetitionWithSeparator) {\n    return <ISerializedTerminalWithSeparator>{\n      type: \"RepetitionWithSeparator\",\n      idx: node.idx,\n      separator: <ISerializedTerminal>(\n        serializeProduction(new Terminal({ terminalType: node.separator }))\n      ),\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof Repetition) {\n    return <ISerializedBasic>{\n      type: \"Repetition\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof Alternation) {\n    return <ISerializedBasic>{\n      type: \"Alternation\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof Terminal) {\n    const serializedTerminal = <ISerializedTerminal>{\n      type: \"Terminal\",\n      name: node.terminalType.name,\n      label: tokenLabel(node.terminalType),\n      idx: node.idx,\n    };\n\n    if (isString(node.label)) {\n      serializedTerminal.terminalLabel = node.label;\n    }\n\n    const pattern = node.terminalType.PATTERN;\n    if (node.terminalType.PATTERN) {\n      serializedTerminal.pattern = isRegExp(pattern)\n        ? (<any>pattern).source\n        : pattern;\n    }\n\n    return serializedTerminal;\n  } else if (node instanceof Rule) {\n    return <ISerializedGastRule>{\n      type: \"Rule\",\n      name: node.name,\n      orgText: node.orgText,\n      definition: convertDefinition(node.definition),\n    };\n    /* c8 ignore next 3 */\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n","import { flatten, map, uniq } from \"lodash-es\";\nimport {\n  isBranchingProd,\n  isOptionalProd,\n  isSequenceProd,\n  NonTerminal,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport { IProduction, TokenType } from \"@chevrotain/types\";\n\nexport function first(prod: IProduction): TokenType[] {\n  /* istanbul ignore else */\n  if (prod instanceof NonTerminal) {\n    // this could in theory cause infinite loops if\n    // (1) prod A refs prod B.\n    // (2) prod B refs prod A\n    // (3) AB can match the empty set\n    // in other words a cycle where everything is optional so the first will keep\n    // looking ahead for the next optional part and will never exit\n    // currently there is no safeguard for this unique edge case because\n    // (1) not sure a grammar in which this can happen is useful for anything (productive)\n    return first((<NonTerminal>prod).referencedRule);\n  } else if (prod instanceof Terminal) {\n    return firstForTerminal(<Terminal>prod);\n  } else if (isSequenceProd(prod)) {\n    return firstForSequence(prod);\n  } else if (isBranchingProd(prod)) {\n    return firstForBranching(prod);\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexport function firstForSequence(prod: {\n  definition: IProduction[];\n}): TokenType[] {\n  let firstSet: TokenType[] = [];\n  const seq = prod.definition;\n  let nextSubProdIdx = 0;\n  let hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n  let currSubProd;\n  // so we enter the loop at least once (if the definition is not empty\n  let isLastInnerProdOptional = true;\n  // scan a sequence until it's end or until we have found a NONE optional production in it\n  while (hasInnerProdsRemaining && isLastInnerProdOptional) {\n    currSubProd = seq[nextSubProdIdx];\n    isLastInnerProdOptional = isOptionalProd(currSubProd);\n    firstSet = firstSet.concat(first(currSubProd));\n    nextSubProdIdx = nextSubProdIdx + 1;\n    hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n  }\n\n  return uniq(firstSet);\n}\n\nexport function firstForBranching(prod: {\n  definition: IProduction[];\n}): TokenType[] {\n  const allAlternativesFirsts: TokenType[][] = map(\n    prod.definition,\n    (innerProd) => {\n      return first(innerProd);\n    },\n  );\n  return uniq(flatten<TokenType>(allAlternativesFirsts));\n}\n\nexport function firstForTerminal(terminal: Terminal): TokenType[] {\n  return [terminal.terminalType];\n}\n","import { VERSION } from \"../version.js\";\nimport { ISerializedGast } from \"@chevrotain/types\";\n\nexport function createSyntaxDiagramsCode(\n  grammar: ISerializedGast[],\n  {\n    resourceBase = `https://unpkg.com/chevrotain@${VERSION}/diagrams/`,\n    css = `https://unpkg.com/chevrotain@${VERSION}/diagrams/diagrams.css`,\n  }: {\n    resourceBase?: string;\n    css?: string;\n  } = {},\n) {\n  const header = `\n<!-- This is a generated file -->\n<!DOCTYPE html>\n<meta charset=\"utf-8\">\n<style>\n  body {\n    background-color: hsl(30, 20%, 95%)\n  }\n</style>\n\n`;\n  const cssHtml = `\n<link rel='stylesheet' href='${css}'>\n`;\n\n  const scripts = `\n<script src='${resourceBase}vendor/railroad-diagrams.js'></script>\n<script src='${resourceBase}src/diagrams_builder.js'></script>\n<script src='${resourceBase}src/diagrams_behavior.js'></script>\n<script src='${resourceBase}src/main.js'></script>\n`;\n  const diagramsDiv = `\n<div id=\"diagrams\" align=\"center\"></div>    \n`;\n  const serializedGrammar = `\n<script>\n    window.serializedGrammar = ${JSON.stringify(grammar, null, \"  \")};\n</script>\n`;\n\n  const initLogic = `\n<script>\n    var diagramsDiv = document.getElementById(\"diagrams\");\n    main.drawDiagramsFromSerializedGrammar(serializedGrammar, diagramsDiv);\n</script>\n`;\n  return (\n    header + cssHtml + scripts + diagramsDiv + serializedGrammar + initLogic\n  );\n}\n","import {\n  AtLeastOneSepMethodOpts,\n  ConsumeMethodOpts,\n  DSLMethodOpts,\n  DSLMethodOptsWithErr,\n  GrammarAction,\n  IOrAlt,\n  IParserConfig,\n  IRuleConfig,\n  IToken,\n  ManySepMethodOpts,\n  OrMethodOpts,\n  ParserMethod,\n  SubruleMethodOpts,\n  TokenType,\n  TokenTypeDictionary,\n  TokenVocabulary,\n} from \"@chevrotain/types\";\nimport {\n  clone,\n  every,\n  flatten,\n  has,\n  isArray,\n  isEmpty,\n  isObject,\n  reduce,\n  uniq,\n  values,\n} from \"lodash-es\";\nimport {\n  AT_LEAST_ONE_IDX,\n  AT_LEAST_ONE_SEP_IDX,\n  BITS_FOR_METHOD_TYPE,\n  BITS_FOR_OCCURRENCE_IDX,\n  MANY_IDX,\n  MANY_SEP_IDX,\n  OPTION_IDX,\n  OR_IDX,\n} from \"../../grammar/keys.js\";\nimport {\n  isRecognitionException,\n  MismatchedTokenException,\n  NotAllInputParsedException,\n} from \"../../exceptions_public.js\";\nimport { PROD_TYPE } from \"../../grammar/lookahead.js\";\nimport {\n  AbstractNextTerminalAfterProductionWalker,\n  NextTerminalAfterAtLeastOneSepWalker,\n  NextTerminalAfterAtLeastOneWalker,\n  NextTerminalAfterManySepWalker,\n  NextTerminalAfterManyWalker,\n} from \"../../grammar/interpreter.js\";\nimport { DEFAULT_RULE_CONFIG, IParserState, TokenMatcher } from \"../parser.js\";\nimport { IN_RULE_RECOVERY_EXCEPTION } from \"./recoverable.js\";\nimport { EOF } from \"../../../scan/tokens_public.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport {\n  augmentTokenTypes,\n  isTokenType,\n  tokenStructuredMatcher,\n  tokenStructuredMatcherNoCategories,\n} from \"../../../scan/tokens.js\";\nimport { Rule } from \"@chevrotain/gast\";\nimport { ParserMethodInternal } from \"../types.js\";\n\n/**\n * This trait is responsible for the runtime parsing engine\n * Used by the official API (recognizer_api.ts)\n */\nexport class RecognizerEngine {\n  isBackTrackingStack: boolean[];\n  className: string;\n  RULE_STACK: number[];\n  RULE_OCCURRENCE_STACK: number[];\n  definedRulesNames: string[];\n  tokensMap: { [fqn: string]: TokenType };\n  gastProductionsCache: Record<string, Rule>;\n  shortRuleNameToFull: Record<string, string>;\n  fullRuleNameToShort: Record<string, number>;\n  // The shortName Index must be coded \"after\" the first 8bits to enable building unique lookahead keys\n  ruleShortNameIdx: number;\n  tokenMatcher: TokenMatcher;\n  subruleIdx: number;\n\n  initRecognizerEngine(\n    tokenVocabulary: TokenVocabulary,\n    config: IParserConfig,\n  ) {\n    this.className = this.constructor.name;\n    // TODO: would using an ES6 Map or plain object be faster (CST building scenario)\n    this.shortRuleNameToFull = {};\n    this.fullRuleNameToShort = {};\n    this.ruleShortNameIdx = 256;\n    this.tokenMatcher = tokenStructuredMatcherNoCategories;\n    this.subruleIdx = 0;\n\n    this.definedRulesNames = [];\n    this.tokensMap = {};\n    this.isBackTrackingStack = [];\n    this.RULE_STACK = [];\n    this.RULE_OCCURRENCE_STACK = [];\n    this.gastProductionsCache = {};\n\n    if (has(config, \"serializedGrammar\")) {\n      throw Error(\n        \"The Parser's configuration can no longer contain a <serializedGrammar> property.\\n\" +\n          \"\\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_6-0-0\\n\" +\n          \"\\tFor Further details.\",\n      );\n    }\n\n    if (isArray(tokenVocabulary)) {\n      // This only checks for Token vocabularies provided as arrays.\n      // That is good enough because the main objective is to detect users of pre-V4.0 APIs\n      // rather than all edge cases of empty Token vocabularies.\n      if (isEmpty(tokenVocabulary as any[])) {\n        throw Error(\n          \"A Token Vocabulary cannot be empty.\\n\" +\n            \"\\tNote that the first argument for the parser constructor\\n\" +\n            \"\\tis no longer a Token vector (since v4.0).\",\n        );\n      }\n\n      if (typeof (tokenVocabulary as any[])[0].startOffset === \"number\") {\n        throw Error(\n          \"The Parser constructor no longer accepts a token vector as the first argument.\\n\" +\n            \"\\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_4-0-0\\n\" +\n            \"\\tFor Further details.\",\n        );\n      }\n    }\n\n    if (isArray(tokenVocabulary)) {\n      this.tokensMap = reduce(\n        tokenVocabulary,\n        (acc, tokType: TokenType) => {\n          acc[tokType.name] = tokType;\n          return acc;\n        },\n        {} as { [tokenName: string]: TokenType },\n      );\n    } else if (\n      has(tokenVocabulary, \"modes\") &&\n      every(flatten(values((<any>tokenVocabulary).modes)), isTokenType)\n    ) {\n      const allTokenTypes = flatten(values((<any>tokenVocabulary).modes));\n      const uniqueTokens = uniq(allTokenTypes);\n      this.tokensMap = <any>reduce(\n        uniqueTokens,\n        (acc, tokType: TokenType) => {\n          acc[tokType.name] = tokType;\n          return acc;\n        },\n        {} as { [tokenName: string]: TokenType },\n      );\n    } else if (isObject(tokenVocabulary)) {\n      this.tokensMap = clone(tokenVocabulary as TokenTypeDictionary);\n    } else {\n      throw new Error(\n        \"<tokensDictionary> argument must be An Array of Token constructors,\" +\n          \" A dictionary of Token constructors or an IMultiModeLexerDefinition\",\n      );\n    }\n\n    // always add EOF to the tokenNames -> constructors map. it is useful to assure all the input has been\n    // parsed with a clear error message (\"expecting EOF but found ...\")\n    this.tokensMap[\"EOF\"] = EOF;\n\n    const allTokenTypes = has(tokenVocabulary, \"modes\")\n      ? flatten(values((<any>tokenVocabulary).modes))\n      : values(tokenVocabulary);\n    const noTokenCategoriesUsed = every(allTokenTypes, (tokenConstructor) =>\n      isEmpty(tokenConstructor.categoryMatches),\n    );\n\n    this.tokenMatcher = noTokenCategoriesUsed\n      ? tokenStructuredMatcherNoCategories\n      : tokenStructuredMatcher;\n\n    // Because ES2015+ syntax should be supported for creating Token classes\n    // We cannot assume that the Token classes were created using the \"extendToken\" utilities\n    // Therefore we must augment the Token classes both on Lexer initialization and on Parser initialization\n    augmentTokenTypes(values(this.tokensMap));\n  }\n\n  defineRule<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleName: string,\n    impl: (...args: ARGS) => R,\n    config: IRuleConfig<R>,\n  ): ParserMethodInternal<ARGS, R> {\n    if (this.selfAnalysisDone) {\n      throw Error(\n        `Grammar rule <${ruleName}> may not be defined after the 'performSelfAnalysis' method has been called'\\n` +\n          `Make sure that all grammar rule definitions are done before 'performSelfAnalysis' is called.`,\n      );\n    }\n    const resyncEnabled: boolean = has(config, \"resyncEnabled\")\n      ? (config.resyncEnabled as boolean) // assumes end user provides the correct config value/type\n      : DEFAULT_RULE_CONFIG.resyncEnabled;\n    const recoveryValueFunc = has(config, \"recoveryValueFunc\")\n      ? (config.recoveryValueFunc as () => R) // assumes end user provides the correct config value/type\n      : DEFAULT_RULE_CONFIG.recoveryValueFunc;\n\n    // performance optimization: Use small integers as keys for the longer human readable \"full\" rule names.\n    // this greatly improves Map access time (as much as 8% for some performance benchmarks).\n    const shortName =\n      this.ruleShortNameIdx << (BITS_FOR_METHOD_TYPE + BITS_FOR_OCCURRENCE_IDX);\n\n    this.ruleShortNameIdx++;\n    this.shortRuleNameToFull[shortName] = ruleName;\n    this.fullRuleNameToShort[ruleName] = shortName;\n\n    let invokeRuleWithTry: ParserMethod<ARGS, R>;\n\n    // Micro optimization, only check the condition **once** on rule definition\n    // instead of **every single** rule invocation.\n    if (this.outputCst === true) {\n      invokeRuleWithTry = function invokeRuleWithTry(\n        this: MixedInParser,\n        ...args: ARGS\n      ): R {\n        try {\n          this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n          impl.apply(this, args);\n          const cst = this.CST_STACK[this.CST_STACK.length - 1];\n          this.cstPostRule(cst);\n          return cst as unknown as R;\n        } catch (e) {\n          return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc) as R;\n        } finally {\n          this.ruleFinallyStateUpdate();\n        }\n      };\n    } else {\n      invokeRuleWithTry = function invokeRuleWithTryCst(\n        this: MixedInParser,\n        ...args: ARGS\n      ): R {\n        try {\n          this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n          return impl.apply(this, args);\n        } catch (e) {\n          return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc) as R;\n        } finally {\n          this.ruleFinallyStateUpdate();\n        }\n      };\n    }\n\n    const wrappedGrammarRule: ParserMethodInternal<ARGS, R> = Object.assign(\n      invokeRuleWithTry as any,\n      { ruleName, originalGrammarAction: impl },\n    );\n\n    return wrappedGrammarRule;\n  }\n\n  invokeRuleCatch(\n    this: MixedInParser,\n    e: Error,\n    resyncEnabledConfig: boolean,\n    recoveryValueFunc: Function,\n  ): unknown {\n    const isFirstInvokedRule = this.RULE_STACK.length === 1;\n    // note the reSync is always enabled for the first rule invocation, because we must always be able to\n    // reSync with EOF and just output some INVALID ParseTree\n    // during backtracking reSync recovery is disabled, otherwise we can't be certain the backtracking\n    // path is really the most valid one\n    const reSyncEnabled =\n      resyncEnabledConfig && !this.isBackTracking() && this.recoveryEnabled;\n\n    if (isRecognitionException(e)) {\n      const recogError: any = e;\n      if (reSyncEnabled) {\n        const reSyncTokType = this.findReSyncTokenType();\n        if (this.isInCurrentRuleReSyncSet(reSyncTokType)) {\n          recogError.resyncedTokens = this.reSyncTo(reSyncTokType);\n          if (this.outputCst) {\n            const partialCstResult: any =\n              this.CST_STACK[this.CST_STACK.length - 1];\n            partialCstResult.recoveredNode = true;\n            return partialCstResult;\n          } else {\n            return recoveryValueFunc(e);\n          }\n        } else {\n          if (this.outputCst) {\n            const partialCstResult: any =\n              this.CST_STACK[this.CST_STACK.length - 1];\n            partialCstResult.recoveredNode = true;\n            recogError.partialCstResult = partialCstResult;\n          }\n          // to be handled Further up the call stack\n          throw recogError;\n        }\n      } else if (isFirstInvokedRule) {\n        // otherwise a Redundant input error will be created as well and we cannot guarantee that this is indeed the case\n        this.moveToTerminatedState();\n        // the parser should never throw one of its own errors outside its flow.\n        // even if error recovery is disabled\n        return recoveryValueFunc(e);\n      } else {\n        // to be recovered Further up the call stack\n        throw recogError;\n      }\n    } else {\n      // some other Error type which we don't know how to handle (for example a built in JavaScript Error)\n      throw e;\n    }\n  }\n\n  // Implementation of parsing DSL\n  optionInternal<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    occurrence: number,\n  ): OUT | undefined {\n    const key = this.getKeyForAutomaticLookahead(OPTION_IDX, occurrence);\n    return this.optionInternalLogic(actionORMethodDef, occurrence, key);\n  }\n\n  optionInternalLogic<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    occurrence: number,\n    key: number,\n  ): OUT | undefined {\n    let lookAheadFunc = this.getLaFuncFromCache(key);\n    let action: GrammarAction<OUT>;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      // predicate present\n      if (predicate !== undefined) {\n        const orgLookaheadFunction = lookAheadFunc;\n        lookAheadFunc = () => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        };\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n\n    if (lookAheadFunc.call(this) === true) {\n      return action.call(this);\n    }\n    return undefined;\n  }\n\n  atLeastOneInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(\n      AT_LEAST_ONE_IDX,\n      prodOccurrence,\n    );\n    return this.atLeastOneInternalLogic(\n      prodOccurrence,\n      actionORMethodDef,\n      laKey,\n    );\n  }\n\n  atLeastOneInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n    key: number,\n  ): void {\n    let lookAheadFunc = this.getLaFuncFromCache(key);\n    let action;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      // predicate present\n      if (predicate !== undefined) {\n        const orgLookaheadFunction = lookAheadFunc;\n        lookAheadFunc = () => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        };\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n\n    if ((<Function>lookAheadFunc).call(this) === true) {\n      let notStuck = this.doSingleRepetition(action);\n      while (\n        (<Function>lookAheadFunc).call(this) === true &&\n        notStuck === true\n      ) {\n        notStuck = this.doSingleRepetition(action);\n      }\n    } else {\n      throw this.raiseEarlyExitException(\n        prodOccurrence,\n        PROD_TYPE.REPETITION_MANDATORY,\n        (<DSLMethodOptsWithErr<OUT>>actionORMethodDef).ERR_MSG,\n      );\n    }\n\n    // note that while it may seem that this can cause an error because by using a recursive call to\n    // AT_LEAST_ONE we change the grammar to AT_LEAST_TWO, AT_LEAST_THREE ... , the possible recursive call\n    // from the tryInRepetitionRecovery(...) will only happen IFF there really are TWO/THREE/.... items.\n\n    // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n    this.attemptInRepetitionRecovery(\n      this.atLeastOneInternal,\n      [prodOccurrence, actionORMethodDef],\n      <any>lookAheadFunc,\n      AT_LEAST_ONE_IDX,\n      prodOccurrence,\n      NextTerminalAfterAtLeastOneWalker,\n    );\n  }\n\n  atLeastOneSepFirstInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(\n      AT_LEAST_ONE_SEP_IDX,\n      prodOccurrence,\n    );\n    this.atLeastOneSepFirstInternalLogic(prodOccurrence, options, laKey);\n  }\n\n  atLeastOneSepFirstInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: AtLeastOneSepMethodOpts<OUT>,\n    key: number,\n  ): void {\n    const action = options.DEF;\n    const separator = options.SEP;\n\n    const firstIterationLookaheadFunc = this.getLaFuncFromCache(key);\n\n    // 1st iteration\n    if (firstIterationLookaheadFunc.call(this) === true) {\n      (<GrammarAction<OUT>>action).call(this);\n\n      //  TODO: Optimization can move this function construction into \"attemptInRepetitionRecovery\"\n      //  because it is only needed in error recovery scenarios.\n      const separatorLookAheadFunc = () => {\n        return this.tokenMatcher(this.LA(1), separator);\n      };\n\n      // 2nd..nth iterations\n      while (this.tokenMatcher(this.LA(1), separator) === true) {\n        // note that this CONSUME will never enter recovery because\n        // the separatorLookAheadFunc checks that the separator really does exist.\n        this.CONSUME(separator);\n        // No need for checking infinite loop here due to consuming the separator.\n        (<GrammarAction<OUT>>action).call(this);\n      }\n\n      // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n      this.attemptInRepetitionRecovery(\n        this.repetitionSepSecondInternal,\n        [\n          prodOccurrence,\n          separator,\n          separatorLookAheadFunc,\n          action,\n          NextTerminalAfterAtLeastOneSepWalker,\n        ],\n        separatorLookAheadFunc,\n        AT_LEAST_ONE_SEP_IDX,\n        prodOccurrence,\n        NextTerminalAfterAtLeastOneSepWalker,\n      );\n    } else {\n      throw this.raiseEarlyExitException(\n        prodOccurrence,\n        PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR,\n        options.ERR_MSG,\n      );\n    }\n  }\n\n  manyInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(MANY_IDX, prodOccurrence);\n    return this.manyInternalLogic(prodOccurrence, actionORMethodDef, laKey);\n  }\n\n  manyInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    key: number,\n  ) {\n    let lookaheadFunction = this.getLaFuncFromCache(key);\n    let action;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      // predicate present\n      if (predicate !== undefined) {\n        const orgLookaheadFunction = lookaheadFunction;\n        lookaheadFunction = () => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        };\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n\n    let notStuck = true;\n    while (lookaheadFunction.call(this) === true && notStuck === true) {\n      notStuck = this.doSingleRepetition(action);\n    }\n\n    // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n    this.attemptInRepetitionRecovery(\n      this.manyInternal,\n      [prodOccurrence, actionORMethodDef],\n      <any>lookaheadFunction,\n      MANY_IDX,\n      prodOccurrence,\n      NextTerminalAfterManyWalker,\n      // The notStuck parameter is only relevant when \"attemptInRepetitionRecovery\"\n      // is invoked from manyInternal, in the MANY_SEP case and AT_LEAST_ONE[_SEP]\n      // An infinite loop cannot occur as:\n      // - Either the lookahead is guaranteed to consume something (Single Token Separator)\n      // - AT_LEAST_ONE by definition is guaranteed to consume something (or error out).\n      notStuck,\n    );\n  }\n\n  manySepFirstInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: ManySepMethodOpts<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(\n      MANY_SEP_IDX,\n      prodOccurrence,\n    );\n    this.manySepFirstInternalLogic(prodOccurrence, options, laKey);\n  }\n\n  manySepFirstInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: ManySepMethodOpts<OUT>,\n    key: number,\n  ): void {\n    const action = options.DEF;\n    const separator = options.SEP;\n    const firstIterationLaFunc = this.getLaFuncFromCache(key);\n\n    // 1st iteration\n    if (firstIterationLaFunc.call(this) === true) {\n      action.call(this);\n\n      const separatorLookAheadFunc = () => {\n        return this.tokenMatcher(this.LA(1), separator);\n      };\n      // 2nd..nth iterations\n      while (this.tokenMatcher(this.LA(1), separator) === true) {\n        // note that this CONSUME will never enter recovery because\n        // the separatorLookAheadFunc checks that the separator really does exist.\n        this.CONSUME(separator);\n        // No need for checking infinite loop here due to consuming the separator.\n        action.call(this);\n      }\n\n      // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n      this.attemptInRepetitionRecovery(\n        this.repetitionSepSecondInternal,\n        [\n          prodOccurrence,\n          separator,\n          separatorLookAheadFunc,\n          action,\n          NextTerminalAfterManySepWalker,\n        ],\n        separatorLookAheadFunc,\n        MANY_SEP_IDX,\n        prodOccurrence,\n        NextTerminalAfterManySepWalker,\n      );\n    }\n  }\n\n  repetitionSepSecondInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    separator: TokenType,\n    separatorLookAheadFunc: () => boolean,\n    action: GrammarAction<OUT>,\n    nextTerminalAfterWalker: typeof AbstractNextTerminalAfterProductionWalker,\n  ): void {\n    while (separatorLookAheadFunc()) {\n      // note that this CONSUME will never enter recovery because\n      // the separatorLookAheadFunc checks that the separator really does exist.\n      this.CONSUME(separator);\n      action.call(this);\n    }\n\n    // we can only arrive to this function after an error\n    // has occurred (hence the name 'second') so the following\n    // IF will always be entered, its possible to remove it...\n    // however it is kept to avoid confusion and be consistent.\n    // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n    /* istanbul ignore else */\n    this.attemptInRepetitionRecovery(\n      this.repetitionSepSecondInternal,\n      [\n        prodOccurrence,\n        separator,\n        separatorLookAheadFunc,\n        action,\n        nextTerminalAfterWalker,\n      ],\n      separatorLookAheadFunc,\n      AT_LEAST_ONE_SEP_IDX,\n      prodOccurrence,\n      nextTerminalAfterWalker,\n    );\n  }\n\n  doSingleRepetition(this: MixedInParser, action: Function): any {\n    const beforeIteration = this.getLexerPosition();\n    action.call(this);\n    const afterIteration = this.getLexerPosition();\n\n    // This boolean will indicate if this repetition progressed\n    // or if we are \"stuck\" (potential infinite loop in the repetition).\n    return afterIteration > beforeIteration;\n  }\n\n  orInternal<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n    occurrence: number,\n  ): T {\n    const laKey = this.getKeyForAutomaticLookahead(OR_IDX, occurrence);\n    const alts = isArray(altsOrOpts) ? altsOrOpts : altsOrOpts.DEF;\n\n    const laFunc = this.getLaFuncFromCache(laKey);\n    const altIdxToTake = laFunc.call(this, alts);\n    if (altIdxToTake !== undefined) {\n      const chosenAlternative: any = alts[altIdxToTake];\n      return chosenAlternative.ALT.call(this);\n    }\n    this.raiseNoAltException(\n      occurrence,\n      (altsOrOpts as OrMethodOpts<unknown>).ERR_MSG,\n    );\n  }\n\n  ruleFinallyStateUpdate(this: MixedInParser): void {\n    this.RULE_STACK.pop();\n    this.RULE_OCCURRENCE_STACK.pop();\n\n    // NOOP when cst is disabled\n    this.cstFinallyStateUpdate();\n\n    if (this.RULE_STACK.length === 0 && this.isAtEndOfInput() === false) {\n      const firstRedundantTok = this.LA(1);\n      const errMsg = this.errorMessageProvider.buildNotAllInputParsedMessage({\n        firstRedundant: firstRedundantTok,\n        ruleName: this.getCurrRuleFullName(),\n      });\n      this.SAVE_ERROR(\n        new NotAllInputParsedException(errMsg, firstRedundantTok),\n      );\n    }\n  }\n\n  subruleInternal<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    idx: number,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    let ruleResult;\n    try {\n      const args = options !== undefined ? options.ARGS : undefined;\n      this.subruleIdx = idx;\n      ruleResult = ruleToCall.apply(this, args);\n      this.cstPostNonTerminal(\n        ruleResult,\n        options !== undefined && options.LABEL !== undefined\n          ? options.LABEL\n          : ruleToCall.ruleName,\n      );\n      return ruleResult;\n    } catch (e) {\n      throw this.subruleInternalError(e, options, ruleToCall.ruleName);\n    }\n  }\n\n  subruleInternalError(\n    this: MixedInParser,\n    e: any,\n    options: SubruleMethodOpts<unknown[]> | undefined,\n    ruleName: string,\n  ): void {\n    if (isRecognitionException(e) && e.partialCstResult !== undefined) {\n      this.cstPostNonTerminal(\n        e.partialCstResult,\n        options !== undefined && options.LABEL !== undefined\n          ? options.LABEL\n          : ruleName,\n      );\n\n      delete e.partialCstResult;\n    }\n    throw e;\n  }\n\n  consumeInternal(\n    this: MixedInParser,\n    tokType: TokenType,\n    idx: number,\n    options: ConsumeMethodOpts | undefined,\n  ): IToken {\n    let consumedToken!: IToken;\n    try {\n      const nextToken = this.LA(1);\n      if (this.tokenMatcher(nextToken, tokType) === true) {\n        this.consumeToken();\n        consumedToken = nextToken;\n      } else {\n        this.consumeInternalError(tokType, nextToken, options);\n      }\n    } catch (eFromConsumption) {\n      consumedToken = this.consumeInternalRecovery(\n        tokType,\n        idx,\n        eFromConsumption,\n      );\n    }\n\n    this.cstPostTerminal(\n      options !== undefined && options.LABEL !== undefined\n        ? options.LABEL\n        : tokType.name,\n      consumedToken,\n    );\n    return consumedToken;\n  }\n\n  consumeInternalError(\n    this: MixedInParser,\n    tokType: TokenType,\n    nextToken: IToken,\n    options: ConsumeMethodOpts | undefined,\n  ): void {\n    let msg;\n    const previousToken = this.LA(0);\n    if (options !== undefined && options.ERR_MSG) {\n      msg = options.ERR_MSG;\n    } else {\n      msg = this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: tokType,\n        actual: nextToken,\n        previous: previousToken,\n        ruleName: this.getCurrRuleFullName(),\n      });\n    }\n    throw this.SAVE_ERROR(\n      new MismatchedTokenException(msg, nextToken, previousToken),\n    );\n  }\n\n  consumeInternalRecovery(\n    this: MixedInParser,\n    tokType: TokenType,\n    idx: number,\n    eFromConsumption: Error,\n  ): IToken {\n    // no recovery allowed during backtracking, otherwise backtracking may recover invalid syntax and accept it\n    // but the original syntax could have been parsed successfully without any backtracking + recovery\n    if (\n      this.recoveryEnabled &&\n      // TODO: more robust checking of the exception type. Perhaps Typescript extending expressions?\n      eFromConsumption.name === \"MismatchedTokenException\" &&\n      !this.isBackTracking()\n    ) {\n      const follows = this.getFollowsForInRuleRecovery(<any>tokType, idx);\n      try {\n        return this.tryInRuleRecovery(<any>tokType, follows);\n      } catch (eFromInRuleRecovery) {\n        if (eFromInRuleRecovery.name === IN_RULE_RECOVERY_EXCEPTION) {\n          // failed in RuleRecovery.\n          // throw the original error in order to trigger reSync error recovery\n          throw eFromConsumption;\n        } else {\n          throw eFromInRuleRecovery;\n        }\n      }\n    } else {\n      throw eFromConsumption;\n    }\n  }\n\n  saveRecogState(this: MixedInParser): IParserState {\n    // errors is a getter which will clone the errors array\n    const savedErrors = this.errors;\n    const savedRuleStack = clone(this.RULE_STACK);\n    return {\n      errors: savedErrors,\n      lexerState: this.exportLexerState(),\n      RULE_STACK: savedRuleStack,\n      CST_STACK: this.CST_STACK,\n    };\n  }\n\n  reloadRecogState(this: MixedInParser, newState: IParserState) {\n    this.errors = newState.errors;\n    this.importLexerState(newState.lexerState);\n    this.RULE_STACK = newState.RULE_STACK;\n  }\n\n  ruleInvocationStateUpdate(\n    this: MixedInParser,\n    shortName: number,\n    fullName: string,\n    idxInCallingRule: number,\n  ): void {\n    this.RULE_OCCURRENCE_STACK.push(idxInCallingRule);\n    this.RULE_STACK.push(shortName);\n    // NOOP when cst is disabled\n    this.cstInvocationStateUpdate(fullName);\n  }\n\n  isBackTracking(this: MixedInParser): boolean {\n    return this.isBackTrackingStack.length !== 0;\n  }\n\n  getCurrRuleFullName(this: MixedInParser): string {\n    const shortName = this.getLastExplicitRuleShortName();\n    return this.shortRuleNameToFull[shortName];\n  }\n\n  shortRuleNameToFullName(this: MixedInParser, shortName: number) {\n    return this.shortRuleNameToFull[shortName];\n  }\n\n  public isAtEndOfInput(this: MixedInParser): boolean {\n    return this.tokenMatcher(this.LA(1), EOF);\n  }\n\n  public reset(this: MixedInParser): void {\n    this.resetLexerState();\n    this.subruleIdx = 0;\n    this.isBackTrackingStack = [];\n    this.errors = [];\n    this.RULE_STACK = [];\n    // TODO: extract a specific reset for TreeBuilder trait\n    this.CST_STACK = [];\n    this.RULE_OCCURRENCE_STACK = [];\n  }\n}\n","import { every, includes, some } from \"lodash-es\";\nimport {\n  AbstractProduction,\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"./model.js\";\nimport type { IProduction, IProductionWithOccurrence } from \"@chevrotain/types\";\n\nexport function isSequenceProd(\n  prod: IProduction,\n): prod is { definition: IProduction[] } & IProduction {\n  return (\n    prod instanceof Alternative ||\n    prod instanceof Option ||\n    prod instanceof Repetition ||\n    prod instanceof RepetitionMandatory ||\n    prod instanceof RepetitionMandatoryWithSeparator ||\n    prod instanceof RepetitionWithSeparator ||\n    prod instanceof Terminal ||\n    prod instanceof Rule\n  );\n}\n\nexport function isOptionalProd(\n  prod: IProduction,\n  alreadyVisited: NonTerminal[] = [],\n): boolean {\n  const isDirectlyOptional =\n    prod instanceof Option ||\n    prod instanceof Repetition ||\n    prod instanceof RepetitionWithSeparator;\n  if (isDirectlyOptional) {\n    return true;\n  }\n\n  // note that this can cause infinite loop if one optional empty TOP production has a cyclic dependency with another\n  // empty optional top rule\n  // may be indirectly optional ((A?B?C?) | (D?E?F?))\n  if (prod instanceof Alternation) {\n    // for OR its enough for just one of the alternatives to be optional\n    return some((<Alternation>prod).definition, (subProd: IProduction) => {\n      return isOptionalProd(subProd, alreadyVisited);\n    });\n  } else if (prod instanceof NonTerminal && includes(alreadyVisited, prod)) {\n    // avoiding stack overflow due to infinite recursion\n    return false;\n  } else if (prod instanceof AbstractProduction) {\n    if (prod instanceof NonTerminal) {\n      alreadyVisited.push(prod);\n    }\n    return every(\n      (<AbstractProduction>prod).definition,\n      (subProd: IProduction) => {\n        return isOptionalProd(subProd, alreadyVisited);\n      },\n    );\n  } else {\n    return false;\n  }\n}\n\nexport function isBranchingProd(\n  prod: IProduction,\n): prod is { definition: IProduction[] } & IProduction {\n  return prod instanceof Alternation;\n}\n\nexport function getProductionDslName(prod: IProductionWithOccurrence): string {\n  /* istanbul ignore else */\n  if (prod instanceof NonTerminal) {\n    return \"SUBRULE\";\n  } else if (prod instanceof Option) {\n    return \"OPTION\";\n  } else if (prod instanceof Alternation) {\n    return \"OR\";\n  } else if (prod instanceof RepetitionMandatory) {\n    return \"AT_LEAST_ONE\";\n  } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n    return \"AT_LEAST_ONE_SEP\";\n  } else if (prod instanceof RepetitionWithSeparator) {\n    return \"MANY_SEP\";\n  } else if (prod instanceof Repetition) {\n    return \"MANY\";\n  } else if (prod instanceof Terminal) {\n    return \"CONSUME\";\n    /* c8 ignore next 3 */\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n","import {\n  AtLeastOneSepMethodOpts,\n  ConsumeMethodOpts,\n  CstNode,\n  DSLMethodOpts,\n  DSLMethodOptsWithErr,\n  GrammarAction,\n  IOrAlt,\n  IParserConfig,\n  IProduction,\n  IToken,\n  ManySepMethodOpts,\n  OrMethodOpts,\n  SubruleMethodOpts,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  forEach,\n  has,\n  isArray,\n  isFunction,\n  last as peek,\n  some,\n} from \"lodash-es\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport { Lexer } from \"../../../scan/lexer_public.js\";\nimport {\n  augmentTokenTypes,\n  hasShortKeyProperty,\n} from \"../../../scan/tokens.js\";\nimport {\n  createToken,\n  createTokenInstance,\n} from \"../../../scan/tokens_public.js\";\nimport { END_OF_FILE } from \"../parser.js\";\nimport { BITS_FOR_OCCURRENCE_IDX } from \"../../grammar/keys.js\";\nimport { ParserMethodInternal } from \"../types.js\";\n\ntype ProdWithDef = IProduction & { definition?: IProduction[] };\nconst RECORDING_NULL_OBJECT = {\n  description: \"This Object indicates the Parser is during Recording Phase\",\n};\nObject.freeze(RECORDING_NULL_OBJECT);\n\nconst HANDLE_SEPARATOR = true;\nconst MAX_METHOD_IDX = Math.pow(2, BITS_FOR_OCCURRENCE_IDX) - 1;\n\nconst RFT = createToken({ name: \"RECORDING_PHASE_TOKEN\", pattern: Lexer.NA });\naugmentTokenTypes([RFT]);\nconst RECORDING_PHASE_TOKEN = createTokenInstance(\n  RFT,\n  \"This IToken indicates the Parser is in Recording Phase\\n\\t\" +\n    \"\" +\n    \"See: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\",\n  // Using \"-1\" instead of NaN (as in EOF) because an actual number is less likely to\n  // cause errors if the output of LA or CONSUME would be (incorrectly) used during the recording phase.\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n);\nObject.freeze(RECORDING_PHASE_TOKEN);\n\nconst RECORDING_PHASE_CSTNODE: CstNode = {\n  name:\n    \"This CSTNode indicates the Parser is in Recording Phase\\n\\t\" +\n    \"See: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\",\n  children: {},\n};\n\n/**\n * This trait handles the creation of the GAST structure for Chevrotain Grammars\n */\nexport class GastRecorder {\n  recordingProdStack: ProdWithDef[];\n  RECORDING_PHASE: boolean;\n\n  initGastRecorder(this: MixedInParser, config: IParserConfig): void {\n    this.recordingProdStack = [];\n    this.RECORDING_PHASE = false;\n  }\n\n  enableRecording(this: MixedInParser): void {\n    this.RECORDING_PHASE = true;\n\n    this.TRACE_INIT(\"Enable Recording\", () => {\n      /**\n       * Warning Dark Voodoo Magic upcoming!\n       * We are \"replacing\" the public parsing DSL methods API\n       * With **new** alternative implementations on the Parser **instance**\n       *\n       * So far this is the only way I've found to avoid performance regressions during parsing time.\n       * - Approx 30% performance regression was measured on Chrome 75 Canary when attempting to replace the \"internal\"\n       *   implementations directly instead.\n       */\n      for (let i = 0; i < 10; i++) {\n        const idx = i > 0 ? i : \"\";\n        this[`CONSUME${idx}` as \"CONSUME\"] = function (arg1, arg2) {\n          return this.consumeInternalRecord(arg1, i, arg2);\n        };\n        this[`SUBRULE${idx}` as \"SUBRULE\"] = function (arg1, arg2) {\n          return this.subruleInternalRecord(arg1, i, arg2) as any;\n        };\n        this[`OPTION${idx}` as \"OPTION\"] = function (arg1) {\n          return this.optionInternalRecord(arg1, i);\n        };\n        this[`OR${idx}` as \"OR\"] = function (arg1) {\n          return this.orInternalRecord(arg1, i);\n        };\n        this[`MANY${idx}` as \"MANY\"] = function (arg1) {\n          this.manyInternalRecord(i, arg1);\n        };\n        this[`MANY_SEP${idx}` as \"MANY_SEP\"] = function (arg1) {\n          this.manySepFirstInternalRecord(i, arg1);\n        };\n        this[`AT_LEAST_ONE${idx}` as \"AT_LEAST_ONE\"] = function (arg1) {\n          this.atLeastOneInternalRecord(i, arg1);\n        };\n        this[`AT_LEAST_ONE_SEP${idx}` as \"AT_LEAST_ONE_SEP\"] = function (arg1) {\n          this.atLeastOneSepFirstInternalRecord(i, arg1);\n        };\n      }\n\n      // DSL methods with the idx(suffix) as an argument\n      this[`consume`] = function (idx, arg1, arg2) {\n        return this.consumeInternalRecord(arg1, idx, arg2);\n      };\n      this[`subrule`] = function (idx, arg1, arg2) {\n        return this.subruleInternalRecord(arg1, idx, arg2) as any;\n      };\n      this[`option`] = function (idx, arg1) {\n        return this.optionInternalRecord(arg1, idx);\n      };\n      this[`or`] = function (idx, arg1) {\n        return this.orInternalRecord(arg1, idx);\n      };\n      this[`many`] = function (idx, arg1) {\n        this.manyInternalRecord(idx, arg1);\n      };\n      this[`atLeastOne`] = function (idx, arg1) {\n        this.atLeastOneInternalRecord(idx, arg1);\n      };\n\n      this.ACTION = this.ACTION_RECORD;\n      this.BACKTRACK = this.BACKTRACK_RECORD;\n      this.LA = this.LA_RECORD;\n    });\n  }\n\n  disableRecording(this: MixedInParser) {\n    this.RECORDING_PHASE = false;\n    // By deleting these **instance** properties, any future invocation\n    // will be deferred to the original methods on the **prototype** object\n    // This seems to get rid of any incorrect optimizations that V8 may\n    // do during the recording phase.\n    this.TRACE_INIT(\"Deleting Recording methods\", () => {\n      const that: any = this;\n\n      for (let i = 0; i < 10; i++) {\n        const idx = i > 0 ? i : \"\";\n        delete that[`CONSUME${idx}`];\n        delete that[`SUBRULE${idx}`];\n        delete that[`OPTION${idx}`];\n        delete that[`OR${idx}`];\n        delete that[`MANY${idx}`];\n        delete that[`MANY_SEP${idx}`];\n        delete that[`AT_LEAST_ONE${idx}`];\n        delete that[`AT_LEAST_ONE_SEP${idx}`];\n      }\n\n      delete that[`consume`];\n      delete that[`subrule`];\n      delete that[`option`];\n      delete that[`or`];\n      delete that[`many`];\n      delete that[`atLeastOne`];\n\n      delete that.ACTION;\n      delete that.BACKTRACK;\n      delete that.LA;\n    });\n  }\n\n  //   Parser methods are called inside an ACTION?\n  //   Maybe try/catch/finally on ACTIONS while disabling the recorders state changes?\n  // @ts-expect-error -- noop place holder\n  ACTION_RECORD<T>(this: MixedInParser, impl: () => T): T {\n    // NO-OP during recording\n  }\n\n  // Executing backtracking logic will break our recording logic assumptions\n  BACKTRACK_RECORD<T>(\n    grammarRule: (...args: any[]) => T,\n    args?: any[],\n  ): () => boolean {\n    return () => true;\n  }\n\n  // LA is part of the official API and may be used for custom lookahead logic\n  // by end users who may forget to wrap it in ACTION or inside a GATE\n  LA_RECORD(howMuch: number): IToken {\n    // We cannot use the RECORD_PHASE_TOKEN here because someone may depend\n    // On LA return EOF at the end of the input so an infinite loop may occur.\n    return END_OF_FILE;\n  }\n\n  topLevelRuleRecord(name: string, def: Function): Rule {\n    try {\n      const newTopLevelRule = new Rule({ definition: [], name: name });\n      newTopLevelRule.name = name;\n      this.recordingProdStack.push(newTopLevelRule);\n      def.call(this);\n      this.recordingProdStack.pop();\n      return newTopLevelRule;\n    } catch (originalError) {\n      if (originalError.KNOWN_RECORDER_ERROR !== true) {\n        try {\n          originalError.message =\n            originalError.message +\n            '\\n\\t This error was thrown during the \"grammar recording phase\" For more info see:\\n\\t' +\n            \"https://chevrotain.io/docs/guide/internals.html#grammar-recording\";\n        } catch (mutabilityError) {\n          // We may not be able to modify the original error object\n          throw originalError;\n        }\n      }\n      throw originalError;\n    }\n  }\n\n  // Implementation of parsing DSL\n  optionInternalRecord<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    occurrence: number,\n  ): OUT {\n    return recordProd.call(this, Option, actionORMethodDef, occurrence);\n  }\n\n  atLeastOneInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    recordProd.call(this, RepetitionMandatory, actionORMethodDef, occurrence);\n  }\n\n  atLeastOneSepFirstInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    recordProd.call(\n      this,\n      RepetitionMandatoryWithSeparator,\n      options,\n      occurrence,\n      HANDLE_SEPARATOR,\n    );\n  }\n\n  manyInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    recordProd.call(this, Repetition, actionORMethodDef, occurrence);\n  }\n\n  manySepFirstInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    options: ManySepMethodOpts<OUT>,\n  ): void {\n    recordProd.call(\n      this,\n      RepetitionWithSeparator,\n      options,\n      occurrence,\n      HANDLE_SEPARATOR,\n    );\n  }\n\n  orInternalRecord<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n    occurrence: number,\n  ): T {\n    return recordOrProd.call(this, altsOrOpts, occurrence);\n  }\n\n  subruleInternalRecord<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    occurrence: number,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R | CstNode {\n    assertMethodIdxIsValid(occurrence);\n    if (!ruleToCall || has(ruleToCall, \"ruleName\") === false) {\n      const error: any = new Error(\n        `<SUBRULE${getIdxSuffix(occurrence)}> argument is invalid` +\n          ` expecting a Parser method reference but got: <${JSON.stringify(\n            ruleToCall,\n          )}>` +\n          `\\n inside top level rule: <${\n            (<Rule>this.recordingProdStack[0]).name\n          }>`,\n      );\n      error.KNOWN_RECORDER_ERROR = true;\n      throw error;\n    }\n\n    const prevProd: any = peek(this.recordingProdStack);\n    const ruleName = ruleToCall.ruleName;\n    const newNoneTerminal = new NonTerminal({\n      idx: occurrence,\n      nonTerminalName: ruleName,\n      label: options?.LABEL,\n      // The resolving of the `referencedRule` property will be done once all the Rule's GASTs have been created\n      referencedRule: undefined,\n    });\n    prevProd.definition.push(newNoneTerminal);\n\n    return this.outputCst\n      ? RECORDING_PHASE_CSTNODE\n      : <any>RECORDING_NULL_OBJECT;\n  }\n\n  consumeInternalRecord(\n    this: MixedInParser,\n    tokType: TokenType,\n    occurrence: number,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    assertMethodIdxIsValid(occurrence);\n    if (!hasShortKeyProperty(tokType)) {\n      const error: any = new Error(\n        `<CONSUME${getIdxSuffix(occurrence)}> argument is invalid` +\n          ` expecting a TokenType reference but got: <${JSON.stringify(\n            tokType,\n          )}>` +\n          `\\n inside top level rule: <${\n            (<Rule>this.recordingProdStack[0]).name\n          }>`,\n      );\n      error.KNOWN_RECORDER_ERROR = true;\n      throw error;\n    }\n    const prevProd: any = peek(this.recordingProdStack);\n    const newNoneTerminal = new Terminal({\n      idx: occurrence,\n      terminalType: tokType,\n      label: options?.LABEL,\n    });\n    prevProd.definition.push(newNoneTerminal);\n\n    return RECORDING_PHASE_TOKEN;\n  }\n}\n\nfunction recordProd(\n  prodConstructor: any,\n  mainProdArg: any,\n  occurrence: number,\n  handleSep: boolean = false,\n): any {\n  assertMethodIdxIsValid(occurrence);\n  const prevProd: any = peek(this.recordingProdStack);\n  const grammarAction = isFunction(mainProdArg) ? mainProdArg : mainProdArg.DEF;\n\n  const newProd = new prodConstructor({ definition: [], idx: occurrence });\n  if (handleSep) {\n    newProd.separator = mainProdArg.SEP;\n  }\n  if (has(mainProdArg, \"MAX_LOOKAHEAD\")) {\n    newProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n  }\n\n  this.recordingProdStack.push(newProd);\n  grammarAction.call(this);\n  prevProd.definition.push(newProd);\n  this.recordingProdStack.pop();\n\n  return RECORDING_NULL_OBJECT;\n}\n\nfunction recordOrProd(mainProdArg: any, occurrence: number): any {\n  assertMethodIdxIsValid(occurrence);\n  const prevProd: any = peek(this.recordingProdStack);\n  // Only an array of alternatives\n  const hasOptions = isArray(mainProdArg) === false;\n  const alts: IOrAlt<unknown>[] =\n    hasOptions === false ? mainProdArg : mainProdArg.DEF;\n\n  const newOrProd = new Alternation({\n    definition: [],\n    idx: occurrence,\n    ignoreAmbiguities: hasOptions && mainProdArg.IGNORE_AMBIGUITIES === true,\n  });\n  if (has(mainProdArg, \"MAX_LOOKAHEAD\")) {\n    newOrProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n  }\n\n  const hasPredicates = some(alts, (currAlt: any) => isFunction(currAlt.GATE));\n  newOrProd.hasPredicates = hasPredicates;\n\n  prevProd.definition.push(newOrProd);\n\n  forEach(alts, (currAlt) => {\n    const currAltFlat = new Alternative({ definition: [] });\n    newOrProd.definition.push(currAltFlat);\n    if (has(currAlt, \"IGNORE_AMBIGUITIES\")) {\n      currAltFlat.ignoreAmbiguities = currAlt.IGNORE_AMBIGUITIES as boolean; // assumes end user provides the correct config value/type\n    }\n    // **implicit** ignoreAmbiguities due to usage of gate\n    else if (has(currAlt, \"GATE\")) {\n      currAltFlat.ignoreAmbiguities = true;\n    }\n    this.recordingProdStack.push(currAltFlat);\n    currAlt.ALT.call(this);\n    this.recordingProdStack.pop();\n  });\n  return RECORDING_NULL_OBJECT;\n}\n\nfunction getIdxSuffix(idx: number): string {\n  return idx === 0 ? \"\" : `${idx}`;\n}\n\nfunction assertMethodIdxIsValid(idx: number): void {\n  if (idx < 0 || idx > MAX_METHOD_IDX) {\n    const error: any = new Error(\n      // The stack trace will contain all the needed details\n      `Invalid DSL Method idx value: <${idx}>\\n\\t` +\n        `Idx value must be a none negative value smaller than ${\n          MAX_METHOD_IDX + 1\n        }`,\n    );\n    error.KNOWN_RECORDER_ERROR = true;\n    throw error;\n  }\n}\n","import { drop, forEach } from \"lodash-es\";\nimport {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport { IProduction } from \"@chevrotain/types\";\n\n/**\n *  A Grammar Walker that computes the \"remaining\" grammar \"after\" a productions in the grammar.\n */\nexport abstract class RestWalker {\n  walk(prod: { definition: IProduction[] }, prevRest: any[] = []): void {\n    forEach(prod.definition, (subProd: IProduction, index) => {\n      const currRest = drop(prod.definition, index + 1);\n      /* istanbul ignore else */\n      if (subProd instanceof NonTerminal) {\n        this.walkProdRef(subProd, currRest, prevRest);\n      } else if (subProd instanceof Terminal) {\n        this.walkTerminal(subProd, currRest, prevRest);\n      } else if (subProd instanceof Alternative) {\n        this.walkFlat(subProd, currRest, prevRest);\n      } else if (subProd instanceof Option) {\n        this.walkOption(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionMandatory) {\n        this.walkAtLeastOne(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionMandatoryWithSeparator) {\n        this.walkAtLeastOneSep(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionWithSeparator) {\n        this.walkManySep(subProd, currRest, prevRest);\n      } else if (subProd instanceof Repetition) {\n        this.walkMany(subProd, currRest, prevRest);\n      } else if (subProd instanceof Alternation) {\n        this.walkOr(subProd, currRest, prevRest);\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n  }\n\n  walkTerminal(\n    terminal: Terminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {}\n\n  walkProdRef(\n    refProd: NonTerminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {}\n\n  walkFlat(\n    flatProd: Alternative,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABCDEF => after the D the rest is EF\n    const fullOrRest = currRest.concat(prevRest);\n    this.walk(flatProd, <any>fullOrRest);\n  }\n\n  walkOption(\n    optionProd: Option,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(DE)?F => after the (DE)? the rest is F\n    const fullOrRest = currRest.concat(prevRest);\n    this.walk(optionProd, <any>fullOrRest);\n  }\n\n  walkAtLeastOne(\n    atLeastOneProd: RepetitionMandatory,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(DE)+F => after the (DE)+ the rest is (DE)?F\n    const fullAtLeastOneRest: IProduction[] = [\n      new Option({ definition: atLeastOneProd.definition }),\n    ].concat(<any>currRest, <any>prevRest);\n    this.walk(atLeastOneProd, fullAtLeastOneRest);\n  }\n\n  walkAtLeastOneSep(\n    atLeastOneSepProd: RepetitionMandatoryWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC DE(,DE)* F => after the (,DE)+ the rest is (,DE)?F\n    const fullAtLeastOneSepRest = restForRepetitionWithSeparator(\n      atLeastOneSepProd,\n      currRest,\n      prevRest,\n    );\n    this.walk(atLeastOneSepProd, fullAtLeastOneSepRest);\n  }\n\n  walkMany(\n    manyProd: Repetition,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(DE)*F => after the (DE)* the rest is (DE)?F\n    const fullManyRest: IProduction[] = [\n      new Option({ definition: manyProd.definition }),\n    ].concat(<any>currRest, <any>prevRest);\n    this.walk(manyProd, fullManyRest);\n  }\n\n  walkManySep(\n    manySepProd: RepetitionWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC (DE(,DE)*)? F => after the (,DE)* the rest is (,DE)?F\n    const fullManySepRest = restForRepetitionWithSeparator(\n      manySepProd,\n      currRest,\n      prevRest,\n    );\n    this.walk(manySepProd, fullManySepRest);\n  }\n\n  walkOr(\n    orProd: Alternation,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(D|E|F)G => when finding the (D|E|F) the rest is G\n    const fullOrRest = currRest.concat(prevRest);\n    // walk all different alternatives\n    forEach(orProd.definition, (alt) => {\n      // wrapping each alternative in a single definition wrapper\n      // to avoid errors in computing the rest of that alternative in the invocation to computeInProdFollows\n      // (otherwise for OR([alt1,alt2]) alt2 will be considered in 'rest' of alt1\n      const prodWrapper = new Alternative({ definition: [alt] });\n      this.walk(prodWrapper, <any>fullOrRest);\n    });\n  }\n}\n\nfunction restForRepetitionWithSeparator(\n  repSepProd: RepetitionWithSeparator,\n  currRest: IProduction[],\n  prevRest: IProduction[],\n) {\n  const repSepRest = [\n    new Option({\n      definition: [\n        new Terminal({ terminalType: repSepProd.separator }) as IProduction,\n      ].concat(repSepProd.definition),\n    }) as IProduction,\n  ];\n  const fullRepSepRest: IProduction[] = repSepRest.concat(currRest, prevRest);\n  return fullRepSepRest;\n}\n","import root from './_root.js';\n\n/** Built-in value references. */\nvar Uint8Array = root.Uint8Array;\n\nexport default Uint8Array;\n","import baseClone from './_baseClone.js';\n\n/** Used to compose bitmasks for cloning. */\nvar CLONE_SYMBOLS_FLAG = 4;\n\n/**\n * Creates a shallow clone of `value`.\n *\n * **Note:** This method is loosely based on the\n * [structured clone algorithm](https://mdn.io/Structured_clone_algorithm)\n * and supports cloning arrays, array buffers, booleans, date objects, maps,\n * numbers, `Object` objects, regexes, sets, strings, symbols, and typed\n * arrays. The own enumerable properties of `arguments` objects are cloned\n * as plain objects. An empty object is returned for uncloneable values such\n * as error objects, functions, DOM nodes, and WeakMaps.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to clone.\n * @returns {*} Returns the cloned value.\n * @see _.cloneDeep\n * @example\n *\n * var objects = [{ 'a': 1 }, { 'b': 2 }];\n *\n * var shallow = _.clone(objects);\n * console.log(shallow[0] === objects[0]);\n * // => true\n */\nfunction clone(value) {\n  return baseClone(value, CLONE_SYMBOLS_FLAG);\n}\n\nexport default clone;\n","import createBaseFor from './_createBaseFor.js';\n\n/**\n * The base implementation of `baseForOwn` which iterates over `object`\n * properties returned by `keysFunc` and invokes `iteratee` for each property.\n * Iteratee functions may exit iteration early by explicitly returning `false`.\n *\n * @private\n * @param {Object} object The object to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @param {Function} keysFunc The function to get the keys of `object`.\n * @returns {Object} Returns `object`.\n */\nvar baseFor = createBaseFor();\n\nexport default baseFor;\n","import isArrayLike from './isArrayLike.js';\n\n/**\n * Creates a `baseEach` or `baseEachRight` function.\n *\n * @private\n * @param {Function} eachFunc The function to iterate over a collection.\n * @param {boolean} [fromRight] Specify iterating from right to left.\n * @returns {Function} Returns the new base function.\n */\nfunction createBaseEach(eachFunc, fromRight) {\n  return function(collection, iteratee) {\n    if (collection == null) {\n      return collection;\n    }\n    if (!isArrayLike(collection)) {\n      return eachFunc(collection, iteratee);\n    }\n    var length = collection.length,\n        index = fromRight ? length : -1,\n        iterable = Object(collection);\n\n    while ((fromRight ? index-- : ++index < length)) {\n      if (iteratee(iterable[index], index, iterable) === false) {\n        break;\n      }\n    }\n    return collection;\n  };\n}\n\nexport default createBaseEach;\n","import identity from './identity.js';\n\n/**\n * Casts `value` to `identity` if it's not a function.\n *\n * @private\n * @param {*} value The value to inspect.\n * @returns {Function} Returns cast function.\n */\nfunction castFunction(value) {\n  return typeof value == 'function' ? value : identity;\n}\n\nexport default castFunction;\n","import overArg from './_overArg.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeKeys = overArg(Object.keys, Object);\n\nexport default nativeKeys;\n","import MapCache from './_MapCache.js';\n\n/** Error message constants. */\nvar FUNC_ERROR_TEXT = 'Expected a function';\n\n/**\n * Creates a function that memoizes the result of `func`. If `resolver` is\n * provided, it determines the cache key for storing the result based on the\n * arguments provided to the memoized function. By default, the first argument\n * provided to the memoized function is used as the map cache key. The `func`\n * is invoked with the `this` binding of the memoized function.\n *\n * **Note:** The cache is exposed as the `cache` property on the memoized\n * function. Its creation may be customized by replacing the `_.memoize.Cache`\n * constructor with one whose instances implement the\n * [`Map`](http://ecma-international.org/ecma-262/7.0/#sec-properties-of-the-map-prototype-object)\n * method interface of `clear`, `delete`, `get`, `has`, and `set`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Function\n * @param {Function} func The function to have its output memoized.\n * @param {Function} [resolver] The function to resolve the cache key.\n * @returns {Function} Returns the new memoized function.\n * @example\n *\n * var object = { 'a': 1, 'b': 2 };\n * var other = { 'c': 3, 'd': 4 };\n *\n * var values = _.memoize(_.values);\n * values(object);\n * // => [1, 2]\n *\n * values(other);\n * // => [3, 4]\n *\n * object.a = 2;\n * values(object);\n * // => [1, 2]\n *\n * // Modify the result cache.\n * values.cache.set(object, ['a', 'b']);\n * values(object);\n * // => ['a', 'b']\n *\n * // Replace `_.memoize.Cache`.\n * _.memoize.Cache = WeakMap;\n */\nfunction memoize(func, resolver) {\n  if (typeof func != 'function' || (resolver != null && typeof resolver != 'function')) {\n    throw new TypeError(FUNC_ERROR_TEXT);\n  }\n  var memoized = function() {\n    var args = arguments,\n        key = resolver ? resolver.apply(this, args) : args[0],\n        cache = memoized.cache;\n\n    if (cache.has(key)) {\n      return cache.get(key);\n    }\n    var result = func.apply(this, args);\n    memoized.cache = cache.set(key, result) || cache;\n    return result;\n  };\n  memoized.cache = new (memoize.Cache || MapCache);\n  return memoized;\n}\n\n// Expose `MapCache`.\nmemoize.Cache = MapCache;\n\nexport default memoize;\n","import memoize from './memoize.js';\n\n/** Used as the maximum memoize cache size. */\nvar MAX_MEMOIZE_SIZE = 500;\n\n/**\n * A specialized version of `_.memoize` which clears the memoized function's\n * cache when it exceeds `MAX_MEMOIZE_SIZE`.\n *\n * @private\n * @param {Function} func The function to have its output memoized.\n * @returns {Function} Returns the new memoized function.\n */\nfunction memoizeCapped(func) {\n  var result = memoize(func, function(key) {\n    if (cache.size === MAX_MEMOIZE_SIZE) {\n      cache.clear();\n    }\n    return key;\n  });\n\n  var cache = result.cache;\n  return result;\n}\n\nexport default memoizeCapped;\n","import memoizeCapped from './_memoizeCapped.js';\n\n/** Used to match property names within property paths. */\nvar rePropName = /[^.[\\]]+|\\[(?:(-?\\d+(?:\\.\\d+)?)|([\"'])((?:(?!\\2)[^\\\\]|\\\\.)*?)\\2)\\]|(?=(?:\\.|\\[\\])(?:\\.|\\[\\]|$))/g;\n\n/** Used to match backslashes in property paths. */\nvar reEscapeChar = /\\\\(\\\\)?/g;\n\n/**\n * Converts `string` to a property path array.\n *\n * @private\n * @param {string} string The string to convert.\n * @returns {Array} Returns the property path array.\n */\nvar stringToPath = memoizeCapped(function(string) {\n  var result = [];\n  if (string.charCodeAt(0) === 46 /* . */) {\n    result.push('');\n  }\n  string.replace(rePropName, function(match, number, quote, subString) {\n    result.push(quote ? subString.replace(reEscapeChar, '$1') : (number || match));\n  });\n  return result;\n});\n\nexport default stringToPath;\n","import baseToString from './_baseToString.js';\n\n/**\n * Converts `value` to a string. An empty string is returned for `null`\n * and `undefined` values. The sign of `-0` is preserved.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {string} Returns the converted string.\n * @example\n *\n * _.toString(null);\n * // => ''\n *\n * _.toString(-0);\n * // => '-0'\n *\n * _.toString([1, 2, 3]);\n * // => '1,2,3'\n */\nfunction toString(value) {\n  return value == null ? '' : baseToString(value);\n}\n\nexport default toString;\n","import isSymbol from './isSymbol.js';\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0;\n\n/**\n * Converts `value` to a string key if it's not a string or symbol.\n *\n * @private\n * @param {*} value The value to inspect.\n * @returns {string|symbol} Returns the key.\n */\nfunction toKey(value) {\n  if (typeof value == 'string' || isSymbol(value)) {\n    return value;\n  }\n  var result = (value + '');\n  return (result == '0' && (1 / value) == -INFINITY) ? '-0' : result;\n}\n\nexport default toKey;\n","import getAllKeys from './_getAllKeys.js';\n\n/** Used to compose bitmasks for value comparisons. */\nvar COMPARE_PARTIAL_FLAG = 1;\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * A specialized version of `baseIsEqualDeep` for objects with support for\n * partial deep comparisons.\n *\n * @private\n * @param {Object} object The object to compare.\n * @param {Object} other The other object to compare.\n * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.\n * @param {Function} customizer The function to customize comparisons.\n * @param {Function} equalFunc The function to determine equivalents of values.\n * @param {Object} stack Tracks traversed `object` and `other` objects.\n * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.\n */\nfunction equalObjects(object, other, bitmask, customizer, equalFunc, stack) {\n  var isPartial = bitmask & COMPARE_PARTIAL_FLAG,\n      objProps = getAllKeys(object),\n      objLength = objProps.length,\n      othProps = getAllKeys(other),\n      othLength = othProps.length;\n\n  if (objLength != othLength && !isPartial) {\n    return false;\n  }\n  var index = objLength;\n  while (index--) {\n    var key = objProps[index];\n    if (!(isPartial ? key in other : hasOwnProperty.call(other, key))) {\n      return false;\n    }\n  }\n  // Check that cyclic values are equal.\n  var objStacked = stack.get(object);\n  var othStacked = stack.get(other);\n  if (objStacked && othStacked) {\n    return objStacked == other && othStacked == object;\n  }\n  var result = true;\n  stack.set(object, other);\n  stack.set(other, object);\n\n  var skipCtor = isPartial;\n  while (++index < objLength) {\n    key = objProps[index];\n    var objValue = object[key],\n        othValue = other[key];\n\n    if (customizer) {\n      var compared = isPartial\n        ? customizer(othValue, objValue, key, other, object, stack)\n        : customizer(objValue, othValue, key, object, other, stack);\n    }\n    // Recursively compare objects (susceptible to call stack limits).\n    if (!(compared === undefined\n          ? (objValue === othValue || equalFunc(objValue, othValue, bitmask, customizer, stack))\n          : compared\n        )) {\n      result = false;\n      break;\n    }\n    skipCtor || (skipCtor = key == 'constructor');\n  }\n  if (result && !skipCtor) {\n    var objCtor = object.constructor,\n        othCtor = other.constructor;\n\n    // Non `Object` object instances with different constructors are not equal.\n    if (objCtor != othCtor &&\n        ('constructor' in object && 'constructor' in other) &&\n        !(typeof objCtor == 'function' && objCtor instanceof objCtor &&\n          typeof othCtor == 'function' && othCtor instanceof othCtor)) {\n      result = false;\n    }\n  }\n  stack['delete'](object);\n  stack['delete'](other);\n  return result;\n}\n\nexport default equalObjects;\n","import isObject from './isObject.js';\n\n/**\n * Checks if `value` is suitable for strict equality comparisons, i.e. `===`.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` if suitable for strict\n *  equality comparisons, else `false`.\n */\nfunction isStrictComparable(value) {\n  return value === value && !isObject(value);\n}\n\nexport default isStrictComparable;\n","import baseGet from './_baseGet.js';\n\n/**\n * Gets the value at `path` of `object`. If the resolved value is\n * `undefined`, the `defaultValue` is returned in its place.\n *\n * @static\n * @memberOf _\n * @since 3.7.0\n * @category Object\n * @param {Object} object The object to query.\n * @param {Array|string} path The path of the property to get.\n * @param {*} [defaultValue] The value returned for `undefined` resolved values.\n * @returns {*} Returns the resolved value.\n * @example\n *\n * var object = { 'a': [{ 'b': { 'c': 3 } }] };\n *\n * _.get(object, 'a[0].b.c');\n * // => 3\n *\n * _.get(object, ['a', '0', 'b', 'c']);\n * // => 3\n *\n * _.get(object, 'a.b.c', 'default');\n * // => 'default'\n */\nfunction get(object, path, defaultValue) {\n  var result = object == null ? undefined : baseGet(object, path);\n  return result === undefined ? defaultValue : result;\n}\n\nexport default get;\n","import baseGet from './_baseGet.js';\n\n/**\n * A specialized version of `baseProperty` which supports deep paths.\n *\n * @private\n * @param {Array|string} path The path of the property to get.\n * @returns {Function} Returns the new accessor function.\n */\nfunction basePropertyDeep(path) {\n  return function(object) {\n    return baseGet(object, path);\n  };\n}\n\nexport default basePropertyDeep;\n","import arrayMap from './_arrayMap.js';\n\n/**\n * The base implementation of `_.values` and `_.valuesIn` which creates an\n * array of `object` property values corresponding to the property names\n * of `props`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {Array} props The property names to get values for.\n * @returns {Object} Returns the array of property values.\n */\nfunction baseValues(object, props) {\n  return arrayMap(props, function(key) {\n    return object[key];\n  });\n}\n\nexport default baseValues;\n","import trimmedEndIndex from './_trimmedEndIndex.js';\n\n/** Used to match leading whitespace. */\nvar reTrimStart = /^\\s+/;\n\n/**\n * The base implementation of `_.trim`.\n *\n * @private\n * @param {string} string The string to trim.\n * @returns {string} Returns the trimmed string.\n */\nfunction baseTrim(string) {\n  return string\n    ? string.slice(0, trimmedEndIndex(string) + 1).replace(reTrimStart, '')\n    : string;\n}\n\nexport default baseTrim;\n","import toNumber from './toNumber.js';\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0,\n    MAX_INTEGER = 1.7976931348623157e+308;\n\n/**\n * Converts `value` to a finite number.\n *\n * @static\n * @memberOf _\n * @since 4.12.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted number.\n * @example\n *\n * _.toFinite(3.2);\n * // => 3.2\n *\n * _.toFinite(Number.MIN_VALUE);\n * // => 5e-324\n *\n * _.toFinite(Infinity);\n * // => 1.7976931348623157e+308\n *\n * _.toFinite('3.2');\n * // => 3.2\n */\nfunction toFinite(value) {\n  if (!value) {\n    return value === 0 ? value : 0;\n  }\n  value = toNumber(value);\n  if (value === INFINITY || value === -INFINITY) {\n    var sign = (value < 0 ? -1 : 1);\n    return sign * MAX_INTEGER;\n  }\n  return value === value ? value : 0;\n}\n\nexport default toFinite;\n","import toFinite from './toFinite.js';\n\n/**\n * Converts `value` to an integer.\n *\n * **Note:** This method is loosely based on\n * [`ToInteger`](http://www.ecma-international.org/ecma-262/7.0/#sec-tointeger).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted integer.\n * @example\n *\n * _.toInteger(3.2);\n * // => 3\n *\n * _.toInteger(Number.MIN_VALUE);\n * // => 0\n *\n * _.toInteger(Infinity);\n * // => 1.7976931348623157e+308\n *\n * _.toInteger('3.2');\n * // => 3\n */\nfunction toInteger(value) {\n  var result = toFinite(value),\n      remainder = result % 1;\n\n  return result === result ? (remainder ? result - remainder : result) : 0;\n}\n\nexport default toInteger;\n","import apply from './_apply.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * A specialized version of `baseRest` which transforms the rest array.\n *\n * @private\n * @param {Function} func The function to apply a rest parameter to.\n * @param {number} [start=func.length-1] The start position of the rest parameter.\n * @param {Function} transform The rest array transform.\n * @returns {Function} Returns the new function.\n */\nfunction overRest(func, start, transform) {\n  start = nativeMax(start === undefined ? (func.length - 1) : start, 0);\n  return function() {\n    var args = arguments,\n        index = -1,\n        length = nativeMax(args.length - start, 0),\n        array = Array(length);\n\n    while (++index < length) {\n      array[index] = args[start + index];\n    }\n    index = -1;\n    var otherArgs = Array(start + 1);\n    while (++index < start) {\n      otherArgs[index] = args[index];\n    }\n    otherArgs[start] = transform(array);\n    return apply(func, this, otherArgs);\n  };\n}\n\nexport default overRest;\n","import baseEach from './_baseEach.js';\n\n/**\n * The base implementation of `_.every` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`\n */\nfunction baseEvery(collection, predicate) {\n  var result = true;\n  baseEach(collection, function(value, index, collection) {\n    result = !!predicate(value, index, collection);\n    return result;\n  });\n  return result;\n}\n\nexport default baseEvery;\n","import baseEach from './_baseEach.js';\n\n/**\n * The base implementation of `_.some` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if any element passes the predicate check,\n *  else `false`.\n */\nfunction baseSome(collection, predicate) {\n  var result;\n\n  baseEach(collection, function(value, index, collection) {\n    result = predicate(value, index, collection);\n    return !result;\n  });\n  return !!result;\n}\n\nexport default baseSome;\n","import baseFlatten from './_baseFlatten.js';\n\n/**\n * Flattens `array` a single level deep.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to flatten.\n * @returns {Array} Returns the new flattened array.\n * @example\n *\n * _.flatten([1, [2, [3, [4]], 5]]);\n * // => [1, 2, [3, [4]], 5]\n */\nfunction flatten(array) {\n  var length = array == null ? 0 : array.length;\n  return length ? baseFlatten(array, 1) : [];\n}\n\nexport default flatten;\n","import baseIndexOf from './_baseIndexOf.js';\n\n/**\n * A specialized version of `_.includes` for arrays without support for\n * specifying an index to search from.\n *\n * @private\n * @param {Array} [array] The array to inspect.\n * @param {*} target The value to search for.\n * @returns {boolean} Returns `true` if `target` is found, else `false`.\n */\nfunction arrayIncludes(array, value) {\n  var length = array == null ? 0 : array.length;\n  return !!length && baseIndexOf(array, value, 0) > -1;\n}\n\nexport default arrayIncludes;\n","import baseUniq from './_baseUniq.js';\n\n/**\n * Creates a duplicate-free version of an array, using\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons, in which only the first occurrence of each element\n * is kept. The order of result values is determined by the order they occur\n * in the array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @returns {Array} Returns the new duplicate free array.\n * @example\n *\n * _.uniq([2, 1, 2]);\n * // => [2, 1]\n */\nfunction uniq(array) {\n  return (array && array.length) ? baseUniq(array) : [];\n}\n\nexport default uniq;\n","import root from './_root.js';\n\n/** Detect free variable `exports`. */\nvar freeExports = typeof exports == 'object' && exports && !exports.nodeType && exports;\n\n/** Detect free variable `module`. */\nvar freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;\n\n/** Detect the popular CommonJS extension `module.exports`. */\nvar moduleExports = freeModule && freeModule.exports === freeExports;\n\n/** Built-in value references. */\nvar Buffer = moduleExports ? root.Buffer : undefined,\n    allocUnsafe = Buffer ? Buffer.allocUnsafe : undefined;\n\n/**\n * Creates a clone of  `buffer`.\n *\n * @private\n * @param {Buffer} buffer The buffer to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Buffer} Returns the cloned buffer.\n */\nfunction cloneBuffer(buffer, isDeep) {\n  if (isDeep) {\n    return buffer.slice();\n  }\n  var length = buffer.length,\n      result = allocUnsafe ? allocUnsafe(length) : new buffer.constructor(length);\n\n  buffer.copy(result);\n  return result;\n}\n\nexport default cloneBuffer;\n","import baseEach from './_baseEach.js';\n\n/**\n * The base implementation of `_.filter` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {Array} Returns the new filtered array.\n */\nfunction baseFilter(collection, predicate) {\n  var result = [];\n  baseEach(collection, function(value, index, collection) {\n    if (predicate(value, index, collection)) {\n      result.push(value);\n    }\n  });\n  return result;\n}\n\nexport default baseFilter;\n","import overArg from './_overArg.js';\n\n/** Built-in value references. */\nvar getPrototype = overArg(Object.getPrototypeOf, Object);\n\nexport default getPrototype;\n","import isObject from './isObject.js';\n\n/** Built-in value references. */\nvar objectCreate = Object.create;\n\n/**\n * The base implementation of `_.create` without support for assigning\n * properties to the created object.\n *\n * @private\n * @param {Object} proto The object to inherit from.\n * @returns {Object} Returns the new object.\n */\nvar baseCreate = (function() {\n  function object() {}\n  return function(proto) {\n    if (!isObject(proto)) {\n      return {};\n    }\n    if (objectCreate) {\n      return objectCreate(proto);\n    }\n    object.prototype = proto;\n    var result = new object;\n    object.prototype = undefined;\n    return result;\n  };\n}());\n\nexport default baseCreate;\n","import Uint8Array from './_Uint8Array.js';\n\n/**\n * Creates a clone of `arrayBuffer`.\n *\n * @private\n * @param {ArrayBuffer} arrayBuffer The array buffer to clone.\n * @returns {ArrayBuffer} Returns the cloned array buffer.\n */\nfunction cloneArrayBuffer(arrayBuffer) {\n  var result = new arrayBuffer.constructor(arrayBuffer.byteLength);\n  new Uint8Array(result).set(new Uint8Array(arrayBuffer));\n  return result;\n}\n\nexport default cloneArrayBuffer;\n","import cloneArrayBuffer from './_cloneArrayBuffer.js';\n\n/**\n * Creates a clone of `dataView`.\n *\n * @private\n * @param {Object} dataView The data view to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned data view.\n */\nfunction cloneDataView(dataView, isDeep) {\n  var buffer = isDeep ? cloneArrayBuffer(dataView.buffer) : dataView.buffer;\n  return new dataView.constructor(buffer, dataView.byteOffset, dataView.byteLength);\n}\n\nexport default cloneDataView;\n","import Symbol from './_Symbol.js';\n\n/** Used to convert symbols to primitives and strings. */\nvar symbolProto = Symbol ? Symbol.prototype : undefined,\n    symbolValueOf = symbolProto ? symbolProto.valueOf : undefined;\n\n/**\n * Creates a clone of the `symbol` object.\n *\n * @private\n * @param {Object} symbol The symbol object to clone.\n * @returns {Object} Returns the cloned symbol object.\n */\nfunction cloneSymbol(symbol) {\n  return symbolValueOf ? Object(symbolValueOf.call(symbol)) : {};\n}\n\nexport default cloneSymbol;\n","import cloneArrayBuffer from './_cloneArrayBuffer.js';\n\n/**\n * Creates a clone of `typedArray`.\n *\n * @private\n * @param {Object} typedArray The typed array to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned typed array.\n */\nfunction cloneTypedArray(typedArray, isDeep) {\n  var buffer = isDeep ? cloneArrayBuffer(typedArray.buffer) : typedArray.buffer;\n  return new typedArray.constructor(buffer, typedArray.byteOffset, typedArray.length);\n}\n\nexport default cloneTypedArray;\n","import baseEach from './_baseEach.js';\n\n/**\n * Aggregates elements of `collection` on `accumulator` with keys transformed\n * by `iteratee` and values set by `setter`.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} setter The function to set `accumulator` values.\n * @param {Function} iteratee The iteratee to transform keys.\n * @param {Object} accumulator The initial aggregated object.\n * @returns {Function} Returns `accumulator`.\n */\nfunction baseAggregator(collection, setter, iteratee, accumulator) {\n  baseEach(collection, function(value, key, collection) {\n    setter(accumulator, value, iteratee(value), collection);\n  });\n  return accumulator;\n}\n\nexport default baseAggregator;\n","import eq from './eq.js';\n\n/**\n * Gets the index at which the `key` is found in `array` of key-value pairs.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} key The key to search for.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction assocIndexOf(array, key) {\n  var length = array.length;\n  while (length--) {\n    if (eq(array[length][0], key)) {\n      return length;\n    }\n  }\n  return -1;\n}\n\nexport default assocIndexOf;\n","import assocIndexOf from './_assocIndexOf.js';\n\n/** Used for built-in method references. */\nvar arrayProto = Array.prototype;\n\n/** Built-in value references. */\nvar splice = arrayProto.splice;\n\n/**\n * Removes `key` and its value from the list cache.\n *\n * @private\n * @name delete\n * @memberOf ListCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction listCacheDelete(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    return false;\n  }\n  var lastIndex = data.length - 1;\n  if (index == lastIndex) {\n    data.pop();\n  } else {\n    splice.call(data, index, 1);\n  }\n  --this.size;\n  return true;\n}\n\nexport default listCacheDelete;\n","import assocIndexOf from './_assocIndexOf.js';\n\n/**\n * Gets the list cache value for `key`.\n *\n * @private\n * @name get\n * @memberOf ListCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction listCacheGet(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  return index < 0 ? undefined : data[index][1];\n}\n\nexport default listCacheGet;\n","import assocIndexOf from './_assocIndexOf.js';\n\n/**\n * Checks if a list cache value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf ListCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction listCacheHas(key) {\n  return assocIndexOf(this.__data__, key) > -1;\n}\n\nexport default listCacheHas;\n","import assocIndexOf from './_assocIndexOf.js';\n\n/**\n * Sets the list cache `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf ListCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the list cache instance.\n */\nfunction listCacheSet(key, value) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    ++this.size;\n    data.push([key, value]);\n  } else {\n    data[index][1] = value;\n  }\n  return this;\n}\n\nexport default listCacheSet;\n","import ListCache from './_ListCache.js';\n\n/**\n * Removes all key-value entries from the stack.\n *\n * @private\n * @name clear\n * @memberOf Stack\n */\nfunction stackClear() {\n  this.__data__ = new ListCache;\n  this.size = 0;\n}\n\nexport default stackClear;\n","import freeGlobal from './_freeGlobal.js';\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root = freeGlobal || freeSelf || Function('return this')();\n\nexport default root;\n","import root from './_root.js';\n\n/** Built-in value references. */\nvar Symbol = root.Symbol;\n\nexport default Symbol;\n","import Symbol from './_Symbol.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar nativeObjectToString = objectProto.toString;\n\n/** Built-in value references. */\nvar symToStringTag = Symbol ? Symbol.toStringTag : undefined;\n\n/**\n * A specialized version of `baseGetTag` which ignores `Symbol.toStringTag` values.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the raw `toStringTag`.\n */\nfunction getRawTag(value) {\n  var isOwn = hasOwnProperty.call(value, symToStringTag),\n      tag = value[symToStringTag];\n\n  try {\n    value[symToStringTag] = undefined;\n    var unmasked = true;\n  } catch (e) {}\n\n  var result = nativeObjectToString.call(value);\n  if (unmasked) {\n    if (isOwn) {\n      value[symToStringTag] = tag;\n    } else {\n      delete value[symToStringTag];\n    }\n  }\n  return result;\n}\n\nexport default getRawTag;\n","import root from './_root.js';\n\n/** Used to detect overreaching core-js shims. */\nvar coreJsData = root['__core-js_shared__'];\n\nexport default coreJsData;\n","import coreJsData from './_coreJsData.js';\n\n/** Used to detect methods masquerading as native. */\nvar maskSrcKey = (function() {\n  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');\n  return uid ? ('Symbol(src)_1.' + uid) : '';\n}());\n\n/**\n * Checks if `func` has its source masked.\n *\n * @private\n * @param {Function} func The function to check.\n * @returns {boolean} Returns `true` if `func` is masked, else `false`.\n */\nfunction isMasked(func) {\n  return !!maskSrcKey && (maskSrcKey in func);\n}\n\nexport default isMasked;\n","import getNative from './_getNative.js';\n\n/* Built-in method references that are verified to be native. */\nvar nativeCreate = getNative(Object, 'create');\n\nexport default nativeCreate;\n","import nativeCreate from './_nativeCreate.js';\n\n/**\n * Removes all key-value entries from the hash.\n *\n * @private\n * @name clear\n * @memberOf Hash\n */\nfunction hashClear() {\n  this.__data__ = nativeCreate ? nativeCreate(null) : {};\n  this.size = 0;\n}\n\nexport default hashClear;\n","import nativeCreate from './_nativeCreate.js';\n\n/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Gets the hash value for `key`.\n *\n * @private\n * @name get\n * @memberOf Hash\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction hashGet(key) {\n  var data = this.__data__;\n  if (nativeCreate) {\n    var result = data[key];\n    return result === HASH_UNDEFINED ? undefined : result;\n  }\n  return hasOwnProperty.call(data, key) ? data[key] : undefined;\n}\n\nexport default hashGet;\n","import nativeCreate from './_nativeCreate.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Checks if a hash value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Hash\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction hashHas(key) {\n  var data = this.__data__;\n  return nativeCreate ? (data[key] !== undefined) : hasOwnProperty.call(data, key);\n}\n\nexport default hashHas;\n","import nativeCreate from './_nativeCreate.js';\n\n/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/**\n * Sets the hash `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Hash\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the hash instance.\n */\nfunction hashSet(key, value) {\n  var data = this.__data__;\n  this.size += this.has(key) ? 0 : 1;\n  data[key] = (nativeCreate && value === undefined) ? HASH_UNDEFINED : value;\n  return this;\n}\n\nexport default hashSet;\n","import isKeyable from './_isKeyable.js';\n\n/**\n * Gets the data for `map`.\n *\n * @private\n * @param {Object} map The map to query.\n * @param {string} key The reference key.\n * @returns {*} Returns the map data.\n */\nfunction getMapData(map, key) {\n  var data = map.__data__;\n  return isKeyable(key)\n    ? data[typeof key == 'string' ? 'string' : 'hash']\n    : data.map;\n}\n\nexport default getMapData;\n","import getMapData from './_getMapData.js';\n\n/**\n * Removes `key` and its value from the map.\n *\n * @private\n * @name delete\n * @memberOf MapCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction mapCacheDelete(key) {\n  var result = getMapData(this, key)['delete'](key);\n  this.size -= result ? 1 : 0;\n  return result;\n}\n\nexport default mapCacheDelete;\n","import getMapData from './_getMapData.js';\n\n/**\n * Gets the map value for `key`.\n *\n * @private\n * @name get\n * @memberOf MapCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction mapCacheGet(key) {\n  return getMapData(this, key).get(key);\n}\n\nexport default mapCacheGet;\n","import getMapData from './_getMapData.js';\n\n/**\n * Checks if a map value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf MapCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction mapCacheHas(key) {\n  return getMapData(this, key).has(key);\n}\n\nexport default mapCacheHas;\n","import getMapData from './_getMapData.js';\n\n/**\n * Sets the map `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf MapCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the map cache instance.\n */\nfunction mapCacheSet(key, value) {\n  var data = getMapData(this, key),\n      size = data.size;\n\n  data.set(key, value);\n  this.size += data.size == size ? 0 : 1;\n  return this;\n}\n\nexport default mapCacheSet;\n","import getNative from './_getNative.js';\n\nvar defineProperty = (function() {\n  try {\n    var func = getNative(Object, 'defineProperty');\n    func({}, '', {});\n    return func;\n  } catch (e) {}\n}());\n\nexport default defineProperty;\n","import defineProperty from './_defineProperty.js';\n\n/**\n * The base implementation of `assignValue` and `assignMergeValue` without\n * value checks.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {string} key The key of the property to assign.\n * @param {*} value The value to assign.\n */\nfunction baseAssignValue(object, key, value) {\n  if (key == '__proto__' && defineProperty) {\n    defineProperty(object, key, {\n      'configurable': true,\n      'enumerable': true,\n      'value': value,\n      'writable': true\n    });\n  } else {\n    object[key] = value;\n  }\n}\n\nexport default baseAssignValue;\n","import freeGlobal from './_freeGlobal.js';\n\n/** Detect free variable `exports`. */\nvar freeExports = typeof exports == 'object' && exports && !exports.nodeType && exports;\n\n/** Detect free variable `module`. */\nvar freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;\n\n/** Detect the popular CommonJS extension `module.exports`. */\nvar moduleExports = freeModule && freeModule.exports === freeExports;\n\n/** Detect free variable `process` from Node.js. */\nvar freeProcess = moduleExports && freeGlobal.process;\n\n/** Used to access faster Node.js helpers. */\nvar nodeUtil = (function() {\n  try {\n    // Use `util.types` for Node.js 10+.\n    var types = freeModule && freeModule.require && freeModule.require('util').types;\n\n    if (types) {\n      return types;\n    }\n\n    // Legacy `process.binding('util')` for Node.js < 10.\n    return freeProcess && freeProcess.binding && freeProcess.binding('util');\n  } catch (e) {}\n}());\n\nexport default nodeUtil;\n","import { cc } from \"./utils.js\";\n\nexport const digitsCharCodes: number[] = [];\nfor (let i = cc(\"0\"); i <= cc(\"9\"); i++) {\n  digitsCharCodes.push(i);\n}\n\nexport const wordCharCodes: number[] = [cc(\"_\")].concat(digitsCharCodes);\nfor (let i = cc(\"a\"); i <= cc(\"z\"); i++) {\n  wordCharCodes.push(i);\n}\n\nfor (let i = cc(\"A\"); i <= cc(\"Z\"); i++) {\n  wordCharCodes.push(i);\n}\n\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp#character-classes\nexport const whitespaceCodes: number[] = [\n  cc(\" \"),\n  cc(\"\\f\"),\n  cc(\"\\n\"),\n  cc(\"\\r\"),\n  cc(\"\\t\"),\n  cc(\"\\v\"),\n  cc(\"\\t\"),\n  cc(\"\\u00a0\"),\n  cc(\"\\u1680\"),\n  cc(\"\\u2000\"),\n  cc(\"\\u2001\"),\n  cc(\"\\u2002\"),\n  cc(\"\\u2003\"),\n  cc(\"\\u2004\"),\n  cc(\"\\u2005\"),\n  cc(\"\\u2006\"),\n  cc(\"\\u2007\"),\n  cc(\"\\u2008\"),\n  cc(\"\\u2009\"),\n  cc(\"\\u200a\"),\n  cc(\"\\u2028\"),\n  cc(\"\\u2029\"),\n  cc(\"\\u202f\"),\n  cc(\"\\u205f\"),\n  cc(\"\\u3000\"),\n  cc(\"\\ufeff\"),\n];\n","const NAME = \"name\";\n\nexport function defineNameProp(obj: {}, nameValue: string): void {\n  Object.defineProperty(obj, NAME, {\n    enumerable: false,\n    configurable: true,\n    writable: false,\n    value: nameValue,\n  });\n}\n","import {\n  Alternative,\n  Assertion,\n  Atom,\n  Disjunction,\n  RegExpParser,\n  RegExpPattern,\n} from \"@chevrotain/regexp-to-ast\";\n\nlet regExpAstCache: { [regex: string]: RegExpPattern } = {};\nconst regExpParser = new RegExpParser();\n\n// this should be moved to regexp-to-ast\nexport type ASTNode =\n  | RegExpPattern\n  | Disjunction\n  | Alternative\n  | Assertion\n  | Atom;\n\nexport function getRegExpAst(regExp: RegExp): RegExpPattern {\n  const regExpStr = regExp.toString();\n  if (regExpAstCache.hasOwnProperty(regExpStr)) {\n    return regExpAstCache[regExpStr];\n  } else {\n    const regExpAst = regExpParser.pattern(regExpStr);\n    regExpAstCache[regExpStr] = regExpAst;\n    return regExpAst;\n  }\n}\n\nexport function clearRegExpParserCache() {\n  regExpAstCache = {};\n}\n","import { GenerateDtsOptions, Rule } from \"@chevrotain/types\";\nimport { buildModel } from \"./model.js\";\nimport { genDts } from \"./generate.js\";\n\nconst defaultOptions: Required<GenerateDtsOptions> = {\n  includeVisitorInterface: true,\n  visitorInterfaceName: \"ICstNodeVisitor\",\n};\n\nexport function generateCstDts(\n  productions: Record<string, Rule>,\n  options?: GenerateDtsOptions,\n): string {\n  const effectiveOptions = {\n    ...defaultOptions,\n    ...options,\n  };\n\n  const model = buildModel(productions);\n\n  return genDts(model, effectiveOptions);\n}\n","import { RestWalker } from \"./rest.js\";\nimport { first } from \"./first.js\";\nimport { assign, forEach } from \"lodash-es\";\nimport { IN } from \"../constants.js\";\nimport { Alternative, NonTerminal, Rule, Terminal } from \"@chevrotain/gast\";\nimport { IProduction, TokenType } from \"@chevrotain/types\";\n\n// This ResyncFollowsWalker computes all of the follows required for RESYNC\n// (skipping reference production).\nexport class ResyncFollowsWalker extends RestWalker {\n  public follows: Record<string, TokenType[]> = {};\n\n  constructor(private topProd: Rule) {\n    super();\n  }\n\n  startWalking(): Record<string, TokenType[]> {\n    this.walk(this.topProd);\n    return this.follows;\n  }\n\n  walkTerminal(\n    terminal: Terminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // do nothing! just like in the public sector after 13:00\n  }\n\n  walkProdRef(\n    refProd: NonTerminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    const followName =\n      buildBetweenProdsFollowPrefix(refProd.referencedRule, refProd.idx) +\n      this.topProd.name;\n    const fullRest: IProduction[] = currRest.concat(prevRest);\n    const restProd = new Alternative({ definition: fullRest });\n    const t_in_topProd_follows = first(restProd);\n    this.follows[followName] = t_in_topProd_follows;\n  }\n}\n\nexport function computeAllProdsFollows(\n  topProductions: Rule[],\n): Record<string, TokenType[]> {\n  const reSyncFollows = {};\n\n  forEach(topProductions, (topProd) => {\n    const currRefsFollow = new ResyncFollowsWalker(topProd).startWalking();\n    assign(reSyncFollows, currRefsFollow);\n  });\n  return reSyncFollows;\n}\n\nexport function buildBetweenProdsFollowPrefix(\n  inner: Rule,\n  occurenceInParent: number,\n): string {\n  return inner.name + occurenceInParent + IN;\n}\n\nexport function buildInProdFollowPrefix(terminal: Terminal): string {\n  const terminalName = terminal.terminalType.name;\n  return terminalName + terminal.idx + IN;\n}\n","import { Rule } from \"@chevrotain/gast\";\nimport { defaults, forEach } from \"lodash-es\";\nimport { resolveGrammar as orgResolveGrammar } from \"../resolver.js\";\nimport { validateGrammar as orgValidateGrammar } from \"../checks.js\";\nimport {\n  defaultGrammarResolverErrorProvider,\n  defaultGrammarValidatorErrorProvider,\n} from \"../../errors_public.js\";\nimport { TokenType } from \"@chevrotain/types\";\nimport {\n  IGrammarResolverErrorMessageProvider,\n  IGrammarValidatorErrorMessageProvider,\n  IParserDefinitionError,\n} from \"../types.js\";\n\ntype ResolveGrammarOpts = {\n  rules: Rule[];\n  errMsgProvider?: IGrammarResolverErrorMessageProvider;\n};\nexport function resolveGrammar(\n  options: ResolveGrammarOpts,\n): IParserDefinitionError[] {\n  const actualOptions: Required<ResolveGrammarOpts> = defaults(options, {\n    errMsgProvider: defaultGrammarResolverErrorProvider,\n  });\n\n  const topRulesTable: { [ruleName: string]: Rule } = {};\n  forEach(options.rules, (rule) => {\n    topRulesTable[rule.name] = rule;\n  });\n  return orgResolveGrammar(topRulesTable, actualOptions.errMsgProvider);\n}\n\nexport function validateGrammar(options: {\n  rules: Rule[];\n  tokenTypes: TokenType[];\n  grammarName: string;\n  errMsgProvider: IGrammarValidatorErrorMessageProvider;\n}): IParserDefinitionError[] {\n  options = defaults(options, {\n    errMsgProvider: defaultGrammarValidatorErrorProvider,\n  });\n\n  return orgValidateGrammar(\n    options.rules,\n    options.tokenTypes,\n    options.errMsgProvider,\n    options.grammarName,\n  );\n}\n","/* istanbul ignore file - tricky to import some things from this module during testing */\n\n// semantic version\nexport { VERSION } from \"./version.js\";\n\nexport {\n  CstParser,\n  EmbeddedActionsParser,\n  ParserDefinitionErrorType,\n  EMPTY_ALT,\n} from \"./parse/parser/parser.js\";\n\nexport { Lexer, LexerDefinitionErrorType } from \"./scan/lexer_public.js\";\n\n// Tokens utilities\nexport {\n  createToken,\n  createTokenInstance,\n  EOF,\n  tokenLabel,\n  tokenMatcher,\n  tokenName,\n} from \"./scan/tokens_public.js\";\n\n// Lookahead\n\nexport { getLookaheadPaths } from \"./parse/grammar/lookahead.js\";\n\nexport { LLkLookaheadStrategy } from \"./parse/grammar/llk_lookahead.js\";\n\n// Other Utilities\n\nexport { defaultParserErrorProvider } from \"./parse/errors_public.js\";\n\nexport {\n  EarlyExitException,\n  isRecognitionException,\n  MismatchedTokenException,\n  NotAllInputParsedException,\n  NoViableAltException,\n} from \"./parse/exceptions_public.js\";\n\nexport { defaultLexerErrorProvider } from \"./scan/lexer_errors_public.js\";\n\n// grammar reflection API\nexport {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"@chevrotain/gast\";\n\n// GAST Utilities\n\nexport {\n  serializeGrammar,\n  serializeProduction,\n  GAstVisitor,\n} from \"@chevrotain/gast\";\n\nexport { generateCstDts } from \"@chevrotain/cst-dts-gen\";\n\n/* istanbul ignore next */\nexport function clearCache() {\n  console.warn(\n    \"The clearCache function was 'soft' removed from the Chevrotain API.\" +\n      \"\\n\\t It performs no action other than printing this message.\" +\n      \"\\n\\t Please avoid using it as it will be completely removed in the future\",\n  );\n}\n\nexport { createSyntaxDiagramsCode } from \"./diagrams/render_public.js\";\n\nexport class Parser {\n  constructor() {\n    throw new Error(\n      \"The Parser class has been deprecated, use CstParser or EmbeddedActionsParser instead.\\t\\n\" +\n        \"See: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_7-0-0\",\n    );\n  }\n}\n","import { ILexerErrorMessageProvider, IToken } from \"@chevrotain/types\";\n\nexport const defaultLexerErrorProvider: ILexerErrorMessageProvider = {\n  buildUnableToPopLexerModeMessage(token: IToken): string {\n    return `Unable to pop Lexer Mode after encountering Token ->${token.image}<- The Mode Stack is empty`;\n  },\n\n  buildUnexpectedCharactersMessage(\n    fullText: string,\n    startOffset: number,\n    length: number,\n    line?: number,\n    column?: number,\n  ): string {\n    return (\n      `unexpected character: ->${fullText.charAt(\n        startOffset,\n      )}<- at offset: ${startOffset},` + ` skipped ${length} characters.`\n    );\n  },\n};\n","import { has, isString, isUndefined } from \"lodash-es\";\nimport { Lexer } from \"./lexer_public.js\";\nimport { augmentTokenTypes, tokenStructuredMatcher } from \"./tokens.js\";\nimport { IToken, ITokenConfig, TokenType } from \"@chevrotain/types\";\n\nexport function tokenLabel(tokType: TokenType): string {\n  if (hasTokenLabel(tokType)) {\n    return tokType.LABEL;\n  } else {\n    return tokType.name;\n  }\n}\n\nexport function tokenName(tokType: TokenType): string {\n  return tokType.name;\n}\n\nexport function hasTokenLabel(\n  obj: TokenType,\n): obj is TokenType & Pick<Required<TokenType>, \"LABEL\"> {\n  return isString(obj.LABEL) && obj.LABEL !== \"\";\n}\n\nconst PARENT = \"parent\";\nconst CATEGORIES = \"categories\";\nconst LABEL = \"label\";\nconst GROUP = \"group\";\nconst PUSH_MODE = \"push_mode\";\nconst POP_MODE = \"pop_mode\";\nconst LONGER_ALT = \"longer_alt\";\nconst LINE_BREAKS = \"line_breaks\";\nconst START_CHARS_HINT = \"start_chars_hint\";\n\nexport function createToken(config: ITokenConfig): TokenType {\n  return createTokenInternal(config);\n}\n\nfunction createTokenInternal(config: ITokenConfig): TokenType {\n  const pattern = config.pattern;\n\n  const tokenType: TokenType = <any>{};\n  tokenType.name = config.name;\n\n  if (!isUndefined(pattern)) {\n    tokenType.PATTERN = pattern;\n  }\n\n  if (has(config, PARENT)) {\n    throw (\n      \"The parent property is no longer supported.\\n\" +\n      \"See: https://github.com/chevrotain/chevrotain/issues/564#issuecomment-349062346 for details.\"\n    );\n  }\n\n  if (has(config, CATEGORIES)) {\n    // casting to ANY as this will be fixed inside `augmentTokenTypes``\n    tokenType.CATEGORIES = <any>config[CATEGORIES];\n  }\n\n  augmentTokenTypes([tokenType]);\n\n  if (has(config, LABEL)) {\n    tokenType.LABEL = config[LABEL];\n  }\n\n  if (has(config, GROUP)) {\n    tokenType.GROUP = config[GROUP];\n  }\n\n  if (has(config, POP_MODE)) {\n    tokenType.POP_MODE = config[POP_MODE];\n  }\n\n  if (has(config, PUSH_MODE)) {\n    tokenType.PUSH_MODE = config[PUSH_MODE];\n  }\n\n  if (has(config, LONGER_ALT)) {\n    tokenType.LONGER_ALT = config[LONGER_ALT];\n  }\n\n  if (has(config, LINE_BREAKS)) {\n    tokenType.LINE_BREAKS = config[LINE_BREAKS];\n  }\n\n  if (has(config, START_CHARS_HINT)) {\n    tokenType.START_CHARS_HINT = config[START_CHARS_HINT];\n  }\n\n  return tokenType;\n}\n\nexport const EOF = createToken({ name: \"EOF\", pattern: Lexer.NA });\naugmentTokenTypes([EOF]);\n\nexport function createTokenInstance(\n  tokType: TokenType,\n  image: string,\n  startOffset: number,\n  endOffset: number,\n  startLine: number,\n  endLine: number,\n  startColumn: number,\n  endColumn: number,\n): IToken {\n  return {\n    image,\n    startOffset,\n    endOffset,\n    startLine,\n    endLine,\n    startColumn,\n    endColumn,\n    tokenTypeIdx: (<any>tokType).tokenTypeIdx,\n    tokenType: tokType,\n  };\n}\n\nexport function tokenMatcher(token: IToken, tokType: TokenType): boolean {\n  return tokenStructuredMatcher(token, tokType);\n}\n","import {\n  IParserConfig,\n  IParserErrorMessageProvider,\n  IRecognitionException,\n} from \"@chevrotain/types\";\nimport {\n  EarlyExitException,\n  isRecognitionException,\n  NoViableAltException,\n} from \"../../exceptions_public.js\";\nimport { clone, has } from \"lodash-es\";\nimport {\n  getLookaheadPathsForOptionalProd,\n  getLookaheadPathsForOr,\n  PROD_TYPE,\n} from \"../../grammar/lookahead.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\n/**\n * Trait responsible for runtime parsing errors.\n */\nexport class ErrorHandler {\n  _errors: IRecognitionException[];\n  errorMessageProvider: IParserErrorMessageProvider;\n\n  initErrorHandler(config: IParserConfig) {\n    this._errors = [];\n    this.errorMessageProvider = has(config, \"errorMessageProvider\")\n      ? (config.errorMessageProvider as IParserErrorMessageProvider) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.errorMessageProvider;\n  }\n\n  SAVE_ERROR(\n    this: MixedInParser,\n    error: IRecognitionException,\n  ): IRecognitionException {\n    if (isRecognitionException(error)) {\n      error.context = {\n        ruleStack: this.getHumanReadableRuleStack(),\n        ruleOccurrenceStack: clone(this.RULE_OCCURRENCE_STACK),\n      };\n      this._errors.push(error);\n      return error;\n    } else {\n      throw Error(\n        \"Trying to save an Error which is not a RecognitionException\",\n      );\n    }\n  }\n\n  get errors(): IRecognitionException[] {\n    return clone(this._errors);\n  }\n\n  set errors(newErrors: IRecognitionException[]) {\n    this._errors = newErrors;\n  }\n\n  // TODO: consider caching the error message computed information\n  raiseEarlyExitException(\n    this: MixedInParser,\n    occurrence: number,\n    prodType: PROD_TYPE,\n    userDefinedErrMsg: string | undefined,\n  ): never {\n    const ruleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[ruleName];\n    const lookAheadPathsPerAlternative = getLookaheadPathsForOptionalProd(\n      occurrence,\n      ruleGrammar,\n      prodType,\n      this.maxLookahead,\n    );\n    const insideProdPaths = lookAheadPathsPerAlternative[0];\n    const actualTokens = [];\n    for (let i = 1; i <= this.maxLookahead; i++) {\n      actualTokens.push(this.LA(i));\n    }\n    const msg = this.errorMessageProvider.buildEarlyExitMessage({\n      expectedIterationPaths: insideProdPaths,\n      actual: actualTokens,\n      previous: this.LA(0),\n      customUserDescription: userDefinedErrMsg,\n      ruleName: ruleName,\n    });\n\n    throw this.SAVE_ERROR(new EarlyExitException(msg, this.LA(1), this.LA(0)));\n  }\n\n  // TODO: consider caching the error message computed information\n  raiseNoAltException(\n    this: MixedInParser,\n    occurrence: number,\n    errMsgTypes: string | undefined,\n  ): never {\n    const ruleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[ruleName];\n    // TODO: getLookaheadPathsForOr can be slow for large enough maxLookahead and certain grammars, consider caching ?\n    const lookAheadPathsPerAlternative = getLookaheadPathsForOr(\n      occurrence,\n      ruleGrammar,\n      this.maxLookahead,\n    );\n\n    const actualTokens = [];\n    for (let i = 1; i <= this.maxLookahead; i++) {\n      actualTokens.push(this.LA(i));\n    }\n    const previousToken = this.LA(0);\n\n    const errMsg = this.errorMessageProvider.buildNoViableAltMessage({\n      expectedPathsPerAlt: lookAheadPathsPerAlternative,\n      actual: actualTokens,\n      previous: previousToken,\n      customUserDescription: errMsgTypes,\n      ruleName: this.getCurrRuleFullName(),\n    });\n\n    throw this.SAVE_ERROR(\n      new NoViableAltException(errMsg, this.LA(1), previousToken),\n    );\n  }\n}\n","import { BaseRegExpVisitor } from \"@chevrotain/regexp-to-ast\";\nimport {\n  IRegExpExec,\n  Lexer,\n  LexerDefinitionErrorType,\n} from \"./lexer_public.js\";\nimport {\n  compact,\n  defaults,\n  difference,\n  filter,\n  find,\n  first,\n  flatten,\n  forEach,\n  has,\n  includes,\n  indexOf,\n  isArray,\n  isEmpty,\n  isFunction,\n  isRegExp,\n  isString,\n  isUndefined,\n  keys,\n  map,\n  reduce,\n  reject,\n  values,\n} from \"lodash-es\";\nimport { PRINT_ERROR } from \"@chevrotain/utils\";\nimport {\n  canMatchCharCode,\n  failedOptimizationPrefixMsg,\n  getOptimizedStartCodesIndices,\n} from \"./reg_exp.js\";\nimport {\n  ILexerDefinitionError,\n  ILineTerminatorsTester,\n  IMultiModeLexerDefinition,\n  IToken,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { getRegExpAst } from \"./reg_exp_parser.js\";\n\nconst PATTERN = \"PATTERN\";\nexport const DEFAULT_MODE = \"defaultMode\";\nexport const MODES = \"modes\";\n\nexport interface IPatternConfig {\n  pattern: IRegExpExec | string;\n  longerAlt: number[] | undefined;\n  canLineTerminator: boolean;\n  isCustom: boolean;\n  short: number | false;\n  group: string | undefined | false;\n  push: string | undefined;\n  pop: boolean;\n  tokenType: TokenType;\n  tokenTypeIdx: number;\n}\n\nexport interface IAnalyzeResult {\n  patternIdxToConfig: IPatternConfig[];\n  charCodeToPatternIdxToConfig: { [charCode: number]: IPatternConfig[] };\n  emptyGroups: { [groupName: string]: IToken[] };\n  hasCustom: boolean;\n  canBeOptimized: boolean;\n}\n\nexport let SUPPORT_STICKY =\n  typeof (<any>new RegExp(\"(?:)\")).sticky === \"boolean\";\n\nexport function disableSticky() {\n  SUPPORT_STICKY = false;\n}\n\nexport function enableSticky() {\n  SUPPORT_STICKY = true;\n}\n\nexport function analyzeTokenTypes(\n  tokenTypes: TokenType[],\n  options: {\n    positionTracking?: \"full\" | \"onlyStart\" | \"onlyOffset\";\n    ensureOptimizations?: boolean;\n    lineTerminatorCharacters?: (number | string)[];\n    // TODO: should `useSticky` be an argument here?\n    useSticky?: boolean;\n    safeMode?: boolean;\n    tracer?: (msg: string, action: () => void) => void;\n  },\n): IAnalyzeResult {\n  options = defaults(options, {\n    useSticky: SUPPORT_STICKY,\n    debug: false as boolean,\n    safeMode: false as boolean,\n    positionTracking: \"full\",\n    lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n    tracer: (msg: string, action: Function) => action(),\n  });\n\n  const tracer = options.tracer!;\n\n  tracer(\"initCharCodeToOptimizedIndexMap\", () => {\n    initCharCodeToOptimizedIndexMap();\n  });\n\n  let onlyRelevantTypes: TokenType[];\n  tracer(\"Reject Lexer.NA\", () => {\n    onlyRelevantTypes = reject(tokenTypes, (currType) => {\n      return currType[PATTERN] === Lexer.NA;\n    });\n  });\n\n  let hasCustom = false;\n  let allTransformedPatterns: (IRegExpExec | string)[];\n  tracer(\"Transform Patterns\", () => {\n    hasCustom = false;\n    allTransformedPatterns = map(\n      onlyRelevantTypes,\n      (currType): IRegExpExec | string => {\n        const currPattern = currType[PATTERN];\n\n        /* istanbul ignore else */\n        if (isRegExp(currPattern)) {\n          const regExpSource = currPattern.source;\n          if (\n            regExpSource.length === 1 &&\n            // only these regExp meta characters which can appear in a length one regExp\n            regExpSource !== \"^\" &&\n            regExpSource !== \"$\" &&\n            regExpSource !== \".\" &&\n            !currPattern.ignoreCase\n          ) {\n            return regExpSource;\n          } else if (\n            regExpSource.length === 2 &&\n            regExpSource[0] === \"\\\\\" &&\n            // not a meta character\n            !includes(\n              [\n                \"d\",\n                \"D\",\n                \"s\",\n                \"S\",\n                \"t\",\n                \"r\",\n                \"n\",\n                \"t\",\n                \"0\",\n                \"c\",\n                \"b\",\n                \"B\",\n                \"f\",\n                \"v\",\n                \"w\",\n                \"W\",\n              ],\n              regExpSource[1],\n            )\n          ) {\n            // escaped meta Characters: /\\+/ /\\[/\n            // or redundant escaping: /\\a/\n            // without the escaping \"\\\"\n            return regExpSource[1];\n          } else {\n            return options.useSticky\n              ? addStickyFlag(currPattern)\n              : addStartOfInput(currPattern);\n          }\n        } else if (isFunction(currPattern)) {\n          hasCustom = true;\n          // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n          return { exec: currPattern };\n        } else if (typeof currPattern === \"object\") {\n          hasCustom = true;\n          // ICustomPattern\n          return currPattern;\n        } else if (typeof currPattern === \"string\") {\n          if (currPattern.length === 1) {\n            return currPattern;\n          } else {\n            const escapedRegExpString = currPattern.replace(\n              /[\\\\^$.*+?()[\\]{}|]/g,\n              \"\\\\$&\",\n            );\n            const wrappedRegExp = new RegExp(escapedRegExpString);\n            return options.useSticky\n              ? addStickyFlag(wrappedRegExp)\n              : addStartOfInput(wrappedRegExp);\n          }\n        } else {\n          throw Error(\"non exhaustive match\");\n        }\n      },\n    );\n  });\n\n  let patternIdxToType: number[];\n  let patternIdxToGroup: (string | undefined | false)[];\n  let patternIdxToLongerAltIdxArr: (number[] | undefined)[];\n  let patternIdxToPushMode: (string | undefined)[];\n  let patternIdxToPopMode: boolean[];\n  tracer(\"misc mapping\", () => {\n    patternIdxToType = map(\n      onlyRelevantTypes,\n      (currType) => currType.tokenTypeIdx!,\n    );\n\n    patternIdxToGroup = map(onlyRelevantTypes, (clazz: any) => {\n      const groupName = clazz.GROUP;\n      /* istanbul ignore next */\n      if (groupName === Lexer.SKIPPED) {\n        return undefined;\n      } else if (isString(groupName)) {\n        return groupName;\n      } else if (isUndefined(groupName)) {\n        return false;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n\n    patternIdxToLongerAltIdxArr = map(onlyRelevantTypes, (clazz: any) => {\n      const longerAltType = clazz.LONGER_ALT;\n\n      if (longerAltType) {\n        const longerAltIdxArr = isArray(longerAltType)\n          ? map(longerAltType, (type: any) => indexOf(onlyRelevantTypes, type))\n          : [indexOf(onlyRelevantTypes, longerAltType)];\n        return longerAltIdxArr;\n      }\n    });\n\n    patternIdxToPushMode = map(\n      onlyRelevantTypes,\n      (clazz: any) => clazz.PUSH_MODE,\n    );\n\n    patternIdxToPopMode = map(onlyRelevantTypes, (clazz: any) =>\n      has(clazz, \"POP_MODE\"),\n    );\n  });\n\n  let patternIdxToCanLineTerminator: boolean[];\n  tracer(\"Line Terminator Handling\", () => {\n    const lineTerminatorCharCodes = getCharCodes(\n      options.lineTerminatorCharacters!,\n    );\n    patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => false);\n    if (options.positionTracking !== \"onlyOffset\") {\n      patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => {\n        if (has(tokType, \"LINE_BREAKS\")) {\n          return !!tokType.LINE_BREAKS;\n        } else {\n          return (\n            checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false &&\n            canMatchCharCode(\n              lineTerminatorCharCodes,\n              tokType.PATTERN as RegExp | string,\n            )\n          );\n        }\n      });\n    }\n  });\n\n  let patternIdxToIsCustom: boolean[];\n  let patternIdxToShort: (number | false)[];\n  let emptyGroups!: { [groupName: string]: IToken[] };\n  let patternIdxToConfig!: IPatternConfig[];\n  tracer(\"Misc Mapping #2\", () => {\n    patternIdxToIsCustom = map(onlyRelevantTypes, isCustomPattern);\n    patternIdxToShort = map(allTransformedPatterns, isShortPattern);\n\n    emptyGroups = reduce(\n      onlyRelevantTypes,\n      (acc, clazz: any) => {\n        const groupName = clazz.GROUP;\n        if (isString(groupName) && !(groupName === Lexer.SKIPPED)) {\n          acc[groupName] = [];\n        }\n        return acc;\n      },\n      {} as { [groupName: string]: IToken[] },\n    );\n\n    patternIdxToConfig = map(\n      allTransformedPatterns,\n      (x, idx): IPatternConfig => {\n        return {\n          pattern: allTransformedPatterns[idx],\n          longerAlt: patternIdxToLongerAltIdxArr[idx],\n          canLineTerminator: patternIdxToCanLineTerminator[idx],\n          isCustom: patternIdxToIsCustom[idx],\n          short: patternIdxToShort[idx],\n          group: patternIdxToGroup[idx],\n          push: patternIdxToPushMode[idx],\n          pop: patternIdxToPopMode[idx],\n          tokenTypeIdx: patternIdxToType[idx],\n          tokenType: onlyRelevantTypes[idx],\n        };\n      },\n    );\n  });\n\n  let canBeOptimized = true;\n  let charCodeToPatternIdxToConfig: { [charCode: number]: IPatternConfig[] } =\n    [];\n\n  if (!options.safeMode) {\n    tracer(\"First Char Optimization\", () => {\n      charCodeToPatternIdxToConfig = reduce(\n        onlyRelevantTypes,\n        (result, currTokType, idx) => {\n          if (typeof currTokType.PATTERN === \"string\") {\n            const charCode = currTokType.PATTERN.charCodeAt(0);\n            const optimizedIdx = charCodeToOptimizedIndex(charCode);\n            addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n          } else if (isArray(currTokType.START_CHARS_HINT)) {\n            let lastOptimizedIdx: number;\n            forEach(currTokType.START_CHARS_HINT, (charOrInt) => {\n              const charCode =\n                typeof charOrInt === \"string\"\n                  ? charOrInt.charCodeAt(0)\n                  : charOrInt;\n              const currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n              // Avoid adding the config multiple times\n              /* istanbul ignore else */\n              // - Difficult to check this scenario effects as it is only a performance\n              //   optimization that does not change correctness\n              if (lastOptimizedIdx !== currOptimizedIdx) {\n                lastOptimizedIdx = currOptimizedIdx;\n                addToMapOfArrays(\n                  result,\n                  currOptimizedIdx,\n                  patternIdxToConfig[idx],\n                );\n              }\n            });\n          } else if (isRegExp(currTokType.PATTERN)) {\n            if (currTokType.PATTERN.unicode) {\n              canBeOptimized = false;\n              if (options.ensureOptimizations) {\n                PRINT_ERROR(\n                  `${failedOptimizationPrefixMsg}` +\n                    `\\tUnable to analyze < ${currTokType.PATTERN.toString()} > pattern.\\n` +\n                    \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" +\n                    \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                    \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\",\n                );\n              }\n            } else {\n              const optimizedCodes = getOptimizedStartCodesIndices(\n                currTokType.PATTERN,\n                options.ensureOptimizations,\n              );\n              /* istanbul ignore if */\n              // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n              // the first should be a different validation and the second cannot be tested.\n              if (isEmpty(optimizedCodes)) {\n                // we cannot understand what codes may start possible matches\n                // The optimization correctness requires knowing start codes for ALL patterns.\n                // Not actually sure this is an error, no debug message\n                canBeOptimized = false;\n              }\n              forEach(optimizedCodes, (code) => {\n                addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n              });\n            }\n          } else {\n            if (options.ensureOptimizations) {\n              PRINT_ERROR(\n                `${failedOptimizationPrefixMsg}` +\n                  `\\tTokenType: <${currTokType.name}> is using a custom token pattern without providing <start_chars_hint> parameter.\\n` +\n                  \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                  \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\",\n              );\n            }\n            canBeOptimized = false;\n          }\n\n          return result;\n        },\n        [] as { [charCode: number]: IPatternConfig[] },\n      );\n    });\n  }\n\n  return {\n    emptyGroups: emptyGroups,\n    patternIdxToConfig: patternIdxToConfig,\n    charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n    hasCustom: hasCustom,\n    canBeOptimized: canBeOptimized,\n  };\n}\n\nexport function validatePatterns(\n  tokenTypes: TokenType[],\n  validModesNames: string[],\n): ILexerDefinitionError[] {\n  let errors: ILexerDefinitionError[] = [];\n\n  const missingResult = findMissingPatterns(tokenTypes);\n  errors = errors.concat(missingResult.errors);\n\n  const invalidResult = findInvalidPatterns(missingResult.valid);\n  const validTokenTypes = invalidResult.valid;\n  errors = errors.concat(invalidResult.errors);\n\n  errors = errors.concat(validateRegExpPattern(validTokenTypes));\n\n  errors = errors.concat(findInvalidGroupType(validTokenTypes));\n\n  errors = errors.concat(\n    findModesThatDoNotExist(validTokenTypes, validModesNames),\n  );\n\n  errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n\n  return errors;\n}\n\nfunction validateRegExpPattern(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  let errors: ILexerDefinitionError[] = [];\n  const withRegExpPatterns = filter(tokenTypes, (currTokType) =>\n    isRegExp(currTokType[PATTERN]),\n  );\n\n  errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n\n  errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n\n  errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n\n  errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n\n  errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n\n  return errors;\n}\n\nexport interface ILexerFilterResult {\n  errors: ILexerDefinitionError[];\n  valid: TokenType[];\n}\n\nexport function findMissingPatterns(\n  tokenTypes: TokenType[],\n): ILexerFilterResult {\n  const tokenTypesWithMissingPattern = filter(tokenTypes, (currType) => {\n    return !has(currType, PATTERN);\n  });\n\n  const errors = map(tokenTypesWithMissingPattern, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- missing static 'PATTERN' property\",\n      type: LexerDefinitionErrorType.MISSING_PATTERN,\n      tokenTypes: [currType],\n    };\n  });\n\n  const valid = difference(tokenTypes, tokenTypesWithMissingPattern);\n  return { errors, valid };\n}\n\nexport function findInvalidPatterns(\n  tokenTypes: TokenType[],\n): ILexerFilterResult {\n  const tokenTypesWithInvalidPattern = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN];\n    return (\n      !isRegExp(pattern) &&\n      !isFunction(pattern) &&\n      !has(pattern, \"exec\") &&\n      !isString(pattern)\n    );\n  });\n\n  const errors = map(tokenTypesWithInvalidPattern, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' can only be a RegExp, a\" +\n        \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n      type: LexerDefinitionErrorType.INVALID_PATTERN,\n      tokenTypes: [currType],\n    };\n  });\n\n  const valid = difference(tokenTypes, tokenTypesWithInvalidPattern);\n  return { errors, valid };\n}\n\nconst end_of_input = /[^\\\\][$]/;\n\nexport function findEndOfInputAnchor(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  class EndAnchorFinder extends BaseRegExpVisitor {\n    found = false;\n\n    visitEndAnchor(node: unknown) {\n      this.found = true;\n    }\n  }\n\n  const invalidRegex = filter(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN;\n\n    try {\n      const regexpAst = getRegExpAst(pattern as RegExp);\n      const endAnchorVisitor = new EndAnchorFinder();\n      endAnchorVisitor.visit(regexpAst);\n\n      return endAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return end_of_input.test((pattern as RegExp).source);\n    }\n  });\n\n  const errors = map(invalidRegex, (currType) => {\n    return {\n      message:\n        \"Unexpected RegExp Anchor Error:\\n\" +\n        \"\\tToken Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" +\n        \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findEmptyMatchRegExps(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const matchesEmptyString = filter(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN as RegExp;\n    return pattern.test(\"\");\n  });\n\n  const errors = map(matchesEmptyString, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' must not match an empty string\",\n      type: LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nconst start_of_input = /[^\\\\[][\\^]|^\\^/;\n\nexport function findStartOfInputAnchor(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  class StartAnchorFinder extends BaseRegExpVisitor {\n    found = false;\n\n    visitStartAnchor(node: unknown) {\n      this.found = true;\n    }\n  }\n\n  const invalidRegex = filter(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN as RegExp;\n    try {\n      const regexpAst = getRegExpAst(pattern);\n      const startAnchorVisitor = new StartAnchorFinder();\n      startAnchorVisitor.visit(regexpAst);\n\n      return startAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return start_of_input.test(pattern.source);\n    }\n  });\n\n  const errors = map(invalidRegex, (currType) => {\n    return {\n      message:\n        \"Unexpected RegExp Anchor Error:\\n\" +\n        \"\\tToken Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" +\n        \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findUnsupportedFlags(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const invalidFlags = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN];\n    return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n  });\n\n  const errors = map(invalidFlags, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n      type: LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nexport function findDuplicatePatterns(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const found: TokenType[] = [];\n  let identicalPatterns = map(tokenTypes, (outerType: any) => {\n    return reduce(\n      tokenTypes,\n      (result, innerType) => {\n        if (\n          outerType.PATTERN.source === (innerType.PATTERN as RegExp).source &&\n          !includes(found, innerType) &&\n          innerType.PATTERN !== Lexer.NA\n        ) {\n          // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n          // in essence we are creating Equivalence classes on equality relation.\n          found.push(innerType);\n          result.push(innerType);\n          return result;\n        }\n        return result;\n      },\n      [] as TokenType[],\n    );\n  });\n\n  identicalPatterns = compact(identicalPatterns);\n\n  const duplicatePatterns = filter(identicalPatterns, (currIdenticalSet) => {\n    return currIdenticalSet.length > 1;\n  });\n\n  const errors = map(duplicatePatterns, (setOfIdentical: any) => {\n    const tokenTypeNames = map(setOfIdentical, (currType: any) => {\n      return currType.name;\n    });\n\n    const dupPatternSrc = (<any>first(setOfIdentical)).PATTERN;\n    return {\n      message:\n        `The same RegExp pattern ->${dupPatternSrc}<-` +\n        `has been used in all of the following Token Types: ${tokenTypeNames.join(\n          \", \",\n        )} <-`,\n      type: LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n      tokenTypes: setOfIdentical,\n    };\n  });\n\n  return errors;\n}\n\nexport function findInvalidGroupType(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const invalidTypes = filter(tokenTypes, (clazz: any) => {\n    if (!has(clazz, \"GROUP\")) {\n      return false;\n    }\n    const group = clazz.GROUP;\n\n    return group !== Lexer.SKIPPED && group !== Lexer.NA && !isString(group);\n  });\n\n  const errors = map(invalidTypes, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n      type: LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findModesThatDoNotExist(\n  tokenTypes: TokenType[],\n  validModes: string[],\n): ILexerDefinitionError[] {\n  const invalidModes = filter(tokenTypes, (clazz: any) => {\n    return (\n      clazz.PUSH_MODE !== undefined && !includes(validModes, clazz.PUSH_MODE)\n    );\n  });\n\n  const errors = map(invalidModes, (tokType) => {\n    const msg =\n      `Token Type: ->${tokType.name}<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->${tokType.PUSH_MODE}<-` +\n      `which does not exist`;\n    return {\n      message: msg,\n      type: LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n      tokenTypes: [tokType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findUnreachablePatterns(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const errors: ILexerDefinitionError[] = [];\n\n  const canBeTested = reduce(\n    tokenTypes,\n    (result, tokType, idx) => {\n      const pattern = tokType.PATTERN;\n\n      if (pattern === Lexer.NA) {\n        return result;\n      }\n\n      // a more comprehensive validation for all forms of regExps would require\n      // deeper regExp analysis capabilities\n      if (isString(pattern)) {\n        result.push({ str: pattern, idx, tokenType: tokType });\n      } else if (isRegExp(pattern) && noMetaChar(pattern)) {\n        result.push({ str: pattern.source, idx, tokenType: tokType });\n      }\n      return result;\n    },\n    [] as { str: string; idx: number; tokenType: TokenType }[],\n  );\n\n  forEach(tokenTypes, (tokType, testIdx) => {\n    forEach(canBeTested, ({ str, idx, tokenType }) => {\n      if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n        const msg =\n          `Token: ->${tokenType.name}<- can never be matched.\\n` +\n          `Because it appears AFTER the Token Type ->${tokType.name}<-` +\n          `in the lexer's definition.\\n` +\n          `See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE`;\n        errors.push({\n          message: msg,\n          type: LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n          tokenTypes: [tokType, tokenType],\n        });\n      }\n    });\n  });\n\n  return errors;\n}\n\nfunction testTokenType(str: string, pattern: any): boolean {\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    const regExpArray = pattern.exec(str);\n    return regExpArray !== null && regExpArray.index === 0;\n  } else if (isFunction(pattern)) {\n    // maintain the API of custom patterns\n    return pattern(str, 0, [], {});\n  } else if (has(pattern, \"exec\")) {\n    // maintain the API of custom patterns\n    return pattern.exec(str, 0, [], {});\n  } else if (typeof pattern === \"string\") {\n    return pattern === str;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nfunction noMetaChar(regExp: RegExp): boolean {\n  //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n  const metaChars = [\n    \".\",\n    \"\\\\\",\n    \"[\",\n    \"]\",\n    \"|\",\n    \"^\",\n    \"$\",\n    \"(\",\n    \")\",\n    \"?\",\n    \"*\",\n    \"+\",\n    \"{\",\n  ];\n  return (\n    find(metaChars, (char) => regExp.source.indexOf(char) !== -1) === undefined\n  );\n}\n\nexport function addStartOfInput(pattern: RegExp): RegExp {\n  const flags = pattern.ignoreCase ? \"i\" : \"\";\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(`^(?:${pattern.source})`, flags);\n}\n\nexport function addStickyFlag(pattern: RegExp): RegExp {\n  const flags = pattern.ignoreCase ? \"iy\" : \"y\";\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(`${pattern.source}`, flags);\n}\n\nexport function performRuntimeChecks(\n  lexerDefinition: IMultiModeLexerDefinition,\n  trackLines: boolean,\n  lineTerminatorCharacters: (number | string)[],\n): ILexerDefinitionError[] {\n  const errors: ILexerDefinitionError[] = [];\n\n  // some run time checks to help the end users.\n  if (!has(lexerDefinition, DEFAULT_MODE)) {\n    errors.push({\n      message:\n        \"A MultiMode Lexer cannot be initialized without a <\" +\n        DEFAULT_MODE +\n        \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE,\n    });\n  }\n  if (!has(lexerDefinition, MODES)) {\n    errors.push({\n      message:\n        \"A MultiMode Lexer cannot be initialized without a <\" +\n        MODES +\n        \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY,\n    });\n  }\n\n  if (\n    has(lexerDefinition, MODES) &&\n    has(lexerDefinition, DEFAULT_MODE) &&\n    !has(lexerDefinition.modes, lexerDefinition.defaultMode)\n  ) {\n    errors.push({\n      message:\n        `A MultiMode Lexer cannot be initialized with a ${DEFAULT_MODE}: <${lexerDefinition.defaultMode}>` +\n        `which does not exist\\n`,\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST,\n    });\n  }\n\n  if (has(lexerDefinition, MODES)) {\n    forEach(lexerDefinition.modes, (currModeValue, currModeName) => {\n      forEach(currModeValue, (currTokType, currIdx) => {\n        if (isUndefined(currTokType)) {\n          errors.push({\n            message:\n              `A Lexer cannot be initialized using an undefined Token Type. Mode:` +\n              `<${currModeName}> at index: <${currIdx}>\\n`,\n            type: LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED,\n          });\n        } else if (has(currTokType, \"LONGER_ALT\")) {\n          const longerAlt = isArray(currTokType.LONGER_ALT)\n            ? currTokType.LONGER_ALT\n            : [currTokType.LONGER_ALT];\n          forEach(longerAlt, (currLongerAlt) => {\n            if (\n              !isUndefined(currLongerAlt) &&\n              !includes(currModeValue, currLongerAlt)\n            ) {\n              errors.push({\n                message: `A MultiMode Lexer cannot be initialized with a longer_alt <${currLongerAlt.name}> on token <${currTokType.name}> outside of mode <${currModeName}>\\n`,\n                type: LexerDefinitionErrorType.MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE,\n              });\n            }\n          });\n        }\n      });\n    });\n  }\n\n  return errors;\n}\n\nexport function performWarningRuntimeChecks(\n  lexerDefinition: IMultiModeLexerDefinition,\n  trackLines: boolean,\n  lineTerminatorCharacters: (number | string)[],\n): ILexerDefinitionError[] {\n  const warnings = [];\n  let hasAnyLineBreak = false;\n  const allTokenTypes = compact(flatten(values(lexerDefinition.modes)));\n\n  const concreteTokenTypes = reject(\n    allTokenTypes,\n    (currType) => currType[PATTERN] === Lexer.NA,\n  );\n  const terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n  if (trackLines) {\n    forEach(concreteTokenTypes, (tokType) => {\n      const currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n      if (currIssue !== false) {\n        const message = buildLineBreakIssueMessage(tokType, currIssue);\n        const warningDescriptor = {\n          message,\n          type: currIssue.issue,\n          tokenType: tokType,\n        };\n        warnings.push(warningDescriptor);\n      } else {\n        // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n        if (has(tokType, \"LINE_BREAKS\")) {\n          if (tokType.LINE_BREAKS === true) {\n            hasAnyLineBreak = true;\n          }\n        } else {\n          if (\n            canMatchCharCode(terminatorCharCodes, tokType.PATTERN as RegExp)\n          ) {\n            hasAnyLineBreak = true;\n          }\n        }\n      }\n    });\n  }\n\n  if (trackLines && !hasAnyLineBreak) {\n    warnings.push({\n      message:\n        \"Warning: No LINE_BREAKS Found.\\n\" +\n        \"\\tThis Lexer has been defined to track line and column information,\\n\" +\n        \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" +\n        \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS,\n    });\n  }\n  return warnings;\n}\n\nexport function cloneEmptyGroups(emptyGroups: {\n  [groupName: string]: IToken;\n}): { [groupName: string]: IToken } {\n  const clonedResult: any = {};\n  const groupKeys = keys(emptyGroups);\n\n  forEach(groupKeys, (currKey) => {\n    const currGroupValue = emptyGroups[currKey];\n\n    /* istanbul ignore else */\n    if (isArray(currGroupValue)) {\n      clonedResult[currKey] = [];\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  });\n\n  return clonedResult;\n}\n\n// TODO: refactor to avoid duplication\nexport function isCustomPattern(tokenType: TokenType): boolean {\n  const pattern = tokenType.PATTERN;\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    return false;\n  } else if (isFunction(pattern)) {\n    // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n    return true;\n  } else if (has(pattern, \"exec\")) {\n    // ICustomPattern\n    return true;\n  } else if (isString(pattern)) {\n    return false;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexport function isShortPattern(pattern: any): number | false {\n  if (isString(pattern) && pattern.length === 1) {\n    return pattern.charCodeAt(0);\n  } else {\n    return false;\n  }\n}\n\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexport const LineTerminatorOptimizedTester: ILineTerminatorsTester = {\n  // implements /\\n|\\r\\n?/g.test\n  test: function (text) {\n    const len = text.length;\n    for (let i = this.lastIndex; i < len; i++) {\n      const c = text.charCodeAt(i);\n      if (c === 10) {\n        this.lastIndex = i + 1;\n        return true;\n      } else if (c === 13) {\n        if (text.charCodeAt(i + 1) === 10) {\n          this.lastIndex = i + 2;\n        } else {\n          this.lastIndex = i + 1;\n        }\n        return true;\n      }\n    }\n    return false;\n  },\n\n  lastIndex: 0,\n};\n\nfunction checkLineBreaksIssues(\n  tokType: TokenType,\n  lineTerminatorCharCodes: number[],\n):\n  | {\n      issue:\n        | LexerDefinitionErrorType.IDENTIFY_TERMINATOR\n        | LexerDefinitionErrorType.CUSTOM_LINE_BREAK;\n      errMsg?: string;\n    }\n  | false {\n  if (has(tokType, \"LINE_BREAKS\")) {\n    // if the user explicitly declared the line_breaks option we will respect their choice\n    // and assume it is correct.\n    return false;\n  } else {\n    /* istanbul ignore else */\n    if (isRegExp(tokType.PATTERN)) {\n      try {\n        // TODO: why is the casting suddenly needed?\n        canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN as RegExp);\n      } catch (e) {\n        /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n        return {\n          issue: LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n          errMsg: (e as Error).message,\n        };\n      }\n      return false;\n    } else if (isString(tokType.PATTERN)) {\n      // string literal patterns can always be analyzed to detect line terminator usage\n      return false;\n    } else if (isCustomPattern(tokType)) {\n      // custom token types\n      return { issue: LexerDefinitionErrorType.CUSTOM_LINE_BREAK };\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n}\n\nexport function buildLineBreakIssueMessage(\n  tokType: TokenType,\n  details: {\n    issue:\n      | LexerDefinitionErrorType.IDENTIFY_TERMINATOR\n      | LexerDefinitionErrorType.CUSTOM_LINE_BREAK;\n    errMsg?: string;\n  },\n): string {\n  /* istanbul ignore else */\n  if (details.issue === LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n    return (\n      \"Warning: unable to identify line terminator usage in pattern.\\n\" +\n      `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n      `\\t Root cause: ${details.errMsg}.\\n` +\n      \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\"\n    );\n  } else if (details.issue === LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n    return (\n      \"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" +\n      `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n      \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\"\n    );\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nfunction getCharCodes(charsOrCodes: (number | string)[]): number[] {\n  const charCodes = map(charsOrCodes, (numOrString) => {\n    if (isString(numOrString)) {\n      return numOrString.charCodeAt(0);\n    } else {\n      return numOrString;\n    }\n  });\n\n  return charCodes;\n}\n\nfunction addToMapOfArrays<T>(\n  map: Record<number, T[]>,\n  key: number,\n  value: T,\n): void {\n  if (map[key] === undefined) {\n    map[key] = [value];\n  } else {\n    map[key].push(value);\n  }\n}\n\nexport const minOptimizationVal = 256;\n\n/**\n * We are mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nlet charCodeToOptimizedIdxMap: number[] = [];\nexport function charCodeToOptimizedIndex(charCode: number): number {\n  return charCode < minOptimizationVal\n    ? charCode\n    : charCodeToOptimizedIdxMap[charCode];\n}\n\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nfunction initCharCodeToOptimizedIndexMap() {\n  if (isEmpty(charCodeToOptimizedIdxMap)) {\n    charCodeToOptimizedIdxMap = new Array(65536);\n    for (let i = 0; i < 65536; i++) {\n      charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n    }\n  }\n}\n","import { forEach, has } from \"lodash-es\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\nimport {\n  ILookaheadStrategy,\n  IParserConfig,\n  OptionalProductionType,\n} from \"@chevrotain/types\";\nimport {\n  AT_LEAST_ONE_IDX,\n  AT_LEAST_ONE_SEP_IDX,\n  getKeyForAutomaticLookahead,\n  MANY_IDX,\n  MANY_SEP_IDX,\n  OPTION_IDX,\n  OR_IDX,\n} from \"../../grammar/keys.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport {\n  Alternation,\n  GAstVisitor,\n  getProductionDslName,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n} from \"@chevrotain/gast\";\nimport { LLkLookaheadStrategy } from \"../../grammar/llk_lookahead.js\";\n\n/**\n * Trait responsible for the lookahead related utilities and optimizations.\n */\nexport class LooksAhead {\n  maxLookahead: number;\n  lookAheadFuncsCache: any;\n  dynamicTokensEnabled: boolean;\n  lookaheadStrategy: ILookaheadStrategy;\n\n  initLooksAhead(config: IParserConfig) {\n    this.dynamicTokensEnabled = has(config, \"dynamicTokensEnabled\")\n      ? (config.dynamicTokensEnabled as boolean) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.dynamicTokensEnabled;\n\n    this.maxLookahead = has(config, \"maxLookahead\")\n      ? (config.maxLookahead as number) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.maxLookahead;\n\n    this.lookaheadStrategy = has(config, \"lookaheadStrategy\")\n      ? (config.lookaheadStrategy as ILookaheadStrategy) // assumes end user provides the correct config value/type\n      : new LLkLookaheadStrategy({ maxLookahead: this.maxLookahead });\n\n    this.lookAheadFuncsCache = new Map();\n  }\n\n  preComputeLookaheadFunctions(this: MixedInParser, rules: Rule[]): void {\n    forEach(rules, (currRule) => {\n      this.TRACE_INIT(`${currRule.name} Rule Lookahead`, () => {\n        const {\n          alternation,\n          repetition,\n          option,\n          repetitionMandatory,\n          repetitionMandatoryWithSeparator,\n          repetitionWithSeparator,\n        } = collectMethods(currRule);\n\n        forEach(alternation, (currProd) => {\n          const prodIdx = currProd.idx === 0 ? \"\" : currProd.idx;\n          this.TRACE_INIT(`${getProductionDslName(currProd)}${prodIdx}`, () => {\n            const laFunc = this.lookaheadStrategy.buildLookaheadForAlternation({\n              prodOccurrence: currProd.idx,\n              rule: currRule,\n              maxLookahead: currProd.maxLookahead || this.maxLookahead,\n              hasPredicates: currProd.hasPredicates,\n              dynamicTokensEnabled: this.dynamicTokensEnabled,\n            });\n\n            const key = getKeyForAutomaticLookahead(\n              this.fullRuleNameToShort[currRule.name],\n              OR_IDX,\n              currProd.idx,\n            );\n            this.setLaFuncCache(key, laFunc);\n          });\n        });\n\n        forEach(repetition, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            MANY_IDX,\n            \"Repetition\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(option, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            OPTION_IDX,\n            \"Option\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(repetitionMandatory, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            AT_LEAST_ONE_IDX,\n            \"RepetitionMandatory\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(repetitionMandatoryWithSeparator, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            AT_LEAST_ONE_SEP_IDX,\n            \"RepetitionMandatoryWithSeparator\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(repetitionWithSeparator, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            MANY_SEP_IDX,\n            \"RepetitionWithSeparator\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n      });\n    });\n  }\n\n  computeLookaheadFunc(\n    this: MixedInParser,\n    rule: Rule,\n    prodOccurrence: number,\n    prodKey: number,\n    prodType: OptionalProductionType,\n    prodMaxLookahead: number | undefined,\n    dslMethodName: string,\n  ): void {\n    this.TRACE_INIT(\n      `${dslMethodName}${prodOccurrence === 0 ? \"\" : prodOccurrence}`,\n      () => {\n        const laFunc = this.lookaheadStrategy.buildLookaheadForOptional({\n          prodOccurrence,\n          rule,\n          maxLookahead: prodMaxLookahead || this.maxLookahead,\n          dynamicTokensEnabled: this.dynamicTokensEnabled,\n          prodType,\n        });\n        const key = getKeyForAutomaticLookahead(\n          this.fullRuleNameToShort[rule.name],\n          prodKey,\n          prodOccurrence,\n        );\n        this.setLaFuncCache(key, laFunc);\n      },\n    );\n  }\n\n  // this actually returns a number, but it is always used as a string (object prop key)\n  getKeyForAutomaticLookahead(\n    this: MixedInParser,\n    dslMethodIdx: number,\n    occurrence: number,\n  ): number {\n    const currRuleShortName: any = this.getLastExplicitRuleShortName();\n    return getKeyForAutomaticLookahead(\n      currRuleShortName,\n      dslMethodIdx,\n      occurrence,\n    );\n  }\n\n  getLaFuncFromCache(this: MixedInParser, key: number): Function {\n    return this.lookAheadFuncsCache.get(key);\n  }\n\n  /* istanbul ignore next */\n  setLaFuncCache(this: MixedInParser, key: number, value: Function): void {\n    this.lookAheadFuncsCache.set(key, value);\n  }\n}\n\nclass DslMethodsCollectorVisitor extends GAstVisitor {\n  public dslMethods: {\n    option: Option[];\n    alternation: Alternation[];\n    repetition: Repetition[];\n    repetitionWithSeparator: RepetitionWithSeparator[];\n    repetitionMandatory: RepetitionMandatory[];\n    repetitionMandatoryWithSeparator: RepetitionMandatoryWithSeparator[];\n  } = {\n    option: [],\n    alternation: [],\n    repetition: [],\n    repetitionWithSeparator: [],\n    repetitionMandatory: [],\n    repetitionMandatoryWithSeparator: [],\n  };\n\n  reset() {\n    this.dslMethods = {\n      option: [],\n      alternation: [],\n      repetition: [],\n      repetitionWithSeparator: [],\n      repetitionMandatory: [],\n      repetitionMandatoryWithSeparator: [],\n    };\n  }\n\n  public visitOption(option: Option): void {\n    this.dslMethods.option.push(option);\n  }\n\n  public visitRepetitionWithSeparator(manySep: RepetitionWithSeparator): void {\n    this.dslMethods.repetitionWithSeparator.push(manySep);\n  }\n\n  public visitRepetitionMandatory(atLeastOne: RepetitionMandatory): void {\n    this.dslMethods.repetitionMandatory.push(atLeastOne);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    atLeastOneSep: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.dslMethods.repetitionMandatoryWithSeparator.push(atLeastOneSep);\n  }\n\n  public visitRepetition(many: Repetition): void {\n    this.dslMethods.repetition.push(many);\n  }\n\n  public visitAlternation(or: Alternation): void {\n    this.dslMethods.alternation.push(or);\n  }\n}\n\nconst collectorVisitor = new DslMethodsCollectorVisitor();\nexport function collectMethods(rule: Rule): {\n  option: Option[];\n  alternation: Alternation[];\n  repetition: Repetition[];\n  repetitionWithSeparator: RepetitionWithSeparator[];\n  repetitionMandatory: RepetitionMandatory[];\n  repetitionMandatoryWithSeparator: RepetitionMandatoryWithSeparator[];\n} {\n  collectorVisitor.reset();\n  rule.accept(collectorVisitor);\n  const dslMethods = collectorVisitor.dslMethods;\n  // avoid uncleaned references\n  collectorVisitor.reset();\n  return <any>dslMethods;\n}\n","import baseEach from './_baseEach.js';\nimport isArrayLike from './isArrayLike.js';\n\n/**\n * The base implementation of `_.map` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the new mapped array.\n */\nfunction baseMap(collection, iteratee) {\n  var index = -1,\n      result = isArrayLike(collection) ? Array(collection.length) : [];\n\n  baseEach(collection, function(value, key, collection) {\n    result[++index] = iteratee(value, key, collection);\n  });\n  return result;\n}\n\nexport default baseMap;\n","import baseValues from './_baseValues.js';\nimport keys from './keys.js';\n\n/**\n * Creates an array of the own enumerable string keyed property values of `object`.\n *\n * **Note:** Non-object values are coerced to objects.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property values.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.values(new Foo);\n * // => [1, 2] (iteration order is not guaranteed)\n *\n * _.values('hi');\n * // => ['h', 'i']\n */\nfunction values(object) {\n  return object == null ? [] : baseValues(object, keys(object));\n}\n\nexport default values;\n","import copyObject from './_copyObject.js';\nimport getSymbolsIn from './_getSymbolsIn.js';\n\n/**\n * Copies own and inherited symbols of `source` to `object`.\n *\n * @private\n * @param {Object} source The object to copy symbols from.\n * @param {Object} [object={}] The object to copy symbols to.\n * @returns {Object} Returns `object`.\n */\nfunction copySymbolsIn(source, object) {\n  return copyObject(source, getSymbolsIn(source), object);\n}\n\nexport default copySymbolsIn;\n","import arrayPush from './_arrayPush.js';\nimport isArray from './isArray.js';\n\n/**\n * The base implementation of `getAllKeys` and `getAllKeysIn` which uses\n * `keysFunc` and `symbolsFunc` to get the enumerable property names and\n * symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {Function} keysFunc The function to get the keys of `object`.\n * @param {Function} symbolsFunc The function to get the symbols of `object`.\n * @returns {Array} Returns the array of property names and symbols.\n */\nfunction baseGetAllKeys(object, keysFunc, symbolsFunc) {\n  var result = keysFunc(object);\n  return isArray(object) ? result : arrayPush(result, symbolsFunc(object));\n}\n\nexport default baseGetAllKeys;\n","import getNative from './_getNative.js';\nimport root from './_root.js';\n\n/* Built-in method references that are verified to be native. */\nvar DataView = getNative(root, 'DataView');\n\nexport default DataView;\n","import getNative from './_getNative.js';\nimport root from './_root.js';\n\n/* Built-in method references that are verified to be native. */\nvar Promise = getNative(root, 'Promise');\n\nexport default Promise;\n","import getNative from './_getNative.js';\nimport root from './_root.js';\n\n/* Built-in method references that are verified to be native. */\nvar Set = getNative(root, 'Set');\n\nexport default Set;\n","import getNative from './_getNative.js';\nimport root from './_root.js';\n\n/* Built-in method references that are verified to be native. */\nvar WeakMap = getNative(root, 'WeakMap');\n\nexport default WeakMap;\n","import baseSlice from './_baseSlice.js';\nimport toInteger from './toInteger.js';\n\n/**\n * Creates a slice of `array` with `n` elements dropped from the beginning.\n *\n * @static\n * @memberOf _\n * @since 0.5.0\n * @category Array\n * @param {Array} array The array to query.\n * @param {number} [n=1] The number of elements to drop.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {Array} Returns the slice of `array`.\n * @example\n *\n * _.drop([1, 2, 3]);\n * // => [2, 3]\n *\n * _.drop([1, 2, 3], 2);\n * // => [3]\n *\n * _.drop([1, 2, 3], 5);\n * // => []\n *\n * _.drop([1, 2, 3], 0);\n * // => [1, 2, 3]\n */\nfunction drop(array, n, guard) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return [];\n  }\n  n = (guard || n === undefined) ? 1 : toInteger(n);\n  return baseSlice(array, n < 0 ? 0 : n, length);\n}\n\nexport default drop;\n","import isPrototype from './_isPrototype.js';\nimport nativeKeys from './_nativeKeys.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * The base implementation of `_.keys` which doesn't treat sparse arrays as dense.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction baseKeys(object) {\n  if (!isPrototype(object)) {\n    return nativeKeys(object);\n  }\n  var result = [];\n  for (var key in Object(object)) {\n    if (hasOwnProperty.call(object, key) && key != 'constructor') {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\nexport default baseKeys;\n","import baseSetToString from './_baseSetToString.js';\nimport shortOut from './_shortOut.js';\n\n/**\n * Sets the `toString` method of `func` to return `string`.\n *\n * @private\n * @param {Function} func The function to modify.\n * @param {Function} string The `toString` result.\n * @returns {Function} Returns `func`.\n */\nvar setToString = shortOut(baseSetToString);\n\nexport default setToString;\n","import baseRest from './_baseRest.js';\nimport isIterateeCall from './_isIterateeCall.js';\n\n/**\n * Creates a function like `_.assign`.\n *\n * @private\n * @param {Function} assigner The function to assign values.\n * @returns {Function} Returns the new assigner function.\n */\nfunction createAssigner(assigner) {\n  return baseRest(function(object, sources) {\n    var index = -1,\n        length = sources.length,\n        customizer = length > 1 ? sources[length - 1] : undefined,\n        guard = length > 2 ? sources[2] : undefined;\n\n    customizer = (assigner.length > 3 && typeof customizer == 'function')\n      ? (length--, customizer)\n      : undefined;\n\n    if (guard && isIterateeCall(sources[0], sources[1], guard)) {\n      customizer = length < 3 ? undefined : customizer;\n      length = 1;\n    }\n    object = Object(object);\n    while (++index < length) {\n      var source = sources[index];\n      if (source) {\n        assigner(object, source, index, customizer);\n      }\n    }\n    return object;\n  });\n}\n\nexport default createAssigner;\n","import baseGetTag from './_baseGetTag.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar regexpTag = '[object RegExp]';\n\n/**\n * The base implementation of `_.isRegExp` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a regexp, else `false`.\n */\nfunction baseIsRegExp(value) {\n  return isObjectLike(value) && baseGetTag(value) == regexpTag;\n}\n\nexport default baseIsRegExp;\n","import isFunction from './isFunction.js';\nimport isLength from './isLength.js';\n\n/**\n * Checks if `value` is array-like. A value is considered array-like if it's\n * not a function and has a `value.length` that's an integer greater than or\n * equal to `0` and less than or equal to `Number.MAX_SAFE_INTEGER`.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is array-like, else `false`.\n * @example\n *\n * _.isArrayLike([1, 2, 3]);\n * // => true\n *\n * _.isArrayLike(document.body.children);\n * // => true\n *\n * _.isArrayLike('abc');\n * // => true\n *\n * _.isArrayLike(_.noop);\n * // => false\n */\nfunction isArrayLike(value) {\n  return value != null && isLength(value.length) && !isFunction(value);\n}\n\nexport default isArrayLike;\n","import arrayPush from './_arrayPush.js';\nimport isFlattenable from './_isFlattenable.js';\n\n/**\n * The base implementation of `_.flatten` with support for restricting flattening.\n *\n * @private\n * @param {Array} array The array to flatten.\n * @param {number} depth The maximum recursion depth.\n * @param {boolean} [predicate=isFlattenable] The function invoked per iteration.\n * @param {boolean} [isStrict] Restrict to values that pass `predicate` checks.\n * @param {Array} [result=[]] The initial result value.\n * @returns {Array} Returns the new flattened array.\n */\nfunction baseFlatten(array, depth, predicate, isStrict, result) {\n  var index = -1,\n      length = array.length;\n\n  predicate || (predicate = isFlattenable);\n  result || (result = []);\n\n  while (++index < length) {\n    var value = array[index];\n    if (depth > 0 && predicate(value)) {\n      if (depth > 1) {\n        // Recursively flatten arrays (susceptible to call stack limits).\n        baseFlatten(value, depth - 1, predicate, isStrict, result);\n      } else {\n        arrayPush(result, value);\n      }\n    } else if (!isStrict) {\n      result[result.length] = value;\n    }\n  }\n  return result;\n}\n\nexport default baseFlatten;\n","import copyObject from './_copyObject.js';\nimport keys from './keys.js';\n\n/**\n * The base implementation of `_.assign` without support for multiple sources\n * or `customizer` functions.\n *\n * @private\n * @param {Object} object The destination object.\n * @param {Object} source The source object.\n * @returns {Object} Returns `object`.\n */\nfunction baseAssign(object, source) {\n  return object && copyObject(source, keys(source), object);\n}\n\nexport default baseAssign;\n","import copyObject from './_copyObject.js';\nimport keysIn from './keysIn.js';\n\n/**\n * The base implementation of `_.assignIn` without support for multiple sources\n * or `customizer` functions.\n *\n * @private\n * @param {Object} object The destination object.\n * @param {Object} source The source object.\n * @returns {Object} Returns `object`.\n */\nfunction baseAssignIn(object, source) {\n  return object && copyObject(source, keysIn(source), object);\n}\n\nexport default baseAssignIn;\n","import isArrayLike from './isArrayLike.js';\nimport isObjectLike from './isObjectLike.js';\n\n/**\n * This method is like `_.isArrayLike` except that it also checks if `value`\n * is an object.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array-like object,\n *  else `false`.\n * @example\n *\n * _.isArrayLikeObject([1, 2, 3]);\n * // => true\n *\n * _.isArrayLikeObject(document.body.children);\n * // => true\n *\n * _.isArrayLikeObject('abc');\n * // => false\n *\n * _.isArrayLikeObject(_.noop);\n * // => false\n */\nfunction isArrayLikeObject(value) {\n  return isObjectLike(value) && isArrayLike(value);\n}\n\nexport default isArrayLikeObject;\n","import createFind from './_createFind.js';\nimport findIndex from './findIndex.js';\n\n/**\n * Iterates over elements of `collection`, returning the first element\n * `predicate` returns truthy for. The predicate is invoked with three\n * arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to inspect.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {*} Returns the matched element, else `undefined`.\n * @example\n *\n * var users = [\n *   { 'user': 'barney',  'age': 36, 'active': true },\n *   { 'user': 'fred',    'age': 40, 'active': false },\n *   { 'user': 'pebbles', 'age': 1,  'active': true }\n * ];\n *\n * _.find(users, function(o) { return o.age < 40; });\n * // => object for 'barney'\n *\n * // The `_.matches` iteratee shorthand.\n * _.find(users, { 'age': 1, 'active': true });\n * // => object for 'pebbles'\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.find(users, ['active', false]);\n * // => object for 'fred'\n *\n * // The `_.property` iteratee shorthand.\n * _.find(users, 'active');\n * // => object for 'barney'\n */\nvar find = createFind(findIndex);\n\nexport default find;\n","import baseIndexOf from './_baseIndexOf.js';\nimport toInteger from './toInteger.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * Gets the index at which the first occurrence of `value` is found in `array`\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons. If `fromIndex` is negative, it's used as the\n * offset from the end of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {*} value The value to search for.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {number} Returns the index of the matched value, else `-1`.\n * @example\n *\n * _.indexOf([1, 2, 1, 2], 2);\n * // => 1\n *\n * // Search from the `fromIndex`.\n * _.indexOf([1, 2, 1, 2], 2, 2);\n * // => 3\n */\nfunction indexOf(array, value, fromIndex) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return -1;\n  }\n  var index = fromIndex == null ? 0 : toInteger(fromIndex);\n  if (index < 0) {\n    index = nativeMax(length + index, 0);\n  }\n  return baseIndexOf(array, value, index);\n}\n\nexport default indexOf;\n","import getTag from './_getTag.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar mapTag = '[object Map]';\n\n/**\n * The base implementation of `_.isMap` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a map, else `false`.\n */\nfunction baseIsMap(value) {\n  return isObjectLike(value) && getTag(value) == mapTag;\n}\n\nexport default baseIsMap;\n","import getTag from './_getTag.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar setTag = '[object Set]';\n\n/**\n * The base implementation of `_.isSet` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a set, else `false`.\n */\nfunction baseIsSet(value) {\n  return isObjectLike(value) && getTag(value) == setTag;\n}\n\nexport default baseIsSet;\n","import baseFor from './_baseFor.js';\nimport keys from './keys.js';\n\n/**\n * The base implementation of `_.forOwn` without support for iteratee shorthands.\n *\n * @private\n * @param {Object} object The object to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Object} Returns `object`.\n */\nfunction baseForOwn(object, iteratee) {\n  return object && baseFor(object, iteratee, keys);\n}\n\nexport default baseForOwn;\n","import baseForOwn from './_baseForOwn.js';\nimport createBaseEach from './_createBaseEach.js';\n\n/**\n * The base implementation of `_.forEach` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array|Object} Returns `collection`.\n */\nvar baseEach = createBaseEach(baseForOwn);\n\nexport default baseEach;\n","import baseSlice from './_baseSlice.js';\nimport toInteger from './toInteger.js';\n\n/**\n * Creates a slice of `array` with `n` elements dropped from the end.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Array\n * @param {Array} array The array to query.\n * @param {number} [n=1] The number of elements to drop.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {Array} Returns the slice of `array`.\n * @example\n *\n * _.dropRight([1, 2, 3]);\n * // => [1, 2]\n *\n * _.dropRight([1, 2, 3], 2);\n * // => [1]\n *\n * _.dropRight([1, 2, 3], 5);\n * // => []\n *\n * _.dropRight([1, 2, 3], 0);\n * // => [1, 2, 3]\n */\nfunction dropRight(array, n, guard) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return [];\n  }\n  n = (guard || n === undefined) ? 1 : toInteger(n);\n  n = length - n;\n  return baseSlice(array, 0, n < 0 ? 0 : n);\n}\n\nexport default dropRight;\n","import baseFlatten from './_baseFlatten.js';\nimport map from './map.js';\n\n/**\n * Creates a flattened array of values by running each element in `collection`\n * thru `iteratee` and flattening the mapped results. The iteratee is invoked\n * with three arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new flattened array.\n * @example\n *\n * function duplicate(n) {\n *   return [n, n];\n * }\n *\n * _.flatMap([1, 2], duplicate);\n * // => [1, 1, 2, 2]\n */\nfunction flatMap(collection, iteratee) {\n  return baseFlatten(map(collection, iteratee), 1);\n}\n\nexport default flatMap;\n","import baseAssignValue from './_baseAssignValue.js';\nimport createAggregator from './_createAggregator.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Creates an object composed of keys generated from the results of running\n * each element of `collection` thru `iteratee`. The order of grouped values\n * is determined by the order they occur in `collection`. The corresponding\n * value of each key is an array of elements responsible for generating the\n * key. The iteratee is invoked with one argument: (value).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The iteratee to transform keys.\n * @returns {Object} Returns the composed aggregate object.\n * @example\n *\n * _.groupBy([6.1, 4.2, 6.3], Math.floor);\n * // => { '4': [4.2], '6': [6.1, 6.3] }\n *\n * // The `_.property` iteratee shorthand.\n * _.groupBy(['one', 'two', 'three'], 'length');\n * // => { '3': ['one', 'two'], '5': ['three'] }\n */\nvar groupBy = createAggregator(function(result, value, key) {\n  if (hasOwnProperty.call(result, key)) {\n    result[key].push(value);\n  } else {\n    baseAssignValue(result, key, [value]);\n  }\n});\n\nexport default groupBy;\n","import baseHasIn from './_baseHasIn.js';\nimport hasPath from './_hasPath.js';\n\n/**\n * Checks if `path` is a direct or inherited property of `object`.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Object\n * @param {Object} object The object to query.\n * @param {Array|string} path The path to check.\n * @returns {boolean} Returns `true` if `path` exists, else `false`.\n * @example\n *\n * var object = _.create({ 'a': _.create({ 'b': 2 }) });\n *\n * _.hasIn(object, 'a');\n * // => true\n *\n * _.hasIn(object, 'a.b');\n * // => true\n *\n * _.hasIn(object, ['a', 'b']);\n * // => true\n *\n * _.hasIn(object, 'b');\n * // => false\n */\nfunction hasIn(object, path) {\n  return object != null && hasPath(object, path, baseHasIn);\n}\n\nexport default hasIn;\n","import baseGetTag from './_baseGetTag.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar symbolTag = '[object Symbol]';\n\n/**\n * Checks if `value` is classified as a `Symbol` primitive or object.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a symbol, else `false`.\n * @example\n *\n * _.isSymbol(Symbol.iterator);\n * // => true\n *\n * _.isSymbol('abc');\n * // => false\n */\nfunction isSymbol(value) {\n  return typeof value == 'symbol' ||\n    (isObjectLike(value) && baseGetTag(value) == symbolTag);\n}\n\nexport default isSymbol;\n","import isArray from './isArray.js';\nimport isSymbol from './isSymbol.js';\n\n/** Used to match property names within property paths. */\nvar reIsDeepProp = /\\.|\\[(?:[^[\\]]*|([\"'])(?:(?!\\1)[^\\\\]|\\\\.)*?\\1)\\]/,\n    reIsPlainProp = /^\\w*$/;\n\n/**\n * Checks if `value` is a property name and not a property path.\n *\n * @private\n * @param {*} value The value to check.\n * @param {Object} [object] The object to query keys on.\n * @returns {boolean} Returns `true` if `value` is a property name, else `false`.\n */\nfunction isKey(value, object) {\n  if (isArray(value)) {\n    return false;\n  }\n  var type = typeof value;\n  if (type == 'number' || type == 'symbol' || type == 'boolean' ||\n      value == null || isSymbol(value)) {\n    return true;\n  }\n  return reIsPlainProp.test(value) || !reIsDeepProp.test(value) ||\n    (object != null && value in Object(object));\n}\n\nexport default isKey;\n","import baseGetTag from './_baseGetTag.js';\nimport isObject from './isObject.js';\n\n/** `Object#toString` result references. */\nvar asyncTag = '[object AsyncFunction]',\n    funcTag = '[object Function]',\n    genTag = '[object GeneratorFunction]',\n    proxyTag = '[object Proxy]';\n\n/**\n * Checks if `value` is classified as a `Function` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a function, else `false`.\n * @example\n *\n * _.isFunction(_);\n * // => true\n *\n * _.isFunction(/abc/);\n * // => false\n */\nfunction isFunction(value) {\n  if (!isObject(value)) {\n    return false;\n  }\n  // The use of `Object#toString` avoids issues with the `typeof` operator\n  // in Safari 9 which returns 'object' for typed arrays and other constructors.\n  var tag = baseGetTag(value);\n  return tag == funcTag || tag == genTag || tag == asyncTag || tag == proxyTag;\n}\n\nexport default isFunction;\n","import arrayFilter from './_arrayFilter.js';\nimport stubArray from './stubArray.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Built-in value references. */\nvar propertyIsEnumerable = objectProto.propertyIsEnumerable;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeGetSymbols = Object.getOwnPropertySymbols;\n\n/**\n * Creates an array of the own enumerable symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of symbols.\n */\nvar getSymbols = !nativeGetSymbols ? stubArray : function(object) {\n  if (object == null) {\n    return [];\n  }\n  object = Object(object);\n  return arrayFilter(nativeGetSymbols(object), function(symbol) {\n    return propertyIsEnumerable.call(object, symbol);\n  });\n};\n\nexport default getSymbols;\n","import baseIsNative from './_baseIsNative.js';\nimport getValue from './_getValue.js';\n\n/**\n * Gets the native function at `key` of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {string} key The key of the method to get.\n * @returns {*} Returns the function if it's native, else `undefined`.\n */\nfunction getNative(object, key) {\n  var value = getValue(object, key);\n  return baseIsNative(value) ? value : undefined;\n}\n\nexport default getNative;\n","import getNative from './_getNative.js';\nimport root from './_root.js';\n\n/* Built-in method references that are verified to be native. */\nvar Map = getNative(root, 'Map');\n\nexport default Map;\n","import baseHas from './_baseHas.js';\nimport hasPath from './_hasPath.js';\n\n/**\n * Checks if `path` is a direct property of `object`.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The object to query.\n * @param {Array|string} path The path to check.\n * @returns {boolean} Returns `true` if `path` exists, else `false`.\n * @example\n *\n * var object = { 'a': { 'b': 2 } };\n * var other = _.create({ 'a': _.create({ 'b': 2 }) });\n *\n * _.has(object, 'a');\n * // => true\n *\n * _.has(object, 'a.b');\n * // => true\n *\n * _.has(object, ['a', 'b']);\n * // => true\n *\n * _.has(other, 'a');\n * // => false\n */\nfunction has(object, path) {\n  return object != null && hasPath(object, path, baseHas);\n}\n\nexport default has;\n","import copyObject from './_copyObject.js';\nimport getSymbols from './_getSymbols.js';\n\n/**\n * Copies own symbols of `source` to `object`.\n *\n * @private\n * @param {Object} source The object to copy symbols from.\n * @param {Object} [object={}] The object to copy symbols to.\n * @returns {Object} Returns `object`.\n */\nfunction copySymbols(source, object) {\n  return copyObject(source, getSymbols(source), object);\n}\n\nexport default copySymbols;\n","import baseIsEqualDeep from './_baseIsEqualDeep.js';\nimport isObjectLike from './isObjectLike.js';\n\n/**\n * The base implementation of `_.isEqual` which supports partial comparisons\n * and tracks traversed objects.\n *\n * @private\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @param {boolean} bitmask The bitmask flags.\n *  1 - Unordered comparison\n *  2 - Partial comparison\n * @param {Function} [customizer] The function to customize comparisons.\n * @param {Object} [stack] Tracks traversed `value` and `other` objects.\n * @returns {boolean} Returns `true` if the values are equivalent, else `false`.\n */\nfunction baseIsEqual(value, other, bitmask, customizer, stack) {\n  if (value === other) {\n    return true;\n  }\n  if (value == null || other == null || (!isObjectLike(value) && !isObjectLike(other))) {\n    return value !== value && other !== other;\n  }\n  return baseIsEqualDeep(value, other, bitmask, customizer, baseIsEqual, stack);\n}\n\nexport default baseIsEqual;\n","import Stack from './_Stack.js';\nimport baseIsEqual from './_baseIsEqual.js';\n\n/** Used to compose bitmasks for value comparisons. */\nvar COMPARE_PARTIAL_FLAG = 1,\n    COMPARE_UNORDERED_FLAG = 2;\n\n/**\n * The base implementation of `_.isMatch` without support for iteratee shorthands.\n *\n * @private\n * @param {Object} object The object to inspect.\n * @param {Object} source The object of property values to match.\n * @param {Array} matchData The property names, values, and compare flags to match.\n * @param {Function} [customizer] The function to customize comparisons.\n * @returns {boolean} Returns `true` if `object` is a match, else `false`.\n */\nfunction baseIsMatch(object, source, matchData, customizer) {\n  var index = matchData.length,\n      length = index,\n      noCustomizer = !customizer;\n\n  if (object == null) {\n    return !length;\n  }\n  object = Object(object);\n  while (index--) {\n    var data = matchData[index];\n    if ((noCustomizer && data[2])\n          ? data[1] !== object[data[0]]\n          : !(data[0] in object)\n        ) {\n      return false;\n    }\n  }\n  while (++index < length) {\n    data = matchData[index];\n    var key = data[0],\n        objValue = object[key],\n        srcValue = data[1];\n\n    if (noCustomizer && data[2]) {\n      if (objValue === undefined && !(key in object)) {\n        return false;\n      }\n    } else {\n      var stack = new Stack;\n      if (customizer) {\n        var result = customizer(objValue, srcValue, key, object, source, stack);\n      }\n      if (!(result === undefined\n            ? baseIsEqual(srcValue, objValue, COMPARE_PARTIAL_FLAG | COMPARE_UNORDERED_FLAG, customizer, stack)\n            : result\n          )) {\n        return false;\n      }\n    }\n  }\n  return true;\n}\n\nexport default baseIsMatch;\n","import baseAssignValue from './_baseAssignValue.js';\nimport eq from './eq.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Assigns `value` to `key` of `object` if the existing value is not equivalent\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {string} key The key of the property to assign.\n * @param {*} value The value to assign.\n */\nfunction assignValue(object, key, value) {\n  var objValue = object[key];\n  if (!(hasOwnProperty.call(object, key) && eq(objValue, value)) ||\n      (value === undefined && !(key in object))) {\n    baseAssignValue(object, key, value);\n  }\n}\n\nexport default assignValue;\n","import assignValue from './_assignValue.js';\nimport baseAssignValue from './_baseAssignValue.js';\n\n/**\n * Copies properties of `source` to `object`.\n *\n * @private\n * @param {Object} source The object to copy properties from.\n * @param {Array} props The property identifiers to copy.\n * @param {Object} [object={}] The object to copy properties to.\n * @param {Function} [customizer] The function to customize copied values.\n * @returns {Object} Returns `object`.\n */\nfunction copyObject(source, props, object, customizer) {\n  var isNew = !object;\n  object || (object = {});\n\n  var index = -1,\n      length = props.length;\n\n  while (++index < length) {\n    var key = props[index];\n\n    var newValue = customizer\n      ? customizer(object[key], source[key], key, object, source)\n      : undefined;\n\n    if (newValue === undefined) {\n      newValue = source[key];\n    }\n    if (isNew) {\n      baseAssignValue(object, key, newValue);\n    } else {\n      assignValue(object, key, newValue);\n    }\n  }\n  return object;\n}\n\nexport default copyObject;\n","import baseGetTag from './_baseGetTag.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]';\n\n/**\n * The base implementation of `_.isArguments`.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an `arguments` object,\n */\nfunction baseIsArguments(value) {\n  return isObjectLike(value) && baseGetTag(value) == argsTag;\n}\n\nexport default baseIsArguments;\n","import baseIsArguments from './_baseIsArguments.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/** Built-in value references. */\nvar propertyIsEnumerable = objectProto.propertyIsEnumerable;\n\n/**\n * Checks if `value` is likely an `arguments` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an `arguments` object,\n *  else `false`.\n * @example\n *\n * _.isArguments(function() { return arguments; }());\n * // => true\n *\n * _.isArguments([1, 2, 3]);\n * // => false\n */\nvar isArguments = baseIsArguments(function() { return arguments; }()) ? baseIsArguments : function(value) {\n  return isObjectLike(value) && hasOwnProperty.call(value, 'callee') &&\n    !propertyIsEnumerable.call(value, 'callee');\n};\n\nexport default isArguments;\n","import root from './_root.js';\nimport stubFalse from './stubFalse.js';\n\n/** Detect free variable `exports`. */\nvar freeExports = typeof exports == 'object' && exports && !exports.nodeType && exports;\n\n/** Detect free variable `module`. */\nvar freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;\n\n/** Detect the popular CommonJS extension `module.exports`. */\nvar moduleExports = freeModule && freeModule.exports === freeExports;\n\n/** Built-in value references. */\nvar Buffer = moduleExports ? root.Buffer : undefined;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeIsBuffer = Buffer ? Buffer.isBuffer : undefined;\n\n/**\n * Checks if `value` is a buffer.\n *\n * @static\n * @memberOf _\n * @since 4.3.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a buffer, else `false`.\n * @example\n *\n * _.isBuffer(new Buffer(2));\n * // => true\n *\n * _.isBuffer(new Uint8Array(2));\n * // => false\n */\nvar isBuffer = nativeIsBuffer || stubFalse;\n\nexport default isBuffer;\n","import isStrictComparable from './_isStrictComparable.js';\nimport keys from './keys.js';\n\n/**\n * Gets the property names, values, and compare flags of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the match data of `object`.\n */\nfunction getMatchData(object) {\n  var result = keys(object),\n      length = result.length;\n\n  while (length--) {\n    var key = result[length],\n        value = object[key];\n\n    result[length] = [key, value, isStrictComparable(value)];\n  }\n  return result;\n}\n\nexport default getMatchData;\n","import castPath from './_castPath.js';\nimport toKey from './_toKey.js';\n\n/**\n * The base implementation of `_.get` without support for default values.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {Array|string} path The path of the property to get.\n * @returns {*} Returns the resolved value.\n */\nfunction baseGet(object, path) {\n  path = castPath(path, object);\n\n  var index = 0,\n      length = path.length;\n\n  while (object != null && index < length) {\n    object = object[toKey(path[index++])];\n  }\n  return (index && index == length) ? object : undefined;\n}\n\nexport default baseGet;\n","import {\n  createTokenInstance,\n  EOF,\n  tokenMatcher,\n} from \"../../../scan/tokens_public.js\";\nimport {\n  AbstractNextTerminalAfterProductionWalker,\n  IFirstAfterRepetition,\n} from \"../../grammar/interpreter.js\";\nimport {\n  clone,\n  dropRight,\n  find,\n  flatten,\n  has,\n  includes,\n  isEmpty,\n  map,\n} from \"lodash-es\";\nimport {\n  IParserConfig,\n  IToken,\n  ITokenGrammarPath,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { MismatchedTokenException } from \"../../exceptions_public.js\";\nimport { IN } from \"../../constants.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\nexport const EOF_FOLLOW_KEY: any = {};\n\nexport interface IFollowKey {\n  ruleName: string;\n  idxInCallingRule: number;\n  inRule: string;\n}\n\nexport const IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\";\n\nexport class InRuleRecoveryException extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = IN_RULE_RECOVERY_EXCEPTION;\n  }\n}\n\n/**\n * This trait is responsible for the error recovery and fault tolerant logic\n */\nexport class Recoverable {\n  recoveryEnabled: boolean;\n  firstAfterRepMap: Record<string, IFirstAfterRepetition>;\n  resyncFollows: Record<string, TokenType[]>;\n\n  initRecoverable(config: IParserConfig) {\n    this.firstAfterRepMap = {};\n    this.resyncFollows = {};\n\n    this.recoveryEnabled = has(config, \"recoveryEnabled\")\n      ? (config.recoveryEnabled as boolean) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.recoveryEnabled;\n\n    // performance optimization, NOOP will be inlined which\n    // effectively means that this optional feature does not exist\n    // when not used.\n    if (this.recoveryEnabled) {\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery;\n    }\n  }\n\n  public getTokenToInsert(tokType: TokenType): IToken {\n    const tokToInsert = createTokenInstance(\n      tokType,\n      \"\",\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n    );\n    tokToInsert.isInsertedInRecovery = true;\n    return tokToInsert;\n  }\n\n  public canTokenTypeBeInsertedInRecovery(tokType: TokenType): boolean {\n    return true;\n  }\n\n  public canTokenTypeBeDeletedInRecovery(tokType: TokenType): boolean {\n    return true;\n  }\n\n  tryInRepetitionRecovery(\n    this: MixedInParser,\n    grammarRule: Function,\n    grammarRuleArgs: any[],\n    lookAheadFunc: () => boolean,\n    expectedTokType: TokenType,\n  ): void {\n    // TODO: can the resyncTokenType be cached?\n    const reSyncTokType = this.findReSyncTokenType();\n    const savedLexerState = this.exportLexerState();\n    const resyncedTokens: IToken[] = [];\n    let passedResyncPoint = false;\n\n    const nextTokenWithoutResync = this.LA(1);\n    let currToken = this.LA(1);\n\n    const generateErrorMessage = () => {\n      const previousToken = this.LA(0);\n      // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n      // the error that would have been thrown\n      const msg = this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: expectedTokType,\n        actual: nextTokenWithoutResync,\n        previous: previousToken,\n        ruleName: this.getCurrRuleFullName(),\n      });\n      const error = new MismatchedTokenException(\n        msg,\n        nextTokenWithoutResync,\n        this.LA(0),\n      );\n      // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n      error.resyncedTokens = dropRight(resyncedTokens);\n      this.SAVE_ERROR(error);\n    };\n\n    while (!passedResyncPoint) {\n      // re-synced to a point where we can safely exit the repetition/\n      if (this.tokenMatcher(currToken, expectedTokType)) {\n        generateErrorMessage();\n        return; // must return here to avoid reverting the inputIdx\n      } else if (lookAheadFunc.call(this)) {\n        // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n        generateErrorMessage();\n        // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n        grammarRule.apply(this, grammarRuleArgs);\n        return; // must return here to avoid reverting the inputIdx\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n        passedResyncPoint = true;\n      } else {\n        currToken = this.SKIP_TOKEN();\n        this.addToResyncTokens(currToken, resyncedTokens);\n      }\n    }\n\n    // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n    // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n    // \"between rules\" resync recovery later in the flow.\n    this.importLexerState(savedLexerState);\n  }\n\n  shouldInRepetitionRecoveryBeTried(\n    this: MixedInParser,\n    expectTokAfterLastMatch: TokenType,\n    nextTokIdx: number,\n    notStuck: boolean | undefined,\n  ): boolean {\n    // Edge case of arriving from a MANY repetition which is stuck\n    // Attempting recovery in this case could cause an infinite loop\n    if (notStuck === false) {\n      return false;\n    }\n\n    // no need to recover, next token is what we expect...\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n      return false;\n    }\n\n    // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n    // and prefer some backtracking path that includes recovered errors.\n    if (this.isBackTracking()) {\n      return false;\n    }\n\n    // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n    // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n    //noinspection RedundantIfStatementJS\n    if (\n      this.canPerformInRuleRecovery(\n        expectTokAfterLastMatch,\n        this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx),\n      )\n    ) {\n      return false;\n    }\n\n    return true;\n  }\n\n  // Error Recovery functionality\n  getFollowsForInRuleRecovery(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number,\n  ): TokenType[] {\n    const grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule);\n    const follows = this.getNextPossibleTokenTypes(grammarPath);\n    return follows;\n  }\n\n  tryInRuleRecovery(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[],\n  ): IToken {\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n      const tokToInsert = this.getTokenToInsert(expectedTokType);\n      return tokToInsert;\n    }\n\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n      const nextTok = this.SKIP_TOKEN();\n      this.consumeToken();\n      return nextTok;\n    }\n\n    throw new InRuleRecoveryException(\"sad sad panda\");\n  }\n\n  canPerformInRuleRecovery(\n    this: MixedInParser,\n    expectedToken: TokenType,\n    follows: TokenType[],\n  ): boolean {\n    return (\n      this.canRecoverWithSingleTokenInsertion(expectedToken, follows) ||\n      this.canRecoverWithSingleTokenDeletion(expectedToken)\n    );\n  }\n\n  canRecoverWithSingleTokenInsertion(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[],\n  ): boolean {\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n      return false;\n    }\n\n    // must know the possible following tokens to perform single token insertion\n    if (isEmpty(follows)) {\n      return false;\n    }\n\n    const mismatchedTok = this.LA(1);\n    const isMisMatchedTokInFollows =\n      find(follows, (possibleFollowsTokType: TokenType) => {\n        return this.tokenMatcher(mismatchedTok, possibleFollowsTokType);\n      }) !== undefined;\n\n    return isMisMatchedTokInFollows;\n  }\n\n  canRecoverWithSingleTokenDeletion(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n  ): boolean {\n    if (!this.canTokenTypeBeDeletedInRecovery(expectedTokType)) {\n      return false;\n    }\n\n    const isNextTokenWhatIsExpected = this.tokenMatcher(\n      this.LA(2),\n      expectedTokType,\n    );\n    return isNextTokenWhatIsExpected;\n  }\n\n  isInCurrentRuleReSyncSet(\n    this: MixedInParser,\n    tokenTypeIdx: TokenType,\n  ): boolean {\n    const followKey = this.getCurrFollowKey();\n    const currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey);\n    return includes(currentRuleReSyncSet, tokenTypeIdx);\n  }\n\n  findReSyncTokenType(this: MixedInParser): TokenType {\n    const allPossibleReSyncTokTypes = this.flattenFollowSet();\n    // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n    let nextToken = this.LA(1);\n    let k = 2;\n    while (true) {\n      const foundMatch = find(allPossibleReSyncTokTypes, (resyncTokType) => {\n        const canMatch = tokenMatcher(nextToken, resyncTokType);\n        return canMatch;\n      });\n      if (foundMatch !== undefined) {\n        return foundMatch;\n      }\n      nextToken = this.LA(k);\n      k++;\n    }\n  }\n\n  getCurrFollowKey(this: MixedInParser): IFollowKey {\n    // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n    if (this.RULE_STACK.length === 1) {\n      return EOF_FOLLOW_KEY;\n    }\n    const currRuleShortName = this.getLastExplicitRuleShortName();\n    const currRuleIdx = this.getLastExplicitRuleOccurrenceIndex();\n    const prevRuleShortName = this.getPreviousExplicitRuleShortName();\n\n    return {\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\n      idxInCallingRule: currRuleIdx,\n      inRule: this.shortRuleNameToFullName(prevRuleShortName),\n    };\n  }\n\n  buildFullFollowKeyStack(this: MixedInParser): IFollowKey[] {\n    const explicitRuleStack = this.RULE_STACK;\n    const explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK;\n\n    return map(explicitRuleStack, (ruleName, idx) => {\n      if (idx === 0) {\n        return EOF_FOLLOW_KEY;\n      }\n      return {\n        ruleName: this.shortRuleNameToFullName(ruleName),\n        idxInCallingRule: explicitOccurrenceStack[idx],\n        inRule: this.shortRuleNameToFullName(explicitRuleStack[idx - 1]),\n      };\n    });\n  }\n\n  flattenFollowSet(this: MixedInParser): TokenType[] {\n    const followStack = map(this.buildFullFollowKeyStack(), (currKey) => {\n      return this.getFollowSetFromFollowKey(currKey);\n    });\n    return <any>flatten(followStack);\n  }\n\n  getFollowSetFromFollowKey(\n    this: MixedInParser,\n    followKey: IFollowKey,\n  ): TokenType[] {\n    if (followKey === EOF_FOLLOW_KEY) {\n      return [EOF];\n    }\n\n    const followName =\n      followKey.ruleName + followKey.idxInCallingRule + IN + followKey.inRule;\n\n    return this.resyncFollows[followName];\n  }\n\n  // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n  addToResyncTokens(\n    this: MixedInParser,\n    token: IToken,\n    resyncTokens: IToken[],\n  ): IToken[] {\n    if (!this.tokenMatcher(token, EOF)) {\n      resyncTokens.push(token);\n    }\n    return resyncTokens;\n  }\n\n  reSyncTo(this: MixedInParser, tokType: TokenType): IToken[] {\n    const resyncedTokens: IToken[] = [];\n    let nextTok = this.LA(1);\n    while (this.tokenMatcher(nextTok, tokType) === false) {\n      nextTok = this.SKIP_TOKEN();\n      this.addToResyncTokens(nextTok, resyncedTokens);\n    }\n    // the last token is not part of the error.\n    return dropRight(resyncedTokens);\n  }\n\n  attemptInRepetitionRecovery(\n    this: MixedInParser,\n    prodFunc: Function,\n    args: any[],\n    lookaheadFunc: () => boolean,\n    dslMethodIdx: number,\n    prodOccurrence: number,\n    nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n    notStuck?: boolean,\n  ): void {\n    // by default this is a NO-OP\n    // The actual implementation is with the function(not method) below\n  }\n\n  getCurrentGrammarPath(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number,\n  ): ITokenGrammarPath {\n    const pathRuleStack: string[] = this.getHumanReadableRuleStack();\n    const pathOccurrenceStack: number[] = clone(this.RULE_OCCURRENCE_STACK);\n    const grammarPath: any = {\n      ruleStack: pathRuleStack,\n      occurrenceStack: pathOccurrenceStack,\n      lastTok: tokType,\n      lastTokOccurrence: tokIdxInRule,\n    };\n\n    return grammarPath;\n  }\n  getHumanReadableRuleStack(this: MixedInParser): string[] {\n    return map(this.RULE_STACK, (currShortName) =>\n      this.shortRuleNameToFullName(currShortName),\n    );\n  }\n}\n\nexport function attemptInRepetitionRecovery(\n  this: MixedInParser,\n  prodFunc: Function,\n  args: any[],\n  lookaheadFunc: () => boolean,\n  dslMethodIdx: number,\n  prodOccurrence: number,\n  nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n  notStuck?: boolean,\n): void {\n  const key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence);\n  let firstAfterRepInfo = this.firstAfterRepMap[key];\n  if (firstAfterRepInfo === undefined) {\n    const currRuleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[currRuleName];\n    const walker: AbstractNextTerminalAfterProductionWalker =\n      new nextToksWalker(ruleGrammar, prodOccurrence);\n    firstAfterRepInfo = walker.startWalking();\n    this.firstAfterRepMap[key] = firstAfterRepInfo;\n  }\n\n  let expectTokAfterLastMatch = firstAfterRepInfo.token;\n  let nextTokIdx = firstAfterRepInfo.occurrence;\n  const isEndOfRule = firstAfterRepInfo.isEndOfRule;\n\n  // special edge case of a TOP most repetition after which the input should END.\n  // this will force an attempt for inRule recovery in that scenario.\n  if (\n    this.RULE_STACK.length === 1 &&\n    isEndOfRule &&\n    expectTokAfterLastMatch === undefined\n  ) {\n    expectTokAfterLastMatch = EOF;\n    nextTokIdx = 1;\n  }\n\n  // We don't have anything to re-sync to...\n  // this condition was extracted from `shouldInRepetitionRecoveryBeTried` to act as a type-guard\n  if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n    return;\n  }\n\n  if (\n    this.shouldInRepetitionRecoveryBeTried(\n      expectTokAfterLastMatch,\n      nextTokIdx,\n      notStuck,\n    )\n  ) {\n    // TODO: performance optimization: instead of passing the original args here, we modify\n    // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n    // to avoid searching the cache for it once more.\n    this.tryInRepetitionRecovery(\n      prodFunc,\n      args,\n      lookaheadFunc,\n      expectTokAfterLastMatch,\n    );\n  }\n}\n","import type {\n  Alternation,\n  Alternative,\n  IProduction,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { GAstVisitor, NonTerminal } from \"@chevrotain/gast\";\nimport { assign, flatten, groupBy, map, some, values } from \"lodash-es\";\n\nexport function buildModel(\n  productions: Record<string, Rule>,\n): CstNodeTypeDefinition[] {\n  const generator = new CstNodeDefinitionGenerator();\n  const allRules = values(productions);\n  return map(allRules, (rule) => generator.visitRule(rule));\n}\n\nexport type CstNodeTypeDefinition = {\n  name: string;\n  properties: PropertyTypeDefinition[];\n};\n\nexport type PropertyTypeDefinition = {\n  name: string;\n  type: PropertyArrayType;\n  optional: boolean;\n};\n\nexport type PropertyArrayType =\n  | TokenArrayType\n  | RuleArrayType\n  | (TokenArrayType | RuleArrayType)[];\n\nexport type TokenArrayType = { kind: \"token\" };\nexport type RuleArrayType = {\n  kind: \"rule\";\n  name: string;\n};\n\nclass CstNodeDefinitionGenerator extends GAstVisitor {\n  visitRule(node: Rule): CstNodeTypeDefinition {\n    const rawElements = this.visitEach(node.definition);\n\n    const grouped = groupBy(rawElements, (el) => el.propertyName);\n    const properties = map(grouped, (group, propertyName) => {\n      const allNullable = !some(group, (el) => !el.canBeNull);\n\n      // In an alternation with a label a property name can have\n      // multiple types.\n      let propertyType: PropertyArrayType = group[0].type;\n      if (group.length > 1) {\n        propertyType = map(group, (g) => g.type);\n      }\n\n      return {\n        name: propertyName,\n        type: propertyType,\n        optional: allNullable,\n      } as PropertyTypeDefinition;\n    });\n\n    return {\n      name: node.name,\n      properties: properties,\n    };\n  }\n\n  visitAlternative(node: Alternative) {\n    return this.visitEachAndOverrideWith(node.definition, { canBeNull: true });\n  }\n\n  visitOption(node: Option) {\n    return this.visitEachAndOverrideWith(node.definition, { canBeNull: true });\n  }\n\n  visitRepetition(node: Repetition) {\n    return this.visitEachAndOverrideWith(node.definition, { canBeNull: true });\n  }\n\n  visitRepetitionMandatory(node: RepetitionMandatory) {\n    return this.visitEach(node.definition);\n  }\n\n  visitRepetitionMandatoryWithSeparator(\n    node: RepetitionMandatoryWithSeparator,\n  ) {\n    return this.visitEach(node.definition).concat({\n      propertyName: node.separator.name,\n      canBeNull: true,\n      type: getType(node.separator),\n    });\n  }\n\n  visitRepetitionWithSeparator(node: RepetitionWithSeparator) {\n    return this.visitEachAndOverrideWith(node.definition, {\n      canBeNull: true,\n    }).concat({\n      propertyName: node.separator.name,\n      canBeNull: true,\n      type: getType(node.separator),\n    });\n  }\n\n  visitAlternation(node: Alternation) {\n    return this.visitEachAndOverrideWith(node.definition, { canBeNull: true });\n  }\n\n  visitTerminal(node: Terminal): PropertyTupleElement[] {\n    return [\n      {\n        propertyName: node.label || node.terminalType.name,\n        canBeNull: false,\n        type: getType(node),\n      },\n    ];\n  }\n\n  visitNonTerminal(node: NonTerminal): PropertyTupleElement[] {\n    return [\n      {\n        propertyName: node.label || node.nonTerminalName,\n        canBeNull: false,\n        type: getType(node),\n      },\n    ];\n  }\n\n  private visitEachAndOverrideWith(\n    definition: IProduction[],\n    override: Partial<PropertyTupleElement>,\n  ) {\n    return map(\n      this.visitEach(definition),\n      (definition) => assign({}, definition, override) as PropertyTupleElement,\n    );\n  }\n\n  private visitEach(definition: IProduction[]) {\n    return flatten<PropertyTupleElement>(\n      map(\n        definition,\n        (definition) => this.visit(definition) as PropertyTupleElement[],\n      ),\n    );\n  }\n}\n\ntype PropertyTupleElement = {\n  propertyName: string;\n  canBeNull: boolean;\n  type: TokenArrayType | RuleArrayType;\n};\n\nfunction getType(\n  production: Terminal | NonTerminal | TokenType,\n): TokenArrayType | RuleArrayType {\n  if (production instanceof NonTerminal) {\n    return {\n      kind: \"rule\",\n      name: production.referencedRule.name,\n    };\n  }\n\n  return { kind: \"token\" };\n}\n","export function applyMixins(derivedCtor: any, baseCtors: any[]) {\n  baseCtors.forEach((baseCtor) => {\n    const baseProto = baseCtor.prototype;\n    Object.getOwnPropertyNames(baseProto).forEach((propName) => {\n      if (propName === \"constructor\") {\n        return;\n      }\n\n      const basePropDescriptor = Object.getOwnPropertyDescriptor(\n        baseProto,\n        propName,\n      );\n      // Handle Accessors\n      if (\n        basePropDescriptor &&\n        (basePropDescriptor.get || basePropDescriptor.set)\n      ) {\n        Object.defineProperty(\n          derivedCtor.prototype,\n          propName,\n          basePropDescriptor,\n        );\n      } else {\n        derivedCtor.prototype[propName] = baseCtor.prototype[propName];\n      }\n    });\n  });\n}\n","import baseCreate from './_baseCreate.js';\nimport getPrototype from './_getPrototype.js';\nimport isPrototype from './_isPrototype.js';\n\n/**\n * Initializes an object clone.\n *\n * @private\n * @param {Object} object The object to clone.\n * @returns {Object} Returns the initialized clone.\n */\nfunction initCloneObject(object) {\n  return (typeof object.constructor == 'function' && !isPrototype(object))\n    ? baseCreate(getPrototype(object))\n    : {};\n}\n\nexport default initCloneObject;\n","import baseIsMap from './_baseIsMap.js';\nimport baseUnary from './_baseUnary.js';\nimport nodeUtil from './_nodeUtil.js';\n\n/* Node.js helper references. */\nvar nodeIsMap = nodeUtil && nodeUtil.isMap;\n\n/**\n * Checks if `value` is classified as a `Map` object.\n *\n * @static\n * @memberOf _\n * @since 4.3.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a map, else `false`.\n * @example\n *\n * _.isMap(new Map);\n * // => true\n *\n * _.isMap(new WeakMap);\n * // => false\n */\nvar isMap = nodeIsMap ? baseUnary(nodeIsMap) : baseIsMap;\n\nexport default isMap;\n","import baseGet from './_baseGet.js';\nimport baseSet from './_baseSet.js';\nimport castPath from './_castPath.js';\n\n/**\n * The base implementation of  `_.pickBy` without support for iteratee shorthands.\n *\n * @private\n * @param {Object} object The source object.\n * @param {string[]} paths The property paths to pick.\n * @param {Function} predicate The function invoked per property.\n * @returns {Object} Returns the new object.\n */\nfunction basePickBy(object, paths, predicate) {\n  var index = -1,\n      length = paths.length,\n      result = {};\n\n  while (++index < length) {\n    var path = paths[index],\n        value = baseGet(object, path);\n\n    if (predicate(value, path)) {\n      baseSet(result, castPath(path, object), value);\n    }\n  }\n  return result;\n}\n\nexport default basePickBy;\n","import baseGetAllKeys from './_baseGetAllKeys.js';\nimport getSymbols from './_getSymbols.js';\nimport keys from './keys.js';\n\n/**\n * Creates an array of own enumerable property names and symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names and symbols.\n */\nfunction getAllKeys(object) {\n  return baseGetAllKeys(object, keys, getSymbols);\n}\n\nexport default getAllKeys;\n","import Symbol from './_Symbol.js';\nimport getRawTag from './_getRawTag.js';\nimport objectToString from './_objectToString.js';\n\n/** `Object#toString` result references. */\nvar nullTag = '[object Null]',\n    undefinedTag = '[object Undefined]';\n\n/** Built-in value references. */\nvar symToStringTag = Symbol ? Symbol.toStringTag : undefined;\n\n/**\n * The base implementation of `getTag` without fallbacks for buggy environments.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nfunction baseGetTag(value) {\n  if (value == null) {\n    return value === undefined ? undefinedTag : nullTag;\n  }\n  return (symToStringTag && symToStringTag in Object(value))\n    ? getRawTag(value)\n    : objectToString(value);\n}\n\nexport default baseGetTag;\n","import baseIsSet from './_baseIsSet.js';\nimport baseUnary from './_baseUnary.js';\nimport nodeUtil from './_nodeUtil.js';\n\n/* Node.js helper references. */\nvar nodeIsSet = nodeUtil && nodeUtil.isSet;\n\n/**\n * Checks if `value` is classified as a `Set` object.\n *\n * @static\n * @memberOf _\n * @since 4.3.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a set, else `false`.\n * @example\n *\n * _.isSet(new Set);\n * // => true\n *\n * _.isSet(new WeakSet);\n * // => false\n */\nvar isSet = nodeIsSet ? baseUnary(nodeIsSet) : baseIsSet;\n\nexport default isSet;\n","import isObject from './isObject.js';\nimport isPrototype from './_isPrototype.js';\nimport nativeKeysIn from './_nativeKeysIn.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * The base implementation of `_.keysIn` which doesn't treat sparse arrays as dense.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction baseKeysIn(object) {\n  if (!isObject(object)) {\n    return nativeKeysIn(object);\n  }\n  var isProto = isPrototype(object),\n      result = [];\n\n  for (var key in object) {\n    if (!(key == 'constructor' && (isProto || !hasOwnProperty.call(object, key)))) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\nexport default baseKeysIn;\n","import arrayLikeKeys from './_arrayLikeKeys.js';\nimport baseKeysIn from './_baseKeysIn.js';\nimport isArrayLike from './isArrayLike.js';\n\n/**\n * Creates an array of the own and inherited enumerable property names of `object`.\n *\n * **Note:** Non-object values are coerced to objects.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Object\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.keysIn(new Foo);\n * // => ['a', 'b', 'c'] (iteration order is not guaranteed)\n */\nfunction keysIn(object) {\n  return isArrayLike(object) ? arrayLikeKeys(object, true) : baseKeysIn(object);\n}\n\nexport default keysIn;\n","import baseTrim from './_baseTrim.js';\nimport isObject from './isObject.js';\nimport isSymbol from './isSymbol.js';\n\n/** Used as references for various `Number` constants. */\nvar NAN = 0 / 0;\n\n/** Used to detect bad signed hexadecimal string values. */\nvar reIsBadHex = /^[-+]0x[0-9a-f]+$/i;\n\n/** Used to detect binary string values. */\nvar reIsBinary = /^0b[01]+$/i;\n\n/** Used to detect octal string values. */\nvar reIsOctal = /^0o[0-7]+$/i;\n\n/** Built-in method references without a dependency on `root`. */\nvar freeParseInt = parseInt;\n\n/**\n * Converts `value` to a number.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to process.\n * @returns {number} Returns the number.\n * @example\n *\n * _.toNumber(3.2);\n * // => 3.2\n *\n * _.toNumber(Number.MIN_VALUE);\n * // => 5e-324\n *\n * _.toNumber(Infinity);\n * // => Infinity\n *\n * _.toNumber('3.2');\n * // => 3.2\n */\nfunction toNumber(value) {\n  if (typeof value == 'number') {\n    return value;\n  }\n  if (isSymbol(value)) {\n    return NAN;\n  }\n  if (isObject(value)) {\n    var other = typeof value.valueOf == 'function' ? value.valueOf() : value;\n    value = isObject(other) ? (other + '') : other;\n  }\n  if (typeof value != 'string') {\n    return value === 0 ? value : +value;\n  }\n  value = baseTrim(value);\n  var isBinary = reIsBinary.test(value);\n  return (isBinary || reIsOctal.test(value))\n    ? freeParseInt(value.slice(2), isBinary ? 2 : 8)\n    : (reIsBadHex.test(value) ? NAN : +value);\n}\n\nexport default toNumber;\n","import baseGetAllKeys from './_baseGetAllKeys.js';\nimport getSymbolsIn from './_getSymbolsIn.js';\nimport keysIn from './keysIn.js';\n\n/**\n * Creates an array of own and inherited enumerable property names and\n * symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names and symbols.\n */\nfunction getAllKeysIn(object) {\n  return baseGetAllKeys(object, keysIn, getSymbolsIn);\n}\n\nexport default getAllKeysIn;\n","import identity from './identity.js';\nimport overRest from './_overRest.js';\nimport setToString from './_setToString.js';\n\n/**\n * The base implementation of `_.rest` which doesn't validate or coerce arguments.\n *\n * @private\n * @param {Function} func The function to apply a rest parameter to.\n * @param {number} [start=func.length-1] The start position of the rest parameter.\n * @returns {Function} Returns the new function.\n */\nfunction baseRest(func, start) {\n  return setToString(overRest(func, start, identity), func + '');\n}\n\nexport default baseRest;\n","import baseIteratee from './_baseIteratee.js';\nimport isArrayLike from './isArrayLike.js';\nimport keys from './keys.js';\n\n/**\n * Creates a `_.find` or `_.findLast` function.\n *\n * @private\n * @param {Function} findIndexFunc The function to find the collection index.\n * @returns {Function} Returns the new find function.\n */\nfunction createFind(findIndexFunc) {\n  return function(collection, predicate, fromIndex) {\n    var iterable = Object(collection);\n    if (!isArrayLike(collection)) {\n      var iteratee = baseIteratee(predicate, 3);\n      collection = keys(collection);\n      predicate = function(key) { return iteratee(iterable[key], key, iterable); };\n    }\n    var index = findIndexFunc(collection, predicate, fromIndex);\n    return index > -1 ? iterable[iteratee ? collection[index] : index] : undefined;\n  };\n}\n\nexport default createFind;\n","import baseFindIndex from './_baseFindIndex.js';\nimport baseIteratee from './_baseIteratee.js';\nimport toInteger from './toInteger.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * This method is like `_.find` except that it returns the index of the first\n * element `predicate` returns truthy for instead of the element itself.\n *\n * @static\n * @memberOf _\n * @since 1.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {number} Returns the index of the found element, else `-1`.\n * @example\n *\n * var users = [\n *   { 'user': 'barney',  'active': false },\n *   { 'user': 'fred',    'active': false },\n *   { 'user': 'pebbles', 'active': true }\n * ];\n *\n * _.findIndex(users, function(o) { return o.user == 'barney'; });\n * // => 0\n *\n * // The `_.matches` iteratee shorthand.\n * _.findIndex(users, { 'user': 'fred', 'active': false });\n * // => 1\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.findIndex(users, ['active', false]);\n * // => 0\n *\n * // The `_.property` iteratee shorthand.\n * _.findIndex(users, 'active');\n * // => 2\n */\nfunction findIndex(array, predicate, fromIndex) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return -1;\n  }\n  var index = fromIndex == null ? 0 : toInteger(fromIndex);\n  if (index < 0) {\n    index = nativeMax(length + index, 0);\n  }\n  return baseFindIndex(array, baseIteratee(predicate, 3), index);\n}\n\nexport default findIndex;\n","import MapCache from './_MapCache.js';\nimport setCacheAdd from './_setCacheAdd.js';\nimport setCacheHas from './_setCacheHas.js';\n\n/**\n *\n * Creates an array cache object to store unique values.\n *\n * @private\n * @constructor\n * @param {Array} [values] The values to cache.\n */\nfunction SetCache(values) {\n  var index = -1,\n      length = values == null ? 0 : values.length;\n\n  this.__data__ = new MapCache;\n  while (++index < length) {\n    this.add(values[index]);\n  }\n}\n\n// Add methods to `SetCache`.\nSetCache.prototype.add = SetCache.prototype.push = setCacheAdd;\nSetCache.prototype.has = setCacheHas;\n\nexport default SetCache;\n","import Hash from './_Hash.js';\nimport ListCache from './_ListCache.js';\nimport Map from './_Map.js';\n\n/**\n * Removes all key-value entries from the map.\n *\n * @private\n * @name clear\n * @memberOf MapCache\n */\nfunction mapCacheClear() {\n  this.size = 0;\n  this.__data__ = {\n    'hash': new Hash,\n    'map': new (Map || ListCache),\n    'string': new Hash\n  };\n}\n\nexport default mapCacheClear;\n","import SetCache from './_SetCache.js';\nimport arraySome from './_arraySome.js';\nimport cacheHas from './_cacheHas.js';\n\n/** Used to compose bitmasks for value comparisons. */\nvar COMPARE_PARTIAL_FLAG = 1,\n    COMPARE_UNORDERED_FLAG = 2;\n\n/**\n * A specialized version of `baseIsEqualDeep` for arrays with support for\n * partial deep comparisons.\n *\n * @private\n * @param {Array} array The array to compare.\n * @param {Array} other The other array to compare.\n * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.\n * @param {Function} customizer The function to customize comparisons.\n * @param {Function} equalFunc The function to determine equivalents of values.\n * @param {Object} stack Tracks traversed `array` and `other` objects.\n * @returns {boolean} Returns `true` if the arrays are equivalent, else `false`.\n */\nfunction equalArrays(array, other, bitmask, customizer, equalFunc, stack) {\n  var isPartial = bitmask & COMPARE_PARTIAL_FLAG,\n      arrLength = array.length,\n      othLength = other.length;\n\n  if (arrLength != othLength && !(isPartial && othLength > arrLength)) {\n    return false;\n  }\n  // Check that cyclic values are equal.\n  var arrStacked = stack.get(array);\n  var othStacked = stack.get(other);\n  if (arrStacked && othStacked) {\n    return arrStacked == other && othStacked == array;\n  }\n  var index = -1,\n      result = true,\n      seen = (bitmask & COMPARE_UNORDERED_FLAG) ? new SetCache : undefined;\n\n  stack.set(array, other);\n  stack.set(other, array);\n\n  // Ignore non-index properties.\n  while (++index < arrLength) {\n    var arrValue = array[index],\n        othValue = other[index];\n\n    if (customizer) {\n      var compared = isPartial\n        ? customizer(othValue, arrValue, index, other, array, stack)\n        : customizer(arrValue, othValue, index, array, other, stack);\n    }\n    if (compared !== undefined) {\n      if (compared) {\n        continue;\n      }\n      result = false;\n      break;\n    }\n    // Recursively compare arrays (susceptible to call stack limits).\n    if (seen) {\n      if (!arraySome(other, function(othValue, othIndex) {\n            if (!cacheHas(seen, othIndex) &&\n                (arrValue === othValue || equalFunc(arrValue, othValue, bitmask, customizer, stack))) {\n              return seen.push(othIndex);\n            }\n          })) {\n        result = false;\n        break;\n      }\n    } else if (!(\n          arrValue === othValue ||\n            equalFunc(arrValue, othValue, bitmask, customizer, stack)\n        )) {\n      result = false;\n      break;\n    }\n  }\n  stack['delete'](array);\n  stack['delete'](other);\n  return result;\n}\n\nexport default equalArrays;\n","import ListCache from './_ListCache.js';\nimport Map from './_Map.js';\nimport MapCache from './_MapCache.js';\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/**\n * Sets the stack `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Stack\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the stack cache instance.\n */\nfunction stackSet(key, value) {\n  var data = this.__data__;\n  if (data instanceof ListCache) {\n    var pairs = data.__data__;\n    if (!Map || (pairs.length < LARGE_ARRAY_SIZE - 1)) {\n      pairs.push([key, value]);\n      this.size = ++data.size;\n      return this;\n    }\n    data = this.__data__ = new MapCache(pairs);\n  }\n  data.set(key, value);\n  this.size = data.size;\n  return this;\n}\n\nexport default stackSet;\n","import baseFindIndex from './_baseFindIndex.js';\nimport baseIsNaN from './_baseIsNaN.js';\nimport strictIndexOf from './_strictIndexOf.js';\n\n/**\n * The base implementation of `_.indexOf` without `fromIndex` bounds checks.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} value The value to search for.\n * @param {number} fromIndex The index to search from.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction baseIndexOf(array, value, fromIndex) {\n  return value === value\n    ? strictIndexOf(array, value, fromIndex)\n    : baseFindIndex(array, baseIsNaN, fromIndex);\n}\n\nexport default baseIndexOf;\n","import Symbol from './_Symbol.js';\nimport isArguments from './isArguments.js';\nimport isArray from './isArray.js';\n\n/** Built-in value references. */\nvar spreadableSymbol = Symbol ? Symbol.isConcatSpreadable : undefined;\n\n/**\n * Checks if `value` is a flattenable `arguments` object or array.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is flattenable, else `false`.\n */\nfunction isFlattenable(value) {\n  return isArray(value) || isArguments(value) ||\n    !!(spreadableSymbol && value && value[spreadableSymbol]);\n}\n\nexport default isFlattenable;\n","import arrayLikeKeys from './_arrayLikeKeys.js';\nimport baseKeys from './_baseKeys.js';\nimport isArrayLike from './isArrayLike.js';\n\n/**\n * Creates an array of the own enumerable property names of `object`.\n *\n * **Note:** Non-object values are coerced to objects. See the\n * [ES spec](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)\n * for more details.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.keys(new Foo);\n * // => ['a', 'b'] (iteration order is not guaranteed)\n *\n * _.keys('hi');\n * // => ['0', '1']\n */\nfunction keys(object) {\n  return isArrayLike(object) ? arrayLikeKeys(object) : baseKeys(object);\n}\n\nexport default keys;\n","import baseGetTag from './_baseGetTag.js';\nimport isLength from './isLength.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]',\n    arrayTag = '[object Array]',\n    boolTag = '[object Boolean]',\n    dateTag = '[object Date]',\n    errorTag = '[object Error]',\n    funcTag = '[object Function]',\n    mapTag = '[object Map]',\n    numberTag = '[object Number]',\n    objectTag = '[object Object]',\n    regexpTag = '[object RegExp]',\n    setTag = '[object Set]',\n    stringTag = '[object String]',\n    weakMapTag = '[object WeakMap]';\n\nvar arrayBufferTag = '[object ArrayBuffer]',\n    dataViewTag = '[object DataView]',\n    float32Tag = '[object Float32Array]',\n    float64Tag = '[object Float64Array]',\n    int8Tag = '[object Int8Array]',\n    int16Tag = '[object Int16Array]',\n    int32Tag = '[object Int32Array]',\n    uint8Tag = '[object Uint8Array]',\n    uint8ClampedTag = '[object Uint8ClampedArray]',\n    uint16Tag = '[object Uint16Array]',\n    uint32Tag = '[object Uint32Array]';\n\n/** Used to identify `toStringTag` values of typed arrays. */\nvar typedArrayTags = {};\ntypedArrayTags[float32Tag] = typedArrayTags[float64Tag] =\ntypedArrayTags[int8Tag] = typedArrayTags[int16Tag] =\ntypedArrayTags[int32Tag] = typedArrayTags[uint8Tag] =\ntypedArrayTags[uint8ClampedTag] = typedArrayTags[uint16Tag] =\ntypedArrayTags[uint32Tag] = true;\ntypedArrayTags[argsTag] = typedArrayTags[arrayTag] =\ntypedArrayTags[arrayBufferTag] = typedArrayTags[boolTag] =\ntypedArrayTags[dataViewTag] = typedArrayTags[dateTag] =\ntypedArrayTags[errorTag] = typedArrayTags[funcTag] =\ntypedArrayTags[mapTag] = typedArrayTags[numberTag] =\ntypedArrayTags[objectTag] = typedArrayTags[regexpTag] =\ntypedArrayTags[setTag] = typedArrayTags[stringTag] =\ntypedArrayTags[weakMapTag] = false;\n\n/**\n * The base implementation of `_.isTypedArray` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.\n */\nfunction baseIsTypedArray(value) {\n  return isObjectLike(value) &&\n    isLength(value.length) && !!typedArrayTags[baseGetTag(value)];\n}\n\nexport default baseIsTypedArray;\n","import baseIsMatch from './_baseIsMatch.js';\nimport getMatchData from './_getMatchData.js';\nimport matchesStrictComparable from './_matchesStrictComparable.js';\n\n/**\n * The base implementation of `_.matches` which doesn't clone `source`.\n *\n * @private\n * @param {Object} source The object of property values to match.\n * @returns {Function} Returns the new spec function.\n */\nfunction baseMatches(source) {\n  var matchData = getMatchData(source);\n  if (matchData.length == 1 && matchData[0][2]) {\n    return matchesStrictComparable(matchData[0][0], matchData[0][1]);\n  }\n  return function(object) {\n    return object === source || baseIsMatch(object, source, matchData);\n  };\n}\n\nexport default baseMatches;\n","import Set from './_Set.js';\nimport noop from './noop.js';\nimport setToArray from './_setToArray.js';\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0;\n\n/**\n * Creates a set object of `values`.\n *\n * @private\n * @param {Array} values The values to add to the set.\n * @returns {Object} Returns the new set.\n */\nvar createSet = !(Set && (1 / setToArray(new Set([,-0]))[1]) == INFINITY) ? noop : function(values) {\n  return new Set(values);\n};\n\nexport default createSet;\n","import constant from './constant.js';\nimport defineProperty from './_defineProperty.js';\nimport identity from './identity.js';\n\n/**\n * The base implementation of `setToString` without support for hot loop shorting.\n *\n * @private\n * @param {Function} func The function to modify.\n * @param {Function} string The `toString` result.\n * @returns {Function} Returns `func`.\n */\nvar baseSetToString = !defineProperty ? identity : function(func, string) {\n  return defineProperty(func, 'toString', {\n    'configurable': true,\n    'enumerable': false,\n    'value': constant(string),\n    'writable': true\n  });\n};\n\nexport default baseSetToString;\n","import baseIsTypedArray from './_baseIsTypedArray.js';\nimport baseUnary from './_baseUnary.js';\nimport nodeUtil from './_nodeUtil.js';\n\n/* Node.js helper references. */\nvar nodeIsTypedArray = nodeUtil && nodeUtil.isTypedArray;\n\n/**\n * Checks if `value` is classified as a typed array.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.\n * @example\n *\n * _.isTypedArray(new Uint8Array);\n * // => true\n *\n * _.isTypedArray([]);\n * // => false\n */\nvar isTypedArray = nodeIsTypedArray ? baseUnary(nodeIsTypedArray) : baseIsTypedArray;\n\nexport default isTypedArray;\n","import baseIsRegExp from './_baseIsRegExp.js';\nimport baseUnary from './_baseUnary.js';\nimport nodeUtil from './_nodeUtil.js';\n\n/* Node.js helper references. */\nvar nodeIsRegExp = nodeUtil && nodeUtil.isRegExp;\n\n/**\n * Checks if `value` is classified as a `RegExp` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a regexp, else `false`.\n * @example\n *\n * _.isRegExp(/abc/);\n * // => true\n *\n * _.isRegExp('/abc/');\n * // => false\n */\nvar isRegExp = nodeIsRegExp ? baseUnary(nodeIsRegExp) : baseIsRegExp;\n\nexport default isRegExp;\n","import baseGetTag from './_baseGetTag.js';\nimport isArray from './isArray.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar stringTag = '[object String]';\n\n/**\n * Checks if `value` is classified as a `String` primitive or object.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a string, else `false`.\n * @example\n *\n * _.isString('abc');\n * // => true\n *\n * _.isString(1);\n * // => false\n */\nfunction isString(value) {\n  return typeof value == 'string' ||\n    (!isArray(value) && isObjectLike(value) && baseGetTag(value) == stringTag);\n}\n\nexport default isString;\n","import type {\n  Alternative,\n  Assertion,\n  Atom,\n  Character,\n  Disjunction,\n  Group,\n  GroupBackReference,\n  Location,\n  Quantifier,\n  Range,\n  RegExpFlags,\n  RegExpPattern,\n  Set,\n  Term,\n} from \"../types\";\nimport {\n  addFlag,\n  ASSERT_EXISTS,\n  ASSERT_NEVER_REACH_HERE,\n  cc,\n  insertToSet,\n  isCharacter,\n} from \"./utils.js\";\nimport {\n  digitsCharCodes,\n  whitespaceCodes,\n  wordCharCodes,\n} from \"./character-classes.js\";\n\n// consts and utilities\nconst hexDigitPattern = /[0-9a-fA-F]/;\nconst decimalPattern = /[0-9]/;\nconst decimalPatternNoZero = /[1-9]/;\n\n// https://hackernoon.com/the-madness-of-parsing-real-world-javascript-regexps-d9ee336df983\n// https://www.ecma-international.org/ecma-262/8.0/index.html#prod-Pattern\nexport class RegExpParser {\n  protected idx: number = 0;\n  protected input: string = \"\";\n  protected groupIdx: number = 0;\n\n  protected saveState() {\n    return {\n      idx: this.idx,\n      input: this.input,\n      groupIdx: this.groupIdx,\n    };\n  }\n\n  protected restoreState(newState: {\n    idx: number;\n    input: string;\n    groupIdx: number;\n  }) {\n    this.idx = newState.idx;\n    this.input = newState.input;\n    this.groupIdx = newState.groupIdx;\n  }\n\n  public pattern(input: string): RegExpPattern {\n    // parser state\n    this.idx = 0;\n    this.input = input;\n    this.groupIdx = 0;\n\n    this.consumeChar(\"/\");\n    const value = this.disjunction();\n    this.consumeChar(\"/\");\n\n    const flags: RegExpFlags = {\n      type: \"Flags\",\n      loc: { begin: this.idx, end: input.length },\n      global: false,\n      ignoreCase: false,\n      multiLine: false,\n      unicode: false,\n      sticky: false,\n    };\n\n    while (this.isRegExpFlag()) {\n      switch (this.popChar()) {\n        case \"g\":\n          addFlag(flags, \"global\");\n          break;\n        case \"i\":\n          addFlag(flags, \"ignoreCase\");\n          break;\n        case \"m\":\n          addFlag(flags, \"multiLine\");\n          break;\n        case \"u\":\n          addFlag(flags, \"unicode\");\n          break;\n        case \"y\":\n          addFlag(flags, \"sticky\");\n          break;\n      }\n    }\n\n    if (this.idx !== this.input.length) {\n      throw Error(\"Redundant input: \" + this.input.substring(this.idx));\n    }\n    return {\n      type: \"Pattern\",\n      flags: flags,\n      value: value,\n      loc: this.loc(0),\n    };\n  }\n\n  protected disjunction(): Disjunction {\n    const alts = [];\n    const begin = this.idx;\n\n    alts.push(this.alternative());\n\n    while (this.peekChar() === \"|\") {\n      this.consumeChar(\"|\");\n      alts.push(this.alternative());\n    }\n\n    return { type: \"Disjunction\", value: alts, loc: this.loc(begin) };\n  }\n\n  protected alternative(): Alternative {\n    const terms = [];\n    const begin = this.idx;\n\n    while (this.isTerm()) {\n      terms.push(this.term());\n    }\n\n    return { type: \"Alternative\", value: terms, loc: this.loc(begin) };\n  }\n\n  protected term(): Term {\n    if (this.isAssertion()) {\n      return this.assertion();\n    } else {\n      return this.atom();\n    }\n  }\n\n  protected assertion(): Assertion {\n    const begin = this.idx;\n    switch (this.popChar()) {\n      case \"^\":\n        return {\n          type: \"StartAnchor\",\n          loc: this.loc(begin),\n        };\n      case \"$\":\n        return { type: \"EndAnchor\", loc: this.loc(begin) };\n      // '\\b' or '\\B'\n      case \"\\\\\":\n        switch (this.popChar()) {\n          case \"b\":\n            return {\n              type: \"WordBoundary\",\n              loc: this.loc(begin),\n            };\n          case \"B\":\n            return {\n              type: \"NonWordBoundary\",\n              loc: this.loc(begin),\n            };\n        }\n        // istanbul ignore next\n        throw Error(\"Invalid Assertion Escape\");\n      // '(?=' or '(?!'\n      case \"(\":\n        this.consumeChar(\"?\");\n\n        let type: \"Lookahead\" | \"NegativeLookahead\" | undefined;\n        switch (this.popChar()) {\n          case \"=\":\n            type = \"Lookahead\";\n            break;\n          case \"!\":\n            type = \"NegativeLookahead\";\n            break;\n        }\n        ASSERT_EXISTS(type);\n\n        const disjunction = this.disjunction();\n\n        this.consumeChar(\")\");\n\n        return {\n          type: type!,\n          value: disjunction,\n          loc: this.loc(begin),\n        };\n    }\n    // istanbul ignore next\n    return ASSERT_NEVER_REACH_HERE();\n  }\n\n  protected quantifier(\n    isBacktracking: boolean = false,\n  ): Quantifier | undefined {\n    let range: Partial<Quantifier> | undefined = undefined;\n    const begin = this.idx;\n    switch (this.popChar()) {\n      case \"*\":\n        range = {\n          atLeast: 0,\n          atMost: Infinity,\n        };\n        break;\n      case \"+\":\n        range = {\n          atLeast: 1,\n          atMost: Infinity,\n        };\n        break;\n      case \"?\":\n        range = {\n          atLeast: 0,\n          atMost: 1,\n        };\n        break;\n      case \"{\":\n        const atLeast = this.integerIncludingZero();\n        switch (this.popChar()) {\n          case \"}\":\n            range = {\n              atLeast: atLeast,\n              atMost: atLeast,\n            };\n            break;\n          case \",\":\n            let atMost;\n            if (this.isDigit()) {\n              atMost = this.integerIncludingZero();\n              range = {\n                atLeast: atLeast,\n                atMost: atMost,\n              };\n            } else {\n              range = {\n                atLeast: atLeast,\n                atMost: Infinity,\n              };\n            }\n            this.consumeChar(\"}\");\n            break;\n        }\n        // throwing exceptions from \"ASSERT_EXISTS\" during backtracking\n        // causes severe performance degradations\n        if (isBacktracking === true && range === undefined) {\n          return undefined;\n        }\n        ASSERT_EXISTS(range);\n        break;\n    }\n\n    // throwing exceptions from \"ASSERT_EXISTS\" during backtracking\n    // causes severe performance degradations\n    if (isBacktracking === true && range === undefined) {\n      return undefined;\n    }\n\n    // istanbul ignore else\n    if (ASSERT_EXISTS(range)) {\n      if (this.peekChar(0) === \"?\") {\n        this.consumeChar(\"?\");\n        range.greedy = false;\n      } else {\n        range.greedy = true;\n      }\n\n      range.type = \"Quantifier\";\n      range.loc = this.loc(begin);\n      return range as Quantifier;\n    }\n  }\n\n  protected atom(): Atom {\n    let atom: Omit<Atom, \"loc\" | \"type\"> | undefined;\n    const begin = this.idx;\n    switch (this.peekChar()) {\n      case \".\":\n        atom = this.dotAll();\n        break;\n      case \"\\\\\":\n        atom = this.atomEscape();\n        break;\n      case \"[\":\n        atom = this.characterClass();\n        break;\n      case \"(\":\n        atom = this.group();\n        break;\n    }\n\n    if (atom === undefined && this.isPatternCharacter()) {\n      atom = this.patternCharacter();\n    }\n\n    // istanbul ignore else\n    if (ASSERT_EXISTS<Atom>(atom)) {\n      atom.loc = this.loc(begin);\n\n      if (this.isQuantifier()) {\n        atom.quantifier = this.quantifier();\n      }\n\n      return atom;\n    }\n\n    // istanbul ignore next\n    return ASSERT_NEVER_REACH_HERE();\n  }\n\n  protected dotAll(): Omit<Set, \"loc\"> {\n    this.consumeChar(\".\");\n    return {\n      type: \"Set\",\n      complement: true,\n      value: [cc(\"\\n\"), cc(\"\\r\"), cc(\"\\u2028\"), cc(\"\\u2029\")],\n    };\n  }\n\n  protected atomEscape(): Omit<GroupBackReference | Set | Character, \"loc\"> {\n    this.consumeChar(\"\\\\\");\n\n    switch (this.peekChar()) {\n      case \"1\":\n      case \"2\":\n      case \"3\":\n      case \"4\":\n      case \"5\":\n      case \"6\":\n      case \"7\":\n      case \"8\":\n      case \"9\":\n        return this.decimalEscapeAtom();\n      case \"d\":\n      case \"D\":\n      case \"s\":\n      case \"S\":\n      case \"w\":\n      case \"W\":\n        return this.characterClassEscape();\n      case \"f\":\n      case \"n\":\n      case \"r\":\n      case \"t\":\n      case \"v\":\n        return this.controlEscapeAtom();\n      case \"c\":\n        return this.controlLetterEscapeAtom();\n      case \"0\":\n        return this.nulCharacterAtom();\n      case \"x\":\n        return this.hexEscapeSequenceAtom();\n      case \"u\":\n        return this.regExpUnicodeEscapeSequenceAtom();\n      default:\n        return this.identityEscapeAtom();\n    }\n  }\n\n  protected decimalEscapeAtom(): Omit<GroupBackReference, \"loc\"> {\n    const value = this.positiveInteger();\n\n    return { type: \"GroupBackReference\", value: value };\n  }\n\n  protected characterClassEscape(): Omit<Set, \"loc\"> {\n    let set: (number | Range)[] | undefined;\n    let complement = false;\n    switch (this.popChar()) {\n      case \"d\":\n        set = digitsCharCodes;\n        break;\n      case \"D\":\n        set = digitsCharCodes;\n        complement = true;\n        break;\n      case \"s\":\n        set = whitespaceCodes;\n        break;\n      case \"S\":\n        set = whitespaceCodes;\n        complement = true;\n        break;\n      case \"w\":\n        set = wordCharCodes;\n        break;\n      case \"W\":\n        set = wordCharCodes;\n        complement = true;\n        break;\n    }\n\n    // istanbul ignore else\n    if (ASSERT_EXISTS(set)) {\n      return { type: \"Set\", value: set, complement: complement };\n    }\n    // istanbul ignore next\n    return ASSERT_NEVER_REACH_HERE();\n  }\n\n  protected controlEscapeAtom(): Omit<Character, \"loc\"> {\n    let escapeCode;\n    switch (this.popChar()) {\n      case \"f\":\n        escapeCode = cc(\"\\f\");\n        break;\n      case \"n\":\n        escapeCode = cc(\"\\n\");\n        break;\n      case \"r\":\n        escapeCode = cc(\"\\r\");\n        break;\n      case \"t\":\n        escapeCode = cc(\"\\t\");\n        break;\n      case \"v\":\n        escapeCode = cc(\"\\v\");\n        break;\n    }\n\n    // istanbul ignore else\n    if (ASSERT_EXISTS(escapeCode)) {\n      return { type: \"Character\", value: escapeCode };\n    }\n    // istanbul ignore next\n    return ASSERT_NEVER_REACH_HERE();\n  }\n\n  protected controlLetterEscapeAtom(): Omit<Character, \"loc\"> {\n    this.consumeChar(\"c\");\n    const letter = this.popChar();\n    if (/[a-zA-Z]/.test(letter) === false) {\n      throw Error(\"Invalid \");\n    }\n\n    const letterCode = letter.toUpperCase().charCodeAt(0) - 64;\n    return { type: \"Character\", value: letterCode };\n  }\n\n  protected nulCharacterAtom(): Omit<Character, \"loc\"> {\n    // TODO implement '[lookahead  DecimalDigit]'\n    // TODO: for the deprecated octal escape sequence\n    this.consumeChar(\"0\");\n    return { type: \"Character\", value: cc(\"\\0\") };\n  }\n\n  protected hexEscapeSequenceAtom(): Omit<Character, \"loc\"> {\n    this.consumeChar(\"x\");\n    return this.parseHexDigits(2);\n  }\n\n  protected regExpUnicodeEscapeSequenceAtom(): Omit<Character, \"loc\"> {\n    this.consumeChar(\"u\");\n    return this.parseHexDigits(4);\n  }\n\n  protected identityEscapeAtom(): Omit<Character, \"loc\"> {\n    // TODO: implement \"SourceCharacter but not UnicodeIDContinue\"\n    // // http://unicode.org/reports/tr31/#Specific_Character_Adjustments\n    const escapedChar = this.popChar();\n    return { type: \"Character\", value: cc(escapedChar) };\n  }\n\n  protected classPatternCharacterAtom(): Omit<Character, \"loc\"> {\n    switch (this.peekChar()) {\n      // istanbul ignore next\n      case \"\\n\":\n      // istanbul ignore next\n      case \"\\r\":\n      // istanbul ignore next\n      case \"\\u2028\":\n      // istanbul ignore next\n      case \"\\u2029\":\n      // istanbul ignore next\n      case \"\\\\\":\n      // istanbul ignore next\n      case \"]\":\n        throw Error(\"TBD\");\n      default:\n        const nextChar = this.popChar();\n        return { type: \"Character\", value: cc(nextChar) };\n    }\n  }\n\n  protected characterClass(): Omit<Set, \"loc\"> {\n    const set: (number | Range)[] = [];\n    let complement = false;\n    this.consumeChar(\"[\");\n    if (this.peekChar(0) === \"^\") {\n      this.consumeChar(\"^\");\n      complement = true;\n    }\n\n    while (this.isClassAtom()) {\n      const from = this.classAtom();\n      const isFromSingleChar = from.type === \"Character\";\n      if (isCharacter(from) && this.isRangeDash()) {\n        this.consumeChar(\"-\");\n        const to = this.classAtom();\n        const isToSingleChar = to.type === \"Character\";\n\n        // a range can only be used when both sides are single characters\n        if (isCharacter(to)) {\n          if (to.value < from.value) {\n            throw Error(\"Range out of order in character class\");\n          }\n          set.push({ from: from.value, to: to.value });\n        } else {\n          // literal dash\n          insertToSet(from.value, set);\n          set.push(cc(\"-\"));\n          insertToSet(to.value, set);\n        }\n      } else {\n        insertToSet(from.value, set);\n      }\n    }\n\n    this.consumeChar(\"]\");\n\n    return { type: \"Set\", complement: complement, value: set };\n  }\n\n  protected classAtom(): Omit<Character | Set, \"loc\"> {\n    switch (this.peekChar()) {\n      // istanbul ignore next\n      case \"]\":\n      // istanbul ignore next\n      case \"\\n\":\n      // istanbul ignore next\n      case \"\\r\":\n      // istanbul ignore next\n      case \"\\u2028\":\n      // istanbul ignore next\n      case \"\\u2029\":\n        throw Error(\"TBD\");\n      case \"\\\\\":\n        return this.classEscape();\n      default:\n        return this.classPatternCharacterAtom();\n    }\n  }\n\n  protected classEscape(): Omit<Character | Set, \"loc\"> {\n    this.consumeChar(\"\\\\\");\n    switch (this.peekChar()) {\n      // Matches a backspace.\n      // (Not to be confused with \\b word boundary outside characterClass)\n      case \"b\":\n        this.consumeChar(\"b\");\n        return { type: \"Character\", value: cc(\"\\u0008\") };\n      case \"d\":\n      case \"D\":\n      case \"s\":\n      case \"S\":\n      case \"w\":\n      case \"W\":\n        return this.characterClassEscape();\n      case \"f\":\n      case \"n\":\n      case \"r\":\n      case \"t\":\n      case \"v\":\n        return this.controlEscapeAtom();\n      case \"c\":\n        return this.controlLetterEscapeAtom();\n      case \"0\":\n        return this.nulCharacterAtom();\n      case \"x\":\n        return this.hexEscapeSequenceAtom();\n      case \"u\":\n        return this.regExpUnicodeEscapeSequenceAtom();\n      default:\n        return this.identityEscapeAtom();\n    }\n  }\n\n  protected group(): Omit<Group, \"loc\"> {\n    let capturing = true;\n    this.consumeChar(\"(\");\n    switch (this.peekChar(0)) {\n      case \"?\":\n        this.consumeChar(\"?\");\n        this.consumeChar(\":\");\n        capturing = false;\n        break;\n      default:\n        this.groupIdx++;\n        break;\n    }\n    const value = this.disjunction();\n    this.consumeChar(\")\");\n\n    const groupAst: Omit<Group, \"loc\"> = {\n      type: \"Group\",\n      capturing: capturing,\n      value: value,\n    };\n\n    if (capturing) {\n      groupAst[\"idx\"] = this.groupIdx;\n    }\n\n    return groupAst;\n  }\n\n  protected positiveInteger(): number {\n    let number = this.popChar();\n\n    // istanbul ignore next - can't ever get here due to previous lookahead checks\n    // still implementing this error checking in case this ever changes.\n    if (decimalPatternNoZero.test(number) === false) {\n      throw Error(\"Expecting a positive integer\");\n    }\n\n    while (decimalPattern.test(this.peekChar(0))) {\n      number += this.popChar();\n    }\n\n    return parseInt(number, 10);\n  }\n\n  protected integerIncludingZero(): number {\n    let number = this.popChar();\n    if (decimalPattern.test(number) === false) {\n      throw Error(\"Expecting an integer\");\n    }\n\n    while (decimalPattern.test(this.peekChar(0))) {\n      number += this.popChar();\n    }\n\n    return parseInt(number, 10);\n  }\n\n  protected patternCharacter(): Omit<Character, \"loc\"> {\n    const nextChar = this.popChar();\n    switch (nextChar) {\n      // istanbul ignore next\n      case \"\\n\":\n      // istanbul ignore next\n      case \"\\r\":\n      // istanbul ignore next\n      case \"\\u2028\":\n      // istanbul ignore next\n      case \"\\u2029\":\n      // istanbul ignore next\n      case \"^\":\n      // istanbul ignore next\n      case \"$\":\n      // istanbul ignore next\n      case \"\\\\\":\n      // istanbul ignore next\n      case \".\":\n      // istanbul ignore next\n      case \"*\":\n      // istanbul ignore next\n      case \"+\":\n      // istanbul ignore next\n      case \"?\":\n      // istanbul ignore next\n      case \"(\":\n      // istanbul ignore next\n      case \")\":\n      // istanbul ignore next\n      case \"[\":\n      // istanbul ignore next\n      case \"|\":\n        // istanbul ignore next\n        throw Error(\"TBD\");\n      default:\n        return { type: \"Character\", value: cc(nextChar) };\n    }\n  }\n  protected isRegExpFlag(): boolean {\n    switch (this.peekChar(0)) {\n      case \"g\":\n      case \"i\":\n      case \"m\":\n      case \"u\":\n      case \"y\":\n        return true;\n      default:\n        return false;\n    }\n  }\n\n  protected isRangeDash(): boolean {\n    return this.peekChar() === \"-\" && this.isClassAtom(1);\n  }\n\n  protected isDigit(): boolean {\n    return decimalPattern.test(this.peekChar(0));\n  }\n\n  protected isClassAtom(howMuch = 0): boolean {\n    switch (this.peekChar(howMuch)) {\n      case \"]\":\n      case \"\\n\":\n      case \"\\r\":\n      case \"\\u2028\":\n      case \"\\u2029\":\n        return false;\n      default:\n        return true;\n    }\n  }\n\n  protected isTerm() {\n    return this.isAtom() || this.isAssertion();\n  }\n\n  protected isAtom(): boolean {\n    if (this.isPatternCharacter()) {\n      return true;\n    }\n\n    switch (this.peekChar(0)) {\n      case \".\":\n      case \"\\\\\": // atomEscape\n      case \"[\": // characterClass\n      // TODO: isAtom must be called before isAssertion - disambiguate\n      case \"(\": // group\n        return true;\n      default:\n        return false;\n    }\n  }\n\n  protected isAssertion(): boolean {\n    switch (this.peekChar(0)) {\n      case \"^\":\n      case \"$\":\n        return true;\n      // '\\b' or '\\B'\n      case \"\\\\\":\n        switch (this.peekChar(1)) {\n          case \"b\":\n          case \"B\":\n            return true;\n          default:\n            return false;\n        }\n      // '(?=' or '(?!'\n      case \"(\":\n        return (\n          this.peekChar(1) === \"?\" &&\n          (this.peekChar(2) === \"=\" || this.peekChar(2) === \"!\")\n        );\n      default:\n        return false;\n    }\n  }\n\n  protected isQuantifier(): boolean {\n    const prevState = this.saveState();\n    try {\n      return this.quantifier(true) !== undefined;\n    } catch (e) {\n      return false;\n    } finally {\n      this.restoreState(prevState);\n    }\n  }\n\n  protected isPatternCharacter(): boolean {\n    switch (this.peekChar()) {\n      case \"^\":\n      case \"$\":\n      case \"\\\\\":\n      case \".\":\n      case \"*\":\n      case \"+\":\n      case \"?\":\n      case \"(\":\n      case \")\":\n      case \"[\":\n      case \"|\":\n      case \"/\":\n      case \"\\n\":\n      case \"\\r\":\n      case \"\\u2028\":\n      case \"\\u2029\":\n        return false;\n      default:\n        return true;\n    }\n  }\n\n  protected parseHexDigits(howMany: number): Omit<Character, \"loc\"> {\n    let hexString = \"\";\n    for (let i = 0; i < howMany; i++) {\n      const hexChar = this.popChar();\n      if (hexDigitPattern.test(hexChar) === false) {\n        throw Error(\"Expecting a HexDecimal digits\");\n      }\n      hexString += hexChar;\n    }\n    const charCode = parseInt(hexString, 16);\n    return { type: \"Character\", value: charCode };\n  }\n\n  protected peekChar(howMuch = 0): string {\n    return this.input[this.idx + howMuch];\n  }\n\n  protected popChar(): string {\n    const nextChar = this.peekChar(0);\n    this.consumeChar(undefined);\n    return nextChar;\n  }\n\n  protected consumeChar(char: string | undefined): void {\n    if (char !== undefined && this.input[this.idx] !== char) {\n      throw Error(\n        \"Expected: '\" +\n          char +\n          \"' but found: '\" +\n          this.input[this.idx] +\n          \"' at offset: \" +\n          this.idx,\n      );\n    }\n\n    if (this.idx >= this.input.length) {\n      throw Error(\"Unexpected end of input\");\n    }\n    this.idx++;\n  }\n\n  protected loc(begin: number): Location {\n    return { begin: begin, end: this.idx };\n  }\n}\n","import { hasTokenLabel, tokenLabel } from \"../scan/tokens_public.js\";\nimport { first, map, reduce } from \"lodash-es\";\nimport {\n  Alternation,\n  getProductionDslName,\n  NonTerminal,\n  Rule,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport {\n  IParserErrorMessageProvider,\n  IProductionWithOccurrence,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  IGrammarResolverErrorMessageProvider,\n  IGrammarValidatorErrorMessageProvider,\n} from \"./grammar/types.js\";\n\nexport const defaultParserErrorProvider: IParserErrorMessageProvider = {\n  buildMismatchTokenMessage({ expected, actual, previous, ruleName }): string {\n    const hasLabel = hasTokenLabel(expected);\n    const expectedMsg = hasLabel\n      ? `--> ${tokenLabel(expected)} <--`\n      : `token of type --> ${expected.name} <--`;\n\n    const msg = `Expecting ${expectedMsg} but found --> '${actual.image}' <--`;\n\n    return msg;\n  },\n\n  buildNotAllInputParsedMessage({ firstRedundant, ruleName }): string {\n    return \"Redundant input, expecting EOF but found: \" + firstRedundant.image;\n  },\n\n  buildNoViableAltMessage({\n    expectedPathsPerAlt,\n    actual,\n    previous,\n    customUserDescription,\n    ruleName,\n  }): string {\n    const errPrefix = \"Expecting: \";\n    // TODO: issue: No Viable Alternative Error may have incomplete details. #502\n    const actualText = first(actual)!.image;\n    const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n\n    if (customUserDescription) {\n      return errPrefix + customUserDescription + errSuffix;\n    } else {\n      const allLookAheadPaths = reduce(\n        expectedPathsPerAlt,\n        (result, currAltPaths) => result.concat(currAltPaths),\n        [] as TokenType[][],\n      );\n      const nextValidTokenSequences = map(\n        allLookAheadPaths,\n        (currPath) =>\n          `[${map(currPath, (currTokenType) => tokenLabel(currTokenType)).join(\n            \", \",\n          )}]`,\n      );\n      const nextValidSequenceItems = map(\n        nextValidTokenSequences,\n        (itemMsg, idx) => `  ${idx + 1}. ${itemMsg}`,\n      );\n      const calculatedDescription = `one of these possible Token sequences:\\n${nextValidSequenceItems.join(\n        \"\\n\",\n      )}`;\n\n      return errPrefix + calculatedDescription + errSuffix;\n    }\n  },\n\n  buildEarlyExitMessage({\n    expectedIterationPaths,\n    actual,\n    customUserDescription,\n    ruleName,\n  }): string {\n    const errPrefix = \"Expecting: \";\n    // TODO: issue: No Viable Alternative Error may have incomplete details. #502\n    const actualText = first(actual)!.image;\n    const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n\n    if (customUserDescription) {\n      return errPrefix + customUserDescription + errSuffix;\n    } else {\n      const nextValidTokenSequences = map(\n        expectedIterationPaths,\n        (currPath) =>\n          `[${map(currPath, (currTokenType) => tokenLabel(currTokenType)).join(\n            \",\",\n          )}]`,\n      );\n      const calculatedDescription =\n        `expecting at least one iteration which starts with one of these possible Token sequences::\\n  ` +\n        `<${nextValidTokenSequences.join(\" ,\")}>`;\n\n      return errPrefix + calculatedDescription + errSuffix;\n    }\n  },\n};\n\nObject.freeze(defaultParserErrorProvider);\n\nexport const defaultGrammarResolverErrorProvider: IGrammarResolverErrorMessageProvider =\n  {\n    buildRuleNotFoundError(\n      topLevelRule: Rule,\n      undefinedRule: NonTerminal,\n    ): string {\n      const msg =\n        \"Invalid grammar, reference to a rule which is not defined: ->\" +\n        undefinedRule.nonTerminalName +\n        \"<-\\n\" +\n        \"inside top level rule: ->\" +\n        topLevelRule.name +\n        \"<-\";\n      return msg;\n    },\n  };\n\nexport const defaultGrammarValidatorErrorProvider: IGrammarValidatorErrorMessageProvider =\n  {\n    buildDuplicateFoundError(\n      topLevelRule: Rule,\n      duplicateProds: IProductionWithOccurrence[],\n    ): string {\n      function getExtraProductionArgument(\n        prod: IProductionWithOccurrence,\n      ): string {\n        if (prod instanceof Terminal) {\n          return prod.terminalType.name;\n        } else if (prod instanceof NonTerminal) {\n          return prod.nonTerminalName;\n        } else {\n          return \"\";\n        }\n      }\n\n      const topLevelName = topLevelRule.name;\n      const duplicateProd = first(duplicateProds)!;\n      const index = duplicateProd.idx;\n      const dslName = getProductionDslName(duplicateProd);\n      const extraArgument = getExtraProductionArgument(duplicateProd);\n\n      const hasExplicitIndex = index > 0;\n      let msg = `->${dslName}${hasExplicitIndex ? index : \"\"}<- ${\n        extraArgument ? `with argument: ->${extraArgument}<-` : \"\"\n      }\n                  appears more than once (${\n                    duplicateProds.length\n                  } times) in the top level rule: ->${topLevelName}<-.                  \n                  For further details see: https://chevrotain.io/docs/FAQ.html#NUMERICAL_SUFFIXES \n                  `;\n\n      // white space trimming time! better to trim afterwards as it allows to use WELL formatted multi line template strings...\n      msg = msg.replace(/[ \\t]+/g, \" \");\n      msg = msg.replace(/\\s\\s+/g, \"\\n\");\n\n      return msg;\n    },\n\n    buildNamespaceConflictError(rule: Rule): string {\n      const errMsg =\n        `Namespace conflict found in grammar.\\n` +\n        `The grammar has both a Terminal(Token) and a Non-Terminal(Rule) named: <${rule.name}>.\\n` +\n        `To resolve this make sure each Terminal and Non-Terminal names are unique\\n` +\n        `This is easy to accomplish by using the convention that Terminal names start with an uppercase letter\\n` +\n        `and Non-Terminal names start with a lower case letter.`;\n\n      return errMsg;\n    },\n\n    buildAlternationPrefixAmbiguityError(options: {\n      topLevelRule: Rule;\n      prefixPath: TokenType[];\n      ambiguityIndices: number[];\n      alternation: Alternation;\n    }): string {\n      const pathMsg = map(options.prefixPath, (currTok) =>\n        tokenLabel(currTok),\n      ).join(\", \");\n      const occurrence =\n        options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n      const errMsg =\n        `Ambiguous alternatives: <${options.ambiguityIndices.join(\n          \" ,\",\n        )}> due to common lookahead prefix\\n` +\n        `in <OR${occurrence}> inside <${options.topLevelRule.name}> Rule,\\n` +\n        `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n` +\n        `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#COMMON_PREFIX\\n` +\n        `For Further details.`;\n\n      return errMsg;\n    },\n\n    buildAlternationAmbiguityError(options: {\n      topLevelRule: Rule;\n      prefixPath: TokenType[];\n      ambiguityIndices: number[];\n      alternation: Alternation;\n    }): string {\n      const pathMsg = map(options.prefixPath, (currtok) =>\n        tokenLabel(currtok),\n      ).join(\", \");\n      const occurrence =\n        options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n      let currMessage =\n        `Ambiguous Alternatives Detected: <${options.ambiguityIndices.join(\n          \" ,\",\n        )}> in <OR${occurrence}>` +\n        ` inside <${options.topLevelRule.name}> Rule,\\n` +\n        `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n`;\n\n      currMessage =\n        currMessage +\n        `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#AMBIGUOUS_ALTERNATIVES\\n` +\n        `For Further details.`;\n      return currMessage;\n    },\n\n    buildEmptyRepetitionError(options: {\n      topLevelRule: Rule;\n      repetition: IProductionWithOccurrence;\n    }): string {\n      let dslName = getProductionDslName(options.repetition);\n      if (options.repetition.idx !== 0) {\n        dslName += options.repetition.idx;\n      }\n\n      const errMsg =\n        `The repetition <${dslName}> within Rule <${options.topLevelRule.name}> can never consume any tokens.\\n` +\n        `This could lead to an infinite loop.`;\n\n      return errMsg;\n    },\n\n    // TODO: remove - `errors_public` from nyc.config.js exclude\n    //       once this method is fully removed from this file\n    buildTokenNameError(options: {\n      tokenType: TokenType;\n      expectedPattern: RegExp;\n    }): string {\n      /* istanbul ignore next */\n      return \"deprecated\";\n    },\n\n    buildEmptyAlternationError(options: {\n      topLevelRule: Rule;\n      alternation: Alternation;\n      emptyChoiceIdx: number;\n    }): string {\n      const errMsg =\n        `Ambiguous empty alternative: <${options.emptyChoiceIdx + 1}>` +\n        ` in <OR${options.alternation.idx}> inside <${options.topLevelRule.name}> Rule.\\n` +\n        `Only the last alternative may be an empty alternative.`;\n\n      return errMsg;\n    },\n\n    buildTooManyAlternativesError(options: {\n      topLevelRule: Rule;\n      alternation: Alternation;\n    }): string {\n      const errMsg =\n        `An Alternation cannot have more than 256 alternatives:\\n` +\n        `<OR${options.alternation.idx}> inside <${\n          options.topLevelRule.name\n        }> Rule.\\n has ${\n          options.alternation.definition.length + 1\n        } alternatives.`;\n\n      return errMsg;\n    },\n\n    buildLeftRecursionError(options: {\n      topLevelRule: Rule;\n      leftRecursionPath: Rule[];\n    }): string {\n      const ruleName = options.topLevelRule.name;\n      const pathNames = map(\n        options.leftRecursionPath,\n        (currRule) => currRule.name,\n      );\n      const leftRecursivePath = `${ruleName} --> ${pathNames\n        .concat([ruleName])\n        .join(\" --> \")}`;\n      const errMsg =\n        `Left Recursion found in grammar.\\n` +\n        `rule: <${ruleName}> can be invoked from itself (directly or indirectly)\\n` +\n        `without consuming any Tokens. The grammar path that causes this is: \\n ${leftRecursivePath}\\n` +\n        ` To fix this refactor your grammar to remove the left recursion.\\n` +\n        `see: https://en.wikipedia.org/wiki/LL_parser#Left_factoring.`;\n\n      return errMsg;\n    },\n\n    // TODO: remove - `errors_public` from nyc.config.js exclude\n    //       once this method is fully removed from this file\n    buildInvalidRuleNameError(options: {\n      topLevelRule: Rule;\n      expectedPattern: RegExp;\n    }): string {\n      /* istanbul ignore next */\n      return \"deprecated\";\n    },\n\n    buildDuplicateRuleNameError(options: {\n      topLevelRule: Rule | string;\n      grammarName: string;\n    }): string {\n      let ruleName;\n      if (options.topLevelRule instanceof Rule) {\n        ruleName = options.topLevelRule.name;\n      } else {\n        ruleName = options.topLevelRule;\n      }\n\n      const errMsg = `Duplicate definition, rule: ->${ruleName}<- is already defined in the grammar: ->${options.grammarName}<-`;\n\n      return errMsg;\n    },\n  };\n","import {\n  IParserUnresolvedRefDefinitionError,\n  ParserDefinitionErrorType,\n} from \"../parser/parser.js\";\nimport { forEach, values } from \"lodash-es\";\nimport { GAstVisitor, NonTerminal, Rule } from \"@chevrotain/gast\";\nimport {\n  IGrammarResolverErrorMessageProvider,\n  IParserDefinitionError,\n} from \"./types.js\";\n\nexport function resolveGrammar(\n  topLevels: Record<string, Rule>,\n  errMsgProvider: IGrammarResolverErrorMessageProvider,\n): IParserDefinitionError[] {\n  const refResolver = new GastRefResolverVisitor(topLevels, errMsgProvider);\n  refResolver.resolveRefs();\n  return refResolver.errors;\n}\n\nexport class GastRefResolverVisitor extends GAstVisitor {\n  public errors: IParserUnresolvedRefDefinitionError[] = [];\n  private currTopLevel: Rule;\n\n  constructor(\n    private nameToTopRule: Record<string, Rule>,\n    private errMsgProvider: IGrammarResolverErrorMessageProvider,\n  ) {\n    super();\n  }\n\n  public resolveRefs(): void {\n    forEach(values(this.nameToTopRule), (prod) => {\n      this.currTopLevel = prod;\n      prod.accept(this);\n    });\n  }\n\n  public visitNonTerminal(node: NonTerminal): void {\n    const ref = this.nameToTopRule[node.nonTerminalName];\n\n    if (!ref) {\n      const msg = this.errMsgProvider.buildRuleNotFoundError(\n        this.currTopLevel,\n        node,\n      );\n      this.errors.push({\n        message: msg,\n        type: ParserDefinitionErrorType.UNRESOLVED_SUBRULE_REF,\n        ruleName: this.currTopLevel.name,\n        unresolvedRefName: node.nonTerminalName,\n      });\n    } else {\n      node.referencedRule = ref;\n    }\n  }\n}\n","import {\n  clone,\n  drop,\n  dropRight,\n  first as _first,\n  forEach,\n  isEmpty,\n  last,\n} from \"lodash-es\";\nimport { first } from \"./first.js\";\nimport { RestWalker } from \"./rest.js\";\nimport { TokenMatcher } from \"../parser/parser.js\";\nimport {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport {\n  IGrammarPath,\n  IProduction,\n  ISyntacticContentAssistPath,\n  IToken,\n  ITokenGrammarPath,\n  TokenType,\n} from \"@chevrotain/types\";\n\nexport abstract class AbstractNextPossibleTokensWalker extends RestWalker {\n  protected possibleTokTypes: TokenType[] = [];\n  protected ruleStack: string[];\n  protected occurrenceStack: number[];\n\n  protected nextProductionName = \"\";\n  protected nextProductionOccurrence = 0;\n  protected found = false;\n  protected isAtEndOfPath = false;\n\n  constructor(\n    protected topProd: Rule,\n    protected path: IGrammarPath,\n  ) {\n    super();\n  }\n\n  startWalking(): TokenType[] {\n    this.found = false;\n\n    if (this.path.ruleStack[0] !== this.topProd.name) {\n      throw Error(\"The path does not start with the walker's top Rule!\");\n    }\n\n    // immutable for the win\n    this.ruleStack = clone(this.path.ruleStack).reverse(); // intelij bug requires assertion\n    this.occurrenceStack = clone(this.path.occurrenceStack).reverse(); // intelij bug requires assertion\n\n    // already verified that the first production is valid, we now seek the 2nd production\n    this.ruleStack.pop();\n    this.occurrenceStack.pop();\n\n    this.updateExpectedNext();\n    this.walk(this.topProd);\n\n    return this.possibleTokTypes;\n  }\n\n  walk(\n    prod: { definition: IProduction[] },\n    prevRest: IProduction[] = [],\n  ): void {\n    // stop scanning once we found the path\n    if (!this.found) {\n      super.walk(prod, prevRest);\n    }\n  }\n\n  walkProdRef(\n    refProd: NonTerminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // found the next production, need to keep walking in it\n    if (\n      refProd.referencedRule.name === this.nextProductionName &&\n      refProd.idx === this.nextProductionOccurrence\n    ) {\n      const fullRest = currRest.concat(prevRest);\n      this.updateExpectedNext();\n      this.walk(refProd.referencedRule, <any>fullRest);\n    }\n  }\n\n  updateExpectedNext(): void {\n    // need to consume the Terminal\n    if (isEmpty(this.ruleStack)) {\n      // must reset nextProductionXXX to avoid walking down another Top Level production while what we are\n      // really seeking is the last Terminal...\n      this.nextProductionName = \"\";\n      this.nextProductionOccurrence = 0;\n      this.isAtEndOfPath = true;\n    } else {\n      this.nextProductionName = this.ruleStack.pop()!;\n      this.nextProductionOccurrence = this.occurrenceStack.pop()!;\n    }\n  }\n}\n\nexport class NextAfterTokenWalker extends AbstractNextPossibleTokensWalker {\n  private nextTerminalName = \"\";\n  private nextTerminalOccurrence = 0;\n\n  constructor(\n    topProd: Rule,\n    protected path: ITokenGrammarPath,\n  ) {\n    super(topProd, path);\n    this.nextTerminalName = this.path.lastTok.name;\n    this.nextTerminalOccurrence = this.path.lastTokOccurrence;\n  }\n\n  walkTerminal(\n    terminal: Terminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      this.isAtEndOfPath &&\n      terminal.terminalType.name === this.nextTerminalName &&\n      terminal.idx === this.nextTerminalOccurrence &&\n      !this.found\n    ) {\n      const fullRest = currRest.concat(prevRest);\n      const restProd = new Alternative({ definition: fullRest });\n      this.possibleTokTypes = first(restProd);\n      this.found = true;\n    }\n  }\n}\n\nexport type AlternativesFirstTokens = TokenType[][];\n\nexport interface IFirstAfterRepetition {\n  token: TokenType | undefined;\n  occurrence: number | undefined;\n  isEndOfRule: boolean | undefined;\n}\n\n/**\n * This walker only \"walks\" a single \"TOP\" level in the Grammar Ast, this means\n * it never \"follows\" production refs\n */\nexport class AbstractNextTerminalAfterProductionWalker extends RestWalker {\n  protected result: IFirstAfterRepetition = {\n    token: undefined,\n    occurrence: undefined,\n    isEndOfRule: undefined,\n  };\n\n  constructor(\n    protected topRule: Rule,\n    protected occurrence: number,\n  ) {\n    super();\n  }\n\n  startWalking(): IFirstAfterRepetition {\n    this.walk(this.topRule);\n    return this.result;\n  }\n}\n\nexport class NextTerminalAfterManyWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkMany(\n    manyProd: Repetition,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (manyProd.idx === this.occurrence) {\n      const firstAfterMany = _first(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterMany === undefined;\n      if (firstAfterMany instanceof Terminal) {\n        this.result.token = firstAfterMany.terminalType;\n        this.result.occurrence = firstAfterMany.idx;\n      }\n    } else {\n      super.walkMany(manyProd, currRest, prevRest);\n    }\n  }\n}\n\nexport class NextTerminalAfterManySepWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkManySep(\n    manySepProd: RepetitionWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (manySepProd.idx === this.occurrence) {\n      const firstAfterManySep = _first(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterManySep === undefined;\n      if (firstAfterManySep instanceof Terminal) {\n        this.result.token = firstAfterManySep.terminalType;\n        this.result.occurrence = firstAfterManySep.idx;\n      }\n    } else {\n      super.walkManySep(manySepProd, currRest, prevRest);\n    }\n  }\n}\n\nexport class NextTerminalAfterAtLeastOneWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkAtLeastOne(\n    atLeastOneProd: RepetitionMandatory,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (atLeastOneProd.idx === this.occurrence) {\n      const firstAfterAtLeastOne = _first(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterAtLeastOne === undefined;\n      if (firstAfterAtLeastOne instanceof Terminal) {\n        this.result.token = firstAfterAtLeastOne.terminalType;\n        this.result.occurrence = firstAfterAtLeastOne.idx;\n      }\n    } else {\n      super.walkAtLeastOne(atLeastOneProd, currRest, prevRest);\n    }\n  }\n}\n\n// TODO: reduce code duplication in the AfterWalkers\nexport class NextTerminalAfterAtLeastOneSepWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkAtLeastOneSep(\n    atleastOneSepProd: RepetitionMandatoryWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (atleastOneSepProd.idx === this.occurrence) {\n      const firstAfterfirstAfterAtLeastOneSep = _first(\n        currRest.concat(prevRest),\n      );\n      this.result.isEndOfRule = firstAfterfirstAfterAtLeastOneSep === undefined;\n      if (firstAfterfirstAfterAtLeastOneSep instanceof Terminal) {\n        this.result.token = firstAfterfirstAfterAtLeastOneSep.terminalType;\n        this.result.occurrence = firstAfterfirstAfterAtLeastOneSep.idx;\n      }\n    } else {\n      super.walkAtLeastOneSep(atleastOneSepProd, currRest, prevRest);\n    }\n  }\n}\n\nexport interface PartialPathAndSuffixes {\n  partialPath: TokenType[];\n  suffixDef: IProduction[];\n}\n\nexport function possiblePathsFrom(\n  targetDef: IProduction[],\n  maxLength: number,\n  currPath: TokenType[] = [],\n): PartialPathAndSuffixes[] {\n  // avoid side effects\n  currPath = clone(currPath);\n  let result: PartialPathAndSuffixes[] = [];\n  let i = 0;\n\n  // TODO: avoid inner funcs\n  function remainingPathWith(nextDef: IProduction[]) {\n    return nextDef.concat(drop(targetDef, i + 1));\n  }\n\n  // TODO: avoid inner funcs\n  function getAlternativesForProd(definition: IProduction[]) {\n    const alternatives = possiblePathsFrom(\n      remainingPathWith(definition),\n      maxLength,\n      currPath,\n    );\n    return result.concat(alternatives);\n  }\n\n  /**\n   * Mandatory productions will halt the loop as the paths computed from their recursive calls will already contain the\n   * following (rest) of the targetDef.\n   *\n   * For optional productions (Option/Repetition/...) the loop will continue to represent the paths that do not include the\n   * the optional production.\n   */\n  while (currPath.length < maxLength && i < targetDef.length) {\n    const prod = targetDef[i];\n\n    /* istanbul ignore else */\n    if (prod instanceof Alternative) {\n      return getAlternativesForProd(prod.definition);\n    } else if (prod instanceof NonTerminal) {\n      return getAlternativesForProd(prod.definition);\n    } else if (prod instanceof Option) {\n      result = getAlternativesForProd(prod.definition);\n    } else if (prod instanceof RepetitionMandatory) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: prod.definition,\n        }),\n      ]);\n      return getAlternativesForProd(newDef);\n    } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n      const newDef = [\n        new Alternative({ definition: prod.definition }),\n        new Repetition({\n          definition: [new Terminal({ terminalType: prod.separator })].concat(\n            <any>prod.definition,\n          ),\n        }),\n      ];\n      return getAlternativesForProd(newDef);\n    } else if (prod instanceof RepetitionWithSeparator) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: [new Terminal({ terminalType: prod.separator })].concat(\n            <any>prod.definition,\n          ),\n        }),\n      ]);\n      result = getAlternativesForProd(newDef);\n    } else if (prod instanceof Repetition) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: prod.definition,\n        }),\n      ]);\n      result = getAlternativesForProd(newDef);\n    } else if (prod instanceof Alternation) {\n      forEach(prod.definition, (currAlt) => {\n        // TODO: this is a limited check for empty alternatives\n        //   It would prevent a common case of infinite loops during parser initialization.\n        //   However **in-directly** empty alternatives may still cause issues.\n        if (isEmpty(currAlt.definition) === false) {\n          result = getAlternativesForProd(currAlt.definition);\n        }\n      });\n      return result;\n    } else if (prod instanceof Terminal) {\n      currPath.push(prod.terminalType);\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n\n    i++;\n  }\n  result.push({\n    partialPath: currPath,\n    suffixDef: drop(targetDef, i),\n  });\n\n  return result;\n}\n\ninterface IPathToExamine {\n  idx: number;\n  def: IProduction[];\n  ruleStack: string[];\n  occurrenceStack: number[];\n}\n\nexport function nextPossibleTokensAfter(\n  initialDef: IProduction[],\n  tokenVector: IToken[],\n  tokMatcher: TokenMatcher,\n  maxLookAhead: number,\n): ISyntacticContentAssistPath[] {\n  const EXIT_NON_TERMINAL: any = \"EXIT_NONE_TERMINAL\";\n  // to avoid creating a new Array each time.\n  const EXIT_NON_TERMINAL_ARR = [EXIT_NON_TERMINAL];\n  const EXIT_ALTERNATIVE: any = \"EXIT_ALTERNATIVE\";\n  let foundCompletePath = false;\n\n  const tokenVectorLength = tokenVector.length;\n  const minimalAlternativesIndex = tokenVectorLength - maxLookAhead - 1;\n\n  const result: ISyntacticContentAssistPath[] = [];\n\n  const possiblePaths: IPathToExamine[] = [];\n  possiblePaths.push({\n    idx: -1,\n    def: initialDef,\n    ruleStack: [],\n    occurrenceStack: [],\n  });\n\n  while (!isEmpty(possiblePaths)) {\n    const currPath = possiblePaths.pop()!;\n\n    // skip alternatives if no more results can be found (assuming deterministic grammar with fixed lookahead)\n    if (currPath === EXIT_ALTERNATIVE) {\n      if (\n        foundCompletePath &&\n        last(possiblePaths)!.idx <= minimalAlternativesIndex\n      ) {\n        // remove irrelevant alternative\n        possiblePaths.pop();\n      }\n      continue;\n    }\n\n    const currDef = currPath.def;\n    const currIdx = currPath.idx;\n    const currRuleStack = currPath.ruleStack;\n    const currOccurrenceStack = currPath.occurrenceStack;\n\n    // For Example: an empty path could exist in a valid grammar in the case of an EMPTY_ALT\n    if (isEmpty(currDef)) {\n      continue;\n    }\n\n    const prod = currDef[0];\n    /* istanbul ignore else */\n    if (prod === EXIT_NON_TERMINAL) {\n      const nextPath = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: dropRight(currRuleStack),\n        occurrenceStack: dropRight(currOccurrenceStack),\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof Terminal) {\n      /* istanbul ignore else */\n      if (currIdx < tokenVectorLength - 1) {\n        const nextIdx = currIdx + 1;\n        const actualToken = tokenVector[nextIdx];\n        if (tokMatcher!(actualToken, prod.terminalType)) {\n          const nextPath = {\n            idx: nextIdx,\n            def: drop(currDef),\n            ruleStack: currRuleStack,\n            occurrenceStack: currOccurrenceStack,\n          };\n          possiblePaths.push(nextPath);\n        }\n        // end of the line\n      } else if (currIdx === tokenVectorLength - 1) {\n        // IGNORE ABOVE ELSE\n        result.push({\n          nextTokenType: prod.terminalType,\n          nextTokenOccurrence: prod.idx,\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack,\n        });\n        foundCompletePath = true;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    } else if (prod instanceof NonTerminal) {\n      const newRuleStack = clone(currRuleStack);\n      newRuleStack.push(prod.nonTerminalName);\n\n      const newOccurrenceStack = clone(currOccurrenceStack);\n      newOccurrenceStack.push(prod.idx);\n\n      const nextPath = {\n        idx: currIdx,\n        def: prod.definition.concat(EXIT_NON_TERMINAL_ARR, drop(currDef)),\n        ruleStack: newRuleStack,\n        occurrenceStack: newOccurrenceStack,\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof Option) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWithout);\n      // required marker to avoid backtracking paths whose higher priority alternatives already matched\n      possiblePaths.push(EXIT_ALTERNATIVE);\n\n      const nextPathWith = {\n        idx: currIdx,\n        def: prod.definition.concat(drop(currDef)),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof RepetitionMandatory) {\n      // TODO:(THE NEW operators here take a while...) (convert once?)\n      const secondIteration = new Repetition({\n        definition: prod.definition,\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([secondIteration], drop(currDef));\n      const nextPath = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n      // TODO:(THE NEW operators here take a while...) (convert once?)\n      const separatorGast = new Terminal({\n        terminalType: prod.separator,\n      });\n      const secondIteration = new Repetition({\n        definition: [<any>separatorGast].concat(prod.definition),\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([secondIteration], drop(currDef));\n      const nextPath = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof RepetitionWithSeparator) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWithout);\n      // required marker to avoid backtracking paths whose higher priority alternatives already matched\n      possiblePaths.push(EXIT_ALTERNATIVE);\n\n      const separatorGast = new Terminal({\n        terminalType: prod.separator,\n      });\n      const nthRepetition = new Repetition({\n        definition: [<any>separatorGast].concat(prod.definition),\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([nthRepetition], drop(currDef));\n      const nextPathWith = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof Repetition) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWithout);\n      // required marker to avoid backtracking paths whose higher priority alternatives already matched\n      possiblePaths.push(EXIT_ALTERNATIVE);\n\n      // TODO: an empty repetition will cause infinite loops here, will the parser detect this in selfAnalysis?\n      const nthRepetition = new Repetition({\n        definition: prod.definition,\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([nthRepetition], drop(currDef));\n      const nextPathWith = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof Alternation) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      for (let i = prod.definition.length - 1; i >= 0; i--) {\n        const currAlt: any = prod.definition[i];\n        const currAltPath = {\n          idx: currIdx,\n          def: currAlt.definition.concat(drop(currDef)),\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack,\n        };\n        possiblePaths.push(currAltPath);\n        possiblePaths.push(EXIT_ALTERNATIVE);\n      }\n    } else if (prod instanceof Alternative) {\n      possiblePaths.push({\n        idx: currIdx,\n        def: prod.definition.concat(drop(currDef)),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      });\n    } else if (prod instanceof Rule) {\n      // last because we should only encounter at most a single one of these per invocation.\n      possiblePaths.push(\n        expandTopLevelRule(prod, currIdx, currRuleStack, currOccurrenceStack),\n      );\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n  return result;\n}\n\nfunction expandTopLevelRule(\n  topRule: Rule,\n  currIdx: number,\n  currRuleStack: string[],\n  currOccurrenceStack: number[],\n): IPathToExamine {\n  const newRuleStack = clone(currRuleStack);\n  newRuleStack.push(topRule.name);\n\n  const newCurrOccurrenceStack = clone(currOccurrenceStack);\n  // top rule is always assumed to have been called with occurrence index 1\n  newCurrOccurrenceStack.push(1);\n\n  return {\n    idx: currIdx,\n    def: topRule.definition,\n    ruleStack: newRuleStack,\n    occurrenceStack: newCurrOccurrenceStack,\n  };\n}\n","import { every, flatten, forEach, has, isEmpty, map, reduce } from \"lodash-es\";\nimport { possiblePathsFrom } from \"./interpreter.js\";\nimport { RestWalker } from \"./rest.js\";\nimport { Predicate, TokenMatcher } from \"../parser/parser.js\";\nimport {\n  tokenStructuredMatcher,\n  tokenStructuredMatcherNoCategories,\n} from \"../../scan/tokens.js\";\nimport {\n  Alternation,\n  Alternative as AlternativeGAST,\n  GAstVisitor,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n} from \"@chevrotain/gast\";\nimport {\n  BaseParser,\n  IOrAlt,\n  IProduction,\n  IProductionWithOccurrence,\n  LookaheadProductionType,\n  LookaheadSequence,\n  Rule,\n  TokenType,\n} from \"@chevrotain/types\";\n\nexport enum PROD_TYPE {\n  OPTION,\n  REPETITION,\n  REPETITION_MANDATORY,\n  REPETITION_MANDATORY_WITH_SEPARATOR,\n  REPETITION_WITH_SEPARATOR,\n  ALTERNATION,\n}\n\nexport function getProdType(\n  prod: IProduction | LookaheadProductionType,\n): PROD_TYPE {\n  /* istanbul ignore else */\n  if (prod instanceof Option || prod === \"Option\") {\n    return PROD_TYPE.OPTION;\n  } else if (prod instanceof Repetition || prod === \"Repetition\") {\n    return PROD_TYPE.REPETITION;\n  } else if (\n    prod instanceof RepetitionMandatory ||\n    prod === \"RepetitionMandatory\"\n  ) {\n    return PROD_TYPE.REPETITION_MANDATORY;\n  } else if (\n    prod instanceof RepetitionMandatoryWithSeparator ||\n    prod === \"RepetitionMandatoryWithSeparator\"\n  ) {\n    return PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR;\n  } else if (\n    prod instanceof RepetitionWithSeparator ||\n    prod === \"RepetitionWithSeparator\"\n  ) {\n    return PROD_TYPE.REPETITION_WITH_SEPARATOR;\n  } else if (prod instanceof Alternation || prod === \"Alternation\") {\n    return PROD_TYPE.ALTERNATION;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexport function getLookaheadPaths(options: {\n  occurrence: number;\n  rule: Rule;\n  prodType: LookaheadProductionType;\n  maxLookahead: number;\n}): LookaheadSequence[] {\n  const { occurrence, rule, prodType, maxLookahead } = options;\n  const type = getProdType(prodType);\n  if (type === PROD_TYPE.ALTERNATION) {\n    return getLookaheadPathsForOr(occurrence, rule, maxLookahead);\n  } else {\n    return getLookaheadPathsForOptionalProd(\n      occurrence,\n      rule,\n      type,\n      maxLookahead,\n    );\n  }\n}\n\nexport function buildLookaheadFuncForOr(\n  occurrence: number,\n  ruleGrammar: Rule,\n  maxLookahead: number,\n  hasPredicates: boolean,\n  dynamicTokensEnabled: boolean,\n  laFuncBuilder: Function,\n): (orAlts?: IOrAlt<any>[]) => number | undefined {\n  const lookAheadPaths = getLookaheadPathsForOr(\n    occurrence,\n    ruleGrammar,\n    maxLookahead,\n  );\n\n  const tokenMatcher = areTokenCategoriesNotUsed(lookAheadPaths)\n    ? tokenStructuredMatcherNoCategories\n    : tokenStructuredMatcher;\n\n  return laFuncBuilder(\n    lookAheadPaths,\n    hasPredicates,\n    tokenMatcher,\n    dynamicTokensEnabled,\n  );\n}\n\n/**\n *  When dealing with an Optional production (OPTION/MANY/2nd iteration of AT_LEAST_ONE/...) we need to compare\n *  the lookahead \"inside\" the production and the lookahead immediately \"after\" it in the same top level rule (context free).\n *\n *  Example: given a production:\n *  ABC(DE)?DF\n *\n *  The optional '(DE)?' should only be entered if we see 'DE'. a single Token 'D' is not sufficient to distinguish between the two\n *  alternatives.\n *\n *  @returns A Lookahead function which will return true IFF the parser should parse the Optional production.\n */\nexport function buildLookaheadFuncForOptionalProd(\n  occurrence: number,\n  ruleGrammar: Rule,\n  k: number,\n  dynamicTokensEnabled: boolean,\n  prodType: PROD_TYPE,\n  lookaheadBuilder: (\n    lookAheadSequence: LookaheadSequence,\n    tokenMatcher: TokenMatcher,\n    dynamicTokensEnabled: boolean,\n  ) => () => boolean,\n): () => boolean {\n  const lookAheadPaths = getLookaheadPathsForOptionalProd(\n    occurrence,\n    ruleGrammar,\n    prodType,\n    k,\n  );\n\n  const tokenMatcher = areTokenCategoriesNotUsed(lookAheadPaths)\n    ? tokenStructuredMatcherNoCategories\n    : tokenStructuredMatcher;\n\n  return lookaheadBuilder(\n    lookAheadPaths[0],\n    tokenMatcher,\n    dynamicTokensEnabled,\n  );\n}\n\nexport type Alternative = TokenType[][];\n\nexport function buildAlternativesLookAheadFunc(\n  alts: LookaheadSequence[],\n  hasPredicates: boolean,\n  tokenMatcher: TokenMatcher,\n  dynamicTokensEnabled: boolean,\n): (orAlts: IOrAlt<any>[]) => number | undefined {\n  const numOfAlts = alts.length;\n  const areAllOneTokenLookahead = every(alts, (currAlt) => {\n    return every(currAlt, (currPath) => {\n      return currPath.length === 1;\n    });\n  });\n\n  // This version takes into account the predicates as well.\n  if (hasPredicates) {\n    /**\n     * @returns {number} - The chosen alternative index\n     */\n    return function (\n      this: BaseParser,\n      orAlts: IOrAlt<any>[],\n    ): number | undefined {\n      // unfortunately the predicates must be extracted every single time\n      // as they cannot be cached due to references to parameters(vars) which are no longer valid.\n      // note that in the common case of no predicates, no cpu time will be wasted on this (see else block)\n      const predicates: (Predicate | undefined)[] = map(\n        orAlts,\n        (currAlt) => currAlt.GATE,\n      );\n\n      for (let t = 0; t < numOfAlts; t++) {\n        const currAlt = alts[t];\n        const currNumOfPaths = currAlt.length;\n\n        const currPredicate = predicates[t];\n        if (currPredicate !== undefined && currPredicate.call(this) === false) {\n          // if the predicate does not match there is no point in checking the paths\n          continue;\n        }\n        nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n          const currPath = currAlt[j];\n          const currPathLength = currPath.length;\n          for (let i = 0; i < currPathLength; i++) {\n            const nextToken = this.LA(i + 1);\n            if (tokenMatcher(nextToken, currPath[i]) === false) {\n              // mismatch in current path\n              // try the next pth\n              continue nextPath;\n            }\n          }\n          // found a full path that matches.\n          // this will also work for an empty ALT as the loop will be skipped\n          return t;\n        }\n        // none of the paths for the current alternative matched\n        // try the next alternative\n      }\n      // none of the alternatives could be matched\n      return undefined;\n    };\n  } else if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n    // optimized (common) case of all the lookaheads paths requiring only\n    // a single token lookahead. These Optimizations cannot work if dynamically defined Tokens are used.\n    const singleTokenAlts = map(alts, (currAlt) => {\n      return flatten(currAlt);\n    });\n\n    const choiceToAlt = reduce(\n      singleTokenAlts,\n      (result, currAlt, idx) => {\n        forEach(currAlt, (currTokType) => {\n          if (!has(result, currTokType.tokenTypeIdx!)) {\n            result[currTokType.tokenTypeIdx!] = idx;\n          }\n          forEach(currTokType.categoryMatches!, (currExtendingType) => {\n            if (!has(result, currExtendingType)) {\n              result[currExtendingType] = idx;\n            }\n          });\n        });\n        return result;\n      },\n      {} as Record<number, number>,\n    );\n\n    /**\n     * @returns {number} - The chosen alternative index\n     */\n    return function (this: BaseParser): number {\n      const nextToken = this.LA(1);\n      return choiceToAlt[nextToken.tokenTypeIdx];\n    };\n  } else {\n    // optimized lookahead without needing to check the predicates at all.\n    // this causes code duplication which is intentional to improve performance.\n    /**\n     * @returns {number} - The chosen alternative index\n     */\n    return function (this: BaseParser): number | undefined {\n      for (let t = 0; t < numOfAlts; t++) {\n        const currAlt = alts[t];\n        const currNumOfPaths = currAlt.length;\n        nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n          const currPath = currAlt[j];\n          const currPathLength = currPath.length;\n          for (let i = 0; i < currPathLength; i++) {\n            const nextToken = this.LA(i + 1);\n            if (tokenMatcher(nextToken, currPath[i]) === false) {\n              // mismatch in current path\n              // try the next pth\n              continue nextPath;\n            }\n          }\n          // found a full path that matches.\n          // this will also work for an empty ALT as the loop will be skipped\n          return t;\n        }\n        // none of the paths for the current alternative matched\n        // try the next alternative\n      }\n      // none of the alternatives could be matched\n      return undefined;\n    };\n  }\n}\n\nexport function buildSingleAlternativeLookaheadFunction(\n  alt: LookaheadSequence,\n  tokenMatcher: TokenMatcher,\n  dynamicTokensEnabled: boolean,\n): () => boolean {\n  const areAllOneTokenLookahead = every(alt, (currPath) => {\n    return currPath.length === 1;\n  });\n\n  const numOfPaths = alt.length;\n\n  // optimized (common) case of all the lookaheads paths requiring only\n  // a single token lookahead.\n  if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n    const singleTokensTypes = flatten(alt);\n\n    if (\n      singleTokensTypes.length === 1 &&\n      isEmpty((<any>singleTokensTypes[0]).categoryMatches)\n    ) {\n      const expectedTokenType = singleTokensTypes[0];\n      const expectedTokenUniqueKey = (<any>expectedTokenType).tokenTypeIdx;\n\n      return function (this: BaseParser): boolean {\n        return this.LA(1).tokenTypeIdx === expectedTokenUniqueKey;\n      };\n    } else {\n      const choiceToAlt = reduce(\n        singleTokensTypes,\n        (result, currTokType, idx) => {\n          result[currTokType.tokenTypeIdx!] = true;\n          forEach(currTokType.categoryMatches!, (currExtendingType) => {\n            result[currExtendingType] = true;\n          });\n          return result;\n        },\n        [] as boolean[],\n      );\n\n      return function (this: BaseParser): boolean {\n        const nextToken = this.LA(1);\n        return choiceToAlt[nextToken.tokenTypeIdx] === true;\n      };\n    }\n  } else {\n    return function (this: BaseParser): boolean {\n      nextPath: for (let j = 0; j < numOfPaths; j++) {\n        const currPath = alt[j];\n        const currPathLength = currPath.length;\n        for (let i = 0; i < currPathLength; i++) {\n          const nextToken = this.LA(i + 1);\n          if (tokenMatcher(nextToken, currPath[i]) === false) {\n            // mismatch in current path\n            // try the next pth\n            continue nextPath;\n          }\n        }\n        // found a full path that matches.\n        return true;\n      }\n\n      // none of the paths matched\n      return false;\n    };\n  }\n}\n\nclass RestDefinitionFinderWalker extends RestWalker {\n  private restDef: IProduction[];\n\n  constructor(\n    private topProd: Rule,\n    private targetOccurrence: number,\n    private targetProdType: PROD_TYPE,\n  ) {\n    super();\n  }\n\n  startWalking(): IProduction[] {\n    this.walk(this.topProd);\n    return this.restDef;\n  }\n\n  private checkIsTarget(\n    node: IProductionWithOccurrence,\n    expectedProdType: PROD_TYPE,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): boolean {\n    if (\n      node.idx === this.targetOccurrence &&\n      this.targetProdType === expectedProdType\n    ) {\n      this.restDef = currRest.concat(prevRest);\n      return true;\n    }\n    // performance optimization, do not iterate over the entire Grammar ast after we have found the target\n    return false;\n  }\n\n  walkOption(\n    optionProd: Option,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (!this.checkIsTarget(optionProd, PROD_TYPE.OPTION, currRest, prevRest)) {\n      super.walkOption(optionProd, currRest, prevRest);\n    }\n  }\n\n  walkAtLeastOne(\n    atLeastOneProd: RepetitionMandatory,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(\n        atLeastOneProd,\n        PROD_TYPE.REPETITION_MANDATORY,\n        currRest,\n        prevRest,\n      )\n    ) {\n      super.walkOption(atLeastOneProd, currRest, prevRest);\n    }\n  }\n\n  walkAtLeastOneSep(\n    atLeastOneSepProd: RepetitionMandatoryWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(\n        atLeastOneSepProd,\n        PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR,\n        currRest,\n        prevRest,\n      )\n    ) {\n      super.walkOption(atLeastOneSepProd, currRest, prevRest);\n    }\n  }\n\n  walkMany(\n    manyProd: Repetition,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(manyProd, PROD_TYPE.REPETITION, currRest, prevRest)\n    ) {\n      super.walkOption(manyProd, currRest, prevRest);\n    }\n  }\n\n  walkManySep(\n    manySepProd: RepetitionWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(\n        manySepProd,\n        PROD_TYPE.REPETITION_WITH_SEPARATOR,\n        currRest,\n        prevRest,\n      )\n    ) {\n      super.walkOption(manySepProd, currRest, prevRest);\n    }\n  }\n}\n\n/**\n * Returns the definition of a target production in a top level level rule.\n */\nclass InsideDefinitionFinderVisitor extends GAstVisitor {\n  public result: IProduction[] = [];\n\n  constructor(\n    private targetOccurrence: number,\n    private targetProdType: PROD_TYPE,\n    private targetRef?: any,\n  ) {\n    super();\n  }\n\n  private checkIsTarget(\n    node: { definition: IProduction[] } & IProductionWithOccurrence,\n    expectedProdName: PROD_TYPE,\n  ): void {\n    if (\n      node.idx === this.targetOccurrence &&\n      this.targetProdType === expectedProdName &&\n      (this.targetRef === undefined || node === this.targetRef)\n    ) {\n      this.result = node.definition;\n    }\n  }\n\n  public visitOption(node: Option): void {\n    this.checkIsTarget(node, PROD_TYPE.OPTION);\n  }\n\n  public visitRepetition(node: Repetition): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION);\n  }\n\n  public visitRepetitionMandatory(node: RepetitionMandatory): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    node: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR);\n  }\n\n  public visitRepetitionWithSeparator(node: RepetitionWithSeparator): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_WITH_SEPARATOR);\n  }\n\n  public visitAlternation(node: Alternation): void {\n    this.checkIsTarget(node, PROD_TYPE.ALTERNATION);\n  }\n}\n\nfunction initializeArrayOfArrays(size: number): any[][] {\n  const result = new Array(size);\n  for (let i = 0; i < size; i++) {\n    result[i] = [];\n  }\n  return result;\n}\n\n/**\n * A sort of hash function between a Path in the grammar and a string.\n * Note that this returns multiple \"hashes\" to support the scenario of token categories.\n * -  A single path with categories may match multiple **actual** paths.\n */\nfunction pathToHashKeys(path: TokenType[]): string[] {\n  let keys = [\"\"];\n  for (let i = 0; i < path.length; i++) {\n    const tokType = path[i];\n    const longerKeys = [];\n    for (let j = 0; j < keys.length; j++) {\n      const currShorterKey = keys[j];\n      longerKeys.push(currShorterKey + \"_\" + tokType.tokenTypeIdx);\n      for (let t = 0; t < tokType.categoryMatches!.length; t++) {\n        const categoriesKeySuffix = \"_\" + tokType.categoryMatches![t];\n        longerKeys.push(currShorterKey + categoriesKeySuffix);\n      }\n    }\n    keys = longerKeys;\n  }\n  return keys;\n}\n\n/**\n * Imperative style due to being called from a hot spot\n */\nfunction isUniquePrefixHash(\n  altKnownPathsKeys: Record<string, boolean>[],\n  searchPathKeys: string[],\n  idx: number,\n): boolean {\n  for (\n    let currAltIdx = 0;\n    currAltIdx < altKnownPathsKeys.length;\n    currAltIdx++\n  ) {\n    // We only want to test vs the other alternatives\n    if (currAltIdx === idx) {\n      continue;\n    }\n    const otherAltKnownPathsKeys = altKnownPathsKeys[currAltIdx];\n    for (let searchIdx = 0; searchIdx < searchPathKeys.length; searchIdx++) {\n      const searchKey = searchPathKeys[searchIdx];\n      if (otherAltKnownPathsKeys[searchKey] === true) {\n        return false;\n      }\n    }\n  }\n  // None of the SearchPathKeys were found in any of the other alternatives\n  return true;\n}\n\nexport function lookAheadSequenceFromAlternatives(\n  altsDefs: IProduction[],\n  k: number,\n): LookaheadSequence[] {\n  const partialAlts = map(altsDefs, (currAlt) =>\n    possiblePathsFrom([currAlt], 1),\n  );\n  const finalResult = initializeArrayOfArrays(partialAlts.length);\n  const altsHashes = map(partialAlts, (currAltPaths) => {\n    const dict: { [key: string]: boolean } = {};\n    forEach(currAltPaths, (item) => {\n      const keys = pathToHashKeys(item.partialPath);\n      forEach(keys, (currKey) => {\n        dict[currKey] = true;\n      });\n    });\n    return dict;\n  });\n  let newData = partialAlts;\n\n  // maxLookahead loop\n  for (let pathLength = 1; pathLength <= k; pathLength++) {\n    const currDataset = newData;\n    newData = initializeArrayOfArrays(currDataset.length);\n\n    // alternatives loop\n    for (let altIdx = 0; altIdx < currDataset.length; altIdx++) {\n      const currAltPathsAndSuffixes = currDataset[altIdx];\n      // paths in current alternative loop\n      for (\n        let currPathIdx = 0;\n        currPathIdx < currAltPathsAndSuffixes.length;\n        currPathIdx++\n      ) {\n        const currPathPrefix = currAltPathsAndSuffixes[currPathIdx].partialPath;\n        const suffixDef = currAltPathsAndSuffixes[currPathIdx].suffixDef;\n        const prefixKeys = pathToHashKeys(currPathPrefix);\n        const isUnique = isUniquePrefixHash(altsHashes, prefixKeys, altIdx);\n        // End of the line for this path.\n        if (isUnique || isEmpty(suffixDef) || currPathPrefix.length === k) {\n          const currAltResult = finalResult[altIdx];\n          // TODO: Can we implement a containsPath using Maps/Dictionaries?\n          if (containsPath(currAltResult, currPathPrefix) === false) {\n            currAltResult.push(currPathPrefix);\n            // Update all new  keys for the current path.\n            for (let j = 0; j < prefixKeys.length; j++) {\n              const currKey = prefixKeys[j];\n              altsHashes[altIdx][currKey] = true;\n            }\n          }\n        }\n        // Expand longer paths\n        else {\n          const newPartialPathsAndSuffixes = possiblePathsFrom(\n            suffixDef,\n            pathLength + 1,\n            currPathPrefix,\n          );\n          newData[altIdx] = newData[altIdx].concat(newPartialPathsAndSuffixes);\n\n          // Update keys for new known paths\n          forEach(newPartialPathsAndSuffixes, (item) => {\n            const prefixKeys = pathToHashKeys(item.partialPath);\n            forEach(prefixKeys, (key) => {\n              altsHashes[altIdx][key] = true;\n            });\n          });\n        }\n      }\n    }\n  }\n\n  return finalResult;\n}\n\nexport function getLookaheadPathsForOr(\n  occurrence: number,\n  ruleGrammar: Rule,\n  k: number,\n  orProd?: Alternation,\n): LookaheadSequence[] {\n  const visitor = new InsideDefinitionFinderVisitor(\n    occurrence,\n    PROD_TYPE.ALTERNATION,\n    orProd,\n  );\n  ruleGrammar.accept(visitor);\n  return lookAheadSequenceFromAlternatives(visitor.result, k);\n}\n\nexport function getLookaheadPathsForOptionalProd(\n  occurrence: number,\n  ruleGrammar: Rule,\n  prodType: PROD_TYPE,\n  k: number,\n): LookaheadSequence[] {\n  const insideDefVisitor = new InsideDefinitionFinderVisitor(\n    occurrence,\n    prodType,\n  );\n  ruleGrammar.accept(insideDefVisitor);\n  const insideDef = insideDefVisitor.result;\n\n  const afterDefWalker = new RestDefinitionFinderWalker(\n    ruleGrammar,\n    occurrence,\n    prodType,\n  );\n  const afterDef = afterDefWalker.startWalking();\n\n  const insideFlat = new AlternativeGAST({ definition: insideDef });\n  const afterFlat = new AlternativeGAST({ definition: afterDef });\n\n  return lookAheadSequenceFromAlternatives([insideFlat, afterFlat], k);\n}\n\nexport function containsPath(\n  alternative: Alternative,\n  searchPath: TokenType[],\n): boolean {\n  compareOtherPath: for (let i = 0; i < alternative.length; i++) {\n    const otherPath = alternative[i];\n    if (otherPath.length !== searchPath.length) {\n      continue;\n    }\n    for (let j = 0; j < otherPath.length; j++) {\n      const searchTok = searchPath[j];\n      const otherTok = otherPath[j];\n\n      const matchingTokens =\n        searchTok === otherTok ||\n        otherTok.categoryMatchesMap![searchTok.tokenTypeIdx!] !== undefined;\n      if (matchingTokens === false) {\n        continue compareOtherPath;\n      }\n    }\n    return true;\n  }\n\n  return false;\n}\n\nexport function isStrictPrefixOfPath(\n  prefix: TokenType[],\n  other: TokenType[],\n): boolean {\n  return (\n    prefix.length < other.length &&\n    every(prefix, (tokType, idx) => {\n      const otherTokType = other[idx];\n      return (\n        tokType === otherTokType ||\n        otherTokType.categoryMatchesMap![tokType.tokenTypeIdx!]\n      );\n    })\n  );\n}\n\nexport function areTokenCategoriesNotUsed(\n  lookAheadPaths: LookaheadSequence[],\n): boolean {\n  return every(lookAheadPaths, (singleAltPaths) =>\n    every(singleAltPaths, (singlePath) =>\n      every(singlePath, (token) => isEmpty(token.categoryMatches!)),\n    ),\n  );\n}\n","import { clone, forEach, has, isEmpty, map, values } from \"lodash-es\";\nimport { toFastProperties } from \"@chevrotain/utils\";\nimport { computeAllProdsFollows } from \"../grammar/follow.js\";\nimport { createTokenInstance, EOF } from \"../../scan/tokens_public.js\";\nimport {\n  defaultGrammarValidatorErrorProvider,\n  defaultParserErrorProvider,\n} from \"../errors_public.js\";\nimport {\n  resolveGrammar,\n  validateGrammar,\n} from \"../grammar/gast/gast_resolver_public.js\";\nimport {\n  CstNode,\n  IParserConfig,\n  IRecognitionException,\n  IRuleConfig,\n  IToken,\n  TokenType,\n  TokenVocabulary,\n} from \"@chevrotain/types\";\nimport { Recoverable } from \"./traits/recoverable.js\";\nimport { LooksAhead } from \"./traits/looksahead.js\";\nimport { TreeBuilder } from \"./traits/tree_builder.js\";\nimport { LexerAdapter } from \"./traits/lexer_adapter.js\";\nimport { RecognizerApi } from \"./traits/recognizer_api.js\";\nimport { RecognizerEngine } from \"./traits/recognizer_engine.js\";\n\nimport { ErrorHandler } from \"./traits/error_handler.js\";\nimport { MixedInParser } from \"./traits/parser_traits.js\";\nimport { ContentAssist } from \"./traits/context_assist.js\";\nimport { GastRecorder } from \"./traits/gast_recorder.js\";\nimport { PerformanceTracer } from \"./traits/perf_tracer.js\";\nimport { applyMixins } from \"./utils/apply_mixins.js\";\nimport { IParserDefinitionError } from \"../grammar/types.js\";\nimport { Rule } from \"@chevrotain/gast\";\nimport { IParserConfigInternal, ParserMethodInternal } from \"./types.js\";\nimport { validateLookahead } from \"../grammar/checks.js\";\n\nexport const END_OF_FILE = createTokenInstance(\n  EOF,\n  \"\",\n  NaN,\n  NaN,\n  NaN,\n  NaN,\n  NaN,\n  NaN,\n);\nObject.freeze(END_OF_FILE);\n\nexport type TokenMatcher = (token: IToken, tokType: TokenType) => boolean;\n\nexport const DEFAULT_PARSER_CONFIG: Required<\n  Omit<IParserConfigInternal, \"lookaheadStrategy\">\n> = Object.freeze({\n  recoveryEnabled: false,\n  maxLookahead: 3,\n  dynamicTokensEnabled: false,\n  outputCst: true,\n  errorMessageProvider: defaultParserErrorProvider,\n  nodeLocationTracking: \"none\",\n  traceInitPerf: false,\n  skipValidations: false,\n});\n\nexport const DEFAULT_RULE_CONFIG: Required<IRuleConfig<any>> = Object.freeze({\n  recoveryValueFunc: () => undefined,\n  resyncEnabled: true,\n});\n\nexport enum ParserDefinitionErrorType {\n  INVALID_RULE_NAME = 0,\n  DUPLICATE_RULE_NAME = 1,\n  INVALID_RULE_OVERRIDE = 2,\n  DUPLICATE_PRODUCTIONS = 3,\n  UNRESOLVED_SUBRULE_REF = 4,\n  LEFT_RECURSION = 5,\n  NONE_LAST_EMPTY_ALT = 6,\n  AMBIGUOUS_ALTS = 7,\n  CONFLICT_TOKENS_RULES_NAMESPACE = 8,\n  INVALID_TOKEN_NAME = 9,\n  NO_NON_EMPTY_LOOKAHEAD = 10,\n  AMBIGUOUS_PREFIX_ALTS = 11,\n  TOO_MANY_ALTS = 12,\n  CUSTOM_LOOKAHEAD_VALIDATION = 13,\n}\n\nexport interface IParserDuplicatesDefinitionError\n  extends IParserDefinitionError {\n  dslName: string;\n  occurrence: number;\n  parameter?: string;\n}\n\nexport interface IParserEmptyAlternativeDefinitionError\n  extends IParserDefinitionError {\n  occurrence: number;\n  alternative: number;\n}\n\nexport interface IParserAmbiguousAlternativesDefinitionError\n  extends IParserDefinitionError {\n  occurrence: number | string;\n  alternatives: number[];\n}\n\nexport interface IParserUnresolvedRefDefinitionError\n  extends IParserDefinitionError {\n  unresolvedRefName: string;\n}\n\nexport interface IParserState {\n  errors: IRecognitionException[];\n  lexerState: any;\n  RULE_STACK: number[];\n  CST_STACK: CstNode[];\n}\n\nexport type Predicate = () => boolean;\n\nexport function EMPTY_ALT(): () => undefined;\nexport function EMPTY_ALT<T>(value: T): () => T;\nexport function EMPTY_ALT(value: any = undefined) {\n  return function () {\n    return value;\n  };\n}\n\nexport class Parser {\n  // Set this flag to true if you don't want the Parser to throw error when problems in it's definition are detected.\n  // (normally during the parser's constructor).\n  // This is a design time flag, it will not affect the runtime error handling of the parser, just design time errors,\n  // for example: duplicate rule names, referencing an unresolved subrule, ect...\n  // This flag should not be enabled during normal usage, it is used in special situations, for example when\n  // needing to display the parser definition errors in some GUI(online playground).\n  static DEFER_DEFINITION_ERRORS_HANDLING: boolean = false;\n\n  /**\n   *  @deprecated use the **instance** method with the same name instead\n   */\n  static performSelfAnalysis(parserInstance: Parser): void {\n    throw Error(\n      \"The **static** `performSelfAnalysis` method has been deprecated.\" +\n        \"\\t\\nUse the **instance** method with the same name instead.\",\n    );\n  }\n\n  public performSelfAnalysis(this: MixedInParser): void {\n    this.TRACE_INIT(\"performSelfAnalysis\", () => {\n      let defErrorsMsgs;\n\n      this.selfAnalysisDone = true;\n      const className = this.className;\n\n      this.TRACE_INIT(\"toFastProps\", () => {\n        // Without this voodoo magic the parser would be x3-x4 slower\n        // It seems it is better to invoke `toFastProperties` **before**\n        // Any manipulations of the `this` object done during the recording phase.\n        toFastProperties(this);\n      });\n\n      this.TRACE_INIT(\"Grammar Recording\", () => {\n        try {\n          this.enableRecording();\n          // Building the GAST\n          forEach(this.definedRulesNames, (currRuleName) => {\n            const wrappedRule = (this as any)[\n              currRuleName\n            ] as ParserMethodInternal<unknown[], unknown>;\n            const originalGrammarAction = wrappedRule[\"originalGrammarAction\"];\n            let recordedRuleGast!: Rule;\n            this.TRACE_INIT(`${currRuleName} Rule`, () => {\n              recordedRuleGast = this.topLevelRuleRecord(\n                currRuleName,\n                originalGrammarAction,\n              );\n            });\n            this.gastProductionsCache[currRuleName] = recordedRuleGast;\n          });\n        } finally {\n          this.disableRecording();\n        }\n      });\n\n      let resolverErrors: IParserDefinitionError[] = [];\n      this.TRACE_INIT(\"Grammar Resolving\", () => {\n        resolverErrors = resolveGrammar({\n          rules: values(this.gastProductionsCache),\n        });\n        this.definitionErrors = this.definitionErrors.concat(resolverErrors);\n      });\n\n      this.TRACE_INIT(\"Grammar Validations\", () => {\n        // only perform additional grammar validations IFF no resolving errors have occurred.\n        // as unresolved grammar may lead to unhandled runtime exceptions in the follow up validations.\n        if (isEmpty(resolverErrors) && this.skipValidations === false) {\n          const validationErrors = validateGrammar({\n            rules: values(this.gastProductionsCache),\n            tokenTypes: values(this.tokensMap),\n            errMsgProvider: defaultGrammarValidatorErrorProvider,\n            grammarName: className,\n          });\n          const lookaheadValidationErrors = validateLookahead({\n            lookaheadStrategy: this.lookaheadStrategy,\n            rules: values(this.gastProductionsCache),\n            tokenTypes: values(this.tokensMap),\n            grammarName: className,\n          });\n          this.definitionErrors = this.definitionErrors.concat(\n            validationErrors,\n            lookaheadValidationErrors,\n          );\n        }\n      });\n\n      // this analysis may fail if the grammar is not perfectly valid\n      if (isEmpty(this.definitionErrors)) {\n        // The results of these computations are not needed unless error recovery is enabled.\n        if (this.recoveryEnabled) {\n          this.TRACE_INIT(\"computeAllProdsFollows\", () => {\n            const allFollows = computeAllProdsFollows(\n              values(this.gastProductionsCache),\n            );\n            this.resyncFollows = allFollows;\n          });\n        }\n\n        this.TRACE_INIT(\"ComputeLookaheadFunctions\", () => {\n          this.lookaheadStrategy.initialize?.({\n            rules: values(this.gastProductionsCache),\n          });\n          this.preComputeLookaheadFunctions(values(this.gastProductionsCache));\n        });\n      }\n\n      if (\n        !Parser.DEFER_DEFINITION_ERRORS_HANDLING &&\n        !isEmpty(this.definitionErrors)\n      ) {\n        defErrorsMsgs = map(\n          this.definitionErrors,\n          (defError) => defError.message,\n        );\n        throw new Error(\n          `Parser Definition Errors detected:\\n ${defErrorsMsgs.join(\n            \"\\n-------------------------------\\n\",\n          )}`,\n        );\n      }\n    });\n  }\n\n  definitionErrors: IParserDefinitionError[] = [];\n  selfAnalysisDone = false;\n  protected skipValidations: boolean;\n\n  constructor(tokenVocabulary: TokenVocabulary, config: IParserConfig) {\n    const that: MixedInParser = this as any;\n    that.initErrorHandler(config);\n    that.initLexerAdapter();\n    that.initLooksAhead(config);\n    that.initRecognizerEngine(tokenVocabulary, config);\n    that.initRecoverable(config);\n    that.initTreeBuilder(config);\n    that.initContentAssist();\n    that.initGastRecorder(config);\n    that.initPerformanceTracer(config);\n\n    if (has(config, \"ignoredIssues\")) {\n      throw new Error(\n        \"The <ignoredIssues> IParserConfig property has been deprecated.\\n\\t\" +\n          \"Please use the <IGNORE_AMBIGUITIES> flag on the relevant DSL method instead.\\n\\t\" +\n          \"See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#IGNORING_AMBIGUITIES\\n\\t\" +\n          \"For further details.\",\n      );\n    }\n\n    this.skipValidations = has(config, \"skipValidations\")\n      ? (config.skipValidations as boolean) // casting assumes the end user passing the correct type\n      : DEFAULT_PARSER_CONFIG.skipValidations;\n  }\n}\n\napplyMixins(Parser, [\n  Recoverable,\n  LooksAhead,\n  TreeBuilder,\n  LexerAdapter,\n  RecognizerEngine,\n  RecognizerApi,\n  ErrorHandler,\n  ContentAssist,\n  GastRecorder,\n  PerformanceTracer,\n]);\n\nexport class CstParser extends Parser {\n  constructor(\n    tokenVocabulary: TokenVocabulary,\n    config: IParserConfigInternal = DEFAULT_PARSER_CONFIG,\n  ) {\n    const configClone = clone(config);\n    configClone.outputCst = true;\n    super(tokenVocabulary, configClone);\n  }\n}\n\nexport class EmbeddedActionsParser extends Parser {\n  constructor(\n    tokenVocabulary: TokenVocabulary,\n    config: IParserConfigInternal = DEFAULT_PARSER_CONFIG,\n  ) {\n    const configClone = clone(config);\n    configClone.outputCst = false;\n    super(tokenVocabulary, configClone);\n  }\n}\n","import {\n  Alternative,\n  Atom,\n  BaseRegExpVisitor,\n  Character,\n  Disjunction,\n  Group,\n  Set,\n} from \"@chevrotain/regexp-to-ast\";\nimport { every, find, forEach, includes, isArray, values } from \"lodash-es\";\nimport { PRINT_ERROR, PRINT_WARNING } from \"@chevrotain/utils\";\nimport { ASTNode, getRegExpAst } from \"./reg_exp_parser.js\";\nimport { charCodeToOptimizedIndex, minOptimizationVal } from \"./lexer.js\";\n\nconst complementErrorMessage =\n  \"Complement Sets are not supported for first char optimization\";\nexport const failedOptimizationPrefixMsg =\n  'Unable to use \"first char\" lexer optimizations:\\n';\n\nexport function getOptimizedStartCodesIndices(\n  regExp: RegExp,\n  ensureOptimizations = false,\n): number[] {\n  try {\n    const ast = getRegExpAst(regExp);\n    const firstChars = firstCharOptimizedIndices(\n      ast.value,\n      {},\n      ast.flags.ignoreCase,\n    );\n    return firstChars;\n  } catch (e) {\n    /* istanbul ignore next */\n    // Testing this relies on the regexp-to-ast library having a bug... */\n    // TODO: only the else branch needs to be ignored, try to fix with newer prettier / tsc\n    if (e.message === complementErrorMessage) {\n      if (ensureOptimizations) {\n        PRINT_WARNING(\n          `${failedOptimizationPrefixMsg}` +\n            `\\tUnable to optimize: < ${regExp.toString()} >\\n` +\n            \"\\tComplement Sets cannot be automatically optimized.\\n\" +\n            \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n            \"\\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#COMPLEMENT for details.\",\n        );\n      }\n    } else {\n      let msgSuffix = \"\";\n      if (ensureOptimizations) {\n        msgSuffix =\n          \"\\n\\tThis will disable the lexer's first char optimizations.\\n\" +\n          \"\\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#REGEXP_PARSING for details.\";\n      }\n      PRINT_ERROR(\n        `${failedOptimizationPrefixMsg}\\n` +\n          `\\tFailed parsing: < ${regExp.toString()} >\\n` +\n          `\\tUsing the @chevrotain/regexp-to-ast library\\n` +\n          \"\\tPlease open an issue at: https://github.com/chevrotain/chevrotain/issues\" +\n          msgSuffix,\n      );\n    }\n  }\n\n  return [];\n}\n\nexport function firstCharOptimizedIndices(\n  ast: ASTNode,\n  result: { [charCode: number]: number },\n  ignoreCase: boolean,\n): number[] {\n  switch (ast.type) {\n    case \"Disjunction\":\n      for (let i = 0; i < ast.value.length; i++) {\n        firstCharOptimizedIndices(ast.value[i], result, ignoreCase);\n      }\n      break;\n    case \"Alternative\":\n      const terms = ast.value;\n      for (let i = 0; i < terms.length; i++) {\n        const term = terms[i];\n\n        // skip terms that cannot effect the first char results\n        switch (term.type) {\n          case \"EndAnchor\":\n          // A group back reference cannot affect potential starting char.\n          // because if a back reference is the first production than automatically\n          // the group being referenced has had to come BEFORE so its codes have already been added\n          case \"GroupBackReference\":\n          // assertions do not affect potential starting codes\n          case \"Lookahead\":\n          case \"NegativeLookahead\":\n          case \"StartAnchor\":\n          case \"WordBoundary\":\n          case \"NonWordBoundary\":\n            continue;\n        }\n\n        const atom = term;\n        switch (atom.type) {\n          case \"Character\":\n            addOptimizedIdxToResult(atom.value, result, ignoreCase);\n            break;\n          case \"Set\":\n            if (atom.complement === true) {\n              throw Error(complementErrorMessage);\n            }\n            forEach(atom.value, (code) => {\n              if (typeof code === \"number\") {\n                addOptimizedIdxToResult(code, result, ignoreCase);\n              } else {\n                // range\n                const range = code as any;\n                // cannot optimize when ignoreCase is\n                if (ignoreCase === true) {\n                  for (\n                    let rangeCode = range.from;\n                    rangeCode <= range.to;\n                    rangeCode++\n                  ) {\n                    addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                  }\n                }\n                // Optimization (2 orders of magnitude less work for very large ranges)\n                else {\n                  // handle unoptimized values\n                  for (\n                    let rangeCode = range.from;\n                    rangeCode <= range.to && rangeCode < minOptimizationVal;\n                    rangeCode++\n                  ) {\n                    addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                  }\n\n                  // Less common charCode where we optimize for faster init time, by using larger \"buckets\"\n                  if (range.to >= minOptimizationVal) {\n                    const minUnOptVal =\n                      range.from >= minOptimizationVal\n                        ? range.from\n                        : minOptimizationVal;\n                    const maxUnOptVal = range.to;\n                    const minOptIdx = charCodeToOptimizedIndex(minUnOptVal);\n                    const maxOptIdx = charCodeToOptimizedIndex(maxUnOptVal);\n\n                    for (\n                      let currOptIdx = minOptIdx;\n                      currOptIdx <= maxOptIdx;\n                      currOptIdx++\n                    ) {\n                      result[currOptIdx] = currOptIdx;\n                    }\n                  }\n                }\n              }\n            });\n            break;\n          case \"Group\":\n            firstCharOptimizedIndices(atom.value, result, ignoreCase);\n            break;\n          /* istanbul ignore next */\n          default:\n            throw Error(\"Non Exhaustive Match\");\n        }\n\n        // reached a mandatory production, no more **start** codes can be found on this alternative\n        const isOptionalQuantifier =\n          atom.quantifier !== undefined && atom.quantifier.atLeast === 0;\n        if (\n          // A group may be optional due to empty contents /(?:)/\n          // or if everything inside it is optional /((a)?)/\n          (atom.type === \"Group\" && isWholeOptional(atom) === false) ||\n          // If this term is not a group it may only be optional if it has an optional quantifier\n          (atom.type !== \"Group\" && isOptionalQuantifier === false)\n        ) {\n          break;\n        }\n      }\n      break;\n    /* istanbul ignore next */\n    default:\n      throw Error(\"non exhaustive match!\");\n  }\n\n  // console.log(Object.keys(result).length)\n  return values(result);\n}\n\nfunction addOptimizedIdxToResult(\n  code: number,\n  result: { [charCode: number]: number },\n  ignoreCase: boolean,\n) {\n  const optimizedCharIdx = charCodeToOptimizedIndex(code);\n  result[optimizedCharIdx] = optimizedCharIdx;\n\n  if (ignoreCase === true) {\n    handleIgnoreCase(code, result);\n  }\n}\n\nfunction handleIgnoreCase(\n  code: number,\n  result: { [charCode: number]: number },\n) {\n  const char = String.fromCharCode(code);\n  const upperChar = char.toUpperCase();\n  /* istanbul ignore else */\n  if (upperChar !== char) {\n    const optimizedCharIdx = charCodeToOptimizedIndex(upperChar.charCodeAt(0));\n    result[optimizedCharIdx] = optimizedCharIdx;\n  } else {\n    const lowerChar = char.toLowerCase();\n    if (lowerChar !== char) {\n      const optimizedCharIdx = charCodeToOptimizedIndex(\n        lowerChar.charCodeAt(0),\n      );\n      result[optimizedCharIdx] = optimizedCharIdx;\n    }\n  }\n}\n\nfunction findCode(setNode: Set, targetCharCodes: number[]) {\n  return find(setNode.value, (codeOrRange) => {\n    if (typeof codeOrRange === \"number\") {\n      return includes(targetCharCodes, codeOrRange);\n    } else {\n      // range\n      const range = <any>codeOrRange;\n      return (\n        find(\n          targetCharCodes,\n          (targetCode) => range.from <= targetCode && targetCode <= range.to,\n        ) !== undefined\n      );\n    }\n  });\n}\n\nfunction isWholeOptional(ast: any): boolean {\n  const quantifier = (ast as Atom).quantifier;\n  if (quantifier && quantifier.atLeast === 0) {\n    return true;\n  }\n\n  if (!ast.value) {\n    return false;\n  }\n\n  return isArray(ast.value)\n    ? every(ast.value, isWholeOptional)\n    : isWholeOptional(ast.value);\n}\n\nclass CharCodeFinder extends BaseRegExpVisitor {\n  found: boolean = false;\n\n  constructor(private targetCharCodes: number[]) {\n    super();\n  }\n\n  visitChildren(node: ASTNode) {\n    // No need to keep looking...\n    if (this.found === true) {\n      return;\n    }\n\n    // switch lookaheads as they do not actually consume any characters thus\n    // finding a charCode at lookahead context does not mean that regexp can actually contain it in a match.\n    switch (node.type) {\n      case \"Lookahead\":\n        this.visitLookahead(node);\n        return;\n      case \"NegativeLookahead\":\n        this.visitNegativeLookahead(node);\n        return;\n    }\n\n    super.visitChildren(node);\n  }\n\n  visitCharacter(node: Character) {\n    if (includes(this.targetCharCodes, node.value)) {\n      this.found = true;\n    }\n  }\n\n  visitSet(node: Set) {\n    if (node.complement) {\n      if (findCode(node, this.targetCharCodes) === undefined) {\n        this.found = true;\n      }\n    } else {\n      if (findCode(node, this.targetCharCodes) !== undefined) {\n        this.found = true;\n      }\n    }\n  }\n}\n\nexport function canMatchCharCode(\n  charCodes: number[],\n  pattern: RegExp | string,\n) {\n  if (pattern instanceof RegExp) {\n    const ast = getRegExpAst(pattern);\n    const charCodeFinder = new CharCodeFinder(charCodes);\n    charCodeFinder.visit(ast);\n    return charCodeFinder.found;\n  } else {\n    return (\n      find(<any>pattern, (char) => {\n        return includes(charCodes, (<string>char).charCodeAt(0));\n      }) !== undefined\n    );\n  }\n}\n","import arrayMap from './_arrayMap.js';\nimport baseIteratee from './_baseIteratee.js';\nimport basePickBy from './_basePickBy.js';\nimport getAllKeysIn from './_getAllKeysIn.js';\n\n/**\n * Creates an object composed of the `object` properties `predicate` returns\n * truthy for. The predicate is invoked with two arguments: (value, key).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Object\n * @param {Object} object The source object.\n * @param {Function} [predicate=_.identity] The function invoked per property.\n * @returns {Object} Returns the new object.\n * @example\n *\n * var object = { 'a': 1, 'b': '2', 'c': 3 };\n *\n * _.pickBy(object, _.isNumber);\n * // => { 'a': 1, 'c': 3 }\n */\nfunction pickBy(object, predicate) {\n  if (object == null) {\n    return {};\n  }\n  var props = arrayMap(getAllKeysIn(object), function(prop) {\n    return [prop];\n  });\n  predicate = baseIteratee(predicate);\n  return basePickBy(object, props, function(value, path) {\n    return predicate(value, path[0]);\n  });\n}\n\nexport default pickBy;\n","/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\n'use strict';\nclass FullTextDocument {\n    constructor(uri, languageId, version, content) {\n        this._uri = uri;\n        this._languageId = languageId;\n        this._version = version;\n        this._content = content;\n        this._lineOffsets = undefined;\n    }\n    get uri() {\n        return this._uri;\n    }\n    get languageId() {\n        return this._languageId;\n    }\n    get version() {\n        return this._version;\n    }\n    getText(range) {\n        if (range) {\n            const start = this.offsetAt(range.start);\n            const end = this.offsetAt(range.end);\n            return this._content.substring(start, end);\n        }\n        return this._content;\n    }\n    update(changes, version) {\n        for (const change of changes) {\n            if (FullTextDocument.isIncremental(change)) {\n                // makes sure start is before end\n                const range = getWellformedRange(change.range);\n                // update content\n                const startOffset = this.offsetAt(range.start);\n                const endOffset = this.offsetAt(range.end);\n                this._content = this._content.substring(0, startOffset) + change.text + this._content.substring(endOffset, this._content.length);\n                // update the offsets\n                const startLine = Math.max(range.start.line, 0);\n                const endLine = Math.max(range.end.line, 0);\n                let lineOffsets = this._lineOffsets;\n                const addedLineOffsets = computeLineOffsets(change.text, false, startOffset);\n                if (endLine - startLine === addedLineOffsets.length) {\n                    for (let i = 0, len = addedLineOffsets.length; i < len; i++) {\n                        lineOffsets[i + startLine + 1] = addedLineOffsets[i];\n                    }\n                }\n                else {\n                    if (addedLineOffsets.length < 10000) {\n                        lineOffsets.splice(startLine + 1, endLine - startLine, ...addedLineOffsets);\n                    }\n                    else { // avoid too many arguments for splice\n                        this._lineOffsets = lineOffsets = lineOffsets.slice(0, startLine + 1).concat(addedLineOffsets, lineOffsets.slice(endLine + 1));\n                    }\n                }\n                const diff = change.text.length - (endOffset - startOffset);\n                if (diff !== 0) {\n                    for (let i = startLine + 1 + addedLineOffsets.length, len = lineOffsets.length; i < len; i++) {\n                        lineOffsets[i] = lineOffsets[i] + diff;\n                    }\n                }\n            }\n            else if (FullTextDocument.isFull(change)) {\n                this._content = change.text;\n                this._lineOffsets = undefined;\n            }\n            else {\n                throw new Error('Unknown change event received');\n            }\n        }\n        this._version = version;\n    }\n    getLineOffsets() {\n        if (this._lineOffsets === undefined) {\n            this._lineOffsets = computeLineOffsets(this._content, true);\n        }\n        return this._lineOffsets;\n    }\n    positionAt(offset) {\n        offset = Math.max(Math.min(offset, this._content.length), 0);\n        const lineOffsets = this.getLineOffsets();\n        let low = 0, high = lineOffsets.length;\n        if (high === 0) {\n            return { line: 0, character: offset };\n        }\n        while (low < high) {\n            const mid = Math.floor((low + high) / 2);\n            if (lineOffsets[mid] > offset) {\n                high = mid;\n            }\n            else {\n                low = mid + 1;\n            }\n        }\n        // low is the least x for which the line offset is larger than the current offset\n        // or array.length if no line offset is larger than the current offset\n        const line = low - 1;\n        offset = this.ensureBeforeEOL(offset, lineOffsets[line]);\n        return { line, character: offset - lineOffsets[line] };\n    }\n    offsetAt(position) {\n        const lineOffsets = this.getLineOffsets();\n        if (position.line >= lineOffsets.length) {\n            return this._content.length;\n        }\n        else if (position.line < 0) {\n            return 0;\n        }\n        const lineOffset = lineOffsets[position.line];\n        if (position.character <= 0) {\n            return lineOffset;\n        }\n        const nextLineOffset = (position.line + 1 < lineOffsets.length) ? lineOffsets[position.line + 1] : this._content.length;\n        const offset = Math.min(lineOffset + position.character, nextLineOffset);\n        return this.ensureBeforeEOL(offset, lineOffset);\n    }\n    ensureBeforeEOL(offset, lineOffset) {\n        while (offset > lineOffset && isEOL(this._content.charCodeAt(offset - 1))) {\n            offset--;\n        }\n        return offset;\n    }\n    get lineCount() {\n        return this.getLineOffsets().length;\n    }\n    static isIncremental(event) {\n        const candidate = event;\n        return candidate !== undefined && candidate !== null &&\n            typeof candidate.text === 'string' && candidate.range !== undefined &&\n            (candidate.rangeLength === undefined || typeof candidate.rangeLength === 'number');\n    }\n    static isFull(event) {\n        const candidate = event;\n        return candidate !== undefined && candidate !== null &&\n            typeof candidate.text === 'string' && candidate.range === undefined && candidate.rangeLength === undefined;\n    }\n}\nexport var TextDocument;\n(function (TextDocument) {\n    /**\n     * Creates a new text document.\n     *\n     * @param uri The document's uri.\n     * @param languageId  The document's language Id.\n     * @param version The document's initial version number.\n     * @param content The document's content.\n     */\n    function create(uri, languageId, version, content) {\n        return new FullTextDocument(uri, languageId, version, content);\n    }\n    TextDocument.create = create;\n    /**\n     * Updates a TextDocument by modifying its content.\n     *\n     * @param document the document to update. Only documents created by TextDocument.create are valid inputs.\n     * @param changes the changes to apply to the document.\n     * @param version the changes version for the document.\n     * @returns The updated TextDocument. Note: That's the same document instance passed in as first parameter.\n     *\n     */\n    function update(document, changes, version) {\n        if (document instanceof FullTextDocument) {\n            document.update(changes, version);\n            return document;\n        }\n        else {\n            throw new Error('TextDocument.update: document must be created by TextDocument.create');\n        }\n    }\n    TextDocument.update = update;\n    function applyEdits(document, edits) {\n        const text = document.getText();\n        const sortedEdits = mergeSort(edits.map(getWellformedEdit), (a, b) => {\n            const diff = a.range.start.line - b.range.start.line;\n            if (diff === 0) {\n                return a.range.start.character - b.range.start.character;\n            }\n            return diff;\n        });\n        let lastModifiedOffset = 0;\n        const spans = [];\n        for (const e of sortedEdits) {\n            const startOffset = document.offsetAt(e.range.start);\n            if (startOffset < lastModifiedOffset) {\n                throw new Error('Overlapping edit');\n            }\n            else if (startOffset > lastModifiedOffset) {\n                spans.push(text.substring(lastModifiedOffset, startOffset));\n            }\n            if (e.newText.length) {\n                spans.push(e.newText);\n            }\n            lastModifiedOffset = document.offsetAt(e.range.end);\n        }\n        spans.push(text.substr(lastModifiedOffset));\n        return spans.join('');\n    }\n    TextDocument.applyEdits = applyEdits;\n})(TextDocument || (TextDocument = {}));\nfunction mergeSort(data, compare) {\n    if (data.length <= 1) {\n        // sorted\n        return data;\n    }\n    const p = (data.length / 2) | 0;\n    const left = data.slice(0, p);\n    const right = data.slice(p);\n    mergeSort(left, compare);\n    mergeSort(right, compare);\n    let leftIdx = 0;\n    let rightIdx = 0;\n    let i = 0;\n    while (leftIdx < left.length && rightIdx < right.length) {\n        const ret = compare(left[leftIdx], right[rightIdx]);\n        if (ret <= 0) {\n            // smaller_equal -> take left to preserve order\n            data[i++] = left[leftIdx++];\n        }\n        else {\n            // greater -> take right\n            data[i++] = right[rightIdx++];\n        }\n    }\n    while (leftIdx < left.length) {\n        data[i++] = left[leftIdx++];\n    }\n    while (rightIdx < right.length) {\n        data[i++] = right[rightIdx++];\n    }\n    return data;\n}\nfunction computeLineOffsets(text, isAtLineStart, textOffset = 0) {\n    const result = isAtLineStart ? [textOffset] : [];\n    for (let i = 0; i < text.length; i++) {\n        const ch = text.charCodeAt(i);\n        if (isEOL(ch)) {\n            if (ch === 13 /* CharCode.CarriageReturn */ && i + 1 < text.length && text.charCodeAt(i + 1) === 10 /* CharCode.LineFeed */) {\n                i++;\n            }\n            result.push(textOffset + i + 1);\n        }\n    }\n    return result;\n}\nfunction isEOL(char) {\n    return char === 13 /* CharCode.CarriageReturn */ || char === 10 /* CharCode.LineFeed */;\n}\nfunction getWellformedRange(range) {\n    const start = range.start;\n    const end = range.end;\n    if (start.line > end.line || (start.line === end.line && start.character > end.character)) {\n        return { start: end, end: start };\n    }\n    return range;\n}\nfunction getWellformedEdit(textEdit) {\n    const range = getWellformedRange(textEdit.range);\n    if (range !== textEdit.range) {\n        return { newText: textEdit.newText, range };\n    }\n    return textEdit;\n}\n","import isArray from './isArray.js';\nimport isKey from './_isKey.js';\nimport stringToPath from './_stringToPath.js';\nimport toString from './toString.js';\n\n/**\n * Casts `value` to a path array if it's not one.\n *\n * @private\n * @param {*} value The value to inspect.\n * @param {Object} [object] The object to query keys on.\n * @returns {Array} Returns the cast property path array.\n */\nfunction castPath(value, object) {\n  if (isArray(value)) {\n    return value;\n  }\n  return isKey(value, object) ? [value] : stringToPath(toString(value));\n}\n\nexport default castPath;\n","import Symbol from './_Symbol.js';\nimport arrayMap from './_arrayMap.js';\nimport isArray from './isArray.js';\nimport isSymbol from './isSymbol.js';\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0;\n\n/** Used to convert symbols to primitives and strings. */\nvar symbolProto = Symbol ? Symbol.prototype : undefined,\n    symbolToString = symbolProto ? symbolProto.toString : undefined;\n\n/**\n * The base implementation of `_.toString` which doesn't convert nullish\n * values to empty strings.\n *\n * @private\n * @param {*} value The value to process.\n * @returns {string} Returns the string.\n */\nfunction baseToString(value) {\n  // Exit early for strings to avoid a performance hit in some environments.\n  if (typeof value == 'string') {\n    return value;\n  }\n  if (isArray(value)) {\n    // Recursively convert values (susceptible to call stack limits).\n    return arrayMap(value, baseToString) + '';\n  }\n  if (isSymbol(value)) {\n    return symbolToString ? symbolToString.call(value) : '';\n  }\n  var result = (value + '');\n  return (result == '0' && (1 / value) == -INFINITY) ? '-0' : result;\n}\n\nexport default baseToString;\n","import isFunction from './isFunction.js';\nimport isMasked from './_isMasked.js';\nimport isObject from './isObject.js';\nimport toSource from './_toSource.js';\n\n/**\n * Used to match `RegExp`\n * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).\n */\nvar reRegExpChar = /[\\\\^$.*+?()[\\]{}|]/g;\n\n/** Used to detect host constructors (Safari). */\nvar reIsHostCtor = /^\\[object .+?Constructor\\]$/;\n\n/** Used for built-in method references. */\nvar funcProto = Function.prototype,\n    objectProto = Object.prototype;\n\n/** Used to resolve the decompiled source of functions. */\nvar funcToString = funcProto.toString;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/** Used to detect if a method is native. */\nvar reIsNative = RegExp('^' +\n  funcToString.call(hasOwnProperty).replace(reRegExpChar, '\\\\$&')\n  .replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g, '$1.*?') + '$'\n);\n\n/**\n * The base implementation of `_.isNative` without bad shim checks.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a native function,\n *  else `false`.\n */\nfunction baseIsNative(value) {\n  if (!isObject(value) || isMasked(value)) {\n    return false;\n  }\n  var pattern = isFunction(value) ? reIsNative : reIsHostCtor;\n  return pattern.test(toSource(value));\n}\n\nexport default baseIsNative;\n","import baseRest from './_baseRest.js';\nimport eq from './eq.js';\nimport isIterateeCall from './_isIterateeCall.js';\nimport keysIn from './keysIn.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Assigns own and inherited enumerable string keyed properties of source\n * objects to the destination object for all destination properties that\n * resolve to `undefined`. Source objects are applied from left to right.\n * Once a property is set, additional values of the same property are ignored.\n *\n * **Note:** This method mutates `object`.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @see _.defaultsDeep\n * @example\n *\n * _.defaults({ 'a': 1 }, { 'b': 2 }, { 'a': 3 });\n * // => { 'a': 1, 'b': 2 }\n */\nvar defaults = baseRest(function(object, sources) {\n  object = Object(object);\n\n  var index = -1;\n  var length = sources.length;\n  var guard = length > 2 ? sources[2] : undefined;\n\n  if (guard && isIterateeCall(sources[0], sources[1], guard)) {\n    length = 1;\n  }\n\n  while (++index < length) {\n    var source = sources[index];\n    var props = keysIn(source);\n    var propsIndex = -1;\n    var propsLength = props.length;\n\n    while (++propsIndex < propsLength) {\n      var key = props[propsIndex];\n      var value = object[key];\n\n      if (value === undefined ||\n          (eq(value, objectProto[key]) && !hasOwnProperty.call(object, key))) {\n        object[key] = source[key];\n      }\n    }\n  }\n\n  return object;\n});\n\nexport default defaults;\n","import baseDifference from './_baseDifference.js';\nimport baseFlatten from './_baseFlatten.js';\nimport baseRest from './_baseRest.js';\nimport isArrayLikeObject from './isArrayLikeObject.js';\n\n/**\n * Creates an array of `array` values not included in the other given arrays\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons. The order and references of result values are\n * determined by the first array.\n *\n * **Note:** Unlike `_.pullAll`, this method returns a new array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {...Array} [values] The values to exclude.\n * @returns {Array} Returns the new array of filtered values.\n * @see _.without, _.xor\n * @example\n *\n * _.difference([2, 1], [2, 3]);\n * // => [1]\n */\nvar difference = baseRest(function(array, values) {\n  return isArrayLikeObject(array)\n    ? baseDifference(array, baseFlatten(values, 1, isArrayLikeObject, true))\n    : [];\n});\n\nexport default difference;\n","import arrayFilter from './_arrayFilter.js';\nimport baseFilter from './_baseFilter.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\n\n/**\n * Iterates over elements of `collection`, returning an array of all elements\n * `predicate` returns truthy for. The predicate is invoked with three\n * arguments: (value, index|key, collection).\n *\n * **Note:** Unlike `_.remove`, this method returns a new array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new filtered array.\n * @see _.reject\n * @example\n *\n * var users = [\n *   { 'user': 'barney', 'age': 36, 'active': true },\n *   { 'user': 'fred',   'age': 40, 'active': false }\n * ];\n *\n * _.filter(users, function(o) { return !o.active; });\n * // => objects for ['fred']\n *\n * // The `_.matches` iteratee shorthand.\n * _.filter(users, { 'age': 36, 'active': true });\n * // => objects for ['barney']\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.filter(users, ['active', false]);\n * // => objects for ['fred']\n *\n * // The `_.property` iteratee shorthand.\n * _.filter(users, 'active');\n * // => objects for ['barney']\n *\n * // Combining several predicates using `_.overEvery` or `_.overSome`.\n * _.filter(users, _.overSome([{ 'age': 36 }, ['age', 40]]));\n * // => objects for ['fred', 'barney']\n */\nfunction filter(collection, predicate) {\n  var func = isArray(collection) ? arrayFilter : baseFilter;\n  return func(collection, baseIteratee(predicate, 3));\n}\n\nexport default filter;\n","import arrayAggregator from './_arrayAggregator.js';\nimport baseAggregator from './_baseAggregator.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\n\n/**\n * Creates a function like `_.groupBy`.\n *\n * @private\n * @param {Function} setter The function to set accumulator values.\n * @param {Function} [initializer] The accumulator object initializer.\n * @returns {Function} Returns the new aggregator function.\n */\nfunction createAggregator(setter, initializer) {\n  return function(collection, iteratee) {\n    var func = isArray(collection) ? arrayAggregator : baseAggregator,\n        accumulator = initializer ? initializer() : {};\n\n    return func(collection, setter, baseIteratee(iteratee, 2), accumulator);\n  };\n}\n\nexport default createAggregator;\n","import baseProperty from './_baseProperty.js';\nimport basePropertyDeep from './_basePropertyDeep.js';\nimport isKey from './_isKey.js';\nimport toKey from './_toKey.js';\n\n/**\n * Creates a function that returns the value at `path` of a given object.\n *\n * @static\n * @memberOf _\n * @since 2.4.0\n * @category Util\n * @param {Array|string} path The path of the property to get.\n * @returns {Function} Returns the new accessor function.\n * @example\n *\n * var objects = [\n *   { 'a': { 'b': 2 } },\n *   { 'a': { 'b': 1 } }\n * ];\n *\n * _.map(objects, _.property('a.b'));\n * // => [2, 1]\n *\n * _.map(_.sortBy(objects, _.property(['a', 'b'])), 'a.b');\n * // => [1, 2]\n */\nfunction property(path) {\n  return isKey(path) ? baseProperty(toKey(path)) : basePropertyDeep(path);\n}\n\nexport default property;\n","import arrayMap from './_arrayMap.js';\nimport baseIteratee from './_baseIteratee.js';\nimport baseMap from './_baseMap.js';\nimport isArray from './isArray.js';\n\n/**\n * Creates an array of values by running each element in `collection` thru\n * `iteratee`. The iteratee is invoked with three arguments:\n * (value, index|key, collection).\n *\n * Many lodash methods are guarded to work as iteratees for methods like\n * `_.every`, `_.filter`, `_.map`, `_.mapValues`, `_.reject`, and `_.some`.\n *\n * The guarded methods are:\n * `ary`, `chunk`, `curry`, `curryRight`, `drop`, `dropRight`, `every`,\n * `fill`, `invert`, `parseInt`, `random`, `range`, `rangeRight`, `repeat`,\n * `sampleSize`, `slice`, `some`, `sortBy`, `split`, `take`, `takeRight`,\n * `template`, `trim`, `trimEnd`, `trimStart`, and `words`\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new mapped array.\n * @example\n *\n * function square(n) {\n *   return n * n;\n * }\n *\n * _.map([4, 8], square);\n * // => [16, 64]\n *\n * _.map({ 'a': 4, 'b': 8 }, square);\n * // => [16, 64] (iteration order is not guaranteed)\n *\n * var users = [\n *   { 'user': 'barney' },\n *   { 'user': 'fred' }\n * ];\n *\n * // The `_.property` iteratee shorthand.\n * _.map(users, 'user');\n * // => ['barney', 'fred']\n */\nfunction map(collection, iteratee) {\n  var func = isArray(collection) ? arrayMap : baseMap;\n  return func(collection, baseIteratee(iteratee, 3));\n}\n\nexport default map;\n","import arrayPush from './_arrayPush.js';\nimport getPrototype from './_getPrototype.js';\nimport getSymbols from './_getSymbols.js';\nimport stubArray from './stubArray.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeGetSymbols = Object.getOwnPropertySymbols;\n\n/**\n * Creates an array of the own and inherited enumerable symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of symbols.\n */\nvar getSymbolsIn = !nativeGetSymbols ? stubArray : function(object) {\n  var result = [];\n  while (object) {\n    arrayPush(result, getSymbols(object));\n    object = getPrototype(object);\n  }\n  return result;\n};\n\nexport default getSymbolsIn;\n","import arrayEach from './_arrayEach.js';\nimport baseEach from './_baseEach.js';\nimport castFunction from './_castFunction.js';\nimport isArray from './isArray.js';\n\n/**\n * Iterates over elements of `collection` and invokes `iteratee` for each element.\n * The iteratee is invoked with three arguments: (value, index|key, collection).\n * Iteratee functions may exit iteration early by explicitly returning `false`.\n *\n * **Note:** As with other \"Collections\" methods, objects with a \"length\"\n * property are iterated like arrays. To avoid this behavior use `_.forIn`\n * or `_.forOwn` for object iteration.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @alias each\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The function invoked per iteration.\n * @returns {Array|Object} Returns `collection`.\n * @see _.forEachRight\n * @example\n *\n * _.forEach([1, 2], function(value) {\n *   console.log(value);\n * });\n * // => Logs `1` then `2`.\n *\n * _.forEach({ 'a': 1, 'b': 2 }, function(value, key) {\n *   console.log(key);\n * });\n * // => Logs 'a' then 'b' (iteration order is not guaranteed).\n */\nfunction forEach(collection, iteratee) {\n  var func = isArray(collection) ? arrayEach : baseEach;\n  return func(collection, castFunction(iteratee));\n}\n\nexport default forEach;\n","import eq from './eq.js';\nimport isArrayLike from './isArrayLike.js';\nimport isIndex from './_isIndex.js';\nimport isObject from './isObject.js';\n\n/**\n * Checks if the given arguments are from an iteratee call.\n *\n * @private\n * @param {*} value The potential iteratee value argument.\n * @param {*} index The potential iteratee index or key argument.\n * @param {*} object The potential iteratee object argument.\n * @returns {boolean} Returns `true` if the arguments are from an iteratee call,\n *  else `false`.\n */\nfunction isIterateeCall(value, index, object) {\n  if (!isObject(object)) {\n    return false;\n  }\n  var type = typeof index;\n  if (type == 'number'\n        ? (isArrayLike(object) && isIndex(index, object.length))\n        : (type == 'string' && index in object)\n      ) {\n    return eq(object[index], value);\n  }\n  return false;\n}\n\nexport default isIterateeCall;\n","/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\n'use strict';\nexport var DocumentUri;\n(function (DocumentUri) {\n    function is(value) {\n        return typeof value === 'string';\n    }\n    DocumentUri.is = is;\n})(DocumentUri || (DocumentUri = {}));\nexport var URI;\n(function (URI) {\n    function is(value) {\n        return typeof value === 'string';\n    }\n    URI.is = is;\n})(URI || (URI = {}));\nexport var integer;\n(function (integer) {\n    integer.MIN_VALUE = -2147483648;\n    integer.MAX_VALUE = 2147483647;\n    function is(value) {\n        return typeof value === 'number' && integer.MIN_VALUE <= value && value <= integer.MAX_VALUE;\n    }\n    integer.is = is;\n})(integer || (integer = {}));\nexport var uinteger;\n(function (uinteger) {\n    uinteger.MIN_VALUE = 0;\n    uinteger.MAX_VALUE = 2147483647;\n    function is(value) {\n        return typeof value === 'number' && uinteger.MIN_VALUE <= value && value <= uinteger.MAX_VALUE;\n    }\n    uinteger.is = is;\n})(uinteger || (uinteger = {}));\n/**\n * The Position namespace provides helper functions to work with\n * {@link Position} literals.\n */\nexport var Position;\n(function (Position) {\n    /**\n     * Creates a new Position literal from the given line and character.\n     * @param line The position's line.\n     * @param character The position's character.\n     */\n    function create(line, character) {\n        if (line === Number.MAX_VALUE) {\n            line = uinteger.MAX_VALUE;\n        }\n        if (character === Number.MAX_VALUE) {\n            character = uinteger.MAX_VALUE;\n        }\n        return { line, character };\n    }\n    Position.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Position} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Is.uinteger(candidate.line) && Is.uinteger(candidate.character);\n    }\n    Position.is = is;\n})(Position || (Position = {}));\n/**\n * The Range namespace provides helper functions to work with\n * {@link Range} literals.\n */\nexport var Range;\n(function (Range) {\n    function create(one, two, three, four) {\n        if (Is.uinteger(one) && Is.uinteger(two) && Is.uinteger(three) && Is.uinteger(four)) {\n            return { start: Position.create(one, two), end: Position.create(three, four) };\n        }\n        else if (Position.is(one) && Position.is(two)) {\n            return { start: one, end: two };\n        }\n        else {\n            throw new Error(`Range#create called with invalid arguments[${one}, ${two}, ${three}, ${four}]`);\n        }\n    }\n    Range.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Range} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Position.is(candidate.start) && Position.is(candidate.end);\n    }\n    Range.is = is;\n})(Range || (Range = {}));\n/**\n * The Location namespace provides helper functions to work with\n * {@link Location} literals.\n */\nexport var Location;\n(function (Location) {\n    /**\n     * Creates a Location literal.\n     * @param uri The location's uri.\n     * @param range The location's range.\n     */\n    function create(uri, range) {\n        return { uri, range };\n    }\n    Location.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Location} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && (Is.string(candidate.uri) || Is.undefined(candidate.uri));\n    }\n    Location.is = is;\n})(Location || (Location = {}));\n/**\n * The LocationLink namespace provides helper functions to work with\n * {@link LocationLink} literals.\n */\nexport var LocationLink;\n(function (LocationLink) {\n    /**\n     * Creates a LocationLink literal.\n     * @param targetUri The definition's uri.\n     * @param targetRange The full range of the definition.\n     * @param targetSelectionRange The span of the symbol definition at the target.\n     * @param originSelectionRange The span of the symbol being defined in the originating source file.\n     */\n    function create(targetUri, targetRange, targetSelectionRange, originSelectionRange) {\n        return { targetUri, targetRange, targetSelectionRange, originSelectionRange };\n    }\n    LocationLink.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link LocationLink} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.targetRange) && Is.string(candidate.targetUri)\n            && Range.is(candidate.targetSelectionRange)\n            && (Range.is(candidate.originSelectionRange) || Is.undefined(candidate.originSelectionRange));\n    }\n    LocationLink.is = is;\n})(LocationLink || (LocationLink = {}));\n/**\n * The Color namespace provides helper functions to work with\n * {@link Color} literals.\n */\nexport var Color;\n(function (Color) {\n    /**\n     * Creates a new Color literal.\n     */\n    function create(red, green, blue, alpha) {\n        return {\n            red,\n            green,\n            blue,\n            alpha,\n        };\n    }\n    Color.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Color} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.numberRange(candidate.red, 0, 1)\n            && Is.numberRange(candidate.green, 0, 1)\n            && Is.numberRange(candidate.blue, 0, 1)\n            && Is.numberRange(candidate.alpha, 0, 1);\n    }\n    Color.is = is;\n})(Color || (Color = {}));\n/**\n * The ColorInformation namespace provides helper functions to work with\n * {@link ColorInformation} literals.\n */\nexport var ColorInformation;\n(function (ColorInformation) {\n    /**\n     * Creates a new ColorInformation literal.\n     */\n    function create(range, color) {\n        return {\n            range,\n            color,\n        };\n    }\n    ColorInformation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ColorInformation} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && Color.is(candidate.color);\n    }\n    ColorInformation.is = is;\n})(ColorInformation || (ColorInformation = {}));\n/**\n * The Color namespace provides helper functions to work with\n * {@link ColorPresentation} literals.\n */\nexport var ColorPresentation;\n(function (ColorPresentation) {\n    /**\n     * Creates a new ColorInformation literal.\n     */\n    function create(label, textEdit, additionalTextEdits) {\n        return {\n            label,\n            textEdit,\n            additionalTextEdits,\n        };\n    }\n    ColorPresentation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ColorInformation} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.label)\n            && (Is.undefined(candidate.textEdit) || TextEdit.is(candidate))\n            && (Is.undefined(candidate.additionalTextEdits) || Is.typedArray(candidate.additionalTextEdits, TextEdit.is));\n    }\n    ColorPresentation.is = is;\n})(ColorPresentation || (ColorPresentation = {}));\n/**\n * A set of predefined range kinds.\n */\nexport var FoldingRangeKind;\n(function (FoldingRangeKind) {\n    /**\n     * Folding range for a comment\n     */\n    FoldingRangeKind.Comment = 'comment';\n    /**\n     * Folding range for an import or include\n     */\n    FoldingRangeKind.Imports = 'imports';\n    /**\n     * Folding range for a region (e.g. `#region`)\n     */\n    FoldingRangeKind.Region = 'region';\n})(FoldingRangeKind || (FoldingRangeKind = {}));\n/**\n * The folding range namespace provides helper functions to work with\n * {@link FoldingRange} literals.\n */\nexport var FoldingRange;\n(function (FoldingRange) {\n    /**\n     * Creates a new FoldingRange literal.\n     */\n    function create(startLine, endLine, startCharacter, endCharacter, kind, collapsedText) {\n        const result = {\n            startLine,\n            endLine\n        };\n        if (Is.defined(startCharacter)) {\n            result.startCharacter = startCharacter;\n        }\n        if (Is.defined(endCharacter)) {\n            result.endCharacter = endCharacter;\n        }\n        if (Is.defined(kind)) {\n            result.kind = kind;\n        }\n        if (Is.defined(collapsedText)) {\n            result.collapsedText = collapsedText;\n        }\n        return result;\n    }\n    FoldingRange.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link FoldingRange} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.uinteger(candidate.startLine) && Is.uinteger(candidate.startLine)\n            && (Is.undefined(candidate.startCharacter) || Is.uinteger(candidate.startCharacter))\n            && (Is.undefined(candidate.endCharacter) || Is.uinteger(candidate.endCharacter))\n            && (Is.undefined(candidate.kind) || Is.string(candidate.kind));\n    }\n    FoldingRange.is = is;\n})(FoldingRange || (FoldingRange = {}));\n/**\n * The DiagnosticRelatedInformation namespace provides helper functions to work with\n * {@link DiagnosticRelatedInformation} literals.\n */\nexport var DiagnosticRelatedInformation;\n(function (DiagnosticRelatedInformation) {\n    /**\n     * Creates a new DiagnosticRelatedInformation literal.\n     */\n    function create(location, message) {\n        return {\n            location,\n            message\n        };\n    }\n    DiagnosticRelatedInformation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DiagnosticRelatedInformation} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Location.is(candidate.location) && Is.string(candidate.message);\n    }\n    DiagnosticRelatedInformation.is = is;\n})(DiagnosticRelatedInformation || (DiagnosticRelatedInformation = {}));\n/**\n * The diagnostic's severity.\n */\nexport var DiagnosticSeverity;\n(function (DiagnosticSeverity) {\n    /**\n     * Reports an error.\n     */\n    DiagnosticSeverity.Error = 1;\n    /**\n     * Reports a warning.\n     */\n    DiagnosticSeverity.Warning = 2;\n    /**\n     * Reports an information.\n     */\n    DiagnosticSeverity.Information = 3;\n    /**\n     * Reports a hint.\n     */\n    DiagnosticSeverity.Hint = 4;\n})(DiagnosticSeverity || (DiagnosticSeverity = {}));\n/**\n * The diagnostic tags.\n *\n * @since 3.15.0\n */\nexport var DiagnosticTag;\n(function (DiagnosticTag) {\n    /**\n     * Unused or unnecessary code.\n     *\n     * Clients are allowed to render diagnostics with this tag faded out instead of having\n     * an error squiggle.\n     */\n    DiagnosticTag.Unnecessary = 1;\n    /**\n     * Deprecated or obsolete code.\n     *\n     * Clients are allowed to rendered diagnostics with this tag strike through.\n     */\n    DiagnosticTag.Deprecated = 2;\n})(DiagnosticTag || (DiagnosticTag = {}));\n/**\n * The CodeDescription namespace provides functions to deal with descriptions for diagnostic codes.\n *\n * @since 3.16.0\n */\nexport var CodeDescription;\n(function (CodeDescription) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.href);\n    }\n    CodeDescription.is = is;\n})(CodeDescription || (CodeDescription = {}));\n/**\n * The Diagnostic namespace provides helper functions to work with\n * {@link Diagnostic} literals.\n */\nexport var Diagnostic;\n(function (Diagnostic) {\n    /**\n     * Creates a new Diagnostic literal.\n     */\n    function create(range, message, severity, code, source, relatedInformation) {\n        let result = { range, message };\n        if (Is.defined(severity)) {\n            result.severity = severity;\n        }\n        if (Is.defined(code)) {\n            result.code = code;\n        }\n        if (Is.defined(source)) {\n            result.source = source;\n        }\n        if (Is.defined(relatedInformation)) {\n            result.relatedInformation = relatedInformation;\n        }\n        return result;\n    }\n    Diagnostic.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Diagnostic} interface.\n     */\n    function is(value) {\n        var _a;\n        let candidate = value;\n        return Is.defined(candidate)\n            && Range.is(candidate.range)\n            && Is.string(candidate.message)\n            && (Is.number(candidate.severity) || Is.undefined(candidate.severity))\n            && (Is.integer(candidate.code) || Is.string(candidate.code) || Is.undefined(candidate.code))\n            && (Is.undefined(candidate.codeDescription) || (Is.string((_a = candidate.codeDescription) === null || _a === void 0 ? void 0 : _a.href)))\n            && (Is.string(candidate.source) || Is.undefined(candidate.source))\n            && (Is.undefined(candidate.relatedInformation) || Is.typedArray(candidate.relatedInformation, DiagnosticRelatedInformation.is));\n    }\n    Diagnostic.is = is;\n})(Diagnostic || (Diagnostic = {}));\n/**\n * The Command namespace provides helper functions to work with\n * {@link Command} literals.\n */\nexport var Command;\n(function (Command) {\n    /**\n     * Creates a new Command literal.\n     */\n    function create(title, command, ...args) {\n        let result = { title, command };\n        if (Is.defined(args) && args.length > 0) {\n            result.arguments = args;\n        }\n        return result;\n    }\n    Command.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Command} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.title) && Is.string(candidate.command);\n    }\n    Command.is = is;\n})(Command || (Command = {}));\n/**\n * The TextEdit namespace provides helper function to create replace,\n * insert and delete edits more easily.\n */\nexport var TextEdit;\n(function (TextEdit) {\n    /**\n     * Creates a replace text edit.\n     * @param range The range of text to be replaced.\n     * @param newText The new text.\n     */\n    function replace(range, newText) {\n        return { range, newText };\n    }\n    TextEdit.replace = replace;\n    /**\n     * Creates an insert text edit.\n     * @param position The position to insert the text at.\n     * @param newText The text to be inserted.\n     */\n    function insert(position, newText) {\n        return { range: { start: position, end: position }, newText };\n    }\n    TextEdit.insert = insert;\n    /**\n     * Creates a delete text edit.\n     * @param range The range of text to be deleted.\n     */\n    function del(range) {\n        return { range, newText: '' };\n    }\n    TextEdit.del = del;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate)\n            && Is.string(candidate.newText)\n            && Range.is(candidate.range);\n    }\n    TextEdit.is = is;\n})(TextEdit || (TextEdit = {}));\nexport var ChangeAnnotation;\n(function (ChangeAnnotation) {\n    function create(label, needsConfirmation, description) {\n        const result = { label };\n        if (needsConfirmation !== undefined) {\n            result.needsConfirmation = needsConfirmation;\n        }\n        if (description !== undefined) {\n            result.description = description;\n        }\n        return result;\n    }\n    ChangeAnnotation.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.label) &&\n            (Is.boolean(candidate.needsConfirmation) || candidate.needsConfirmation === undefined) &&\n            (Is.string(candidate.description) || candidate.description === undefined);\n    }\n    ChangeAnnotation.is = is;\n})(ChangeAnnotation || (ChangeAnnotation = {}));\nexport var ChangeAnnotationIdentifier;\n(function (ChangeAnnotationIdentifier) {\n    function is(value) {\n        const candidate = value;\n        return Is.string(candidate);\n    }\n    ChangeAnnotationIdentifier.is = is;\n})(ChangeAnnotationIdentifier || (ChangeAnnotationIdentifier = {}));\nexport var AnnotatedTextEdit;\n(function (AnnotatedTextEdit) {\n    /**\n     * Creates an annotated replace text edit.\n     *\n     * @param range The range of text to be replaced.\n     * @param newText The new text.\n     * @param annotation The annotation.\n     */\n    function replace(range, newText, annotation) {\n        return { range, newText, annotationId: annotation };\n    }\n    AnnotatedTextEdit.replace = replace;\n    /**\n     * Creates an annotated insert text edit.\n     *\n     * @param position The position to insert the text at.\n     * @param newText The text to be inserted.\n     * @param annotation The annotation.\n     */\n    function insert(position, newText, annotation) {\n        return { range: { start: position, end: position }, newText, annotationId: annotation };\n    }\n    AnnotatedTextEdit.insert = insert;\n    /**\n     * Creates an annotated delete text edit.\n     *\n     * @param range The range of text to be deleted.\n     * @param annotation The annotation.\n     */\n    function del(range, annotation) {\n        return { range, newText: '', annotationId: annotation };\n    }\n    AnnotatedTextEdit.del = del;\n    function is(value) {\n        const candidate = value;\n        return TextEdit.is(candidate) && (ChangeAnnotation.is(candidate.annotationId) || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    AnnotatedTextEdit.is = is;\n})(AnnotatedTextEdit || (AnnotatedTextEdit = {}));\n/**\n * The TextDocumentEdit namespace provides helper function to create\n * an edit that manipulates a text document.\n */\nexport var TextDocumentEdit;\n(function (TextDocumentEdit) {\n    /**\n     * Creates a new `TextDocumentEdit`\n     */\n    function create(textDocument, edits) {\n        return { textDocument, edits };\n    }\n    TextDocumentEdit.create = create;\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate)\n            && OptionalVersionedTextDocumentIdentifier.is(candidate.textDocument)\n            && Array.isArray(candidate.edits);\n    }\n    TextDocumentEdit.is = is;\n})(TextDocumentEdit || (TextDocumentEdit = {}));\nexport var CreateFile;\n(function (CreateFile) {\n    function create(uri, options, annotation) {\n        let result = {\n            kind: 'create',\n            uri\n        };\n        if (options !== undefined && (options.overwrite !== undefined || options.ignoreIfExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    CreateFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'create' && Is.string(candidate.uri) && (candidate.options === undefined ||\n            ((candidate.options.overwrite === undefined || Is.boolean(candidate.options.overwrite)) && (candidate.options.ignoreIfExists === undefined || Is.boolean(candidate.options.ignoreIfExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    CreateFile.is = is;\n})(CreateFile || (CreateFile = {}));\nexport var RenameFile;\n(function (RenameFile) {\n    function create(oldUri, newUri, options, annotation) {\n        let result = {\n            kind: 'rename',\n            oldUri,\n            newUri\n        };\n        if (options !== undefined && (options.overwrite !== undefined || options.ignoreIfExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    RenameFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'rename' && Is.string(candidate.oldUri) && Is.string(candidate.newUri) && (candidate.options === undefined ||\n            ((candidate.options.overwrite === undefined || Is.boolean(candidate.options.overwrite)) && (candidate.options.ignoreIfExists === undefined || Is.boolean(candidate.options.ignoreIfExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    RenameFile.is = is;\n})(RenameFile || (RenameFile = {}));\nexport var DeleteFile;\n(function (DeleteFile) {\n    function create(uri, options, annotation) {\n        let result = {\n            kind: 'delete',\n            uri\n        };\n        if (options !== undefined && (options.recursive !== undefined || options.ignoreIfNotExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    DeleteFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'delete' && Is.string(candidate.uri) && (candidate.options === undefined ||\n            ((candidate.options.recursive === undefined || Is.boolean(candidate.options.recursive)) && (candidate.options.ignoreIfNotExists === undefined || Is.boolean(candidate.options.ignoreIfNotExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    DeleteFile.is = is;\n})(DeleteFile || (DeleteFile = {}));\nexport var WorkspaceEdit;\n(function (WorkspaceEdit) {\n    function is(value) {\n        let candidate = value;\n        return candidate &&\n            (candidate.changes !== undefined || candidate.documentChanges !== undefined) &&\n            (candidate.documentChanges === undefined || candidate.documentChanges.every((change) => {\n                if (Is.string(change.kind)) {\n                    return CreateFile.is(change) || RenameFile.is(change) || DeleteFile.is(change);\n                }\n                else {\n                    return TextDocumentEdit.is(change);\n                }\n            }));\n    }\n    WorkspaceEdit.is = is;\n})(WorkspaceEdit || (WorkspaceEdit = {}));\nclass TextEditChangeImpl {\n    constructor(edits, changeAnnotations) {\n        this.edits = edits;\n        this.changeAnnotations = changeAnnotations;\n    }\n    insert(position, newText, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.insert(position, newText);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.insert(position, newText, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.insert(position, newText, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    replace(range, newText, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.replace(range, newText);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.replace(range, newText, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.replace(range, newText, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    delete(range, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.del(range);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.del(range, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.del(range, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    add(edit) {\n        this.edits.push(edit);\n    }\n    all() {\n        return this.edits;\n    }\n    clear() {\n        this.edits.splice(0, this.edits.length);\n    }\n    assertChangeAnnotations(value) {\n        if (value === undefined) {\n            throw new Error(`Text edit change is not configured to manage change annotations.`);\n        }\n    }\n}\n/**\n * A helper class\n */\nclass ChangeAnnotations {\n    constructor(annotations) {\n        this._annotations = annotations === undefined ? Object.create(null) : annotations;\n        this._counter = 0;\n        this._size = 0;\n    }\n    all() {\n        return this._annotations;\n    }\n    get size() {\n        return this._size;\n    }\n    manage(idOrAnnotation, annotation) {\n        let id;\n        if (ChangeAnnotationIdentifier.is(idOrAnnotation)) {\n            id = idOrAnnotation;\n        }\n        else {\n            id = this.nextId();\n            annotation = idOrAnnotation;\n        }\n        if (this._annotations[id] !== undefined) {\n            throw new Error(`Id ${id} is already in use.`);\n        }\n        if (annotation === undefined) {\n            throw new Error(`No annotation provided for id ${id}`);\n        }\n        this._annotations[id] = annotation;\n        this._size++;\n        return id;\n    }\n    nextId() {\n        this._counter++;\n        return this._counter.toString();\n    }\n}\n/**\n * A workspace change helps constructing changes to a workspace.\n */\nexport class WorkspaceChange {\n    constructor(workspaceEdit) {\n        this._textEditChanges = Object.create(null);\n        if (workspaceEdit !== undefined) {\n            this._workspaceEdit = workspaceEdit;\n            if (workspaceEdit.documentChanges) {\n                this._changeAnnotations = new ChangeAnnotations(workspaceEdit.changeAnnotations);\n                workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n                workspaceEdit.documentChanges.forEach((change) => {\n                    if (TextDocumentEdit.is(change)) {\n                        const textEditChange = new TextEditChangeImpl(change.edits, this._changeAnnotations);\n                        this._textEditChanges[change.textDocument.uri] = textEditChange;\n                    }\n                });\n            }\n            else if (workspaceEdit.changes) {\n                Object.keys(workspaceEdit.changes).forEach((key) => {\n                    const textEditChange = new TextEditChangeImpl(workspaceEdit.changes[key]);\n                    this._textEditChanges[key] = textEditChange;\n                });\n            }\n        }\n        else {\n            this._workspaceEdit = {};\n        }\n    }\n    /**\n     * Returns the underlying {@link WorkspaceEdit} literal\n     * use to be returned from a workspace edit operation like rename.\n     */\n    get edit() {\n        this.initDocumentChanges();\n        if (this._changeAnnotations !== undefined) {\n            if (this._changeAnnotations.size === 0) {\n                this._workspaceEdit.changeAnnotations = undefined;\n            }\n            else {\n                this._workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n            }\n        }\n        return this._workspaceEdit;\n    }\n    getTextEditChange(key) {\n        if (OptionalVersionedTextDocumentIdentifier.is(key)) {\n            this.initDocumentChanges();\n            if (this._workspaceEdit.documentChanges === undefined) {\n                throw new Error('Workspace edit is not configured for document changes.');\n            }\n            const textDocument = { uri: key.uri, version: key.version };\n            let result = this._textEditChanges[textDocument.uri];\n            if (!result) {\n                const edits = [];\n                const textDocumentEdit = {\n                    textDocument,\n                    edits\n                };\n                this._workspaceEdit.documentChanges.push(textDocumentEdit);\n                result = new TextEditChangeImpl(edits, this._changeAnnotations);\n                this._textEditChanges[textDocument.uri] = result;\n            }\n            return result;\n        }\n        else {\n            this.initChanges();\n            if (this._workspaceEdit.changes === undefined) {\n                throw new Error('Workspace edit is not configured for normal text edit changes.');\n            }\n            let result = this._textEditChanges[key];\n            if (!result) {\n                let edits = [];\n                this._workspaceEdit.changes[key] = edits;\n                result = new TextEditChangeImpl(edits);\n                this._textEditChanges[key] = result;\n            }\n            return result;\n        }\n    }\n    initDocumentChanges() {\n        if (this._workspaceEdit.documentChanges === undefined && this._workspaceEdit.changes === undefined) {\n            this._changeAnnotations = new ChangeAnnotations();\n            this._workspaceEdit.documentChanges = [];\n            this._workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n        }\n    }\n    initChanges() {\n        if (this._workspaceEdit.documentChanges === undefined && this._workspaceEdit.changes === undefined) {\n            this._workspaceEdit.changes = Object.create(null);\n        }\n    }\n    createFile(uri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = CreateFile.create(uri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = CreateFile.create(uri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    renameFile(oldUri, newUri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = RenameFile.create(oldUri, newUri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = RenameFile.create(oldUri, newUri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    deleteFile(uri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = DeleteFile.create(uri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = DeleteFile.create(uri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n}\n/**\n * The TextDocumentIdentifier namespace provides helper functions to work with\n * {@link TextDocumentIdentifier} literals.\n */\nexport var TextDocumentIdentifier;\n(function (TextDocumentIdentifier) {\n    /**\n     * Creates a new TextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     */\n    function create(uri) {\n        return { uri };\n    }\n    TextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link TextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri);\n    }\n    TextDocumentIdentifier.is = is;\n})(TextDocumentIdentifier || (TextDocumentIdentifier = {}));\n/**\n * The VersionedTextDocumentIdentifier namespace provides helper functions to work with\n * {@link VersionedTextDocumentIdentifier} literals.\n */\nexport var VersionedTextDocumentIdentifier;\n(function (VersionedTextDocumentIdentifier) {\n    /**\n     * Creates a new VersionedTextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     * @param version The document's version.\n     */\n    function create(uri, version) {\n        return { uri, version };\n    }\n    VersionedTextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link VersionedTextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && Is.integer(candidate.version);\n    }\n    VersionedTextDocumentIdentifier.is = is;\n})(VersionedTextDocumentIdentifier || (VersionedTextDocumentIdentifier = {}));\n/**\n * The OptionalVersionedTextDocumentIdentifier namespace provides helper functions to work with\n * {@link OptionalVersionedTextDocumentIdentifier} literals.\n */\nexport var OptionalVersionedTextDocumentIdentifier;\n(function (OptionalVersionedTextDocumentIdentifier) {\n    /**\n     * Creates a new OptionalVersionedTextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     * @param version The document's version.\n     */\n    function create(uri, version) {\n        return { uri, version };\n    }\n    OptionalVersionedTextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link OptionalVersionedTextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && (candidate.version === null || Is.integer(candidate.version));\n    }\n    OptionalVersionedTextDocumentIdentifier.is = is;\n})(OptionalVersionedTextDocumentIdentifier || (OptionalVersionedTextDocumentIdentifier = {}));\n/**\n * The TextDocumentItem namespace provides helper functions to work with\n * {@link TextDocumentItem} literals.\n */\nexport var TextDocumentItem;\n(function (TextDocumentItem) {\n    /**\n     * Creates a new TextDocumentItem literal.\n     * @param uri The document's uri.\n     * @param languageId The document's language identifier.\n     * @param version The document's version number.\n     * @param text The document's text.\n     */\n    function create(uri, languageId, version, text) {\n        return { uri, languageId, version, text };\n    }\n    TextDocumentItem.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link TextDocumentItem} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && Is.string(candidate.languageId) && Is.integer(candidate.version) && Is.string(candidate.text);\n    }\n    TextDocumentItem.is = is;\n})(TextDocumentItem || (TextDocumentItem = {}));\n/**\n * Describes the content type that a client supports in various\n * result literals like `Hover`, `ParameterInfo` or `CompletionItem`.\n *\n * Please note that `MarkupKinds` must not start with a `$`. This kinds\n * are reserved for internal usage.\n */\nexport var MarkupKind;\n(function (MarkupKind) {\n    /**\n     * Plain text is supported as a content format\n     */\n    MarkupKind.PlainText = 'plaintext';\n    /**\n     * Markdown is supported as a content format\n     */\n    MarkupKind.Markdown = 'markdown';\n    /**\n     * Checks whether the given value is a value of the {@link MarkupKind} type.\n     */\n    function is(value) {\n        const candidate = value;\n        return candidate === MarkupKind.PlainText || candidate === MarkupKind.Markdown;\n    }\n    MarkupKind.is = is;\n})(MarkupKind || (MarkupKind = {}));\nexport var MarkupContent;\n(function (MarkupContent) {\n    /**\n     * Checks whether the given value conforms to the {@link MarkupContent} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(value) && MarkupKind.is(candidate.kind) && Is.string(candidate.value);\n    }\n    MarkupContent.is = is;\n})(MarkupContent || (MarkupContent = {}));\n/**\n * The kind of a completion entry.\n */\nexport var CompletionItemKind;\n(function (CompletionItemKind) {\n    CompletionItemKind.Text = 1;\n    CompletionItemKind.Method = 2;\n    CompletionItemKind.Function = 3;\n    CompletionItemKind.Constructor = 4;\n    CompletionItemKind.Field = 5;\n    CompletionItemKind.Variable = 6;\n    CompletionItemKind.Class = 7;\n    CompletionItemKind.Interface = 8;\n    CompletionItemKind.Module = 9;\n    CompletionItemKind.Property = 10;\n    CompletionItemKind.Unit = 11;\n    CompletionItemKind.Value = 12;\n    CompletionItemKind.Enum = 13;\n    CompletionItemKind.Keyword = 14;\n    CompletionItemKind.Snippet = 15;\n    CompletionItemKind.Color = 16;\n    CompletionItemKind.File = 17;\n    CompletionItemKind.Reference = 18;\n    CompletionItemKind.Folder = 19;\n    CompletionItemKind.EnumMember = 20;\n    CompletionItemKind.Constant = 21;\n    CompletionItemKind.Struct = 22;\n    CompletionItemKind.Event = 23;\n    CompletionItemKind.Operator = 24;\n    CompletionItemKind.TypeParameter = 25;\n})(CompletionItemKind || (CompletionItemKind = {}));\n/**\n * Defines whether the insert text in a completion item should be interpreted as\n * plain text or a snippet.\n */\nexport var InsertTextFormat;\n(function (InsertTextFormat) {\n    /**\n     * The primary text to be inserted is treated as a plain string.\n     */\n    InsertTextFormat.PlainText = 1;\n    /**\n     * The primary text to be inserted is treated as a snippet.\n     *\n     * A snippet can define tab stops and placeholders with `$1`, `$2`\n     * and `${3:foo}`. `$0` defines the final tab stop, it defaults to\n     * the end of the snippet. Placeholders with equal identifiers are linked,\n     * that is typing in one will update others too.\n     *\n     * See also: https://microsoft.github.io/language-server-protocol/specifications/specification-current/#snippet_syntax\n     */\n    InsertTextFormat.Snippet = 2;\n})(InsertTextFormat || (InsertTextFormat = {}));\n/**\n * Completion item tags are extra annotations that tweak the rendering of a completion\n * item.\n *\n * @since 3.15.0\n */\nexport var CompletionItemTag;\n(function (CompletionItemTag) {\n    /**\n     * Render a completion as obsolete, usually using a strike-out.\n     */\n    CompletionItemTag.Deprecated = 1;\n})(CompletionItemTag || (CompletionItemTag = {}));\n/**\n * The InsertReplaceEdit namespace provides functions to deal with insert / replace edits.\n *\n * @since 3.16.0\n */\nexport var InsertReplaceEdit;\n(function (InsertReplaceEdit) {\n    /**\n     * Creates a new insert / replace edit\n     */\n    function create(newText, insert, replace) {\n        return { newText, insert, replace };\n    }\n    InsertReplaceEdit.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link InsertReplaceEdit} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return candidate && Is.string(candidate.newText) && Range.is(candidate.insert) && Range.is(candidate.replace);\n    }\n    InsertReplaceEdit.is = is;\n})(InsertReplaceEdit || (InsertReplaceEdit = {}));\n/**\n * How whitespace and indentation is handled during completion\n * item insertion.\n *\n * @since 3.16.0\n */\nexport var InsertTextMode;\n(function (InsertTextMode) {\n    /**\n     * The insertion or replace strings is taken as it is. If the\n     * value is multi line the lines below the cursor will be\n     * inserted using the indentation defined in the string value.\n     * The client will not apply any kind of adjustments to the\n     * string.\n     */\n    InsertTextMode.asIs = 1;\n    /**\n     * The editor adjusts leading whitespace of new lines so that\n     * they match the indentation up to the cursor of the line for\n     * which the item is accepted.\n     *\n     * Consider a line like this: <2tabs><cursor><3tabs>foo. Accepting a\n     * multi line completion item is indented using 2 tabs and all\n     * following lines inserted will be indented using 2 tabs as well.\n     */\n    InsertTextMode.adjustIndentation = 2;\n})(InsertTextMode || (InsertTextMode = {}));\nexport var CompletionItemLabelDetails;\n(function (CompletionItemLabelDetails) {\n    function is(value) {\n        const candidate = value;\n        return candidate && (Is.string(candidate.detail) || candidate.detail === undefined) &&\n            (Is.string(candidate.description) || candidate.description === undefined);\n    }\n    CompletionItemLabelDetails.is = is;\n})(CompletionItemLabelDetails || (CompletionItemLabelDetails = {}));\n/**\n * The CompletionItem namespace provides functions to deal with\n * completion items.\n */\nexport var CompletionItem;\n(function (CompletionItem) {\n    /**\n     * Create a completion item and seed it with a label.\n     * @param label The completion item's label\n     */\n    function create(label) {\n        return { label };\n    }\n    CompletionItem.create = create;\n})(CompletionItem || (CompletionItem = {}));\n/**\n * The CompletionList namespace provides functions to deal with\n * completion lists.\n */\nexport var CompletionList;\n(function (CompletionList) {\n    /**\n     * Creates a new completion list.\n     *\n     * @param items The completion items.\n     * @param isIncomplete The list is not complete.\n     */\n    function create(items, isIncomplete) {\n        return { items: items ? items : [], isIncomplete: !!isIncomplete };\n    }\n    CompletionList.create = create;\n})(CompletionList || (CompletionList = {}));\nexport var MarkedString;\n(function (MarkedString) {\n    /**\n     * Creates a marked string from plain text.\n     *\n     * @param plainText The plain text.\n     */\n    function fromPlainText(plainText) {\n        return plainText.replace(/[\\\\`*_{}[\\]()#+\\-.!]/g, '\\\\$&'); // escape markdown syntax tokens: http://daringfireball.net/projects/markdown/syntax#backslash\n    }\n    MarkedString.fromPlainText = fromPlainText;\n    /**\n     * Checks whether the given value conforms to the {@link MarkedString} type.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.string(candidate) || (Is.objectLiteral(candidate) && Is.string(candidate.language) && Is.string(candidate.value));\n    }\n    MarkedString.is = is;\n})(MarkedString || (MarkedString = {}));\nexport var Hover;\n(function (Hover) {\n    /**\n     * Checks whether the given value conforms to the {@link Hover} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return !!candidate && Is.objectLiteral(candidate) && (MarkupContent.is(candidate.contents) ||\n            MarkedString.is(candidate.contents) ||\n            Is.typedArray(candidate.contents, MarkedString.is)) && (value.range === undefined || Range.is(value.range));\n    }\n    Hover.is = is;\n})(Hover || (Hover = {}));\n/**\n * The ParameterInformation namespace provides helper functions to work with\n * {@link ParameterInformation} literals.\n */\nexport var ParameterInformation;\n(function (ParameterInformation) {\n    /**\n     * Creates a new parameter information literal.\n     *\n     * @param label A label string.\n     * @param documentation A doc string.\n     */\n    function create(label, documentation) {\n        return documentation ? { label, documentation } : { label };\n    }\n    ParameterInformation.create = create;\n})(ParameterInformation || (ParameterInformation = {}));\n/**\n * The SignatureInformation namespace provides helper functions to work with\n * {@link SignatureInformation} literals.\n */\nexport var SignatureInformation;\n(function (SignatureInformation) {\n    function create(label, documentation, ...parameters) {\n        let result = { label };\n        if (Is.defined(documentation)) {\n            result.documentation = documentation;\n        }\n        if (Is.defined(parameters)) {\n            result.parameters = parameters;\n        }\n        else {\n            result.parameters = [];\n        }\n        return result;\n    }\n    SignatureInformation.create = create;\n})(SignatureInformation || (SignatureInformation = {}));\n/**\n * A document highlight kind.\n */\nexport var DocumentHighlightKind;\n(function (DocumentHighlightKind) {\n    /**\n     * A textual occurrence.\n     */\n    DocumentHighlightKind.Text = 1;\n    /**\n     * Read-access of a symbol, like reading a variable.\n     */\n    DocumentHighlightKind.Read = 2;\n    /**\n     * Write-access of a symbol, like writing to a variable.\n     */\n    DocumentHighlightKind.Write = 3;\n})(DocumentHighlightKind || (DocumentHighlightKind = {}));\n/**\n * DocumentHighlight namespace to provide helper functions to work with\n * {@link DocumentHighlight} literals.\n */\nexport var DocumentHighlight;\n(function (DocumentHighlight) {\n    /**\n     * Create a DocumentHighlight object.\n     * @param range The range the highlight applies to.\n     * @param kind The highlight kind\n     */\n    function create(range, kind) {\n        let result = { range };\n        if (Is.number(kind)) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    DocumentHighlight.create = create;\n})(DocumentHighlight || (DocumentHighlight = {}));\n/**\n * A symbol kind.\n */\nexport var SymbolKind;\n(function (SymbolKind) {\n    SymbolKind.File = 1;\n    SymbolKind.Module = 2;\n    SymbolKind.Namespace = 3;\n    SymbolKind.Package = 4;\n    SymbolKind.Class = 5;\n    SymbolKind.Method = 6;\n    SymbolKind.Property = 7;\n    SymbolKind.Field = 8;\n    SymbolKind.Constructor = 9;\n    SymbolKind.Enum = 10;\n    SymbolKind.Interface = 11;\n    SymbolKind.Function = 12;\n    SymbolKind.Variable = 13;\n    SymbolKind.Constant = 14;\n    SymbolKind.String = 15;\n    SymbolKind.Number = 16;\n    SymbolKind.Boolean = 17;\n    SymbolKind.Array = 18;\n    SymbolKind.Object = 19;\n    SymbolKind.Key = 20;\n    SymbolKind.Null = 21;\n    SymbolKind.EnumMember = 22;\n    SymbolKind.Struct = 23;\n    SymbolKind.Event = 24;\n    SymbolKind.Operator = 25;\n    SymbolKind.TypeParameter = 26;\n})(SymbolKind || (SymbolKind = {}));\n/**\n * Symbol tags are extra annotations that tweak the rendering of a symbol.\n *\n * @since 3.16\n */\nexport var SymbolTag;\n(function (SymbolTag) {\n    /**\n     * Render a symbol as obsolete, usually using a strike-out.\n     */\n    SymbolTag.Deprecated = 1;\n})(SymbolTag || (SymbolTag = {}));\nexport var SymbolInformation;\n(function (SymbolInformation) {\n    /**\n     * Creates a new symbol information literal.\n     *\n     * @param name The name of the symbol.\n     * @param kind The kind of the symbol.\n     * @param range The range of the location of the symbol.\n     * @param uri The resource of the location of symbol.\n     * @param containerName The name of the symbol containing the symbol.\n     */\n    function create(name, kind, range, uri, containerName) {\n        let result = {\n            name,\n            kind,\n            location: { uri, range }\n        };\n        if (containerName) {\n            result.containerName = containerName;\n        }\n        return result;\n    }\n    SymbolInformation.create = create;\n})(SymbolInformation || (SymbolInformation = {}));\nexport var WorkspaceSymbol;\n(function (WorkspaceSymbol) {\n    /**\n     * Create a new workspace symbol.\n     *\n     * @param name The name of the symbol.\n     * @param kind The kind of the symbol.\n     * @param uri The resource of the location of the symbol.\n     * @param range An options range of the location.\n     * @returns A WorkspaceSymbol.\n     */\n    function create(name, kind, uri, range) {\n        return range !== undefined\n            ? { name, kind, location: { uri, range } }\n            : { name, kind, location: { uri } };\n    }\n    WorkspaceSymbol.create = create;\n})(WorkspaceSymbol || (WorkspaceSymbol = {}));\nexport var DocumentSymbol;\n(function (DocumentSymbol) {\n    /**\n     * Creates a new symbol information literal.\n     *\n     * @param name The name of the symbol.\n     * @param detail The detail of the symbol.\n     * @param kind The kind of the symbol.\n     * @param range The range of the symbol.\n     * @param selectionRange The selectionRange of the symbol.\n     * @param children Children of the symbol.\n     */\n    function create(name, detail, kind, range, selectionRange, children) {\n        let result = {\n            name,\n            detail,\n            kind,\n            range,\n            selectionRange\n        };\n        if (children !== undefined) {\n            result.children = children;\n        }\n        return result;\n    }\n    DocumentSymbol.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DocumentSymbol} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return candidate &&\n            Is.string(candidate.name) && Is.number(candidate.kind) &&\n            Range.is(candidate.range) && Range.is(candidate.selectionRange) &&\n            (candidate.detail === undefined || Is.string(candidate.detail)) &&\n            (candidate.deprecated === undefined || Is.boolean(candidate.deprecated)) &&\n            (candidate.children === undefined || Array.isArray(candidate.children)) &&\n            (candidate.tags === undefined || Array.isArray(candidate.tags));\n    }\n    DocumentSymbol.is = is;\n})(DocumentSymbol || (DocumentSymbol = {}));\n/**\n * A set of predefined code action kinds\n */\nexport var CodeActionKind;\n(function (CodeActionKind) {\n    /**\n     * Empty kind.\n     */\n    CodeActionKind.Empty = '';\n    /**\n     * Base kind for quickfix actions: 'quickfix'\n     */\n    CodeActionKind.QuickFix = 'quickfix';\n    /**\n     * Base kind for refactoring actions: 'refactor'\n     */\n    CodeActionKind.Refactor = 'refactor';\n    /**\n     * Base kind for refactoring extraction actions: 'refactor.extract'\n     *\n     * Example extract actions:\n     *\n     * - Extract method\n     * - Extract function\n     * - Extract variable\n     * - Extract interface from class\n     * - ...\n     */\n    CodeActionKind.RefactorExtract = 'refactor.extract';\n    /**\n     * Base kind for refactoring inline actions: 'refactor.inline'\n     *\n     * Example inline actions:\n     *\n     * - Inline function\n     * - Inline variable\n     * - Inline constant\n     * - ...\n     */\n    CodeActionKind.RefactorInline = 'refactor.inline';\n    /**\n     * Base kind for refactoring rewrite actions: 'refactor.rewrite'\n     *\n     * Example rewrite actions:\n     *\n     * - Convert JavaScript function to class\n     * - Add or remove parameter\n     * - Encapsulate field\n     * - Make method static\n     * - Move method to base class\n     * - ...\n     */\n    CodeActionKind.RefactorRewrite = 'refactor.rewrite';\n    /**\n     * Base kind for source actions: `source`\n     *\n     * Source code actions apply to the entire file.\n     */\n    CodeActionKind.Source = 'source';\n    /**\n     * Base kind for an organize imports source action: `source.organizeImports`\n     */\n    CodeActionKind.SourceOrganizeImports = 'source.organizeImports';\n    /**\n     * Base kind for auto-fix source actions: `source.fixAll`.\n     *\n     * Fix all actions automatically fix errors that have a clear fix that do not require user input.\n     * They should not suppress errors or perform unsafe fixes such as generating new types or classes.\n     *\n     * @since 3.15.0\n     */\n    CodeActionKind.SourceFixAll = 'source.fixAll';\n})(CodeActionKind || (CodeActionKind = {}));\n/**\n * The reason why code actions were requested.\n *\n * @since 3.17.0\n */\nexport var CodeActionTriggerKind;\n(function (CodeActionTriggerKind) {\n    /**\n     * Code actions were explicitly requested by the user or by an extension.\n     */\n    CodeActionTriggerKind.Invoked = 1;\n    /**\n     * Code actions were requested automatically.\n     *\n     * This typically happens when current selection in a file changes, but can\n     * also be triggered when file content changes.\n     */\n    CodeActionTriggerKind.Automatic = 2;\n})(CodeActionTriggerKind || (CodeActionTriggerKind = {}));\n/**\n * The CodeActionContext namespace provides helper functions to work with\n * {@link CodeActionContext} literals.\n */\nexport var CodeActionContext;\n(function (CodeActionContext) {\n    /**\n     * Creates a new CodeActionContext literal.\n     */\n    function create(diagnostics, only, triggerKind) {\n        let result = { diagnostics };\n        if (only !== undefined && only !== null) {\n            result.only = only;\n        }\n        if (triggerKind !== undefined && triggerKind !== null) {\n            result.triggerKind = triggerKind;\n        }\n        return result;\n    }\n    CodeActionContext.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link CodeActionContext} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.typedArray(candidate.diagnostics, Diagnostic.is)\n            && (candidate.only === undefined || Is.typedArray(candidate.only, Is.string))\n            && (candidate.triggerKind === undefined || candidate.triggerKind === CodeActionTriggerKind.Invoked || candidate.triggerKind === CodeActionTriggerKind.Automatic);\n    }\n    CodeActionContext.is = is;\n})(CodeActionContext || (CodeActionContext = {}));\nexport var CodeAction;\n(function (CodeAction) {\n    function create(title, kindOrCommandOrEdit, kind) {\n        let result = { title };\n        let checkKind = true;\n        if (typeof kindOrCommandOrEdit === 'string') {\n            checkKind = false;\n            result.kind = kindOrCommandOrEdit;\n        }\n        else if (Command.is(kindOrCommandOrEdit)) {\n            result.command = kindOrCommandOrEdit;\n        }\n        else {\n            result.edit = kindOrCommandOrEdit;\n        }\n        if (checkKind && kind !== undefined) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    CodeAction.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && Is.string(candidate.title) &&\n            (candidate.diagnostics === undefined || Is.typedArray(candidate.diagnostics, Diagnostic.is)) &&\n            (candidate.kind === undefined || Is.string(candidate.kind)) &&\n            (candidate.edit !== undefined || candidate.command !== undefined) &&\n            (candidate.command === undefined || Command.is(candidate.command)) &&\n            (candidate.isPreferred === undefined || Is.boolean(candidate.isPreferred)) &&\n            (candidate.edit === undefined || WorkspaceEdit.is(candidate.edit));\n    }\n    CodeAction.is = is;\n})(CodeAction || (CodeAction = {}));\n/**\n * The CodeLens namespace provides helper functions to work with\n * {@link CodeLens} literals.\n */\nexport var CodeLens;\n(function (CodeLens) {\n    /**\n     * Creates a new CodeLens literal.\n     */\n    function create(range, data) {\n        let result = { range };\n        if (Is.defined(data)) {\n            result.data = data;\n        }\n        return result;\n    }\n    CodeLens.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link CodeLens} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Range.is(candidate.range) && (Is.undefined(candidate.command) || Command.is(candidate.command));\n    }\n    CodeLens.is = is;\n})(CodeLens || (CodeLens = {}));\n/**\n * The FormattingOptions namespace provides helper functions to work with\n * {@link FormattingOptions} literals.\n */\nexport var FormattingOptions;\n(function (FormattingOptions) {\n    /**\n     * Creates a new FormattingOptions literal.\n     */\n    function create(tabSize, insertSpaces) {\n        return { tabSize, insertSpaces };\n    }\n    FormattingOptions.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link FormattingOptions} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.uinteger(candidate.tabSize) && Is.boolean(candidate.insertSpaces);\n    }\n    FormattingOptions.is = is;\n})(FormattingOptions || (FormattingOptions = {}));\n/**\n * The DocumentLink namespace provides helper functions to work with\n * {@link DocumentLink} literals.\n */\nexport var DocumentLink;\n(function (DocumentLink) {\n    /**\n     * Creates a new DocumentLink literal.\n     */\n    function create(range, target, data) {\n        return { range, target, data };\n    }\n    DocumentLink.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DocumentLink} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Range.is(candidate.range) && (Is.undefined(candidate.target) || Is.string(candidate.target));\n    }\n    DocumentLink.is = is;\n})(DocumentLink || (DocumentLink = {}));\n/**\n * The SelectionRange namespace provides helper function to work with\n * SelectionRange literals.\n */\nexport var SelectionRange;\n(function (SelectionRange) {\n    /**\n     * Creates a new SelectionRange\n     * @param range the range.\n     * @param parent an optional parent.\n     */\n    function create(range, parent) {\n        return { range, parent };\n    }\n    SelectionRange.create = create;\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && (candidate.parent === undefined || SelectionRange.is(candidate.parent));\n    }\n    SelectionRange.is = is;\n})(SelectionRange || (SelectionRange = {}));\n/**\n * A set of predefined token types. This set is not fixed\n * an clients can specify additional token types via the\n * corresponding client capabilities.\n *\n * @since 3.16.0\n */\nexport var SemanticTokenTypes;\n(function (SemanticTokenTypes) {\n    SemanticTokenTypes[\"namespace\"] = \"namespace\";\n    /**\n     * Represents a generic type. Acts as a fallback for types which can't be mapped to\n     * a specific type like class or enum.\n     */\n    SemanticTokenTypes[\"type\"] = \"type\";\n    SemanticTokenTypes[\"class\"] = \"class\";\n    SemanticTokenTypes[\"enum\"] = \"enum\";\n    SemanticTokenTypes[\"interface\"] = \"interface\";\n    SemanticTokenTypes[\"struct\"] = \"struct\";\n    SemanticTokenTypes[\"typeParameter\"] = \"typeParameter\";\n    SemanticTokenTypes[\"parameter\"] = \"parameter\";\n    SemanticTokenTypes[\"variable\"] = \"variable\";\n    SemanticTokenTypes[\"property\"] = \"property\";\n    SemanticTokenTypes[\"enumMember\"] = \"enumMember\";\n    SemanticTokenTypes[\"event\"] = \"event\";\n    SemanticTokenTypes[\"function\"] = \"function\";\n    SemanticTokenTypes[\"method\"] = \"method\";\n    SemanticTokenTypes[\"macro\"] = \"macro\";\n    SemanticTokenTypes[\"keyword\"] = \"keyword\";\n    SemanticTokenTypes[\"modifier\"] = \"modifier\";\n    SemanticTokenTypes[\"comment\"] = \"comment\";\n    SemanticTokenTypes[\"string\"] = \"string\";\n    SemanticTokenTypes[\"number\"] = \"number\";\n    SemanticTokenTypes[\"regexp\"] = \"regexp\";\n    SemanticTokenTypes[\"operator\"] = \"operator\";\n    /**\n     * @since 3.17.0\n     */\n    SemanticTokenTypes[\"decorator\"] = \"decorator\";\n})(SemanticTokenTypes || (SemanticTokenTypes = {}));\n/**\n * A set of predefined token modifiers. This set is not fixed\n * an clients can specify additional token types via the\n * corresponding client capabilities.\n *\n * @since 3.16.0\n */\nexport var SemanticTokenModifiers;\n(function (SemanticTokenModifiers) {\n    SemanticTokenModifiers[\"declaration\"] = \"declaration\";\n    SemanticTokenModifiers[\"definition\"] = \"definition\";\n    SemanticTokenModifiers[\"readonly\"] = \"readonly\";\n    SemanticTokenModifiers[\"static\"] = \"static\";\n    SemanticTokenModifiers[\"deprecated\"] = \"deprecated\";\n    SemanticTokenModifiers[\"abstract\"] = \"abstract\";\n    SemanticTokenModifiers[\"async\"] = \"async\";\n    SemanticTokenModifiers[\"modification\"] = \"modification\";\n    SemanticTokenModifiers[\"documentation\"] = \"documentation\";\n    SemanticTokenModifiers[\"defaultLibrary\"] = \"defaultLibrary\";\n})(SemanticTokenModifiers || (SemanticTokenModifiers = {}));\n/**\n * @since 3.16.0\n */\nexport var SemanticTokens;\n(function (SemanticTokens) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && (candidate.resultId === undefined || typeof candidate.resultId === 'string') &&\n            Array.isArray(candidate.data) && (candidate.data.length === 0 || typeof candidate.data[0] === 'number');\n    }\n    SemanticTokens.is = is;\n})(SemanticTokens || (SemanticTokens = {}));\n/**\n * The InlineValueText namespace provides functions to deal with InlineValueTexts.\n *\n * @since 3.17.0\n */\nexport var InlineValueText;\n(function (InlineValueText) {\n    /**\n     * Creates a new InlineValueText literal.\n     */\n    function create(range, text) {\n        return { range, text };\n    }\n    InlineValueText.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range) && Is.string(candidate.text);\n    }\n    InlineValueText.is = is;\n})(InlineValueText || (InlineValueText = {}));\n/**\n * The InlineValueVariableLookup namespace provides functions to deal with InlineValueVariableLookups.\n *\n * @since 3.17.0\n */\nexport var InlineValueVariableLookup;\n(function (InlineValueVariableLookup) {\n    /**\n     * Creates a new InlineValueText literal.\n     */\n    function create(range, variableName, caseSensitiveLookup) {\n        return { range, variableName, caseSensitiveLookup };\n    }\n    InlineValueVariableLookup.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range) && Is.boolean(candidate.caseSensitiveLookup)\n            && (Is.string(candidate.variableName) || candidate.variableName === undefined);\n    }\n    InlineValueVariableLookup.is = is;\n})(InlineValueVariableLookup || (InlineValueVariableLookup = {}));\n/**\n * The InlineValueEvaluatableExpression namespace provides functions to deal with InlineValueEvaluatableExpression.\n *\n * @since 3.17.0\n */\nexport var InlineValueEvaluatableExpression;\n(function (InlineValueEvaluatableExpression) {\n    /**\n     * Creates a new InlineValueEvaluatableExpression literal.\n     */\n    function create(range, expression) {\n        return { range, expression };\n    }\n    InlineValueEvaluatableExpression.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range)\n            && (Is.string(candidate.expression) || candidate.expression === undefined);\n    }\n    InlineValueEvaluatableExpression.is = is;\n})(InlineValueEvaluatableExpression || (InlineValueEvaluatableExpression = {}));\n/**\n * The InlineValueContext namespace provides helper functions to work with\n * {@link InlineValueContext} literals.\n *\n * @since 3.17.0\n */\nexport var InlineValueContext;\n(function (InlineValueContext) {\n    /**\n     * Creates a new InlineValueContext literal.\n     */\n    function create(frameId, stoppedLocation) {\n        return { frameId, stoppedLocation };\n    }\n    InlineValueContext.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link InlineValueContext} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.defined(candidate) && Range.is(value.stoppedLocation);\n    }\n    InlineValueContext.is = is;\n})(InlineValueContext || (InlineValueContext = {}));\n/**\n * Inlay hint kinds.\n *\n * @since 3.17.0\n */\nexport var InlayHintKind;\n(function (InlayHintKind) {\n    /**\n     * An inlay hint that for a type annotation.\n     */\n    InlayHintKind.Type = 1;\n    /**\n     * An inlay hint that is for a parameter.\n     */\n    InlayHintKind.Parameter = 2;\n    function is(value) {\n        return value === 1 || value === 2;\n    }\n    InlayHintKind.is = is;\n})(InlayHintKind || (InlayHintKind = {}));\nexport var InlayHintLabelPart;\n(function (InlayHintLabelPart) {\n    function create(value) {\n        return { value };\n    }\n    InlayHintLabelPart.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate)\n            && (candidate.tooltip === undefined || Is.string(candidate.tooltip) || MarkupContent.is(candidate.tooltip))\n            && (candidate.location === undefined || Location.is(candidate.location))\n            && (candidate.command === undefined || Command.is(candidate.command));\n    }\n    InlayHintLabelPart.is = is;\n})(InlayHintLabelPart || (InlayHintLabelPart = {}));\nexport var InlayHint;\n(function (InlayHint) {\n    function create(position, label, kind) {\n        const result = { position, label };\n        if (kind !== undefined) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    InlayHint.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Position.is(candidate.position)\n            && (Is.string(candidate.label) || Is.typedArray(candidate.label, InlayHintLabelPart.is))\n            && (candidate.kind === undefined || InlayHintKind.is(candidate.kind))\n            && (candidate.textEdits === undefined) || Is.typedArray(candidate.textEdits, TextEdit.is)\n            && (candidate.tooltip === undefined || Is.string(candidate.tooltip) || MarkupContent.is(candidate.tooltip))\n            && (candidate.paddingLeft === undefined || Is.boolean(candidate.paddingLeft))\n            && (candidate.paddingRight === undefined || Is.boolean(candidate.paddingRight));\n    }\n    InlayHint.is = is;\n})(InlayHint || (InlayHint = {}));\nexport var StringValue;\n(function (StringValue) {\n    function createSnippet(value) {\n        return { kind: 'snippet', value };\n    }\n    StringValue.createSnippet = createSnippet;\n})(StringValue || (StringValue = {}));\nexport var InlineCompletionItem;\n(function (InlineCompletionItem) {\n    function create(insertText, filterText, range, command) {\n        return { insertText, filterText, range, command };\n    }\n    InlineCompletionItem.create = create;\n})(InlineCompletionItem || (InlineCompletionItem = {}));\nexport var InlineCompletionList;\n(function (InlineCompletionList) {\n    function create(items) {\n        return { items };\n    }\n    InlineCompletionList.create = create;\n})(InlineCompletionList || (InlineCompletionList = {}));\n/**\n * Describes how an {@link InlineCompletionItemProvider inline completion provider} was triggered.\n *\n * @since 3.18.0\n * @proposed\n */\nexport var InlineCompletionTriggerKind;\n(function (InlineCompletionTriggerKind) {\n    /**\n     * Completion was triggered explicitly by a user gesture.\n     */\n    InlineCompletionTriggerKind.Invoked = 0;\n    /**\n     * Completion was triggered automatically while editing.\n     */\n    InlineCompletionTriggerKind.Automatic = 1;\n})(InlineCompletionTriggerKind || (InlineCompletionTriggerKind = {}));\nexport var SelectedCompletionInfo;\n(function (SelectedCompletionInfo) {\n    function create(range, text) {\n        return { range, text };\n    }\n    SelectedCompletionInfo.create = create;\n})(SelectedCompletionInfo || (SelectedCompletionInfo = {}));\nexport var InlineCompletionContext;\n(function (InlineCompletionContext) {\n    function create(triggerKind, selectedCompletionInfo) {\n        return { triggerKind, selectedCompletionInfo };\n    }\n    InlineCompletionContext.create = create;\n})(InlineCompletionContext || (InlineCompletionContext = {}));\nexport var WorkspaceFolder;\n(function (WorkspaceFolder) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && URI.is(candidate.uri) && Is.string(candidate.name);\n    }\n    WorkspaceFolder.is = is;\n})(WorkspaceFolder || (WorkspaceFolder = {}));\nexport const EOL = ['\\n', '\\r\\n', '\\r'];\n/**\n * @deprecated Use the text document from the new vscode-languageserver-textdocument package.\n */\nexport var TextDocument;\n(function (TextDocument) {\n    /**\n     * Creates a new ITextDocument literal from the given uri and content.\n     * @param uri The document's uri.\n     * @param languageId The document's language Id.\n     * @param version The document's version.\n     * @param content The document's content.\n     */\n    function create(uri, languageId, version, content) {\n        return new FullTextDocument(uri, languageId, version, content);\n    }\n    TextDocument.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ITextDocument} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && (Is.undefined(candidate.languageId) || Is.string(candidate.languageId)) && Is.uinteger(candidate.lineCount)\n            && Is.func(candidate.getText) && Is.func(candidate.positionAt) && Is.func(candidate.offsetAt) ? true : false;\n    }\n    TextDocument.is = is;\n    function applyEdits(document, edits) {\n        let text = document.getText();\n        let sortedEdits = mergeSort(edits, (a, b) => {\n            let diff = a.range.start.line - b.range.start.line;\n            if (diff === 0) {\n                return a.range.start.character - b.range.start.character;\n            }\n            return diff;\n        });\n        let lastModifiedOffset = text.length;\n        for (let i = sortedEdits.length - 1; i >= 0; i--) {\n            let e = sortedEdits[i];\n            let startOffset = document.offsetAt(e.range.start);\n            let endOffset = document.offsetAt(e.range.end);\n            if (endOffset <= lastModifiedOffset) {\n                text = text.substring(0, startOffset) + e.newText + text.substring(endOffset, text.length);\n            }\n            else {\n                throw new Error('Overlapping edit');\n            }\n            lastModifiedOffset = startOffset;\n        }\n        return text;\n    }\n    TextDocument.applyEdits = applyEdits;\n    function mergeSort(data, compare) {\n        if (data.length <= 1) {\n            // sorted\n            return data;\n        }\n        const p = (data.length / 2) | 0;\n        const left = data.slice(0, p);\n        const right = data.slice(p);\n        mergeSort(left, compare);\n        mergeSort(right, compare);\n        let leftIdx = 0;\n        let rightIdx = 0;\n        let i = 0;\n        while (leftIdx < left.length && rightIdx < right.length) {\n            let ret = compare(left[leftIdx], right[rightIdx]);\n            if (ret <= 0) {\n                // smaller_equal -> take left to preserve order\n                data[i++] = left[leftIdx++];\n            }\n            else {\n                // greater -> take right\n                data[i++] = right[rightIdx++];\n            }\n        }\n        while (leftIdx < left.length) {\n            data[i++] = left[leftIdx++];\n        }\n        while (rightIdx < right.length) {\n            data[i++] = right[rightIdx++];\n        }\n        return data;\n    }\n})(TextDocument || (TextDocument = {}));\n/**\n * @deprecated Use the text document from the new vscode-languageserver-textdocument package.\n */\nclass FullTextDocument {\n    constructor(uri, languageId, version, content) {\n        this._uri = uri;\n        this._languageId = languageId;\n        this._version = version;\n        this._content = content;\n        this._lineOffsets = undefined;\n    }\n    get uri() {\n        return this._uri;\n    }\n    get languageId() {\n        return this._languageId;\n    }\n    get version() {\n        return this._version;\n    }\n    getText(range) {\n        if (range) {\n            let start = this.offsetAt(range.start);\n            let end = this.offsetAt(range.end);\n            return this._content.substring(start, end);\n        }\n        return this._content;\n    }\n    update(event, version) {\n        this._content = event.text;\n        this._version = version;\n        this._lineOffsets = undefined;\n    }\n    getLineOffsets() {\n        if (this._lineOffsets === undefined) {\n            let lineOffsets = [];\n            let text = this._content;\n            let isLineStart = true;\n            for (let i = 0; i < text.length; i++) {\n                if (isLineStart) {\n                    lineOffsets.push(i);\n                    isLineStart = false;\n                }\n                let ch = text.charAt(i);\n                isLineStart = (ch === '\\r' || ch === '\\n');\n                if (ch === '\\r' && i + 1 < text.length && text.charAt(i + 1) === '\\n') {\n                    i++;\n                }\n            }\n            if (isLineStart && text.length > 0) {\n                lineOffsets.push(text.length);\n            }\n            this._lineOffsets = lineOffsets;\n        }\n        return this._lineOffsets;\n    }\n    positionAt(offset) {\n        offset = Math.max(Math.min(offset, this._content.length), 0);\n        let lineOffsets = this.getLineOffsets();\n        let low = 0, high = lineOffsets.length;\n        if (high === 0) {\n            return Position.create(0, offset);\n        }\n        while (low < high) {\n            let mid = Math.floor((low + high) / 2);\n            if (lineOffsets[mid] > offset) {\n                high = mid;\n            }\n            else {\n                low = mid + 1;\n            }\n        }\n        // low is the least x for which the line offset is larger than the current offset\n        // or array.length if no line offset is larger than the current offset\n        let line = low - 1;\n        return Position.create(line, offset - lineOffsets[line]);\n    }\n    offsetAt(position) {\n        let lineOffsets = this.getLineOffsets();\n        if (position.line >= lineOffsets.length) {\n            return this._content.length;\n        }\n        else if (position.line < 0) {\n            return 0;\n        }\n        let lineOffset = lineOffsets[position.line];\n        let nextLineOffset = (position.line + 1 < lineOffsets.length) ? lineOffsets[position.line + 1] : this._content.length;\n        return Math.max(Math.min(lineOffset + position.character, nextLineOffset), lineOffset);\n    }\n    get lineCount() {\n        return this.getLineOffsets().length;\n    }\n}\nvar Is;\n(function (Is) {\n    const toString = Object.prototype.toString;\n    function defined(value) {\n        return typeof value !== 'undefined';\n    }\n    Is.defined = defined;\n    function undefined(value) {\n        return typeof value === 'undefined';\n    }\n    Is.undefined = undefined;\n    function boolean(value) {\n        return value === true || value === false;\n    }\n    Is.boolean = boolean;\n    function string(value) {\n        return toString.call(value) === '[object String]';\n    }\n    Is.string = string;\n    function number(value) {\n        return toString.call(value) === '[object Number]';\n    }\n    Is.number = number;\n    function numberRange(value, min, max) {\n        return toString.call(value) === '[object Number]' && min <= value && value <= max;\n    }\n    Is.numberRange = numberRange;\n    function integer(value) {\n        return toString.call(value) === '[object Number]' && -2147483648 <= value && value <= 2147483647;\n    }\n    Is.integer = integer;\n    function uinteger(value) {\n        return toString.call(value) === '[object Number]' && 0 <= value && value <= 2147483647;\n    }\n    Is.uinteger = uinteger;\n    function func(value) {\n        return toString.call(value) === '[object Function]';\n    }\n    Is.func = func;\n    function objectLiteral(value) {\n        // Strictly speaking class instances pass this check as well. Since the LSP\n        // doesn't use classes we ignore this for now. If we do we need to add something\n        // like this: `Object.getPrototypeOf(Object.getPrototypeOf(x)) === null`\n        return value !== null && typeof value === 'object';\n    }\n    Is.objectLiteral = objectLiteral;\n    function typedArray(value, check) {\n        return Array.isArray(value) && value.every(check);\n    }\n    Is.typedArray = typedArray;\n})(Is || (Is = {}));\n","import type {\n  Alternative,\n  Assertion,\n  Character,\n  Disjunction,\n  Group,\n  GroupBackReference,\n  IRegExpAST,\n  Quantifier,\n  RegExpAstPart,\n  RegExpFlags,\n  RegExpPattern,\n  Set,\n} from \"../types\";\n\nexport class BaseRegExpVisitor {\n  public visitChildren(node: IRegExpAST) {\n    for (const key in node) {\n      const child = (node as any)[key];\n      /* istanbul ignore else */\n      if (node.hasOwnProperty(key)) {\n        if (child.type !== undefined) {\n          this.visit(child);\n        } else if (Array.isArray(child)) {\n          child.forEach((subChild) => {\n            this.visit(subChild);\n          }, this);\n        }\n      }\n    }\n  }\n\n  public visit(node: RegExpAstPart): void {\n    switch (node.type) {\n      case \"Pattern\":\n        this.visitPattern(node);\n        break;\n      case \"Flags\":\n        this.visitFlags(node);\n        break;\n      case \"Disjunction\":\n        this.visitDisjunction(node);\n        break;\n      case \"Alternative\":\n        this.visitAlternative(node);\n        break;\n      case \"StartAnchor\":\n        this.visitStartAnchor(node);\n        break;\n      case \"EndAnchor\":\n        this.visitEndAnchor(node);\n        break;\n      case \"WordBoundary\":\n        this.visitWordBoundary(node);\n        break;\n      case \"NonWordBoundary\":\n        this.visitNonWordBoundary(node);\n        break;\n      case \"Lookahead\":\n        this.visitLookahead(node);\n        break;\n      case \"NegativeLookahead\":\n        this.visitNegativeLookahead(node);\n        break;\n      case \"Character\":\n        this.visitCharacter(node);\n        break;\n      case \"Set\":\n        this.visitSet(node);\n        break;\n      case \"Group\":\n        this.visitGroup(node);\n        break;\n      case \"GroupBackReference\":\n        this.visitGroupBackReference(node);\n        break;\n      case \"Quantifier\":\n        this.visitQuantifier(node);\n        break;\n    }\n\n    this.visitChildren(node);\n  }\n\n  public visitPattern(node: RegExpPattern): void {}\n\n  public visitFlags(node: RegExpFlags): void {}\n\n  public visitDisjunction(node: Disjunction): void {}\n\n  public visitAlternative(node: Alternative): void {}\n\n  // Assertion\n  public visitStartAnchor(node: Assertion): void {}\n\n  public visitEndAnchor(node: Assertion): void {}\n\n  public visitWordBoundary(node: Assertion): void {}\n\n  public visitNonWordBoundary(node: Assertion): void {}\n\n  public visitLookahead(node: Assertion): void {}\n\n  public visitNegativeLookahead(node: Assertion): void {}\n\n  // atoms\n  public visitCharacter(node: Character): void {}\n\n  public visitSet(node: Set): void {}\n\n  public visitGroup(node: Group): void {}\n\n  public visitGroupBackReference(node: GroupBackReference): void {}\n\n  public visitQuantifier(node: Quantifier): void {}\n}\n","import {\n  ISyntacticContentAssistPath,\n  IToken,\n  ITokenGrammarPath,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  NextAfterTokenWalker,\n  nextPossibleTokensAfter,\n} from \"../../grammar/interpreter.js\";\nimport { first, isUndefined } from \"lodash-es\";\nimport { MixedInParser } from \"./parser_traits.js\";\n\nexport class ContentAssist {\n  initContentAssist() {}\n\n  public computeContentAssist(\n    this: MixedInParser,\n    startRuleName: string,\n    precedingInput: IToken[],\n  ): ISyntacticContentAssistPath[] {\n    const startRuleGast = this.gastProductionsCache[startRuleName];\n\n    if (isUndefined(startRuleGast)) {\n      throw Error(`Rule ->${startRuleName}<- does not exist in this grammar.`);\n    }\n\n    return nextPossibleTokensAfter(\n      [startRuleGast],\n      precedingInput,\n      this.tokenMatcher,\n      this.maxLookahead,\n    );\n  }\n\n  // TODO: should this be a member method or a utility? it does not have any state or usage of 'this'...\n  // TODO: should this be more explicitly part of the public API?\n  public getNextPossibleTokenTypes(\n    this: MixedInParser,\n    grammarPath: ITokenGrammarPath,\n  ): TokenType[] {\n    const topRuleName = first(grammarPath.ruleStack)!;\n    const gastProductions = this.getGAstProductions();\n    const topProduction = gastProductions[topRuleName];\n    const nextPossibleTokenTypes = new NextAfterTokenWalker(\n      topProduction,\n      grammarPath,\n    ).startWalking();\n    return nextPossibleTokenTypes;\n  }\n}\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { createDefaultCoreModule, createDefaultSharedCoreModule } from '../default-module.js';\r\nimport type { Module } from '../dependency-injection.js';\r\nimport { inject } from '../dependency-injection.js';\r\nimport * as ast from '../languages/generated/ast.js';\r\nimport type { LangiumCoreServices, LangiumSharedCoreServices, PartialLangiumCoreServices, PartialLangiumSharedCoreServices } from '../services.js';\r\nimport type { Mutable } from '../syntax-tree.js';\r\nimport { EmptyFileSystem } from '../workspace/file-system-provider.js';\r\nimport { URI } from './uri-utils.js';\r\n\r\nconst minimalGrammarModule: Module<LangiumCoreServices, PartialLangiumCoreServices> = {\r\n    Grammar: () => undefined as unknown as ast.Grammar,\r\n    LanguageMetaData: () => ({\r\n        caseInsensitive: false,\r\n        fileExtensions: ['.langium'],\r\n        languageId: 'langium'\r\n    })\r\n};\r\n\r\nconst minimalSharedGrammarModule: Module<LangiumSharedCoreServices, PartialLangiumSharedCoreServices> = {\r\n    AstReflection: () => new ast.LangiumGrammarAstReflection()\r\n};\r\n\r\nfunction createMinimalGrammarServices(): LangiumCoreServices {\r\n    const shared = inject(\r\n        createDefaultSharedCoreModule(EmptyFileSystem),\r\n        minimalSharedGrammarModule\r\n    );\r\n    const grammar = inject(\r\n        createDefaultCoreModule({ shared }),\r\n        minimalGrammarModule\r\n    );\r\n    shared.ServiceRegistry.register(grammar);\r\n    return grammar;\r\n}\r\n\r\n/**\r\n * Load a Langium grammar for your language from a JSON string. This is used by several services,\r\n * most notably the parser builder which interprets the grammar to create a parser.\r\n */\r\nexport function loadGrammarFromJson(json: string): ast.Grammar {\r\n    const services = createMinimalGrammarServices();\r\n    const astNode = services.serializer.JsonSerializer.deserialize(json) as Mutable<ast.Grammar>;\r\n    services.shared.workspace.LangiumDocumentFactory.fromModel(astNode, URI.parse(`memory://${astNode.name ?? 'grammar'}.langium`));\r\n    return astNode;\r\n}\r\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { GrammarConfig } from '../languages/grammar-config.js';\r\nimport { isAstNodeWithComment } from '../serializer/json-serializer.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode } from '../syntax-tree.js';\r\nimport { findCommentNode } from '../utils/cst-utils.js';\r\n\r\n/**\r\n * Provides comments for AST nodes.\r\n */\r\nexport interface CommentProvider {\r\n    /**\r\n     * Returns the comment associated with the specified AST node.\r\n     * @param node The AST node to get the comment for.\r\n     * @returns The comment associated with the specified AST node or `undefined` if there is no comment.\r\n     */\r\n    getComment(node: AstNode): string | undefined;\r\n}\r\n\r\nexport class DefaultCommentProvider implements CommentProvider {\r\n    protected readonly grammarConfig: () => GrammarConfig;\r\n    constructor(services: LangiumCoreServices) {\r\n        this.grammarConfig = () => services.parser.GrammarConfig;\r\n    }\r\n    getComment(node: AstNode): string | undefined {\r\n        if(isAstNodeWithComment(node)) {\r\n            return node.$comment;\r\n        }\r\n        return findCommentNode(node.$cstNode, this.grammarConfig().multilineCommentRules)?.text;\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2024 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\n/* eslint-disable @typescript-eslint/no-explicit-any */\r\n\r\nimport type { TokenType } from 'chevrotain';\r\nimport { CompositeCstNodeImpl, LeafCstNodeImpl, RootCstNodeImpl } from '../parser/cst-node-builder.js';\r\nimport { isAbstractElement, type AbstractElement, type Grammar } from '../languages/generated/ast.js';\r\nimport type { Linker } from '../references/linker.js';\r\nimport type { Lexer } from '../parser/lexer.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { ParseResult } from '../parser/langium-parser.js';\r\nimport type { Reference, AstNode, CstNode, LeafCstNode, GenericAstNode, Mutable, RootCstNode } from '../syntax-tree.js';\r\nimport { isRootCstNode, isCompositeCstNode, isLeafCstNode, isAstNode, isReference } from '../syntax-tree.js';\r\nimport { streamAst } from '../utils/ast-utils.js';\r\nimport { BiMap } from '../utils/collections.js';\r\nimport { streamCst } from '../utils/cst-utils.js';\r\nimport type { LexingReport } from '../parser/token-builder.js';\r\n\r\n/**\r\n * The hydrator service is responsible for allowing AST parse results to be sent across worker threads.\r\n */\r\nexport interface Hydrator {\r\n    /**\r\n     * Converts a parse result to a plain object. The resulting object can be sent across worker threads.\r\n     */\r\n    dehydrate(result: ParseResult<AstNode>): ParseResult<object>;\r\n    /**\r\n     * Converts a plain object to a parse result. The included AST node can then be used in the main thread.\r\n     * Calling this method on objects that have not been dehydrated first will result in undefined behavior.\r\n     */\r\n    hydrate<T extends AstNode = AstNode>(result: ParseResult<object>): ParseResult<T>;\r\n}\r\n\r\nexport interface DehydrateContext {\r\n    astNodes: Map<AstNode, any>;\r\n    cstNodes: Map<CstNode, any>;\r\n}\r\n\r\nexport interface HydrateContext {\r\n    astNodes: Map<any, AstNode>;\r\n    cstNodes: Map<any, CstNode>;\r\n}\r\n\r\nexport class DefaultHydrator implements Hydrator {\r\n\r\n    protected readonly grammar: Grammar;\r\n    protected readonly lexer: Lexer;\r\n    protected readonly linker: Linker;\r\n\r\n    protected readonly grammarElementIdMap = new BiMap<AbstractElement, number>();\r\n    protected readonly tokenTypeIdMap = new BiMap<number, TokenType>();\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.grammar = services.Grammar;\r\n        this.lexer = services.parser.Lexer;\r\n        this.linker = services.references.Linker;\r\n    }\r\n\r\n    dehydrate(result: ParseResult<AstNode>): ParseResult<object> {\r\n        return {\r\n            lexerErrors: result.lexerErrors,\r\n            lexerReport: result.lexerReport ? this.dehydrateLexerReport(result.lexerReport) : undefined,\r\n            // We need to create shallow copies of the errors\r\n            // The original errors inherit from the `Error` class, which is not transferable across worker threads\r\n            parserErrors: result.parserErrors.map(e => ({ ...e, message: e.message })),\r\n            value: this.dehydrateAstNode(result.value, this.createDehyrationContext(result.value))\r\n        };\r\n    }\r\n\r\n    protected dehydrateLexerReport(lexerReport: LexingReport): LexingReport {\r\n        // By default, lexer reports are serializable\r\n        return lexerReport;\r\n    }\r\n\r\n    protected createDehyrationContext(node: AstNode): DehydrateContext {\r\n        const astNodes = new Map<AstNode, any>();\r\n        const cstNodes = new Map<CstNode, any>();\r\n        for (const astNode of streamAst(node)) {\r\n            astNodes.set(astNode, {});\r\n        }\r\n        if (node.$cstNode) {\r\n            for (const cstNode of streamCst(node.$cstNode)) {\r\n                cstNodes.set(cstNode, {});\r\n            }\r\n        }\r\n        return {\r\n            astNodes,\r\n            cstNodes\r\n        };\r\n    }\r\n\r\n    protected dehydrateAstNode(node: AstNode, context: DehydrateContext): object {\r\n        const obj = context.astNodes.get(node) as Record<string, any>;\r\n        obj.$type = node.$type;\r\n        obj.$containerIndex = node.$containerIndex;\r\n        obj.$containerProperty = node.$containerProperty;\r\n        if (node.$cstNode !== undefined) {\r\n            obj.$cstNode = this.dehydrateCstNode(node.$cstNode, context);\r\n        }\r\n        for (const [name, value] of Object.entries(node)) {\r\n            if (name.startsWith('$')) {\r\n                continue;\r\n            }\r\n            if (Array.isArray(value)) {\r\n                const arr: any[] = [];\r\n                obj[name] = arr;\r\n                for (const item of value) {\r\n                    if (isAstNode(item)) {\r\n                        arr.push(this.dehydrateAstNode(item, context));\r\n                    } else if (isReference(item)) {\r\n                        arr.push(this.dehydrateReference(item, context));\r\n                    } else {\r\n                        arr.push(item);\r\n                    }\r\n                }\r\n            } else if (isAstNode(value)) {\r\n                obj[name] = this.dehydrateAstNode(value, context);\r\n            } else if (isReference(value)) {\r\n                obj[name] = this.dehydrateReference(value, context);\r\n            } else if (value !== undefined) {\r\n                obj[name] = value;\r\n            }\r\n        }\r\n        return obj;\r\n    }\r\n\r\n    protected dehydrateReference(reference: Reference, context: DehydrateContext): any {\r\n        const obj: Record<string, unknown> = {};\r\n        obj.$refText = reference.$refText;\r\n        if (reference.$refNode) {\r\n            obj.$refNode = context.cstNodes.get(reference.$refNode);\r\n        }\r\n        return obj;\r\n    }\r\n\r\n    protected dehydrateCstNode(node: CstNode, context: DehydrateContext): any {\r\n        const cstNode = context.cstNodes.get(node) as Record<string, any>;\r\n        if (isRootCstNode(node)) {\r\n            cstNode.fullText = node.fullText;\r\n        } else {\r\n            // Note: This returns undefined for hidden nodes (i.e. comments)\r\n            cstNode.grammarSource = this.getGrammarElementId(node.grammarSource);\r\n        }\r\n        cstNode.hidden = node.hidden;\r\n        cstNode.astNode = context.astNodes.get(node.astNode);\r\n        if (isCompositeCstNode(node)) {\r\n            cstNode.content = node.content.map(child => this.dehydrateCstNode(child, context));\r\n        } else if (isLeafCstNode(node)) {\r\n            cstNode.tokenType = node.tokenType.name;\r\n            cstNode.offset = node.offset;\r\n            cstNode.length = node.length;\r\n            cstNode.startLine = node.range.start.line;\r\n            cstNode.startColumn = node.range.start.character;\r\n            cstNode.endLine = node.range.end.line;\r\n            cstNode.endColumn = node.range.end.character;\r\n        }\r\n        return cstNode;\r\n    }\r\n\r\n    hydrate<T extends AstNode = AstNode>(result: ParseResult<object>): ParseResult<T> {\r\n        const node = result.value;\r\n        const context = this.createHydrationContext(node);\r\n        if ('$cstNode' in node) {\r\n            this.hydrateCstNode(node.$cstNode, context);\r\n        }\r\n        return {\r\n            lexerErrors: result.lexerErrors,\r\n            lexerReport: result.lexerReport,\r\n            parserErrors: result.parserErrors,\r\n            value: this.hydrateAstNode(node, context) as T\r\n        };\r\n    }\r\n\r\n    protected createHydrationContext(node: any): HydrateContext {\r\n        const astNodes = new Map<any, AstNode>();\r\n        const cstNodes = new Map<any, CstNode>();\r\n        for (const astNode of streamAst(node)) {\r\n            astNodes.set(astNode, {} as AstNode);\r\n        }\r\n        let root: RootCstNode;\r\n        if (node.$cstNode) {\r\n            for (const cstNode of streamCst(node.$cstNode)) {\r\n                let cst: Mutable<CstNode> | undefined;\r\n                if ('fullText' in cstNode) {\r\n                    cst = new RootCstNodeImpl(cstNode.fullText as string);\r\n                    root = cst as RootCstNode;\r\n                } else if ('content' in cstNode) {\r\n                    cst = new CompositeCstNodeImpl();\r\n                } else if ('tokenType' in cstNode) {\r\n                    cst = this.hydrateCstLeafNode(cstNode);\r\n                }\r\n                if (cst) {\r\n                    cstNodes.set(cstNode, cst);\r\n                    cst.root = root!;\r\n                }\r\n            }\r\n        }\r\n        return {\r\n            astNodes,\r\n            cstNodes\r\n        };\r\n    }\r\n\r\n    protected hydrateAstNode(node: any, context: HydrateContext): AstNode {\r\n        const astNode = context.astNodes.get(node) as Mutable<GenericAstNode>;\r\n        astNode.$type = node.$type;\r\n        astNode.$containerIndex = node.$containerIndex;\r\n        astNode.$containerProperty = node.$containerProperty;\r\n        if (node.$cstNode) {\r\n            astNode.$cstNode = context.cstNodes.get(node.$cstNode);\r\n        }\r\n        for (const [name, value] of Object.entries(node)) {\r\n            if (name.startsWith('$')) {\r\n                continue;\r\n            }\r\n            if (Array.isArray(value)) {\r\n                const arr: unknown[] = [];\r\n                astNode[name] = arr;\r\n                for (const item of value) {\r\n                    if (isAstNode(item)) {\r\n                        arr.push(this.setParent(this.hydrateAstNode(item, context), astNode));\r\n                    } else if (isReference(item)) {\r\n                        arr.push(this.hydrateReference(item, astNode, name, context));\r\n                    } else {\r\n                        arr.push(item);\r\n                    }\r\n                }\r\n            } else if (isAstNode(value)) {\r\n                astNode[name] = this.setParent(this.hydrateAstNode(value, context), astNode);\r\n            } else if (isReference(value)) {\r\n                astNode[name] = this.hydrateReference(value, astNode, name, context);\r\n            } else if (value !== undefined) {\r\n                astNode[name] = value;\r\n            }\r\n        }\r\n        return astNode;\r\n    }\r\n\r\n    protected setParent(node: any, parent: any): any {\r\n        node.$container = parent as AstNode;\r\n        return node;\r\n    }\r\n\r\n    protected hydrateReference(reference: any, node: AstNode, name: string, context: HydrateContext): Reference {\r\n        return this.linker.buildReference(node, name, context.cstNodes.get(reference.$refNode)!, reference.$refText);\r\n    }\r\n\r\n    protected hydrateCstNode(cstNode: any, context: HydrateContext, num = 0): CstNode {\r\n        const cstNodeObj = context.cstNodes.get(cstNode) as Mutable<CstNode>;\r\n        if (typeof cstNode.grammarSource === 'number') {\r\n            cstNodeObj.grammarSource = this.getGrammarElement(cstNode.grammarSource);\r\n        }\r\n        cstNodeObj.astNode = context.astNodes.get(cstNode.astNode)!;\r\n        if (isCompositeCstNode(cstNodeObj)) {\r\n            for (const child of cstNode.content) {\r\n                const hydrated = this.hydrateCstNode(child, context, num++);\r\n                cstNodeObj.content.push(hydrated);\r\n            }\r\n        }\r\n        return cstNodeObj;\r\n    }\r\n\r\n    protected hydrateCstLeafNode(cstNode: any): LeafCstNode {\r\n        const tokenType = this.getTokenType(cstNode.tokenType);\r\n        const offset = cstNode.offset;\r\n        const length = cstNode.length;\r\n        const startLine = cstNode.startLine;\r\n        const startColumn = cstNode.startColumn;\r\n        const endLine = cstNode.endLine;\r\n        const endColumn = cstNode.endColumn;\r\n        const hidden = cstNode.hidden;\r\n        const node = new LeafCstNodeImpl(\r\n            offset,\r\n            length,\r\n            {\r\n                start: {\r\n                    line: startLine,\r\n                    character: startColumn\r\n                },\r\n                end: {\r\n                    line: endLine,\r\n                    character: endColumn\r\n                }\r\n            },\r\n            tokenType,\r\n            hidden\r\n        );\r\n        return node;\r\n    }\r\n\r\n    protected getTokenType(name: string): TokenType {\r\n        return this.lexer.definition[name];\r\n    }\r\n\r\n    protected getGrammarElementId(node: AbstractElement | undefined): number | undefined {\r\n        if (!node) {\r\n            return undefined;\r\n        }\r\n        if (this.grammarElementIdMap.size === 0) {\r\n            this.createGrammarElementIdMap();\r\n        }\r\n        return this.grammarElementIdMap.get(node);\r\n    }\r\n\r\n    protected getGrammarElement(id: number): AbstractElement | undefined {\r\n        if (this.grammarElementIdMap.size === 0) {\r\n            this.createGrammarElementIdMap();\r\n        }\r\n        const element = this.grammarElementIdMap.getKey(id);\r\n        return element;\r\n    }\r\n\r\n    protected createGrammarElementIdMap(): void {\r\n        let id = 0;\r\n        for (const element of streamAst(this.grammar)) {\r\n            if (isAbstractElement(element)) {\r\n                this.grammarElementIdMap.set(element, id++);\r\n            }\r\n        }\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport {\r\n    IToken,\r\n    TokenType,\r\n    tokenMatcher,\r\n    tokenLabel,\r\n    Rule,\r\n    IProductionWithOccurrence,\r\n    NonTerminal,\r\n    Alternation,\r\n    Option,\r\n    RepetitionMandatory,\r\n    RepetitionMandatoryWithSeparator,\r\n    RepetitionWithSeparator,\r\n    Repetition,\r\n    Terminal,\r\n    BaseParser,\r\n    LLkLookaheadStrategy,\r\n    ILookaheadValidationError,\r\n    IOrAlt,\r\n    getLookaheadPaths,\r\n    OptionalProductionType\r\n} from \"chevrotain\";\r\nimport {\r\n    ATN,\r\n    ATNState,\r\n    ATN_RULE_STOP,\r\n    AtomTransition,\r\n    buildATNKey,\r\n    createATN,\r\n    DecisionState,\r\n    EpsilonTransition,\r\n    RuleTransition,\r\n    Transition\r\n} from \"./atn.js\";\r\nimport {\r\n    ATNConfig,\r\n    ATNConfigSet,\r\n    DFA,\r\n    DFAState,\r\n    DFA_ERROR,\r\n    getATNConfigKey\r\n} from \"./dfa.js\";\r\nimport min from \"lodash-es/min.js\";\r\nimport flatMap from \"lodash-es/flatMap.js\";\r\nimport uniqBy from \"lodash-es/uniqBy.js\";\r\nimport map from \"lodash-es/map.js\";\r\nimport flatten from \"lodash-es/flatten.js\";\r\nimport forEach from \"lodash-es/forEach.js\";\r\nimport isEmpty from \"lodash-es/isEmpty.js\";\r\nimport reduce from \"lodash-es/reduce.js\";\r\n\r\ntype DFACache = (predicateSet: PredicateSet) => DFA\r\n\r\nexport type AmbiguityReport = (message: string) => void;\r\n\r\nfunction createDFACache(startState: DecisionState, decision: number): DFACache {\r\n    const map: Record<string, DFA | undefined> = {}\r\n    return (predicateSet) => {\r\n        const key = predicateSet.toString()\r\n        let existing = map[key]\r\n        if (existing !== undefined) {\r\n            return existing\r\n        } else {\r\n            existing = {\r\n                atnStartState: startState,\r\n                decision,\r\n                states: {}\r\n            }\r\n            map[key] = existing\r\n            return existing\r\n        }\r\n    }\r\n}\r\n\r\nclass PredicateSet {\r\n    private predicates: boolean[] = []\r\n\r\n    is(index: number): boolean {\r\n        return index >= this.predicates.length || this.predicates[index]\r\n    }\r\n\r\n    set(index: number, value: boolean) {\r\n        this.predicates[index] = value\r\n    }\r\n\r\n    toString(): string {\r\n        let value = \"\"\r\n        const size = this.predicates.length\r\n        for (let i = 0; i < size; i++) {\r\n            value += this.predicates[i] === true ? \"1\" : \"0\"\r\n        }\r\n        return value\r\n    }\r\n}\r\n\r\ninterface AdaptivePredictError {\r\n    tokenPath: IToken[]\r\n    possibleTokenTypes: TokenType[]\r\n    actualToken: IToken\r\n}\r\n\r\nconst EMPTY_PREDICATES = new PredicateSet()\r\n\r\nexport interface LLStarLookaheadOptions {\r\n    logging?: AmbiguityReport\r\n}\r\n\r\nexport class LLStarLookaheadStrategy extends LLkLookaheadStrategy {\r\n\r\n    private atn: ATN;\r\n    private dfas: DFACache[];\r\n    private logging: AmbiguityReport;\r\n\r\n    constructor(options?: LLStarLookaheadOptions) {\r\n        super();\r\n        this.logging = options?.logging ?? ((message) => console.log(message));\r\n    }\r\n\r\n    override initialize(options: { rules: Rule[] }): void {\r\n        this.atn = createATN(options.rules);\r\n        this.dfas = initATNSimulator(this.atn);\r\n    }\r\n\r\n    override validateAmbiguousAlternationAlternatives(): ILookaheadValidationError[] {\r\n        return [];\r\n    }\r\n\r\n    override validateEmptyOrAlternatives(): ILookaheadValidationError[] {\r\n        return [];\r\n    }\r\n\r\n    override buildLookaheadForAlternation(options: {\r\n        prodOccurrence: number;\r\n        rule: Rule;\r\n        maxLookahead: number;\r\n        hasPredicates: boolean;\r\n        dynamicTokensEnabled: boolean\r\n    }): (this: BaseParser, orAlts?: IOrAlt<any>[] | undefined) => number | undefined {\r\n        const { prodOccurrence, rule, hasPredicates, dynamicTokensEnabled } = options;\r\n        const dfas = this.dfas;\r\n        const logging = this.logging;\r\n        const key = buildATNKey(rule, 'Alternation', prodOccurrence);\r\n        const decisionState = this.atn.decisionMap[key];\r\n        const decisionIndex = decisionState.decision;\r\n        const partialAlts: (TokenType | undefined)[][] = map(\r\n            getLookaheadPaths({\r\n                maxLookahead: 1,\r\n                occurrence: prodOccurrence,\r\n                prodType: \"Alternation\",\r\n                rule: rule\r\n            }),\r\n            (currAlt) => map(currAlt, (path) => path[0])\r\n        )\r\n\r\n        if (isLL1Sequence(partialAlts, false) && !dynamicTokensEnabled) {\r\n            const choiceToAlt = reduce(\r\n                partialAlts,\r\n                (result, currAlt, idx) => {\r\n                    forEach(currAlt, (currTokType) => {\r\n                        if (currTokType) {\r\n                            result[currTokType.tokenTypeIdx!] = idx\r\n                            forEach(currTokType.categoryMatches!, (currExtendingType) => {\r\n                                result[currExtendingType] = idx\r\n                            })\r\n                        }\r\n                    })\r\n                    return result\r\n                },\r\n                {} as Record<number, number>\r\n            )\r\n\r\n            if (hasPredicates) {\r\n                return function (this: BaseParser, orAlts) {\r\n                    const nextToken = this.LA(1)\r\n                    const prediction: number | undefined = choiceToAlt[nextToken.tokenTypeIdx]\r\n                    if (orAlts !== undefined && prediction !== undefined) {\r\n                        const gate = orAlts[prediction]?.GATE\r\n                        if (gate !== undefined && gate.call(this) === false) {\r\n                            return undefined;\r\n                        }\r\n                    }\r\n                    return prediction\r\n                }\r\n            } else {\r\n                return function (this: BaseParser): number | undefined {\r\n                    const nextToken = this.LA(1)\r\n                    return choiceToAlt[nextToken.tokenTypeIdx];\r\n                }\r\n            }\r\n        } else if (hasPredicates) {\r\n            return function (this: BaseParser, orAlts) {\r\n                const predicates = new PredicateSet()\r\n                const length = orAlts === undefined ? 0 : orAlts.length\r\n                for (let i = 0; i < length; i++) {\r\n                    const gate = orAlts?.[i].GATE\r\n                    predicates.set(i, gate === undefined || gate.call(this))\r\n                }\r\n                const result = adaptivePredict.call(this, dfas, decisionIndex, predicates, logging);\r\n                return typeof result === 'number' ? result : undefined;\r\n            }\r\n        } else {\r\n            return function (this: BaseParser) {\r\n                const result = adaptivePredict.call(this, dfas, decisionIndex, EMPTY_PREDICATES, logging);\r\n                return typeof result === 'number' ? result : undefined;\r\n            }\r\n        }\r\n    }\r\n\r\n    override buildLookaheadForOptional(options: {\r\n        prodOccurrence: number;\r\n        prodType: OptionalProductionType;\r\n        rule: Rule;\r\n        maxLookahead: number;\r\n        dynamicTokensEnabled: boolean\r\n    }): (this: BaseParser) => boolean {\r\n        const { prodOccurrence, rule, prodType, dynamicTokensEnabled } = options;\r\n        const dfas = this.dfas;\r\n        const logging = this.logging;\r\n        const key = buildATNKey(rule, prodType, prodOccurrence);\r\n        const decisionState = this.atn.decisionMap[key];\r\n        const decisionIndex = decisionState.decision;\r\n        const alts = map(\r\n            getLookaheadPaths({\r\n                maxLookahead: 1,\r\n                occurrence: prodOccurrence,\r\n                prodType,\r\n                rule\r\n            }),\r\n            (e) => {\r\n              return map(e, (g) => g[0])\r\n            }\r\n          )\r\n        \r\n          if (isLL1Sequence(alts) && alts[0][0] && !dynamicTokensEnabled) {\r\n            const alt = alts[0]\r\n            const singleTokensTypes = flatten(alt)\r\n        \r\n            if (\r\n              singleTokensTypes.length === 1 &&\r\n              isEmpty(singleTokensTypes[0].categoryMatches)\r\n            ) {\r\n              const expectedTokenType = singleTokensTypes[0]\r\n              const expectedTokenUniqueKey = expectedTokenType.tokenTypeIdx\r\n        \r\n              return function (this: BaseParser): boolean {\r\n                return this.LA(1).tokenTypeIdx === expectedTokenUniqueKey\r\n              }\r\n            } else {\r\n              const choiceToAlt = reduce(\r\n                singleTokensTypes,\r\n                (result, currTokType) => {\r\n                  if (currTokType !== undefined) {\r\n                    result[currTokType.tokenTypeIdx!] = true\r\n                    forEach(currTokType.categoryMatches, (currExtendingType) => {\r\n                      result[currExtendingType] = true\r\n                    })\r\n                  }\r\n                  return result\r\n                },\r\n                {} as Record<number, boolean>\r\n              )\r\n        \r\n              return function (this: BaseParser): boolean {\r\n                const nextToken = this.LA(1)\r\n                return choiceToAlt[nextToken.tokenTypeIdx] === true\r\n              }\r\n            }\r\n          }\r\n          return function (this: BaseParser) {\r\n            const result = adaptivePredict.call(this, dfas, decisionIndex, EMPTY_PREDICATES, logging)\r\n              return typeof result === \"object\" ? false : result === 0;\r\n          }\r\n    }\r\n\r\n}\r\n\r\nfunction isLL1Sequence(sequences: (TokenType | undefined)[][], allowEmpty = true): boolean {\r\n    const fullSet = new Set<number>()\r\n\r\n    for (const alt of sequences) {\r\n        const altSet = new Set<number>()\r\n        for (const tokType of alt) {\r\n            if (tokType === undefined) {\r\n                if (allowEmpty) {\r\n                    // Epsilon production encountered\r\n                    break\r\n                } else {\r\n                    return false;\r\n                }\r\n            }\r\n            const indices = [tokType.tokenTypeIdx!].concat(tokType.categoryMatches!)\r\n            for (const index of indices) {\r\n                if (fullSet.has(index)) {\r\n                    if (!altSet.has(index)) {\r\n                        return false\r\n                    }\r\n                } else {\r\n                    fullSet.add(index)\r\n                    altSet.add(index)\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return true\r\n}\r\n\r\nfunction initATNSimulator(atn: ATN): DFACache[] {\r\n    const decisionLength = atn.decisionStates.length\r\n    const decisionToDFA: DFACache[] = Array(decisionLength)\r\n    for (let i = 0; i < decisionLength; i++) {\r\n        decisionToDFA[i] = createDFACache(atn.decisionStates[i], i)\r\n    }\r\n    return decisionToDFA;\r\n}\r\n\r\nfunction adaptivePredict(\r\n    this: BaseParser,\r\n    dfaCaches: DFACache[],\r\n    decision: number,\r\n    predicateSet: PredicateSet,\r\n    logging: AmbiguityReport\r\n): number | AdaptivePredictError {\r\n    const dfa = dfaCaches[decision](predicateSet)\r\n    let start = dfa.start\r\n    if (start === undefined) {\r\n        const closure = computeStartState(dfa.atnStartState as ATNState)\r\n        start = addDFAState(dfa, newDFAState(closure))\r\n        dfa.start = start\r\n    }\r\n\r\n    const alt = performLookahead.apply(this, [dfa, start, predicateSet, logging])\r\n    return alt\r\n}\r\n\r\nfunction performLookahead(\r\n    this: BaseParser,\r\n    dfa: DFA,\r\n    s0: DFAState,\r\n    predicateSet: PredicateSet,\r\n    logging: AmbiguityReport\r\n): number | AdaptivePredictError {\r\n    let previousD = s0\r\n\r\n    let i = 1\r\n    const path: IToken[] = []\r\n    let t = this.LA(i++)\r\n\r\n    while (true) {\r\n        let d = getExistingTargetState(previousD, t)\r\n        if (d === undefined) {\r\n            d = computeLookaheadTarget.apply(this, [dfa, previousD, t, i, predicateSet, logging])\r\n        }\r\n\r\n        if (d === DFA_ERROR) {\r\n            return buildAdaptivePredictError(path, previousD, t)\r\n        }\r\n\r\n        if (d.isAcceptState === true) {\r\n            return d.prediction\r\n        }\r\n\r\n        previousD = d\r\n        path.push(t)\r\n        t = this.LA(i++)\r\n    }\r\n}\r\n\r\nfunction computeLookaheadTarget(\r\n    this: BaseParser,\r\n    dfa: DFA,\r\n    previousD: DFAState,\r\n    token: IToken,\r\n    lookahead: number,\r\n    predicateSet: PredicateSet,\r\n    logging: AmbiguityReport\r\n): DFAState {\r\n    const reach = computeReachSet(previousD.configs, token, predicateSet)\r\n    if (reach.size === 0) {\r\n        addDFAEdge(dfa, previousD, token, DFA_ERROR)\r\n        return DFA_ERROR\r\n    }\r\n\r\n    let newState = newDFAState(reach)\r\n    const predictedAlt = getUniqueAlt(reach, predicateSet)\r\n\r\n    if (predictedAlt !== undefined) {\r\n        newState.isAcceptState = true\r\n        newState.prediction = predictedAlt\r\n        newState.configs.uniqueAlt = predictedAlt\r\n    } else if (hasConflictTerminatingPrediction(reach)) {\r\n        const prediction = min(reach.alts)!\r\n        newState.isAcceptState = true\r\n        newState.prediction = prediction\r\n        newState.configs.uniqueAlt = prediction\r\n        reportLookaheadAmbiguity.apply(this, [dfa, lookahead, reach.alts, logging])\r\n    }\r\n\r\n    newState = addDFAEdge(dfa, previousD, token, newState)\r\n    return newState\r\n}\r\n\r\nfunction reportLookaheadAmbiguity(\r\n    this: BaseParser,\r\n    dfa: DFA,\r\n    lookahead: number,\r\n    ambiguityIndices: number[],\r\n    logging: AmbiguityReport\r\n) {\r\n    const prefixPath: TokenType[] = []\r\n    for (let i = 1; i <= lookahead; i++) {\r\n        prefixPath.push(this.LA(i).tokenType)\r\n    }\r\n    const atnState = dfa.atnStartState\r\n    const topLevelRule = atnState.rule\r\n    const production = atnState.production\r\n    const message = buildAmbiguityError({\r\n        topLevelRule,\r\n        ambiguityIndices,\r\n        production,\r\n        prefixPath\r\n    })\r\n    logging(message)\r\n}\r\n\r\nfunction buildAmbiguityError(options: {\r\n    topLevelRule: Rule\r\n    prefixPath: TokenType[]\r\n    ambiguityIndices: number[]\r\n    production: IProductionWithOccurrence\r\n}): string {\r\n    const pathMsg = map(options.prefixPath, (currtok) =>\r\n        tokenLabel(currtok)\r\n    ).join(\", \")\r\n    const occurrence =\r\n        options.production.idx === 0 ? \"\" : options.production.idx\r\n    let currMessage =\r\n        `Ambiguous Alternatives Detected: <${options.ambiguityIndices.join(\r\n            \", \"\r\n        )}> in <${getProductionDslName(options.production)}${occurrence}>` +\r\n        ` inside <${options.topLevelRule.name}> Rule,\\n` +\r\n        `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n`\r\n\r\n    currMessage =\r\n        currMessage +\r\n        `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#AMBIGUOUS_ALTERNATIVES\\n` +\r\n        `For Further details.`\r\n    return currMessage\r\n}\r\n\r\nfunction getProductionDslName(prod: IProductionWithOccurrence): string {\r\n    if (prod instanceof NonTerminal) {\r\n        return \"SUBRULE\"\r\n    } else if (prod instanceof Option) {\r\n        return \"OPTION\"\r\n    } else if (prod instanceof Alternation) {\r\n        return \"OR\"\r\n    } else if (prod instanceof RepetitionMandatory) {\r\n        return \"AT_LEAST_ONE\"\r\n    } else if (prod instanceof RepetitionMandatoryWithSeparator) {\r\n        return \"AT_LEAST_ONE_SEP\"\r\n    } else if (prod instanceof RepetitionWithSeparator) {\r\n        return \"MANY_SEP\"\r\n    } else if (prod instanceof Repetition) {\r\n        return \"MANY\"\r\n    } else if (prod instanceof Terminal) {\r\n        return \"CONSUME\"\r\n    } else {\r\n        throw Error(\"non exhaustive match\")\r\n    }\r\n}\r\n\r\nfunction buildAdaptivePredictError(\r\n    path: IToken[],\r\n    previous: DFAState,\r\n    current: IToken\r\n): AdaptivePredictError {\r\n    const nextTransitions = flatMap(\r\n        previous.configs.elements,\r\n        (e) => e.state.transitions\r\n    )\r\n    const nextTokenTypes = uniqBy(\r\n        nextTransitions\r\n            .filter((e): e is AtomTransition => e instanceof AtomTransition)\r\n            .map((e) => e.tokenType),\r\n        (e) => e.tokenTypeIdx\r\n    )\r\n    return {\r\n        actualToken: current,\r\n        possibleTokenTypes: nextTokenTypes,\r\n        tokenPath: path\r\n    }\r\n}\r\n\r\nfunction getExistingTargetState(\r\n    state: DFAState,\r\n    token: IToken\r\n): DFAState | undefined {\r\n    return state.edges[token.tokenTypeIdx]\r\n}\r\n\r\nfunction computeReachSet(\r\n    configs: ATNConfigSet,\r\n    token: IToken,\r\n    predicateSet: PredicateSet\r\n): ATNConfigSet {\r\n    const intermediate = new ATNConfigSet()\r\n    const skippedStopStates: ATNConfig[] = []\r\n\r\n    for (const c of configs.elements) {\r\n        if (predicateSet.is(c.alt) === false) {\r\n            continue\r\n        }\r\n        if (c.state.type === ATN_RULE_STOP) {\r\n            skippedStopStates.push(c)\r\n            continue\r\n        }\r\n        const transitionLength = c.state.transitions.length\r\n        for (let i = 0; i < transitionLength; i++) {\r\n            const transition = c.state.transitions[i]\r\n            const target = getReachableTarget(transition, token)\r\n            if (target !== undefined) {\r\n                intermediate.add({\r\n                    state: target,\r\n                    alt: c.alt,\r\n                    stack: c.stack\r\n                })\r\n            }\r\n        }\r\n    }\r\n\r\n    let reach: ATNConfigSet | undefined\r\n\r\n    if (skippedStopStates.length === 0 && intermediate.size === 1) {\r\n        reach = intermediate\r\n    }\r\n\r\n    if (reach === undefined) {\r\n        reach = new ATNConfigSet()\r\n        for (const c of intermediate.elements) {\r\n            closure(c, reach)\r\n        }\r\n    }\r\n\r\n    if (skippedStopStates.length > 0 && !hasConfigInRuleStopState(reach)) {\r\n        for (const c of skippedStopStates) {\r\n            reach.add(c)\r\n        }\r\n    }\r\n\r\n    return reach\r\n}\r\n\r\nfunction getReachableTarget(\r\n    transition: Transition,\r\n    token: IToken\r\n): ATNState | undefined {\r\n    if (\r\n        transition instanceof AtomTransition &&\r\n        tokenMatcher(token, transition.tokenType)\r\n    ) {\r\n        return transition.target\r\n    }\r\n    return undefined\r\n}\r\n\r\nfunction getUniqueAlt(\r\n    configs: ATNConfigSet,\r\n    predicateSet: PredicateSet\r\n): number | undefined {\r\n    let alt: number | undefined\r\n    for (const c of configs.elements) {\r\n        if (predicateSet.is(c.alt) === true) {\r\n            if (alt === undefined) {\r\n                alt = c.alt\r\n            } else if (alt !== c.alt) {\r\n                return undefined\r\n            }\r\n        }\r\n    }\r\n    return alt\r\n}\r\n\r\nfunction newDFAState(closure: ATNConfigSet): DFAState {\r\n    return {\r\n        configs: closure,\r\n        edges: {},\r\n        isAcceptState: false,\r\n        prediction: -1\r\n    }\r\n}\r\n\r\nfunction addDFAEdge(\r\n    dfa: DFA,\r\n    from: DFAState,\r\n    token: IToken,\r\n    to: DFAState\r\n): DFAState {\r\n    to = addDFAState(dfa, to)\r\n    from.edges[token.tokenTypeIdx] = to\r\n    return to\r\n}\r\n\r\nfunction addDFAState(dfa: DFA, state: DFAState): DFAState {\r\n    if (state === DFA_ERROR) {\r\n        return state\r\n    }\r\n    // Repetitions have the same config set\r\n    // Therefore, storing the key of the config in a map allows us to create a loop in our DFA\r\n    const mapKey = state.configs.key\r\n    const existing = dfa.states[mapKey]\r\n    if (existing !== undefined) {\r\n        return existing\r\n    }\r\n    state.configs.finalize()\r\n    dfa.states[mapKey] = state\r\n    return state\r\n}\r\n\r\nfunction computeStartState(atnState: ATNState): ATNConfigSet {\r\n    const configs = new ATNConfigSet()\r\n\r\n    const numberOfTransitions = atnState.transitions.length\r\n    for (let i = 0; i < numberOfTransitions; i++) {\r\n        const target = atnState.transitions[i].target\r\n        const config: ATNConfig = {\r\n            state: target,\r\n            alt: i,\r\n            stack: []\r\n        }\r\n        closure(config, configs)\r\n    }\r\n\r\n    return configs\r\n}\r\n\r\nfunction closure(config: ATNConfig, configs: ATNConfigSet): void {\r\n    const p = config.state\r\n\r\n    if (p.type === ATN_RULE_STOP) {\r\n        if (config.stack.length > 0) {\r\n            const atnStack = [...config.stack]\r\n            const followState = atnStack.pop()!\r\n            const followConfig: ATNConfig = {\r\n                state: followState,\r\n                alt: config.alt,\r\n                stack: atnStack\r\n            }\r\n            closure(followConfig, configs)\r\n        } else {\r\n            // Dipping into outer context, simply add the config\r\n            // This will stop computation once every config is at the rule stop state\r\n            configs.add(config)\r\n        }\r\n        return\r\n    }\r\n\r\n    if (!p.epsilonOnlyTransitions) {\r\n        configs.add(config)\r\n    }\r\n\r\n    const transitionLength = p.transitions.length\r\n    for (let i = 0; i < transitionLength; i++) {\r\n        const transition = p.transitions[i]\r\n        const c = getEpsilonTarget(config, transition)\r\n\r\n        if (c !== undefined) {\r\n            closure(c, configs)\r\n        }\r\n    }\r\n}\r\n\r\nfunction getEpsilonTarget(\r\n    config: ATNConfig,\r\n    transition: Transition\r\n): ATNConfig | undefined {\r\n    if (transition instanceof EpsilonTransition) {\r\n        return {\r\n            state: transition.target,\r\n            alt: config.alt,\r\n            stack: config.stack\r\n        }\r\n    } else if (transition instanceof RuleTransition) {\r\n        const stack = [...config.stack, transition.followState]\r\n        return {\r\n            state: transition.target,\r\n            alt: config.alt,\r\n            stack\r\n        }\r\n    }\r\n    return undefined\r\n}\r\n\r\nfunction hasConfigInRuleStopState(configs: ATNConfigSet): boolean {\r\n    for (const c of configs.elements) {\r\n        if (c.state.type === ATN_RULE_STOP) {\r\n            return true\r\n        }\r\n    }\r\n    return false\r\n}\r\n\r\nfunction allConfigsInRuleStopStates(configs: ATNConfigSet): boolean {\r\n    for (const c of configs.elements) {\r\n        if (c.state.type !== ATN_RULE_STOP) {\r\n            return false\r\n        }\r\n    }\r\n    return true\r\n}\r\n\r\nfunction hasConflictTerminatingPrediction(configs: ATNConfigSet): boolean {\r\n    if (allConfigsInRuleStopStates(configs)) {\r\n        return true\r\n    }\r\n    const altSets = getConflictingAltSets(configs.elements)\r\n    const heuristic =\r\n        hasConflictingAltSet(altSets) && !hasStateAssociatedWithOneAlt(altSets)\r\n    return heuristic\r\n}\r\n\r\nfunction getConflictingAltSets(\r\n    configs: readonly ATNConfig[]\r\n): Map<string, Record<number, boolean>> {\r\n    const configToAlts = new Map<string, Record<number, boolean>>()\r\n    for (const c of configs) {\r\n        const key = getATNConfigKey(c, false)\r\n        let alts = configToAlts.get(key)\r\n        if (alts === undefined) {\r\n            alts = {}\r\n            configToAlts.set(key, alts)\r\n        }\r\n        alts[c.alt] = true\r\n    }\r\n    return configToAlts\r\n}\r\n\r\nfunction hasConflictingAltSet(\r\n    altSets: Map<string, Record<number, boolean>>\r\n): boolean {\r\n    for (const value of Array.from(altSets.values())) {\r\n        if (Object.keys(value).length > 1) {\r\n            return true\r\n        }\r\n    }\r\n    return false\r\n}\r\n\r\nfunction hasStateAssociatedWithOneAlt(\r\n    altSets: Map<string, Record<number, boolean>>\r\n): boolean {\r\n    for (const value of Array.from(altSets.values())) {\r\n        if (Object.keys(value).length === 1) {\r\n            return true\r\n        }\r\n    }\r\n    return false\r\n}\r\n","import baseMatches from './_baseMatches.js';\nimport baseMatchesProperty from './_baseMatchesProperty.js';\nimport identity from './identity.js';\nimport isArray from './isArray.js';\nimport property from './property.js';\n\n/**\n * The base implementation of `_.iteratee`.\n *\n * @private\n * @param {*} [value=_.identity] The value to convert to an iteratee.\n * @returns {Function} Returns the iteratee.\n */\nfunction baseIteratee(value) {\n  // Don't store the `typeof` result in a variable to avoid a JIT bug in Safari 9.\n  // See https://bugs.webkit.org/show_bug.cgi?id=156034 for more details.\n  if (typeof value == 'function') {\n    return value;\n  }\n  if (value == null) {\n    return identity;\n  }\n  if (typeof value == 'object') {\n    return isArray(value)\n      ? baseMatchesProperty(value[0], value[1])\n      : baseMatches(value);\n  }\n  return property(value);\n}\n\nexport default baseIteratee;\n","import hashClear from './_hashClear.js';\nimport hashDelete from './_hashDelete.js';\nimport hashGet from './_hashGet.js';\nimport hashHas from './_hashHas.js';\nimport hashSet from './_hashSet.js';\n\n/**\n * Creates a hash object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Hash(entries) {\n  var index = -1,\n      length = entries == null ? 0 : entries.length;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n// Add methods to `Hash`.\nHash.prototype.clear = hashClear;\nHash.prototype['delete'] = hashDelete;\nHash.prototype.get = hashGet;\nHash.prototype.has = hashHas;\nHash.prototype.set = hashSet;\n\nexport default Hash;\n","import mapCacheClear from './_mapCacheClear.js';\nimport mapCacheDelete from './_mapCacheDelete.js';\nimport mapCacheGet from './_mapCacheGet.js';\nimport mapCacheHas from './_mapCacheHas.js';\nimport mapCacheSet from './_mapCacheSet.js';\n\n/**\n * Creates a map cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction MapCache(entries) {\n  var index = -1,\n      length = entries == null ? 0 : entries.length;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n// Add methods to `MapCache`.\nMapCache.prototype.clear = mapCacheClear;\nMapCache.prototype['delete'] = mapCacheDelete;\nMapCache.prototype.get = mapCacheGet;\nMapCache.prototype.has = mapCacheHas;\nMapCache.prototype.set = mapCacheSet;\n\nexport default MapCache;\n","import arrayReduce from './_arrayReduce.js';\nimport baseEach from './_baseEach.js';\nimport baseIteratee from './_baseIteratee.js';\nimport baseReduce from './_baseReduce.js';\nimport isArray from './isArray.js';\n\n/**\n * Reduces `collection` to a value which is the accumulated result of running\n * each element in `collection` thru `iteratee`, where each successive\n * invocation is supplied the return value of the previous. If `accumulator`\n * is not given, the first element of `collection` is used as the initial\n * value. The iteratee is invoked with four arguments:\n * (accumulator, value, index|key, collection).\n *\n * Many lodash methods are guarded to work as iteratees for methods like\n * `_.reduce`, `_.reduceRight`, and `_.transform`.\n *\n * The guarded methods are:\n * `assign`, `defaults`, `defaultsDeep`, `includes`, `merge`, `orderBy`,\n * and `sortBy`\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The function invoked per iteration.\n * @param {*} [accumulator] The initial value.\n * @returns {*} Returns the accumulated value.\n * @see _.reduceRight\n * @example\n *\n * _.reduce([1, 2], function(sum, n) {\n *   return sum + n;\n * }, 0);\n * // => 3\n *\n * _.reduce({ 'a': 1, 'b': 2, 'c': 1 }, function(result, value, key) {\n *   (result[value] || (result[value] = [])).push(key);\n *   return result;\n * }, {});\n * // => { '1': ['a', 'c'], '2': ['b'] } (iteration order is not guaranteed)\n */\nfunction reduce(collection, iteratee, accumulator) {\n  var func = isArray(collection) ? arrayReduce : baseReduce,\n      initAccum = arguments.length < 3;\n\n  return func(collection, baseIteratee(iteratee, 4), accumulator, initAccum, baseEach);\n}\n\nexport default reduce;\n","import arrayFilter from './_arrayFilter.js';\nimport baseFilter from './_baseFilter.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\nimport negate from './negate.js';\n\n/**\n * The opposite of `_.filter`; this method returns the elements of `collection`\n * that `predicate` does **not** return truthy for.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new filtered array.\n * @see _.filter\n * @example\n *\n * var users = [\n *   { 'user': 'barney', 'age': 36, 'active': false },\n *   { 'user': 'fred',   'age': 40, 'active': true }\n * ];\n *\n * _.reject(users, function(o) { return !o.active; });\n * // => objects for ['fred']\n *\n * // The `_.matches` iteratee shorthand.\n * _.reject(users, { 'age': 40, 'active': true });\n * // => objects for ['barney']\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.reject(users, ['active', false]);\n * // => objects for ['fred']\n *\n * // The `_.property` iteratee shorthand.\n * _.reject(users, 'active');\n * // => objects for ['barney']\n */\nfunction reject(collection, predicate) {\n  var func = isArray(collection) ? arrayFilter : baseFilter;\n  return func(collection, negate(baseIteratee(predicate, 3)));\n}\n\nexport default reject;\n","import assignValue from './_assignValue.js';\nimport castPath from './_castPath.js';\nimport isIndex from './_isIndex.js';\nimport isObject from './isObject.js';\nimport toKey from './_toKey.js';\n\n/**\n * The base implementation of `_.set`.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {Array|string} path The path of the property to set.\n * @param {*} value The value to set.\n * @param {Function} [customizer] The function to customize path creation.\n * @returns {Object} Returns `object`.\n */\nfunction baseSet(object, path, value, customizer) {\n  if (!isObject(object)) {\n    return object;\n  }\n  path = castPath(path, object);\n\n  var index = -1,\n      length = path.length,\n      lastIndex = length - 1,\n      nested = object;\n\n  while (nested != null && ++index < length) {\n    var key = toKey(path[index]),\n        newValue = value;\n\n    if (key === '__proto__' || key === 'constructor' || key === 'prototype') {\n      return object;\n    }\n\n    if (index != lastIndex) {\n      var objValue = nested[key];\n      newValue = customizer ? customizer(objValue, key, nested) : undefined;\n      if (newValue === undefined) {\n        newValue = isObject(objValue)\n          ? objValue\n          : (isIndex(path[index + 1]) ? [] : {});\n      }\n    }\n    assignValue(nested, key, newValue);\n    nested = nested[key];\n  }\n  return object;\n}\n\nexport default baseSet;\n","import arrayEvery from './_arrayEvery.js';\nimport baseEvery from './_baseEvery.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\nimport isIterateeCall from './_isIterateeCall.js';\n\n/**\n * Checks if `predicate` returns truthy for **all** elements of `collection`.\n * Iteration is stopped once `predicate` returns falsey. The predicate is\n * invoked with three arguments: (value, index|key, collection).\n *\n * **Note:** This method returns `true` for\n * [empty collections](https://en.wikipedia.org/wiki/Empty_set) because\n * [everything is true](https://en.wikipedia.org/wiki/Vacuous_truth) of\n * elements of empty collections.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`.\n * @example\n *\n * _.every([true, 1, null, 'yes'], Boolean);\n * // => false\n *\n * var users = [\n *   { 'user': 'barney', 'age': 36, 'active': false },\n *   { 'user': 'fred',   'age': 40, 'active': false }\n * ];\n *\n * // The `_.matches` iteratee shorthand.\n * _.every(users, { 'user': 'barney', 'active': false });\n * // => false\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.every(users, ['active', false]);\n * // => true\n *\n * // The `_.property` iteratee shorthand.\n * _.every(users, 'active');\n * // => false\n */\nfunction every(collection, predicate, guard) {\n  var func = isArray(collection) ? arrayEvery : baseEvery;\n  if (guard && isIterateeCall(collection, predicate, guard)) {\n    predicate = undefined;\n  }\n  return func(collection, baseIteratee(predicate, 3));\n}\n\nexport default every;\n","import baseIndexOf from './_baseIndexOf.js';\nimport isArrayLike from './isArrayLike.js';\nimport isString from './isString.js';\nimport toInteger from './toInteger.js';\nimport values from './values.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * Checks if `value` is in `collection`. If `collection` is a string, it's\n * checked for a substring of `value`, otherwise\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * is used for equality comparisons. If `fromIndex` is negative, it's used as\n * the offset from the end of `collection`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object|string} collection The collection to inspect.\n * @param {*} value The value to search for.\n * @param {number} [fromIndex=0] The index to search from.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.reduce`.\n * @returns {boolean} Returns `true` if `value` is found, else `false`.\n * @example\n *\n * _.includes([1, 2, 3], 1);\n * // => true\n *\n * _.includes([1, 2, 3], 1, 2);\n * // => false\n *\n * _.includes({ 'a': 1, 'b': 2 }, 1);\n * // => true\n *\n * _.includes('abcd', 'bc');\n * // => true\n */\nfunction includes(collection, value, fromIndex, guard) {\n  collection = isArrayLike(collection) ? collection : values(collection);\n  fromIndex = (fromIndex && !guard) ? toInteger(fromIndex) : 0;\n\n  var length = collection.length;\n  if (fromIndex < 0) {\n    fromIndex = nativeMax(length + fromIndex, 0);\n  }\n  return isString(collection)\n    ? (fromIndex <= length && collection.indexOf(value, fromIndex) > -1)\n    : (!!length && baseIndexOf(collection, value, fromIndex) > -1);\n}\n\nexport default includes;\n","import arraySome from './_arraySome.js';\nimport baseIteratee from './_baseIteratee.js';\nimport baseSome from './_baseSome.js';\nimport isArray from './isArray.js';\nimport isIterateeCall from './_isIterateeCall.js';\n\n/**\n * Checks if `predicate` returns truthy for **any** element of `collection`.\n * Iteration is stopped once `predicate` returns truthy. The predicate is\n * invoked with three arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {boolean} Returns `true` if any element passes the predicate check,\n *  else `false`.\n * @example\n *\n * _.some([null, 0, 'yes', false], Boolean);\n * // => true\n *\n * var users = [\n *   { 'user': 'barney', 'active': true },\n *   { 'user': 'fred',   'active': false }\n * ];\n *\n * // The `_.matches` iteratee shorthand.\n * _.some(users, { 'user': 'barney', 'active': false });\n * // => false\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.some(users, ['active', false]);\n * // => true\n *\n * // The `_.property` iteratee shorthand.\n * _.some(users, 'active');\n * // => true\n */\nfunction some(collection, predicate, guard) {\n  var func = isArray(collection) ? arraySome : baseSome;\n  if (guard && isIterateeCall(collection, predicate, guard)) {\n    predicate = undefined;\n  }\n  return func(collection, baseIteratee(predicate, 3));\n}\n\nexport default some;\n","import listCacheClear from './_listCacheClear.js';\nimport listCacheDelete from './_listCacheDelete.js';\nimport listCacheGet from './_listCacheGet.js';\nimport listCacheHas from './_listCacheHas.js';\nimport listCacheSet from './_listCacheSet.js';\n\n/**\n * Creates an list cache object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction ListCache(entries) {\n  var index = -1,\n      length = entries == null ? 0 : entries.length;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n// Add methods to `ListCache`.\nListCache.prototype.clear = listCacheClear;\nListCache.prototype['delete'] = listCacheDelete;\nListCache.prototype.get = listCacheGet;\nListCache.prototype.has = listCacheHas;\nListCache.prototype.set = listCacheSet;\n\nexport default ListCache;\n","import cloneArrayBuffer from './_cloneArrayBuffer.js';\nimport cloneDataView from './_cloneDataView.js';\nimport cloneRegExp from './_cloneRegExp.js';\nimport cloneSymbol from './_cloneSymbol.js';\nimport cloneTypedArray from './_cloneTypedArray.js';\n\n/** `Object#toString` result references. */\nvar boolTag = '[object Boolean]',\n    dateTag = '[object Date]',\n    mapTag = '[object Map]',\n    numberTag = '[object Number]',\n    regexpTag = '[object RegExp]',\n    setTag = '[object Set]',\n    stringTag = '[object String]',\n    symbolTag = '[object Symbol]';\n\nvar arrayBufferTag = '[object ArrayBuffer]',\n    dataViewTag = '[object DataView]',\n    float32Tag = '[object Float32Array]',\n    float64Tag = '[object Float64Array]',\n    int8Tag = '[object Int8Array]',\n    int16Tag = '[object Int16Array]',\n    int32Tag = '[object Int32Array]',\n    uint8Tag = '[object Uint8Array]',\n    uint8ClampedTag = '[object Uint8ClampedArray]',\n    uint16Tag = '[object Uint16Array]',\n    uint32Tag = '[object Uint32Array]';\n\n/**\n * Initializes an object clone based on its `toStringTag`.\n *\n * **Note:** This function only supports cloning values with tags of\n * `Boolean`, `Date`, `Error`, `Map`, `Number`, `RegExp`, `Set`, or `String`.\n *\n * @private\n * @param {Object} object The object to clone.\n * @param {string} tag The `toStringTag` of the object to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the initialized clone.\n */\nfunction initCloneByTag(object, tag, isDeep) {\n  var Ctor = object.constructor;\n  switch (tag) {\n    case arrayBufferTag:\n      return cloneArrayBuffer(object);\n\n    case boolTag:\n    case dateTag:\n      return new Ctor(+object);\n\n    case dataViewTag:\n      return cloneDataView(object, isDeep);\n\n    case float32Tag: case float64Tag:\n    case int8Tag: case int16Tag: case int32Tag:\n    case uint8Tag: case uint8ClampedTag: case uint16Tag: case uint32Tag:\n      return cloneTypedArray(object, isDeep);\n\n    case mapTag:\n      return new Ctor;\n\n    case numberTag:\n    case stringTag:\n      return new Ctor(object);\n\n    case regexpTag:\n      return cloneRegExp(object);\n\n    case setTag:\n      return new Ctor;\n\n    case symbolTag:\n      return cloneSymbol(object);\n  }\n}\n\nexport default initCloneByTag;\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { TokenType } from 'chevrotain';\r\nimport type { URI } from './utils/uri-utils.js';\r\nimport type { AbstractElement } from './languages/generated/ast.js';\r\nimport type { DocumentSegment, LangiumDocument } from './workspace/documents.js';\r\n\r\n/**\r\n * A node in the Abstract Syntax Tree (AST).\r\n */\r\nexport interface AstNode {\r\n    /** Every AST node has a type corresponding to what was specified in the grammar declaration. */\r\n    readonly $type: string;\r\n    /** The container node in the AST; every node except the root node has a container. */\r\n    readonly $container?: AstNode;\r\n    /** The property of the `$container` node that contains this node. This is either a direct reference or an array. */\r\n    readonly $containerProperty?: string;\r\n    /** In case `$containerProperty` is an array, the array index is stored here. */\r\n    readonly $containerIndex?: number;\r\n    /** The Concrete Syntax Tree (CST) node of the text range from which this node was parsed. */\r\n    readonly $cstNode?: CstNode;\r\n    /** The document containing the AST; only the root node has a direct reference to the document. */\r\n    readonly $document?: LangiumDocument;\r\n}\r\n\r\nexport function isAstNode(obj: unknown): obj is AstNode {\r\n    return typeof obj === 'object' && obj !== null && typeof (obj as AstNode).$type === 'string';\r\n}\r\n\r\nexport interface GenericAstNode extends AstNode {\r\n    [key: string]: unknown\r\n}\r\n\r\ntype SpecificNodeProperties<N extends AstNode> = keyof Omit<N, keyof AstNode | number | symbol>;\r\n\r\n/**\r\n * The property names of a given AST node type.\r\n */\r\nexport type Properties<N extends AstNode> = SpecificNodeProperties<N> extends never ? string : SpecificNodeProperties<N>\r\n\r\n/**\r\n * A cross-reference in the AST. Cross-references may or may not be successfully resolved.\r\n */\r\nexport interface Reference<T extends AstNode = AstNode> {\r\n    /**\r\n     * The target AST node of this reference. Accessing this property may trigger cross-reference\r\n     * resolution by the `Linker` in case it has not been done yet. If the reference cannot be resolved,\r\n     * the value is `undefined`.\r\n     */\r\n    readonly ref?: T;\r\n\r\n    /** If any problem occurred while resolving the reference, it is described by this property. */\r\n    readonly error?: LinkingError;\r\n    /** The CST node from which the reference was parsed */\r\n    readonly $refNode?: CstNode;\r\n    /** The actual text used to look up in the surrounding scope */\r\n    readonly $refText: string;\r\n    /** The node description for the AstNode returned by `ref`  */\r\n    readonly $nodeDescription?: AstNodeDescription;\r\n}\r\n\r\nexport function isReference(obj: unknown): obj is Reference {\r\n    return typeof obj === 'object' && obj !== null && typeof (obj as Reference).$refText === 'string';\r\n}\r\n\r\nexport type ResolvedReference<T extends AstNode = AstNode> = Reference<T> & {\r\n    readonly ref: T;\r\n}\r\n\r\n/**\r\n * A description of an AST node is used when constructing scopes and looking up cross-reference targets.\r\n */\r\nexport interface AstNodeDescription {\r\n    /** The target node; should be present only for local references (linking to the same document). */\r\n    node?: AstNode;\r\n    /**\r\n     * The document segment that represents the range of the name of the AST node.\r\n     */\r\n    nameSegment?: DocumentSegment;\r\n    /**\r\n     * The document segment that represents the full range of the AST node.\r\n     */\r\n    selectionSegment?: DocumentSegment;\r\n    /** `$type` property value of the AST node */\r\n    type: string;\r\n    /** Name of the AST node; this is usually determined by the `NameProvider` service. */\r\n    name: string;\r\n    /** URI to the document containing the AST node */\r\n    documentUri: URI;\r\n    /** Navigation path inside the document */\r\n    path: string;\r\n}\r\n\r\nexport function isAstNodeDescription(obj: unknown): obj is AstNodeDescription {\r\n    return typeof obj === 'object' && obj !== null\r\n        && typeof (obj as AstNodeDescription).name === 'string'\r\n        && typeof (obj as AstNodeDescription).type === 'string'\r\n        && typeof (obj as AstNodeDescription).path === 'string';\r\n}\r\n\r\n/**\r\n * Information about a cross-reference. This is used when traversing references in an AST or to describe\r\n * unresolved references.\r\n */\r\nexport interface ReferenceInfo {\r\n    reference: Reference\r\n    container: AstNode\r\n    property: string\r\n    index?: number\r\n}\r\n\r\n/**\r\n * Used to collect information when the `Linker` service fails to resolve a cross-reference.\r\n */\r\nexport interface LinkingError extends ReferenceInfo {\r\n    message: string;\r\n    targetDescription?: AstNodeDescription;\r\n}\r\n\r\nexport function isLinkingError(obj: unknown): obj is LinkingError {\r\n    return typeof obj === 'object' && obj !== null\r\n        && isAstNode((obj as LinkingError).container)\r\n        && isReference((obj as LinkingError).reference)\r\n        && typeof (obj as LinkingError).message === 'string';\r\n}\r\n\r\n/**\r\n * Service used for generic access to the structure of the AST. This service is shared between\r\n * all involved languages, so it operates on the superset of types of these languages.\r\n */\r\nexport interface AstReflection {\r\n    getAllTypes(): string[]\r\n    getAllSubTypes(type: string): string[]\r\n    getReferenceType(refInfo: ReferenceInfo): string\r\n    getTypeMetaData(type: string): TypeMetaData\r\n    isInstance(node: unknown, type: string): boolean\r\n    isSubtype(subtype: string, supertype: string): boolean\r\n}\r\n\r\n/**\r\n * An abstract implementation of the {@link AstReflection} interface.\r\n * Serves to cache subtype computation results to improve performance throughout different parts of Langium.\r\n */\r\nexport abstract class AbstractAstReflection implements AstReflection {\r\n\r\n    protected subtypes: Record<string, Record<string, boolean | undefined>> = {};\r\n    protected allSubtypes: Record<string, string[] | undefined> = {};\r\n\r\n    abstract getAllTypes(): string[];\r\n    abstract getReferenceType(refInfo: ReferenceInfo): string;\r\n    abstract getTypeMetaData(type: string): TypeMetaData;\r\n    protected abstract computeIsSubtype(subtype: string, supertype: string): boolean;\r\n\r\n    isInstance(node: unknown, type: string): boolean {\r\n        return isAstNode(node) && this.isSubtype(node.$type, type);\r\n    }\r\n\r\n    isSubtype(subtype: string, supertype: string): boolean {\r\n        if (subtype === supertype) {\r\n            return true;\r\n        }\r\n        let nested = this.subtypes[subtype];\r\n        if (!nested) {\r\n            nested = this.subtypes[subtype] = {};\r\n        }\r\n        const existing = nested[supertype];\r\n        if (existing !== undefined) {\r\n            return existing;\r\n        } else {\r\n            const result = this.computeIsSubtype(subtype, supertype);\r\n            nested[supertype] = result;\r\n            return result;\r\n        }\r\n    }\r\n\r\n    getAllSubTypes(type: string): string[] {\r\n        const existing = this.allSubtypes[type];\r\n        if (existing) {\r\n            return existing;\r\n        } else {\r\n            const allTypes = this.getAllTypes();\r\n            const types: string[] = [];\r\n            for (const possibleSubType of allTypes) {\r\n                if (this.isSubtype(possibleSubType, type)) {\r\n                    types.push(possibleSubType);\r\n                }\r\n            }\r\n            this.allSubtypes[type] = types;\r\n            return types;\r\n        }\r\n    }\r\n}\r\n\r\n/**\r\n * Represents runtime meta data about a meta model type.\r\n */\r\nexport interface TypeMetaData {\r\n    /** The name of this meta model type. Corresponds to the `AstNode.$type` value. */\r\n    name: string\r\n    /** A list of properties. They can contain default values for their respective property in the AST. */\r\n    properties: TypeProperty[]\r\n}\r\n\r\n/**\r\n * Describes the meta data of a property of an AST node.\r\n *\r\n * The optional `defaultValue` indicates that the property is mandatory in the AST node.\r\n * For example, if an AST node contains an array, but no elements of this array have been parsed, we still expect an empty array instead of `undefined`.\r\n */\r\nexport interface TypeProperty {\r\n    name: string\r\n    defaultValue?: PropertyType\r\n}\r\n\r\n/**\r\n * Represents a default value for an AST property.\r\n */\r\nexport type PropertyType = number | string | boolean | PropertyType[];\r\n\r\n/**\r\n * A node in the Concrete Syntax Tree (CST).\r\n */\r\nexport interface CstNode extends DocumentSegment {\r\n    /** The container node in the CST */\r\n    readonly container?: CompositeCstNode;\r\n    /** @deprecated use `container` instead. */\r\n    readonly parent?: CompositeCstNode;\r\n    /** The actual text */\r\n    readonly text: string;\r\n    /** The root CST node */\r\n    readonly root: RootCstNode;\r\n    /** The grammar element from which this node was parsed */\r\n    readonly grammarSource?: AbstractElement;\r\n    /** @deprecated use `grammarSource` instead. */\r\n    readonly feature?: AbstractElement;\r\n    /** The AST node created from this CST node */\r\n    readonly astNode: AstNode;\r\n    /** @deprecated use `astNode` instead. */\r\n    readonly element: AstNode;\r\n    /** Whether the token is hidden, i.e. not explicitly part of the containing grammar rule */\r\n    readonly hidden: boolean;\r\n}\r\n\r\n/**\r\n * A composite CST node contains other nodes, but no directly associated token.\r\n */\r\nexport interface CompositeCstNode extends CstNode {\r\n    readonly content: CstNode[];\r\n    /** @deprecated use `content` instead. */\r\n    readonly children: CstNode[];\r\n}\r\n\r\nexport function isCompositeCstNode(node: unknown): node is CompositeCstNode {\r\n    return typeof node === 'object' && node !== null && Array.isArray((node as CompositeCstNode).content);\r\n}\r\n\r\n/**\r\n * A leaf CST node corresponds to a token in the input token stream.\r\n */\r\nexport interface LeafCstNode extends CstNode {\r\n    readonly tokenType: TokenType;\r\n}\r\n\r\nexport function isLeafCstNode(node: unknown): node is LeafCstNode {\r\n    return typeof node === 'object' && node !== null && typeof (node as LeafCstNode).tokenType === 'object';\r\n}\r\n\r\nexport interface RootCstNode extends CompositeCstNode {\r\n    readonly fullText: string\r\n}\r\n\r\nexport function isRootCstNode(node: unknown): node is RootCstNode {\r\n    return isCompositeCstNode(node) && typeof (node as RootCstNode).fullText === 'string';\r\n}\r\n\r\n/**\r\n * Returns a type to have only properties names (!) of a type T whose property value is of a certain type K.\r\n */\r\ntype ExtractKeysOfValueType<T, K> = { [I in keyof T]: T[I] extends K ? I : never }[keyof T];\r\n\r\n/**\r\n * Returns the property names (!) of an AstNode that are cross-references.\r\n * Meant to be used during cross-reference resolution in combination with `assertUnreachable(context.property)`.\r\n */\r\nexport type CrossReferencesOfAstNodeType<N extends AstNode> = (\r\n    ExtractKeysOfValueType<N, Reference|undefined>\r\n    | ExtractKeysOfValueType<N, Array<Reference|undefined>|undefined>\r\n// eslint-disable-next-line @typescript-eslint/ban-types\r\n) & {};\r\n\r\n/**\r\n * Represents the enumeration-like type, that lists all AstNode types of your grammar.\r\n */\r\nexport type AstTypeList<T> = Record<keyof T, AstNode>;\r\n\r\n/**\r\n * Returns all types that contain cross-references, A is meant to be the interface `XXXAstType` fromm your generated `ast.ts` file.\r\n * Meant to be used during cross-reference resolution in combination with `assertUnreachable(context.container)`.\r\n */\r\nexport type AstNodeTypesWithCrossReferences<A extends AstTypeList<A>> = {\r\n    [T in keyof A]: CrossReferencesOfAstNodeType<A[T]> extends never ? never : A[T]\r\n}[keyof A];\r\n\r\nexport type Mutable<T> = {\r\n    -readonly [P in keyof T]: T[P]\r\n};\r\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { Position, Range } from 'vscode-languageserver-types';\r\nimport type { CstNode } from '../syntax-tree.js';\r\nimport { NEWLINE_REGEXP, escapeRegExp } from '../utils/regexp-utils.js';\r\nimport { URI } from '../utils/uri-utils.js';\r\n\r\nexport interface JSDocComment extends JSDocValue {\r\n    readonly elements: JSDocElement[]\r\n    getTag(name: string): JSDocTag | undefined\r\n    getTags(name: string): JSDocTag[]\r\n}\r\n\r\nexport type JSDocElement = JSDocParagraph | JSDocTag;\r\n\r\nexport type JSDocInline = JSDocTag | JSDocLine;\r\n\r\nexport interface JSDocValue {\r\n    /**\r\n     * Represents the range that this JSDoc element occupies.\r\n     * If the JSDoc was parsed from a `CstNode`, the range will represent the location in the source document.\r\n     */\r\n    readonly range: Range\r\n    /**\r\n     * Renders this JSDoc element to a plain text representation.\r\n     */\r\n    toString(): string\r\n    /**\r\n     * Renders this JSDoc element to a markdown representation.\r\n     *\r\n     * @param options Rendering options to customize the markdown result.\r\n     */\r\n    toMarkdown(options?: JSDocRenderOptions): string\r\n}\r\n\r\nexport interface JSDocParagraph extends JSDocValue {\r\n    readonly inlines: JSDocInline[]\r\n}\r\n\r\nexport interface JSDocLine extends JSDocValue {\r\n    readonly text: string\r\n}\r\n\r\nexport interface JSDocTag extends JSDocValue {\r\n    readonly name: string\r\n    readonly content: JSDocParagraph\r\n    readonly inline: boolean\r\n}\r\n\r\nexport interface JSDocParseOptions {\r\n    /**\r\n     * The start symbol of your comment format. Defaults to `/**`.\r\n     */\r\n    readonly start?: RegExp | string\r\n    /**\r\n     * The symbol that start a line of your comment format. Defaults to `*`.\r\n     */\r\n    readonly line?: RegExp | string\r\n    /**\r\n     * The end symbol of your comment format. Defaults to `*\\/`.\r\n     */\r\n    readonly end?: RegExp | string\r\n}\r\n\r\nexport interface JSDocRenderOptions {\r\n    /**\r\n     * Determines the style for rendering tags. Defaults to `italic`.\r\n     */\r\n    tag?: 'plain' | 'italic' | 'bold' | 'bold-italic'\r\n    /**\r\n     * Determines the default for rendering `@link` tags. Defaults to `plain`.\r\n     */\r\n    link?: 'code' | 'plain'\r\n    /**\r\n     * Custom tag rendering function.\r\n     * Return a markdown formatted tag or `undefined` to fall back to the default rendering.\r\n     */\r\n    renderTag?(tag: JSDocTag): string | undefined\r\n    /**\r\n     * Custom link rendering function. Accepts a link target and a display value for the link.\r\n     * Return a markdown formatted link with the format `[$display]($link)` or `undefined` if the link is not a valid target.\r\n     */\r\n    renderLink?(link: string, display: string): string | undefined\r\n}\r\n\r\n/**\r\n * Parses a JSDoc from a `CstNode` containing a comment.\r\n *\r\n * @param node A `CstNode` from a parsed Langium document.\r\n * @param options Parsing options specialized to your language. See {@link JSDocParseOptions}.\r\n */\r\nexport function parseJSDoc(node: CstNode, options?: JSDocParseOptions): JSDocComment;\r\n/**\r\n * Parses a JSDoc from a string comment.\r\n *\r\n * @param content A string containing the source of the JSDoc comment.\r\n * @param start The start position the comment occupies in the source document.\r\n * @param options Parsing options specialized to your language. See {@link JSDocParseOptions}.\r\n */\r\nexport function parseJSDoc(content: string, start?: Position, options?: JSDocParseOptions): JSDocComment;\r\nexport function parseJSDoc(node: CstNode | string, start?: Position | JSDocParseOptions, options?: JSDocParseOptions): JSDocComment {\r\n    let opts: JSDocParseOptions | undefined;\r\n    let position: Position | undefined;\r\n    if (typeof node === 'string') {\r\n        position = start as Position | undefined;\r\n        opts = options as JSDocParseOptions | undefined;\r\n    } else {\r\n        position = node.range.start;\r\n        opts = start as JSDocParseOptions | undefined;\r\n    }\r\n    if (!position) {\r\n        position = Position.create(0, 0);\r\n    }\r\n\r\n    const lines = getLines(node);\r\n    const normalizedOptions = normalizeOptions(opts);\r\n\r\n    const tokens = tokenize({\r\n        lines,\r\n        position,\r\n        options: normalizedOptions\r\n    });\r\n\r\n    return parseJSDocComment({\r\n        index: 0,\r\n        tokens,\r\n        position\r\n    });\r\n}\r\n\r\nexport function isJSDoc(node: CstNode | string, options?: JSDocParseOptions): boolean {\r\n    const normalizedOptions = normalizeOptions(options);\r\n    const lines = getLines(node);\r\n    if (lines.length === 0) {\r\n        return false;\r\n    }\r\n\r\n    const first = lines[0];\r\n    const last = lines[lines.length - 1];\r\n    const firstRegex = normalizedOptions.start;\r\n    const lastRegex = normalizedOptions.end;\r\n\r\n    return Boolean(firstRegex?.exec(first)) && Boolean(lastRegex?.exec(last));\r\n}\r\n\r\nfunction getLines(node: CstNode | string): string[] {\r\n    let content = '';\r\n    if (typeof node === 'string') {\r\n        content = node;\r\n    } else {\r\n        content = node.text;\r\n    }\r\n    const lines = content.split(NEWLINE_REGEXP);\r\n    return lines;\r\n}\r\n\r\n// Tokenization\r\n\r\ninterface JSDocToken {\r\n    type: 'text' | 'tag' | 'inline-tag' | 'break'\r\n    content: string\r\n    range: Range\r\n}\r\n\r\nconst tagRegex = /\\s*(@([\\p{L}][\\p{L}\\p{N}]*)?)/uy;\r\nconst inlineTagRegex = /\\{(@[\\p{L}][\\p{L}\\p{N}]*)(\\s*)([^\\r\\n}]+)?\\}/gu;\r\n\r\nfunction tokenize(context: TokenizationContext): JSDocToken[] {\r\n    const tokens: JSDocToken[] = [];\r\n    let currentLine = context.position.line;\r\n    let currentCharacter = context.position.character;\r\n    for (let i = 0; i < context.lines.length; i++) {\r\n        const first = i === 0;\r\n        const last = i === context.lines.length - 1;\r\n        let line = context.lines[i];\r\n        let index = 0;\r\n\r\n        if (first && context.options.start) {\r\n            const match = context.options.start?.exec(line);\r\n            if (match) {\r\n                index = match.index + match[0].length;\r\n            }\r\n        } else {\r\n            const match = context.options.line?.exec(line);\r\n            if (match) {\r\n                index = match.index + match[0].length;\r\n            }\r\n        }\r\n        if (last) {\r\n            const match = context.options.end?.exec(line);\r\n            if (match) {\r\n                line = line.substring(0, match.index);\r\n            }\r\n        }\r\n\r\n        line = line.substring(0, lastCharacter(line));\r\n        const whitespaceEnd = skipWhitespace(line, index);\r\n\r\n        if (whitespaceEnd >= line.length) {\r\n            // Only create a break token when we already have previous tokens\r\n            if (tokens.length > 0) {\r\n                const position = Position.create(currentLine, currentCharacter);\r\n                tokens.push({\r\n                    type: 'break',\r\n                    content: '',\r\n                    range: Range.create(position, position)\r\n                });\r\n            }\r\n        } else {\r\n            tagRegex.lastIndex = index;\r\n            const tagMatch = tagRegex.exec(line);\r\n            if (tagMatch) {\r\n                const fullMatch = tagMatch[0];\r\n                const value = tagMatch[1];\r\n                const start = Position.create(currentLine, currentCharacter + index);\r\n                const end = Position.create(currentLine, currentCharacter + index + fullMatch.length);\r\n                tokens.push({\r\n                    type: 'tag',\r\n                    content: value,\r\n                    range: Range.create(start, end)\r\n                });\r\n                index += fullMatch.length;\r\n                index = skipWhitespace(line, index);\r\n            }\r\n\r\n            if (index < line.length) {\r\n                const rest = line.substring(index);\r\n                const inlineTagMatches = Array.from(rest.matchAll(inlineTagRegex));\r\n                tokens.push(...buildInlineTokens(inlineTagMatches, rest, currentLine, currentCharacter + index));\r\n            }\r\n        }\r\n\r\n        currentLine++;\r\n        currentCharacter = 0;\r\n    }\r\n\r\n    // Remove last break token if there is one\r\n    if (tokens.length > 0 && tokens[tokens.length - 1].type === 'break') {\r\n        return tokens.slice(0, -1);\r\n    }\r\n\r\n    return tokens;\r\n}\r\n\r\nfunction buildInlineTokens(tags: RegExpMatchArray[], line: string, lineIndex: number, characterIndex: number): JSDocToken[] {\r\n    const tokens: JSDocToken[] = [];\r\n\r\n    if (tags.length === 0) {\r\n        const start = Position.create(lineIndex, characterIndex);\r\n        const end = Position.create(lineIndex, characterIndex + line.length);\r\n        tokens.push({\r\n            type: 'text',\r\n            content: line,\r\n            range: Range.create(start, end)\r\n        });\r\n    } else {\r\n        let lastIndex = 0;\r\n        for (const match of tags) {\r\n            const matchIndex = match.index!;\r\n            const startContent = line.substring(lastIndex, matchIndex);\r\n            if (startContent.length > 0) {\r\n                tokens.push({\r\n                    type: 'text',\r\n                    content: line.substring(lastIndex, matchIndex),\r\n                    range: Range.create(\r\n                        Position.create(lineIndex, lastIndex + characterIndex),\r\n                        Position.create(lineIndex, matchIndex + characterIndex)\r\n                    )\r\n                });\r\n            }\r\n            let offset = startContent.length + 1;\r\n            const tagName = match[1];\r\n            tokens.push({\r\n                type: 'inline-tag',\r\n                content: tagName,\r\n                range: Range.create(\r\n                    Position.create(lineIndex, lastIndex + offset + characterIndex),\r\n                    Position.create(lineIndex, lastIndex + offset + tagName.length + characterIndex)\r\n                )\r\n            });\r\n            offset += tagName.length;\r\n            if (match.length === 4) {\r\n                offset += match[2].length;\r\n                const value = match[3];\r\n                tokens.push({\r\n                    type: 'text',\r\n                    content: value,\r\n                    range: Range.create(\r\n                        Position.create(lineIndex, lastIndex + offset + characterIndex),\r\n                        Position.create(lineIndex, lastIndex + offset + value.length + characterIndex)\r\n                    )\r\n                });\r\n            } else {\r\n                tokens.push({\r\n                    type: 'text',\r\n                    content: '',\r\n                    range: Range.create(\r\n                        Position.create(lineIndex, lastIndex + offset + characterIndex),\r\n                        Position.create(lineIndex, lastIndex + offset + characterIndex)\r\n                    )\r\n                });\r\n            }\r\n            lastIndex = matchIndex + match[0].length;\r\n        }\r\n        const endContent = line.substring(lastIndex);\r\n        if (endContent.length > 0) {\r\n            tokens.push({\r\n                type: 'text',\r\n                content: endContent,\r\n                range: Range.create(\r\n                    Position.create(lineIndex, lastIndex + characterIndex),\r\n                    Position.create(lineIndex, lastIndex + characterIndex + endContent.length)\r\n                )\r\n            });\r\n        }\r\n    }\r\n\r\n    return tokens;\r\n}\r\n\r\nconst nonWhitespaceRegex = /\\S/;\r\nconst whitespaceEndRegex = /\\s*$/;\r\n\r\nfunction skipWhitespace(line: string, index: number): number {\r\n    const match = line.substring(index).match(nonWhitespaceRegex);\r\n    if (match) {\r\n        return index + match.index!;\r\n    } else {\r\n        return line.length;\r\n    }\r\n}\r\n\r\nfunction lastCharacter(line: string): number | undefined {\r\n    const match = line.match(whitespaceEndRegex);\r\n    if (match && typeof match.index === 'number') {\r\n        return match.index;\r\n    }\r\n    return undefined;\r\n}\r\n\r\n// Parsing\r\n\r\nfunction parseJSDocComment(context: ParseContext): JSDocComment {\r\n    const startPosition: Position = Position.create(context.position.line, context.position.character);\r\n    if (context.tokens.length === 0) {\r\n        return new JSDocCommentImpl([], Range.create(startPosition, startPosition));\r\n    }\r\n    const elements: JSDocElement[] = [];\r\n    while (context.index < context.tokens.length) {\r\n        const element = parseJSDocElement(context, elements[elements.length - 1]);\r\n        if (element) {\r\n            elements.push(element);\r\n        }\r\n    }\r\n    const start = elements[0]?.range.start ?? startPosition;\r\n    const end = elements[elements.length - 1]?.range.end ?? startPosition;\r\n    return new JSDocCommentImpl(elements, Range.create(start, end));\r\n}\r\n\r\nfunction parseJSDocElement(context: ParseContext, last?: JSDocElement): JSDocElement | undefined {\r\n    const next = context.tokens[context.index];\r\n    if (next.type === 'tag') {\r\n        return parseJSDocTag(context, false);\r\n    } else if (next.type === 'text' || next.type === 'inline-tag') {\r\n        return parseJSDocText(context);\r\n    } else {\r\n        appendEmptyLine(next, last);\r\n        context.index++;\r\n        return undefined;\r\n    }\r\n}\r\n\r\nfunction appendEmptyLine(token: JSDocToken, element?: JSDocElement): void {\r\n    if (element) {\r\n        const line = new JSDocLineImpl('', token.range);\r\n        if ('inlines' in element) {\r\n            element.inlines.push(line);\r\n        } else {\r\n            element.content.inlines.push(line);\r\n        }\r\n    }\r\n}\r\n\r\nfunction parseJSDocText(context: ParseContext): JSDocParagraph {\r\n    let token = context.tokens[context.index];\r\n    const firstToken = token;\r\n    let lastToken = token;\r\n    const lines: JSDocInline[] = [];\r\n    while (token && token.type !== 'break' && token.type !== 'tag') {\r\n        lines.push(parseJSDocInline(context));\r\n        lastToken = token;\r\n        token = context.tokens[context.index];\r\n    }\r\n    return new JSDocTextImpl(lines, Range.create(firstToken.range.start, lastToken.range.end));\r\n}\r\n\r\nfunction parseJSDocInline(context: ParseContext): JSDocInline {\r\n    const token = context.tokens[context.index];\r\n    if (token.type === 'inline-tag') {\r\n        return parseJSDocTag(context, true);\r\n    } else {\r\n        return parseJSDocLine(context);\r\n    }\r\n}\r\n\r\nfunction parseJSDocTag(context: ParseContext, inline: boolean): JSDocTag {\r\n    const tagToken = context.tokens[context.index++];\r\n    const name = tagToken.content.substring(1);\r\n    const nextToken = context.tokens[context.index];\r\n    if (nextToken?.type === 'text') {\r\n        if (inline) {\r\n            const docLine = parseJSDocLine(context);\r\n            return new JSDocTagImpl(\r\n                name,\r\n                new JSDocTextImpl([docLine], docLine.range),\r\n                inline,\r\n                Range.create(tagToken.range.start, docLine.range.end)\r\n            );\r\n        } else {\r\n            const textDoc = parseJSDocText(context);\r\n            return new JSDocTagImpl(\r\n                name,\r\n                textDoc,\r\n                inline,\r\n                Range.create(tagToken.range.start, textDoc.range.end)\r\n            );\r\n        }\r\n    } else {\r\n        const range = tagToken.range;\r\n        return new JSDocTagImpl(name, new JSDocTextImpl([], range), inline, range);\r\n    }\r\n}\r\n\r\nfunction parseJSDocLine(context: ParseContext): JSDocLine {\r\n    const token = context.tokens[context.index++];\r\n    return new JSDocLineImpl(token.content, token.range);\r\n}\r\n\r\ninterface NormalizedOptions {\r\n    start?: RegExp\r\n    end?: RegExp\r\n    line?: RegExp\r\n}\r\n\r\ninterface TokenizationContext {\r\n    position: Position\r\n    lines: string[]\r\n    options: NormalizedOptions\r\n}\r\n\r\ninterface ParseContext {\r\n    position: Position\r\n    tokens: JSDocToken[]\r\n    index: number\r\n}\r\n\r\nfunction normalizeOptions(options?: JSDocParseOptions): NormalizedOptions {\r\n    if (!options) {\r\n        return normalizeOptions({\r\n            start: '/**',\r\n            end: '*/',\r\n            line: '*'\r\n        });\r\n    }\r\n    const { start, end, line } = options;\r\n    return {\r\n        start: normalizeOption(start, true),\r\n        end: normalizeOption(end, false),\r\n        line: normalizeOption(line, true)\r\n    };\r\n}\r\n\r\nfunction normalizeOption(option: RegExp | string | undefined, start: boolean): RegExp | undefined {\r\n    if (typeof option === 'string' || typeof option === 'object') {\r\n        const escaped = typeof option === 'string' ? escapeRegExp(option) : option.source;\r\n        if (start) {\r\n            return new RegExp(`^\\\\s*${escaped}`);\r\n        } else {\r\n            return new RegExp(`\\\\s*${escaped}\\\\s*$`);\r\n        }\r\n    } else {\r\n        return option;\r\n    }\r\n}\r\n\r\nclass JSDocCommentImpl implements JSDocComment {\r\n\r\n    readonly elements: JSDocElement[];\r\n    readonly range: Range;\r\n\r\n    constructor(elements: JSDocElement[], range: Range) {\r\n        this.elements = elements;\r\n        this.range = range;\r\n    }\r\n\r\n    getTag(name: string): JSDocTag | undefined {\r\n        return this.getAllTags().find(e => e.name === name);\r\n    }\r\n\r\n    getTags(name: string): JSDocTag[] {\r\n        return this.getAllTags().filter(e => e.name === name);\r\n    }\r\n\r\n    private getAllTags(): JSDocTag[] {\r\n        return this.elements.filter((e): e is JSDocTag => 'name' in e);\r\n    }\r\n\r\n    toString(): string {\r\n        let value = '';\r\n        for (const element of this.elements) {\r\n            if (value.length === 0) {\r\n                value = element.toString();\r\n            } else {\r\n                const text = element.toString();\r\n                value += fillNewlines(value) + text;\r\n            }\r\n        }\r\n        return value.trim();\r\n    }\r\n\r\n    toMarkdown(options?: JSDocRenderOptions): string {\r\n        let value = '';\r\n        for (const element of this.elements) {\r\n            if (value.length === 0) {\r\n                value = element.toMarkdown(options);\r\n            } else {\r\n                const text = element.toMarkdown(options);\r\n                value += fillNewlines(value) + text;\r\n            }\r\n        }\r\n        return value.trim();\r\n    }\r\n}\r\n\r\nclass JSDocTagImpl implements JSDocTag {\r\n    name: string;\r\n    content: JSDocParagraph;\r\n    range: Range;\r\n    inline: boolean;\r\n\r\n    constructor(name: string, content: JSDocParagraph, inline: boolean, range: Range) {\r\n        this.name = name;\r\n        this.content = content;\r\n        this.inline = inline;\r\n        this.range = range;\r\n    }\r\n\r\n    toString(): string {\r\n        let text = `@${this.name}`;\r\n        const content = this.content.toString();\r\n        if (this.content.inlines.length === 1) {\r\n            text = `${text} ${content}`;\r\n        } else if (this.content.inlines.length > 1) {\r\n            text = `${text}\\n${content}`;\r\n        }\r\n        if (this.inline) {\r\n            // Inline tags are surrounded by curly braces\r\n            return `{${text}}`;\r\n        } else {\r\n            return text;\r\n        }\r\n    }\r\n\r\n    toMarkdown(options?: JSDocRenderOptions): string {\r\n        return options?.renderTag?.(this) ?? this.toMarkdownDefault(options);\r\n    }\r\n\r\n    private toMarkdownDefault(options?: JSDocRenderOptions): string {\r\n        const content = this.content.toMarkdown(options);\r\n        if (this.inline) {\r\n            const rendered = renderInlineTag(this.name, content, options ?? {});\r\n            if (typeof rendered === 'string') {\r\n                return rendered;\r\n            }\r\n        }\r\n        let marker = '';\r\n        if (options?.tag === 'italic' || options?.tag === undefined) {\r\n            marker = '*';\r\n        } else if (options?.tag === 'bold') {\r\n            marker = '**';\r\n        } else if (options?.tag === 'bold-italic') {\r\n            marker = '***';\r\n        }\r\n        let text = `${marker}@${this.name}${marker}`;\r\n        if (this.content.inlines.length === 1) {\r\n            text = `${text}  ${content}`;\r\n        } else if (this.content.inlines.length > 1) {\r\n            text = `${text}\\n${content}`;\r\n        }\r\n        if (this.inline) {\r\n            // Inline tags are surrounded by curly braces\r\n            return `{${text}}`;\r\n        } else {\r\n            return text;\r\n        }\r\n    }\r\n}\r\n\r\nfunction renderInlineTag(tag: string, content: string, options: JSDocRenderOptions): string | undefined {\r\n    if (tag === 'linkplain' || tag === 'linkcode' || tag === 'link') {\r\n        const index = content.indexOf(' ');\r\n        let display = content;\r\n        if (index > 0) {\r\n            const displayStart = skipWhitespace(content, index);\r\n            display = content.substring(displayStart);\r\n            content = content.substring(0, index);\r\n        }\r\n        if (tag === 'linkcode' || (tag === 'link' && options.link === 'code')) {\r\n            // Surround the display value in a markdown inline code block\r\n            display = `\\`${display}\\``;\r\n        }\r\n        const renderedLink = options.renderLink?.(content, display) ?? renderLinkDefault(content, display);\r\n        return renderedLink;\r\n    }\r\n    return undefined;\r\n}\r\n\r\nfunction renderLinkDefault(content: string, display: string): string {\r\n    try {\r\n        URI.parse(content, true);\r\n        return `[${display}](${content})`;\r\n    } catch {\r\n        return content;\r\n    }\r\n}\r\n\r\nclass JSDocTextImpl implements JSDocParagraph {\r\n    inlines: JSDocInline[];\r\n    range: Range;\r\n\r\n    constructor(lines: JSDocInline[], range: Range) {\r\n        this.inlines = lines;\r\n        this.range = range;\r\n    }\r\n\r\n    toString(): string {\r\n        let text = '';\r\n        for (let i = 0; i < this.inlines.length; i++) {\r\n            const inline = this.inlines[i];\r\n            const next = this.inlines[i + 1];\r\n            text += inline.toString();\r\n            if (next && next.range.start.line > inline.range.start.line) {\r\n                text += '\\n';\r\n            }\r\n        }\r\n        return text;\r\n    }\r\n\r\n    toMarkdown(options?: JSDocRenderOptions): string {\r\n        let text = '';\r\n        for (let i = 0; i < this.inlines.length; i++) {\r\n            const inline = this.inlines[i];\r\n            const next = this.inlines[i + 1];\r\n            text += inline.toMarkdown(options);\r\n            if (next && next.range.start.line > inline.range.start.line) {\r\n                text += '\\n';\r\n            }\r\n        }\r\n        return text;\r\n    }\r\n}\r\n\r\nclass JSDocLineImpl implements JSDocLine {\r\n    text: string;\r\n    range: Range;\r\n\r\n    constructor(text: string, range: Range) {\r\n        this.text = text;\r\n        this.range = range;\r\n    }\r\n\r\n    toString(): string {\r\n        return this.text;\r\n    }\r\n    toMarkdown(): string {\r\n        return this.text;\r\n    }\r\n\r\n}\r\n\r\nfunction fillNewlines(text: string): string {\r\n    if (text.endsWith('\\n')) {\r\n        return '\\n';\r\n    } else {\r\n        return '\\n\\n';\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n******************************************************************************/\r\n\r\nimport type { Module } from './dependency-injection.js';\r\nimport type { LangiumDefaultCoreServices, LangiumDefaultSharedCoreServices, LangiumCoreServices, LangiumSharedCoreServices } from './services.js';\r\nimport type { FileSystemProvider } from './workspace/file-system-provider.js';\r\nimport { createGrammarConfig } from './languages/grammar-config.js';\r\nimport { createCompletionParser } from './parser/completion-parser-builder.js';\r\nimport { createLangiumParser } from './parser/langium-parser-builder.js';\r\nimport { DefaultTokenBuilder } from './parser/token-builder.js';\r\nimport { DefaultValueConverter } from './parser/value-converter.js';\r\nimport { DefaultLinker } from './references/linker.js';\r\nimport { DefaultNameProvider } from './references/name-provider.js';\r\nimport { DefaultReferences } from './references/references.js';\r\nimport { DefaultScopeComputation } from './references/scope-computation.js';\r\nimport { DefaultScopeProvider } from './references/scope-provider.js';\r\nimport { DefaultJsonSerializer } from './serializer/json-serializer.js';\r\nimport { DefaultServiceRegistry } from './service-registry.js';\r\nimport { DefaultDocumentValidator } from './validation/document-validator.js';\r\nimport { ValidationRegistry } from './validation/validation-registry.js';\r\nimport { DefaultAstNodeDescriptionProvider, DefaultReferenceDescriptionProvider } from './workspace/ast-descriptions.js';\r\nimport { DefaultAstNodeLocator } from './workspace/ast-node-locator.js';\r\nimport { DefaultConfigurationProvider } from './workspace/configuration.js';\r\nimport { DefaultDocumentBuilder } from './workspace/document-builder.js';\r\nimport { DefaultLangiumDocumentFactory, DefaultLangiumDocuments } from './workspace/documents.js';\r\nimport { DefaultIndexManager } from './workspace/index-manager.js';\r\nimport { DefaultWorkspaceManager } from './workspace/workspace-manager.js';\r\nimport { DefaultLexer, DefaultLexerErrorMessageProvider } from './parser/lexer.js';\r\nimport { JSDocDocumentationProvider } from './documentation/documentation-provider.js';\r\nimport { DefaultCommentProvider } from './documentation/comment-provider.js';\r\nimport { LangiumParserErrorMessageProvider } from './parser/langium-parser.js';\r\nimport { DefaultAsyncParser } from './parser/async-parser.js';\r\nimport { DefaultWorkspaceLock } from './workspace/workspace-lock.js';\r\nimport { DefaultHydrator } from './serializer/hydrator.js';\r\n\r\n/**\r\n * Context required for creating the default language-specific dependency injection module.\r\n */\r\nexport interface DefaultCoreModuleContext {\r\n    shared: LangiumSharedCoreServices;\r\n}\r\n\r\n/**\r\n * Creates a dependency injection module configuring the default core services.\r\n * This is a set of services that are dedicated to a specific language.\r\n */\r\nexport function createDefaultCoreModule(context: DefaultCoreModuleContext): Module<LangiumCoreServices, LangiumDefaultCoreServices> {\r\n    return {\r\n        documentation: {\r\n            CommentProvider: (services) => new DefaultCommentProvider(services),\r\n            DocumentationProvider: (services) => new JSDocDocumentationProvider(services)\r\n        },\r\n        parser: {\r\n            AsyncParser: (services) => new DefaultAsyncParser(services),\r\n            GrammarConfig: (services) => createGrammarConfig(services),\r\n            LangiumParser: (services) => createLangiumParser(services),\r\n            CompletionParser: (services) => createCompletionParser(services),\r\n            ValueConverter: () => new DefaultValueConverter(),\r\n            TokenBuilder: () => new DefaultTokenBuilder(),\r\n            Lexer: (services) => new DefaultLexer(services),\r\n            ParserErrorMessageProvider: () => new LangiumParserErrorMessageProvider(),\r\n            LexerErrorMessageProvider: () => new DefaultLexerErrorMessageProvider()\r\n        },\r\n        workspace: {\r\n            AstNodeLocator: () => new DefaultAstNodeLocator(),\r\n            AstNodeDescriptionProvider: (services) => new DefaultAstNodeDescriptionProvider(services),\r\n            ReferenceDescriptionProvider: (services) => new DefaultReferenceDescriptionProvider(services)\r\n        },\r\n        references: {\r\n            Linker: (services) => new DefaultLinker(services),\r\n            NameProvider: () => new DefaultNameProvider(),\r\n            ScopeProvider: (services) => new DefaultScopeProvider(services),\r\n            ScopeComputation: (services) => new DefaultScopeComputation(services),\r\n            References: (services) => new DefaultReferences(services)\r\n        },\r\n        serializer: {\r\n            Hydrator: (services) => new DefaultHydrator(services),\r\n            JsonSerializer: (services) => new DefaultJsonSerializer(services)\r\n        },\r\n        validation: {\r\n            DocumentValidator: (services) => new DefaultDocumentValidator(services),\r\n            ValidationRegistry: (services) => new ValidationRegistry(services)\r\n        },\r\n        shared: () => context.shared\r\n    };\r\n}\r\n\r\n/**\r\n * Context required for creating the default shared dependency injection module.\r\n */\r\nexport interface DefaultSharedCoreModuleContext {\r\n    /**\r\n     * Factory function to create a {@link FileSystemProvider}.\r\n     *\r\n     * Langium exposes an `EmptyFileSystem` and `NodeFileSystem`, exported through `langium/node`.\r\n     * When running Langium as part of a vscode language server or a Node.js app, using the `NodeFileSystem` is recommended,\r\n     * the `EmptyFileSystem` in every other use case.\r\n     */\r\n    fileSystemProvider: (services: LangiumSharedCoreServices) => FileSystemProvider;\r\n}\r\n\r\n/**\r\n * Creates a dependency injection module configuring the default shared core services.\r\n * This is the set of services that are shared between multiple languages.\r\n */\r\nexport function createDefaultSharedCoreModule(context: DefaultSharedCoreModuleContext): Module<LangiumSharedCoreServices, LangiumDefaultSharedCoreServices> {\r\n    return {\r\n        ServiceRegistry: (services) => new DefaultServiceRegistry(services),\r\n        workspace: {\r\n            LangiumDocuments: (services) => new DefaultLangiumDocuments(services),\r\n            LangiumDocumentFactory: (services) => new DefaultLangiumDocumentFactory(services),\r\n            DocumentBuilder: (services) => new DefaultDocumentBuilder(services),\r\n            IndexManager: (services) => new DefaultIndexManager(services),\r\n            WorkspaceManager: (services) => new DefaultWorkspaceManager(services),\r\n            FileSystemProvider: (services) => context.fileSystemProvider(services),\r\n            WorkspaceLock: () => new DefaultWorkspaceLock(),\r\n            ConfigurationProvider: (services) => new DefaultConfigurationProvider(services)\r\n        }\r\n    };\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { Set, Group, Character, IRegExpAST } from '@chevrotain/regexp-to-ast';\r\nimport { RegExpParser, BaseRegExpVisitor } from '@chevrotain/regexp-to-ast';\r\n\r\nexport const NEWLINE_REGEXP = /\\r?\\n/gm;\r\n\r\nconst regexpParser = new RegExpParser();\r\n\r\n/**\r\n * This class is in charge of heuristically identifying start/end tokens of terminals.\r\n *\r\n * The way this works is by doing the following:\r\n * 1. Traverse the regular expression in the \"start state\"\r\n * 2. Add any encountered sets/single characters to the \"start regexp\"\r\n * 3. Once we encounter any variable-length content (i.e. with quantifiers such as +/?/*), we enter the \"end state\"\r\n * 4. In the end state, any sets/single characters are added to an \"end stack\".\r\n * 5. If we re-encounter any variable-length content we reset the end stack\r\n * 6. We continue visiting the regex until the end, reseting the end stack and rebuilding it as necessary\r\n *\r\n * After traversing a regular expression the `startRegexp/endRegexp` properties allow access to the stored start/end of the terminal\r\n */\r\nclass TerminalRegExpVisitor extends BaseRegExpVisitor {\r\n\r\n    private isStarting = true;\r\n    startRegexp: string;\r\n    private endRegexpStack: string[] = [];\r\n    multiline = false;\r\n    regex: string;\r\n\r\n    get endRegex(): string {\r\n        return this.endRegexpStack.join('');\r\n    }\r\n\r\n    reset(regex: string): void {\r\n        this.multiline = false;\r\n        this.regex = regex;\r\n        this.startRegexp = '';\r\n        this.isStarting = true;\r\n        this.endRegexpStack = [];\r\n    }\r\n\r\n    override visitGroup(node: Group) {\r\n        if (node.quantifier) {\r\n            this.isStarting = false;\r\n            this.endRegexpStack = [];\r\n        }\r\n    }\r\n\r\n    override visitCharacter(node: Character): void {\r\n        const char = String.fromCharCode(node.value);\r\n        if (!this.multiline && char === '\\n') {\r\n            this.multiline = true;\r\n        }\r\n        if (node.quantifier) {\r\n            this.isStarting = false;\r\n            this.endRegexpStack = [];\r\n        } else {\r\n            const escapedChar = escapeRegExp(char);\r\n            this.endRegexpStack.push(escapedChar);\r\n            if (this.isStarting) {\r\n                this.startRegexp += escapedChar;\r\n            }\r\n        }\r\n    }\r\n\r\n    override visitSet(node: Set): void {\r\n        if (!this.multiline) {\r\n            const set = this.regex.substring(node.loc.begin, node.loc.end);\r\n            const regex = new RegExp(set);\r\n            this.multiline = Boolean('\\n'.match(regex));\r\n        }\r\n        if (node.quantifier) {\r\n            this.isStarting = false;\r\n            this.endRegexpStack = [];\r\n        } else {\r\n            const set = this.regex.substring(node.loc.begin, node.loc.end);\r\n            this.endRegexpStack.push(set);\r\n            if (this.isStarting) {\r\n                this.startRegexp += set;\r\n            }\r\n        }\r\n    }\r\n\r\n    override visitChildren(node: IRegExpAST): void {\r\n        if (node.type === 'Group') {\r\n            // Ignore children of groups with quantifier (+/*/?)\r\n            // These groups are unrelated to start/end tokens of terminals\r\n            const group = node as Group;\r\n            if (group.quantifier) {\r\n                return;\r\n            }\r\n        }\r\n        super.visitChildren(node);\r\n    }\r\n}\r\n\r\nconst visitor = new TerminalRegExpVisitor();\r\n\r\nexport function getTerminalParts(regexp: RegExp | string): Array<{ start: string, end: string }> {\r\n    try {\r\n        if (typeof regexp !== 'string') {\r\n            regexp = regexp.source;\r\n        }\r\n        regexp = `/${regexp}/`;\r\n        const pattern = regexpParser.pattern(regexp);\r\n        const parts: Array<{ start: string, end: string }> = [];\r\n        for (const alternative of pattern.value.value) {\r\n            visitor.reset(regexp);\r\n            visitor.visit(alternative);\r\n            parts.push({\r\n                start: visitor.startRegexp,\r\n                end: visitor.endRegex\r\n            });\r\n        }\r\n        return parts;\r\n    } catch {\r\n        return [];\r\n    }\r\n}\r\n\r\nexport function isMultilineComment(regexp: RegExp | string): boolean {\r\n    try {\r\n        if (typeof regexp === 'string') {\r\n            regexp = new RegExp(regexp);\r\n        }\r\n        regexp = regexp.toString();\r\n        visitor.reset(regexp);\r\n        // Parsing the pattern might fail (since it's user code)\r\n        visitor.visit(regexpParser.pattern(regexp));\r\n        return visitor.multiline;\r\n    } catch {\r\n        return false;\r\n    }\r\n}\r\n\r\n/**\r\n * A set of all characters that are considered whitespace by the '\\s' RegExp character class.\r\n * Taken from [MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_expressions/Character_classes).\r\n */\r\nexport const whitespaceCharacters = (\r\n    '\\f\\n\\r\\t\\v\\u0020\\u00a0\\u1680\\u2000\\u2001\\u2002\\u2003\\u2004\\u2005\\u2006\\u2007' +\r\n    '\\u2008\\u2009\\u200a\\u2028\\u2029\\u202f\\u205f\\u3000\\ufeff').split('');\r\n\r\nexport function isWhitespace(value: RegExp | string): boolean {\r\n    const regexp = typeof value === 'string' ? new RegExp(value) : value;\r\n    return whitespaceCharacters.some((ws) => regexp.test(ws));\r\n}\r\n\r\nexport function escapeRegExp(value: string): string {\r\n    return value.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\r\n}\r\n\r\nexport function getCaseInsensitivePattern(keyword: string): string {\r\n    return Array.prototype.map.call(keyword, letter =>\r\n        /\\w/.test(letter) ? `[${letter.toLowerCase()}${letter.toUpperCase()}]` : escapeRegExp(letter)\r\n    ).join('');\r\n}\r\n\r\n/**\r\n * Determines whether the given input has a partial match with the specified regex.\r\n * @param regex The regex to partially match against\r\n * @param input The input string\r\n * @returns Whether any match exists.\r\n */\r\nexport function partialMatches(regex: RegExp | string, input: string): boolean {\r\n    const partial = partialRegExp(regex);\r\n    const match = input.match(partial);\r\n    return !!match && match[0].length > 0;\r\n}\r\n\r\n/**\r\n * Builds a partial regex from the input regex. A partial regex is able to match incomplete input strings. E.g.\r\n * a partial regex constructed from `/ab/` is able to match the string `a` without needing a following `b` character. However it won't match `b` alone.\r\n * @param regex The input regex to be converted.\r\n * @returns A partial regex constructed from the input regex.\r\n */\r\nexport function partialRegExp(regex: RegExp | string): RegExp {\r\n    if (typeof regex === 'string') {\r\n        regex = new RegExp(regex);\r\n    }\r\n    const re = regex, source = regex.source;\r\n    let i = 0;\r\n\r\n    function process() {\r\n        let result = '',\r\n            tmp;\r\n\r\n        function appendRaw(nbChars: number) {\r\n            result += source.substr(i, nbChars);\r\n            i += nbChars;\r\n        }\r\n\r\n        function appendOptional(nbChars: number) {\r\n            result += '(?:' + source.substr(i, nbChars) + '|$)';\r\n            i += nbChars;\r\n        }\r\n\r\n        while (i < source.length) {\r\n            switch (source[i]) {\r\n                case '\\\\':\r\n                    switch (source[i + 1]) {\r\n                        case 'c':\r\n                            appendOptional(3);\r\n                            break;\r\n                        case 'x':\r\n                            appendOptional(4);\r\n                            break;\r\n                        case 'u':\r\n                            if (re.unicode) {\r\n                                if (source[i + 2] === '{') {\r\n                                    appendOptional(source.indexOf('}', i) - i + 1);\r\n                                } else {\r\n                                    appendOptional(6);\r\n                                }\r\n                            } else {\r\n                                appendOptional(2);\r\n                            }\r\n                            break;\r\n                        case 'p':\r\n                        case 'P':\r\n                            if (re.unicode) {\r\n                                appendOptional(source.indexOf('}', i) - i + 1);\r\n                            } else {\r\n                                appendOptional(2);\r\n                            }\r\n                            break;\r\n                        case 'k':\r\n                            appendOptional(source.indexOf('>', i) - i + 1);\r\n                            break;\r\n                        default:\r\n                            appendOptional(2);\r\n                            break;\r\n                    }\r\n                    break;\r\n\r\n                case '[':\r\n                    tmp = /\\[(?:\\\\.|.)*?\\]/g;\r\n                    tmp.lastIndex = i;\r\n                    tmp = tmp.exec(source) || [];\r\n                    appendOptional(tmp[0].length);\r\n                    break;\r\n\r\n                case '|':\r\n                case '^':\r\n                case '$':\r\n                case '*':\r\n                case '+':\r\n                case '?':\r\n                    appendRaw(1);\r\n                    break;\r\n                case '{':\r\n                    tmp = /\\{\\d+,?\\d*\\}/g;\r\n                    tmp.lastIndex = i;\r\n                    tmp = tmp.exec(source);\r\n                    if (tmp) {\r\n                        appendRaw(tmp[0].length);\r\n                    } else {\r\n                        appendOptional(1);\r\n                    }\r\n                    break;\r\n                case '(':\r\n                    if (source[i + 1] === '?') {\r\n                        switch (source[i + 2]) {\r\n                            case ':':\r\n                                result += '(?:';\r\n                                i += 3;\r\n                                result += process() + '|$)';\r\n                                break;\r\n                            case '=':\r\n                                result += '(?=';\r\n                                i += 3;\r\n                                result += process() + ')';\r\n                                break;\r\n                            case '!':\r\n                                tmp = i;\r\n                                i += 3;\r\n                                process();\r\n                                result += source.substr(tmp, i - tmp);\r\n                                break;\r\n                            case '<':\r\n                                switch (source[i + 3]) {\r\n                                    case '=':\r\n                                    case '!':\r\n                                        tmp = i;\r\n                                        i += 4;\r\n                                        process();\r\n                                        result += source.substr(tmp, i - tmp);\r\n                                        break;\r\n                                    default:\r\n                                        appendRaw(source.indexOf('>', i) - i + 1);\r\n                                        result += process() + '|$)';\r\n                                        break;\r\n                                }\r\n                                break;\r\n                        }\r\n                    } else {\r\n                        appendRaw(1);\r\n                        result += process() + '|$)';\r\n                    }\r\n                    break;\r\n                case ')':\r\n                    ++i;\r\n                    return result;\r\n                default:\r\n                    appendOptional(1);\r\n                    break;\r\n            }\r\n        }\r\n\r\n        return result;\r\n    }\r\n\r\n    return new RegExp(process(), regex.flags);\r\n}\r\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { type AbstractCancellationTokenSource, CancellationToken, CancellationTokenSource } from '../utils/cancellation.js';\r\nimport { Deferred, isOperationCancelled, startCancelableOperation, type MaybePromise } from '../utils/promise-utils.js';\r\n\r\n/**\r\n * Utility service to execute mutually exclusive actions.\r\n */\r\nexport interface WorkspaceLock {\r\n    /**\r\n     * Performs a single async action, like initializing the workspace or processing document changes.\r\n     * Only one action will be executed at a time.\r\n     *\r\n     * When another action is queued up, the token provided for the action will be cancelled.\r\n     * Assuming the action makes use of this token, the next action only has to wait for the current action to finish cancellation.\r\n     */\r\n    write(action: (token: CancellationToken) => MaybePromise<void>): Promise<void>;\r\n\r\n    /**\r\n     * Performs a single action, like computing completion results or providing workspace symbols.\r\n     * Read actions will only be executed after all write actions have finished. They will be executed in parallel if possible.\r\n     *\r\n     * If a write action is currently running, the read action will be queued up and executed afterwards.\r\n     * If a new write action is queued up while a read action is waiting, the write action will receive priority and will be handled before the read action.\r\n     *\r\n     * Note that read actions are not allowed to modify anything in the workspace. Please use {@link write} instead.\r\n     */\r\n    read<T>(action: () => MaybePromise<T>): Promise<T>;\r\n\r\n    /**\r\n     * Cancels the last queued write action. All previous write actions already have been cancelled.\r\n     */\r\n    cancelWrite(): void;\r\n}\r\n\r\ntype LockAction<T = void> = (token: CancellationToken) => MaybePromise<T>;\r\n\r\ninterface LockEntry {\r\n    action: LockAction<unknown>;\r\n    deferred: Deferred<unknown>;\r\n    cancellationToken: CancellationToken;\r\n}\r\n\r\nexport class DefaultWorkspaceLock implements WorkspaceLock {\r\n\r\n    private previousTokenSource: AbstractCancellationTokenSource = new CancellationTokenSource();\r\n    private writeQueue: LockEntry[] = [];\r\n    private readQueue: LockEntry[] = [];\r\n    private done = true;\r\n\r\n    write(action: (token: CancellationToken) => MaybePromise<void>): Promise<void> {\r\n        this.cancelWrite();\r\n        const tokenSource = startCancelableOperation();\r\n        this.previousTokenSource = tokenSource;\r\n        return this.enqueue(this.writeQueue, action, tokenSource.token);\r\n    }\r\n\r\n    read<T>(action: () => MaybePromise<T>): Promise<T> {\r\n        return this.enqueue(this.readQueue, action);\r\n    }\r\n\r\n    private enqueue<T = void>(queue: LockEntry[], action: LockAction<T>, cancellationToken = CancellationToken.None): Promise<T> {\r\n        const deferred = new Deferred<unknown>();\r\n        const entry: LockEntry = {\r\n            action,\r\n            deferred,\r\n            cancellationToken\r\n        };\r\n        queue.push(entry);\r\n        this.performNextOperation();\r\n        return deferred.promise as Promise<T>;\r\n    }\r\n\r\n    private async performNextOperation(): Promise<void> {\r\n        if (!this.done) {\r\n            return;\r\n        }\r\n        const entries: LockEntry[] = [];\r\n        if (this.writeQueue.length > 0) {\r\n            // Just perform the next write action\r\n            entries.push(this.writeQueue.shift()!);\r\n        } else if (this.readQueue.length > 0) {\r\n            // Empty the read queue and perform all actions in parallel\r\n            entries.push(...this.readQueue.splice(0, this.readQueue.length));\r\n        } else {\r\n            return;\r\n        }\r\n        this.done = false;\r\n        await Promise.all(entries.map(async ({ action, deferred, cancellationToken }) => {\r\n            try {\r\n                // Move the execution of the action to the next event loop tick via `Promise.resolve()`\r\n                const result = await Promise.resolve().then(() => action(cancellationToken));\r\n                deferred.resolve(result);\r\n            } catch (err) {\r\n                if (isOperationCancelled(err)) {\r\n                    // If the operation was cancelled, we don't want to reject the promise\r\n                    deferred.resolve(undefined);\r\n                } else {\r\n                    deferred.reject(err);\r\n                }\r\n            }\r\n        }));\r\n        this.done = true;\r\n        this.performNextOperation();\r\n    }\r\n\r\n    cancelWrite(): void {\r\n        this.previousTokenSource.cancel();\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { URI } from 'vscode-uri';\r\nimport type { CommentProvider } from '../documentation/comment-provider.js';\r\nimport type { NameProvider } from '../references/name-provider.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, CstNode, GenericAstNode, Mutable, Reference } from '../syntax-tree.js';\r\nimport { isAstNode, isReference } from '../syntax-tree.js';\r\nimport { getDocument } from '../utils/ast-utils.js';\r\nimport { findNodesForProperty } from '../utils/grammar-utils.js';\r\nimport type { AstNodeLocator } from '../workspace/ast-node-locator.js';\r\nimport type { DocumentSegment, LangiumDocument, LangiumDocuments } from '../workspace/documents.js';\r\n\r\nexport interface JsonSerializeOptions {\r\n    /** The space parameter for `JSON.stringify`, controlling whether and how to pretty-print the output. */\r\n    space?: string | number;\r\n    /** Whether to include the `$refText` property for references (the name used to identify the target node). */\r\n    refText?: boolean;\r\n    /** Whether to include the `$sourceText` property, which holds the full source text from which an AST node was parsed. */\r\n    sourceText?: boolean;\r\n    /** Whether to include the `$textRegion` property, which holds information to trace AST node properties to their respective source text regions. */\r\n    textRegions?: boolean;\r\n    /** Whether to include the `$comment` property, which holds comments according to the CommentProvider service. */\r\n    comments?: boolean;\r\n    /** The replacer parameter for `JSON.stringify`; the default replacer given as parameter should be used to apply basic replacements. */\r\n    replacer?: (key: string, value: unknown, defaultReplacer: (key: string, value: unknown) => unknown) => unknown\r\n    /** Used to convert and serialize URIs when the target of a cross-reference is in a different document. */\r\n    uriConverter?: (uri: URI, reference: Reference) => string\r\n}\r\n\r\nexport interface JsonDeserializeOptions {\r\n    /** Used to parse and convert URIs when the target of a cross-reference is in a different document. */\r\n    uriConverter?: (uri: string) => URI\r\n}\r\n\r\n/**\r\n * {@link AstNode}s that may carry information on their definition area within the DSL text.\r\n */\r\nexport interface AstNodeWithTextRegion extends AstNode {\r\n    $sourceText?: string;\r\n    $textRegion?: AstNodeRegionWithAssignments;\r\n}\r\n\r\n/**\r\n * {@link AstNode}s that may carry a semantically relevant comment.\r\n */\r\nexport interface AstNodeWithComment extends AstNode {\r\n    $comment?: string;\r\n}\r\n\r\nexport function isAstNodeWithComment(node: AstNode): node is AstNodeWithComment {\r\n    return typeof (node as AstNodeWithComment).$comment === 'string';\r\n}\r\n\r\n/**\r\n * A {@link DocumentSegment} representing the definition area of an AstNode within the DSL text.\r\n * Usually contains text region information on all assigned property values of the AstNode,\r\n * and may contain the defining file's URI as string.\r\n */\r\nexport interface AstNodeRegionWithAssignments extends DocumentSegment {\r\n    /**\r\n     * A record containing an entry for each assigned property of the AstNode.\r\n     * The key is equal to the property name and the value is an array of the property values'\r\n     * text regions, regardless of whether the property is a single value or list property.\r\n     */\r\n    assignments?: Record<string, DocumentSegment[]>;\r\n    /**\r\n     * The AstNode defining file's URI as string\r\n     */\r\n    documentURI?: string;\r\n}\r\n\r\n/**\r\n * Utility service for transforming an `AstNode` into a JSON string and vice versa.\r\n */\r\nexport interface JsonSerializer {\r\n    /**\r\n     * Serialize an `AstNode` into a JSON `string`.\r\n     * @param node The `AstNode` to be serialized.\r\n     * @param options Serialization options\r\n     */\r\n    serialize(node: AstNode, options?: JsonSerializeOptions): string;\r\n    /**\r\n     * Deserialize (parse) a JSON `string` into an `AstNode`.\r\n     */\r\n    deserialize<T extends AstNode = AstNode>(content: string, options?: JsonDeserializeOptions): T;\r\n}\r\n\r\n/**\r\n * A cross-reference in the serialized JSON representation of an AstNode.\r\n */\r\ninterface IntermediateReference {\r\n    /** URI pointing to the target element. This is either `#${path}` if the target is in the same document, or `${documentURI}#${path}` otherwise. */\r\n    $ref?: string\r\n    /** The actual text used to look up the reference target in the surrounding scope. */\r\n    $refText?: string\r\n    /** If any problem occurred while resolving the reference, it is described by this property. */\r\n    $error?: string\r\n}\r\n\r\nfunction isIntermediateReference(obj: unknown): obj is IntermediateReference {\r\n    return typeof obj === 'object' && !!obj && ('$ref' in obj || '$error' in obj);\r\n}\r\n\r\nexport class DefaultJsonSerializer implements JsonSerializer {\r\n\r\n    /** The set of AstNode properties to be ignored by the serializer. */\r\n    ignoreProperties = new Set(['$container', '$containerProperty', '$containerIndex', '$document', '$cstNode']);\r\n\r\n    /** The document that is currently processed by the serializer; this is used by the replacer function.  */\r\n    protected currentDocument: LangiumDocument | undefined;\r\n\r\n    protected readonly langiumDocuments: LangiumDocuments;\r\n    protected readonly astNodeLocator: AstNodeLocator;\r\n    protected readonly nameProvider: NameProvider;\r\n    protected readonly commentProvider: CommentProvider;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.langiumDocuments = services.shared.workspace.LangiumDocuments;\r\n        this.astNodeLocator = services.workspace.AstNodeLocator;\r\n        this.nameProvider = services.references.NameProvider;\r\n        this.commentProvider = services.documentation.CommentProvider;\r\n    }\r\n\r\n    serialize(node: AstNode, options?: JsonSerializeOptions): string {\r\n        const serializeOptions = options ?? {};\r\n        const specificReplacer = options?.replacer;\r\n        const defaultReplacer = (key: string, value: unknown) => this.replacer(key, value, serializeOptions);\r\n        const replacer = specificReplacer ? (key: string, value: unknown) => specificReplacer(key, value, defaultReplacer) : defaultReplacer;\r\n\r\n        try {\r\n            this.currentDocument = getDocument(node);\r\n            return JSON.stringify(node, replacer, options?.space);\r\n        } finally {\r\n            this.currentDocument = undefined;\r\n        }\r\n    }\r\n\r\n    deserialize<T extends AstNode = AstNode>(content: string, options?: JsonDeserializeOptions): T {\r\n        const deserializeOptions = options ?? {};\r\n        const root = JSON.parse(content);\r\n        this.linkNode(root, root, deserializeOptions);\r\n        return root;\r\n    }\r\n\r\n    protected replacer(key: string, value: unknown, { refText, sourceText, textRegions, comments, uriConverter }: JsonSerializeOptions): unknown {\r\n        if (this.ignoreProperties.has(key)) {\r\n            return undefined;\r\n        } else if (isReference(value)) {\r\n            const refValue = value.ref;\r\n            const $refText = refText ? value.$refText : undefined;\r\n            if (refValue) {\r\n                const targetDocument = getDocument(refValue);\r\n                let targetUri = '';\r\n                if (this.currentDocument && this.currentDocument !== targetDocument) {\r\n                    if (uriConverter) {\r\n                        targetUri = uriConverter(targetDocument.uri, value);\r\n                    } else {\r\n                        targetUri = targetDocument.uri.toString();\r\n                    }\r\n                }\r\n                const targetPath = this.astNodeLocator.getAstNodePath(refValue);\r\n                return {\r\n                    $ref: `${targetUri}#${targetPath}`,\r\n                    $refText\r\n                } satisfies IntermediateReference;\r\n            } else {\r\n                return {\r\n                    $error: value.error?.message ?? 'Could not resolve reference',\r\n                    $refText\r\n                } satisfies IntermediateReference;\r\n            }\r\n        } else if (isAstNode(value)) {\r\n            let astNode: AstNodeWithTextRegion | undefined = undefined;\r\n            if (textRegions) {\r\n                astNode = this.addAstNodeRegionWithAssignmentsTo({ ...value });\r\n                if ((!key || value.$document) && astNode?.$textRegion) {\r\n                    // The document URI is added to the root node of the resulting JSON tree\r\n                    astNode.$textRegion.documentURI = this.currentDocument?.uri.toString();\r\n                }\r\n            }\r\n            if (sourceText && !key) {\r\n                astNode ??= { ...value };\r\n                astNode.$sourceText = value.$cstNode?.text;\r\n            }\r\n            if (comments) {\r\n                astNode ??= { ...value };\r\n                const comment = this.commentProvider.getComment(value);\r\n                if (comment) {\r\n                    (astNode as AstNodeWithComment).$comment = comment.replace(/\\r/g, '');\r\n                }\r\n            }\r\n            return astNode ?? value;\r\n        } else {\r\n            return value;\r\n        }\r\n    }\r\n\r\n    protected addAstNodeRegionWithAssignmentsTo(node: AstNodeWithTextRegion) {\r\n        const createDocumentSegment: (cstNode: CstNode) => AstNodeRegionWithAssignments = cstNode => <DocumentSegment>{\r\n            offset: cstNode.offset,\r\n            end: cstNode.end,\r\n            length: cstNode.length,\r\n            range: cstNode.range,\r\n        };\r\n\r\n        if (node.$cstNode) {\r\n            const textRegion = node.$textRegion = createDocumentSegment(node.$cstNode);\r\n            const assignments: Record<string, DocumentSegment[]> = textRegion.assignments = {};\r\n\r\n            Object.keys(node).filter(key => !key.startsWith('$')).forEach(key => {\r\n                const propertyAssignments = findNodesForProperty(node.$cstNode, key).map(createDocumentSegment);\r\n                if (propertyAssignments.length !== 0) {\r\n                    assignments[key] = propertyAssignments;\r\n                }\r\n            });\r\n\r\n            return node;\r\n        }\r\n        return undefined;\r\n    }\r\n\r\n    protected linkNode(node: GenericAstNode, root: AstNode, options: JsonDeserializeOptions, container?: AstNode, containerProperty?: string, containerIndex?: number) {\r\n        for (const [propertyName, item] of Object.entries(node)) {\r\n            if (Array.isArray(item)) {\r\n                for (let index = 0; index < item.length; index++) {\r\n                    const element = item[index];\r\n                    if (isIntermediateReference(element)) {\r\n                        item[index] = this.reviveReference(node, propertyName, root, element, options);\r\n                    } else if (isAstNode(element)) {\r\n                        this.linkNode(element as GenericAstNode, root, options, node, propertyName, index);\r\n                    }\r\n                }\r\n            } else if (isIntermediateReference(item)) {\r\n                node[propertyName] = this.reviveReference(node, propertyName, root, item, options);\r\n            } else if (isAstNode(item)) {\r\n                this.linkNode(item as GenericAstNode, root, options, node, propertyName);\r\n            }\r\n        }\r\n        const mutable = node as Mutable<AstNode>;\r\n        mutable.$container = container;\r\n        mutable.$containerProperty = containerProperty;\r\n        mutable.$containerIndex = containerIndex;\r\n    }\r\n\r\n    protected reviveReference(container: AstNode, property: string, root: AstNode, reference: IntermediateReference, options: JsonDeserializeOptions): Reference | undefined {\r\n        let refText = reference.$refText;\r\n        let error = reference.$error;\r\n        if (reference.$ref) {\r\n            const ref = this.getRefNode(root, reference.$ref, options.uriConverter);\r\n            if (isAstNode(ref)) {\r\n                if (!refText) {\r\n                    refText = this.nameProvider.getName(ref);\r\n                }\r\n                return {\r\n                    $refText: refText ?? '',\r\n                    ref\r\n                };\r\n            } else {\r\n                error = ref;\r\n            }\r\n        }\r\n        if (error) {\r\n            const ref: Mutable<Reference> = {\r\n                $refText: refText ?? ''\r\n            };\r\n            ref.error = {\r\n                container,\r\n                property,\r\n                message: error,\r\n                reference: ref\r\n            };\r\n            return ref;\r\n        } else {\r\n            return undefined;\r\n        }\r\n    }\r\n\r\n    protected getRefNode(root: AstNode, uri: string, uriConverter?: (uri: string) => URI): AstNode | string {\r\n        try {\r\n            const fragmentIndex = uri.indexOf('#');\r\n            if (fragmentIndex === 0) {\r\n                const node = this.astNodeLocator.getAstNode(root, uri.substring(1));\r\n                if (!node) {\r\n                    return 'Could not resolve path: ' + uri;\r\n                }\r\n                return node;\r\n            }\r\n            if (fragmentIndex < 0) {\r\n                const documentUri = uriConverter ? uriConverter(uri) : URI.parse(uri);\r\n                const document = this.langiumDocuments.getDocument(documentUri);\r\n                if (!document) {\r\n                    return 'Could not find document for URI: ' + uri;\r\n                }\r\n                return document.parseResult.value;\r\n            }\r\n            const documentUri = uriConverter ? uriConverter(uri.substring(0, fragmentIndex)) : URI.parse(uri.substring(0, fragmentIndex));\r\n            const document = this.langiumDocuments.getDocument(documentUri);\r\n            if (!document) {\r\n                return 'Could not find document for URI: ' + uri;\r\n            }\r\n            if (fragmentIndex === uri.length - 1) {\r\n                return document.parseResult.value;\r\n            }\r\n            const node = this.astNodeLocator.getAstNode(document.parseResult.value, uri.substring(fragmentIndex + 1));\r\n            if (!node) {\r\n                return 'Could not resolve URI: ' + uri;\r\n            }\r\n            return node;\r\n        } catch (err) {\r\n            return String(err);\r\n        }\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { AbstractElement, AbstractRule } from '../languages/generated/ast.js';\r\nimport type { CstNode } from '../syntax-tree.js';\r\nimport { isCrossReference, isRuleCall } from '../languages/generated/ast.js';\r\nimport { getCrossReferenceTerminal, getRuleType } from '../utils/grammar-utils.js';\r\n\r\n/**\r\n * Language-specific service for converting string values from the source text format into a value to be held in the AST.\r\n */\r\nexport interface ValueConverter {\r\n    /**\r\n     * Converts a string value from the source text format into a value to be held in the AST.\r\n     */\r\n    convert(input: string, cstNode: CstNode): ValueType;\r\n}\r\n\r\nexport type ValueType = string | number | boolean | bigint | Date;\r\n\r\nexport class DefaultValueConverter implements ValueConverter {\r\n\r\n    convert(input: string, cstNode: CstNode): ValueType {\r\n        let feature: AbstractElement | undefined = cstNode.grammarSource;\r\n        if (isCrossReference(feature)) {\r\n            feature = getCrossReferenceTerminal(feature);\r\n        }\r\n        if (isRuleCall(feature)) {\r\n            const rule = feature.rule.ref;\r\n            if (!rule) {\r\n                throw new Error('This cst node was not parsed by a rule.');\r\n            }\r\n            return this.runConverter(rule, input, cstNode);\r\n        }\r\n        return input;\r\n    }\r\n\r\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\r\n    protected runConverter(rule: AbstractRule, input: string, cstNode: CstNode): ValueType {\r\n        switch (rule.name.toUpperCase()) {\r\n            case 'INT': return ValueConverter.convertInt(input);\r\n            case 'STRING': return ValueConverter.convertString(input);\r\n            case 'ID': return ValueConverter.convertID(input);\r\n        }\r\n        switch (getRuleType(rule)?.toLowerCase()) {\r\n            case 'number': return ValueConverter.convertNumber(input);\r\n            case 'boolean': return ValueConverter.convertBoolean(input);\r\n            case 'bigint': return ValueConverter.convertBigint(input);\r\n            case 'date': return ValueConverter.convertDate(input);\r\n            default: return input;\r\n        }\r\n    }\r\n}\r\n\r\nexport namespace ValueConverter {\r\n\r\n    export function convertString(input: string): string {\r\n        let result = '';\r\n        for (let i = 1; i < input.length - 1; i++) {\r\n            const c = input.charAt(i);\r\n            if (c === '\\\\') {\r\n                const c1 = input.charAt(++i);\r\n                result += convertEscapeCharacter(c1);\r\n            } else {\r\n                result += c;\r\n            }\r\n        }\r\n        return result;\r\n    }\r\n\r\n    function convertEscapeCharacter(char: string): string {\r\n        switch (char) {\r\n            case 'b': return '\\b';\r\n            case 'f': return '\\f';\r\n            case 'n': return '\\n';\r\n            case 'r': return '\\r';\r\n            case 't': return '\\t';\r\n            case 'v': return '\\v';\r\n            case '0': return '\\0';\r\n            default: return char;\r\n        }\r\n    }\r\n\r\n    export function convertID(input: string): string {\r\n        if (input.charAt(0) === '^') {\r\n            return input.substring(1);\r\n        } else {\r\n            return input;\r\n        }\r\n    }\r\n\r\n    export function convertInt(input: string): number {\r\n        return parseInt(input);\r\n    }\r\n\r\n    export function convertBigint(input: string): bigint {\r\n        return BigInt(input);\r\n    }\r\n\r\n    export function convertDate(input: string): Date {\r\n        return new Date(input);\r\n    }\r\n\r\n    export function convertNumber(input: string): number {\r\n        return Number(input);\r\n    }\r\n\r\n    export function convertBoolean(input: string): boolean {\r\n        return input.toLowerCase() === 'true';\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, AstNodeDescription, AstReflection, CstNode, LinkingError, Reference, ReferenceInfo } from '../syntax-tree.js';\r\nimport type { AstNodeLocator } from '../workspace/ast-node-locator.js';\r\nimport type { LangiumDocument, LangiumDocuments } from '../workspace/documents.js';\r\nimport type { ScopeProvider } from './scope-provider.js';\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport { isAstNode, isAstNodeDescription, isLinkingError } from '../syntax-tree.js';\r\nimport { findRootNode, streamAst, streamReferences } from '../utils/ast-utils.js';\r\nimport { interruptAndCheck } from '../utils/promise-utils.js';\r\nimport { DocumentState } from '../workspace/documents.js';\r\n\r\n/**\r\n * Language-specific service for resolving cross-references in the AST.\r\n */\r\nexport interface Linker {\r\n\r\n    /**\r\n     * Links all cross-references within the specified document. The default implementation loads only target\r\n     * elements from documents that are present in the `LangiumDocuments` service. The linked references are\r\n     * stored in the document's `references` property.\r\n     *\r\n     * @param document A LangiumDocument that shall be linked.\r\n     * @param cancelToken A token for cancelling the operation.\r\n     *\r\n     * @throws `OperationCancelled` if a cancellation event is detected\r\n     */\r\n    link(document: LangiumDocument, cancelToken?: CancellationToken): Promise<void>;\r\n\r\n    /**\r\n     * Unlinks all references within the specified document and removes them from the list of `references`.\r\n     *\r\n     * @param document A LangiumDocument that shall be unlinked.\r\n     */\r\n    unlink(document: LangiumDocument): void;\r\n\r\n    /**\r\n     * Determines a candidate AST node description for linking the given reference.\r\n     *\r\n     * @param refInfo Information about the reference.\r\n     */\r\n    getCandidate(refInfo: ReferenceInfo): AstNodeDescription | LinkingError;\r\n\r\n    /**\r\n     * Creates a cross reference node being aware of its containing AstNode, the corresponding CstNode,\r\n     * the cross reference text denoting the target AstNode being already extracted of the document text,\r\n     * as well as the unique cross reference identifier.\r\n     *\r\n     * Default behavior:\r\n     *  - The returned Reference's 'ref' property pointing to the target AstNode is populated lazily on its\r\n     *    first visit.\r\n     *  - If the target AstNode cannot be resolved on the first visit, an error indicator will be installed\r\n     *    and further resolution attempts will *not* be performed.\r\n     *\r\n     * @param node The containing AST node\r\n     * @param property The AST node property being referenced\r\n     * @param refNode The corresponding CST node\r\n     * @param refText The cross reference text denoting the target AstNode\r\n     * @returns the desired Reference node, whose behavior wrt. resolving the cross reference is implementation specific.\r\n     */\r\n    buildReference(node: AstNode, property: string, refNode: CstNode | undefined, refText: string): Reference;\r\n\r\n}\r\n\r\nconst ref_resolving = Symbol('ref_resolving');\r\n\r\ninterface DefaultReference extends Reference {\r\n    _ref?: AstNode | LinkingError | typeof ref_resolving;\r\n    _nodeDescription?: AstNodeDescription;\r\n}\r\n\r\nexport class DefaultLinker implements Linker {\r\n    protected readonly reflection: AstReflection;\r\n    protected readonly scopeProvider: ScopeProvider;\r\n    protected readonly astNodeLocator: AstNodeLocator;\r\n    protected readonly langiumDocuments: () => LangiumDocuments;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.reflection = services.shared.AstReflection;\r\n        this.langiumDocuments = () => services.shared.workspace.LangiumDocuments;\r\n        this.scopeProvider = services.references.ScopeProvider;\r\n        this.astNodeLocator = services.workspace.AstNodeLocator;\r\n    }\r\n\r\n    async link(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<void> {\r\n        for (const node of streamAst(document.parseResult.value)) {\r\n            await interruptAndCheck(cancelToken);\r\n            streamReferences(node).forEach(ref => this.doLink(ref, document));\r\n        }\r\n    }\r\n\r\n    protected doLink(refInfo: ReferenceInfo, document: LangiumDocument): void {\r\n        const ref = refInfo.reference as DefaultReference;\r\n        // The reference may already have been resolved lazily by accessing its `ref` property.\r\n        if (ref._ref === undefined) {\r\n            ref._ref = ref_resolving;\r\n            try {\r\n                const description = this.getCandidate(refInfo);\r\n                if (isLinkingError(description)) {\r\n                    ref._ref = description;\r\n                } else {\r\n                    ref._nodeDescription = description;\r\n                    if (this.langiumDocuments().hasDocument(description.documentUri)) {\r\n                        // The target document is already loaded\r\n                        const linkedNode = this.loadAstNode(description);\r\n                        ref._ref = linkedNode ?? this.createLinkingError(refInfo, description);\r\n                    } else {\r\n                        // Try to load the target AST node later using the already provided description\r\n                        ref._ref = undefined;\r\n                    }\r\n                }\r\n            } catch (err) {\r\n                console.error(`An error occurred while resolving reference to '${ref.$refText}':`, err);\r\n                const errorMessage = (err as Error).message ?? String(err);\r\n                ref._ref = {\r\n                    ...refInfo,\r\n                    message: `An error occurred while resolving reference to '${ref.$refText}': ${errorMessage}`\r\n                };\r\n            }\r\n            // Add the reference to the document's array of references\r\n            // Only add if the reference has been not been resolved earlier\r\n            // Otherwise we end up with duplicates\r\n            // See also implementation of `buildReference`\r\n            document.references.push(ref);\r\n        }\r\n    }\r\n\r\n    unlink(document: LangiumDocument): void {\r\n        for (const ref of document.references) {\r\n            delete (ref as DefaultReference)._ref;\r\n            delete (ref as DefaultReference)._nodeDescription;\r\n        }\r\n        document.references = [];\r\n    }\r\n\r\n    getCandidate(refInfo: ReferenceInfo): AstNodeDescription | LinkingError {\r\n        const scope = this.scopeProvider.getScope(refInfo);\r\n        const description = scope.getElement(refInfo.reference.$refText);\r\n        return description ?? this.createLinkingError(refInfo);\r\n    }\r\n\r\n    buildReference(node: AstNode, property: string, refNode: CstNode | undefined, refText: string): Reference {\r\n        // See behavior description in doc of Linker, update that on changes in here.\r\n        // eslint-disable-next-line @typescript-eslint/no-this-alias\r\n        const linker = this;\r\n        const reference: DefaultReference = {\r\n            $refNode: refNode,\r\n            $refText: refText,\r\n\r\n            get ref() {\r\n                if (isAstNode(this._ref)) {\r\n                    // Most frequent case: the target is already resolved.\r\n                    return this._ref;\r\n                } else if (isAstNodeDescription(this._nodeDescription)) {\r\n                    // A candidate has been found before, but it is not loaded yet.\r\n                    const linkedNode = linker.loadAstNode(this._nodeDescription);\r\n                    this._ref = linkedNode ??\r\n                        linker.createLinkingError({ reference, container: node, property }, this._nodeDescription);\r\n                } else if (this._ref === undefined) {\r\n                    // The reference has not been linked yet, so do that now.\r\n                    this._ref = ref_resolving;\r\n                    const document = findRootNode(node).$document;\r\n                    const refData = linker.getLinkedNode({ reference, container: node, property });\r\n                    if (refData.error && document && document.state < DocumentState.ComputedScopes) {\r\n                        // Document scope is not ready, don't set `this._ref` so linker can retry later.\r\n                        return this._ref = undefined;\r\n                    }\r\n                    this._ref = refData.node ?? refData.error;\r\n                    this._nodeDescription = refData.descr;\r\n                    document?.references.push(this);\r\n                } else if (this._ref === ref_resolving) {\r\n                    throw new Error(`Cyclic reference resolution detected: ${linker.astNodeLocator.getAstNodePath(node)}/${property} (symbol '${refText}')`);\r\n                }\r\n                return isAstNode(this._ref) ? this._ref : undefined;\r\n            },\r\n            get $nodeDescription() {\r\n                return this._nodeDescription;\r\n            },\r\n            get error() {\r\n                return isLinkingError(this._ref) ? this._ref : undefined;\r\n            }\r\n        };\r\n        return reference;\r\n    }\r\n\r\n    protected getLinkedNode(refInfo: ReferenceInfo): { node?: AstNode, descr?: AstNodeDescription, error?: LinkingError } {\r\n        try {\r\n            const description = this.getCandidate(refInfo);\r\n            if (isLinkingError(description)) {\r\n                return { error: description };\r\n            }\r\n            const linkedNode = this.loadAstNode(description);\r\n            if (linkedNode) {\r\n                return { node: linkedNode, descr: description };\r\n            }\r\n            else {\r\n                return {\r\n                    descr: description,\r\n                    error:\r\n                        this.createLinkingError(refInfo, description)\r\n                };\r\n            }\r\n        } catch (err) {\r\n            console.error(`An error occurred while resolving reference to '${refInfo.reference.$refText}':`, err);\r\n            const errorMessage = (err as Error).message ?? String(err);\r\n            return {\r\n                error: {\r\n                    ...refInfo,\r\n                    message: `An error occurred while resolving reference to '${refInfo.reference.$refText}': ${errorMessage}`\r\n                }\r\n            };\r\n        }\r\n    }\r\n\r\n    protected loadAstNode(nodeDescription: AstNodeDescription): AstNode | undefined {\r\n        if (nodeDescription.node) {\r\n            return nodeDescription.node;\r\n        }\r\n        const doc = this.langiumDocuments().getDocument(nodeDescription.documentUri);\r\n        if (!doc) {\r\n            return undefined;\r\n        }\r\n        return this.astNodeLocator.getAstNode(doc.parseResult.value, nodeDescription.path);\r\n    }\r\n\r\n    protected createLinkingError(refInfo: ReferenceInfo, targetDescription?: AstNodeDescription): LinkingError {\r\n        // Check whether the document is sufficiently processed by the DocumentBuilder. If not, this is a hint for a bug\r\n        // in the language implementation.\r\n        const document = findRootNode(refInfo.container).$document;\r\n        if (document && document.state < DocumentState.ComputedScopes) {\r\n            console.warn(`Attempted reference resolution before document reached ComputedScopes state (${document.uri}).`);\r\n        }\r\n        const referenceType = this.reflection.getReferenceType(refInfo);\r\n        return {\r\n            ...refInfo,\r\n            message: `Could not resolve reference to ${referenceType} named '${refInfo.reference.$refText}'.`,\r\n            targetDescription\r\n        };\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { MismatchedTokenException } from 'chevrotain';\r\nimport type { DiagnosticSeverity, Position, Range, Diagnostic } from 'vscode-languageserver-types';\r\nimport type { LanguageMetaData } from '../languages/language-meta-data.js';\r\nimport type { ParseResult } from '../parser/langium-parser.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, CstNode } from '../syntax-tree.js';\r\nimport type { LangiumDocument } from '../workspace/documents.js';\r\nimport type { DiagnosticData, DiagnosticInfo, ValidationAcceptor, ValidationCategory, ValidationRegistry, ValidationSeverity } from './validation-registry.js';\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport { findNodeForKeyword, findNodeForProperty } from '../utils/grammar-utils.js';\r\nimport { streamAst } from '../utils/ast-utils.js';\r\nimport { tokenToRange } from '../utils/cst-utils.js';\r\nimport { interruptAndCheck, isOperationCancelled } from '../utils/promise-utils.js';\r\nimport { diagnosticData } from './validation-registry.js';\r\nimport type { LexingDiagnostic, LexingDiagnosticSeverity } from '../parser/token-builder.js';\r\n\r\nexport interface ValidationOptions {\r\n    /**\r\n     * If this is set, only the checks associated with these categories are executed; otherwise\r\n     * all checks are executed. The default category if not specified to the registry is `'fast'`.\r\n     */\r\n    categories?: ValidationCategory[];\r\n    /** If true, no further diagnostics are reported if there are lexing errors. */\r\n    stopAfterLexingErrors?: boolean\r\n    /** If true, no further diagnostics are reported if there are parsing errors. */\r\n    stopAfterParsingErrors?: boolean\r\n    /** If true, no further diagnostics are reported if there are linking errors. */\r\n    stopAfterLinkingErrors?: boolean\r\n}\r\n\r\n/**\r\n * Language-specific service for validating `LangiumDocument`s.\r\n */\r\nexport interface DocumentValidator {\r\n    /**\r\n     * Validates the whole specified document.\r\n     *\r\n     * @param document specified document to validate\r\n     * @param options options to control the validation process\r\n     * @param cancelToken allows to cancel the current operation\r\n     * @throws `OperationCanceled` if a user action occurs during execution\r\n     */\r\n    validateDocument(document: LangiumDocument, options?: ValidationOptions, cancelToken?: CancellationToken): Promise<Diagnostic[]>;\r\n}\r\n\r\nexport class DefaultDocumentValidator implements DocumentValidator {\r\n\r\n    protected readonly validationRegistry: ValidationRegistry;\r\n    protected readonly metadata: LanguageMetaData;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.validationRegistry = services.validation.ValidationRegistry;\r\n        this.metadata = services.LanguageMetaData;\r\n    }\r\n\r\n    async validateDocument(document: LangiumDocument, options: ValidationOptions = {}, cancelToken = CancellationToken.None): Promise<Diagnostic[]> {\r\n        const parseResult = document.parseResult;\r\n        const diagnostics: Diagnostic[] = [];\r\n\r\n        await interruptAndCheck(cancelToken);\r\n\r\n        if (!options.categories || options.categories.includes('built-in')) {\r\n            this.processLexingErrors(parseResult, diagnostics, options);\r\n            if (options.stopAfterLexingErrors && diagnostics.some(d => d.data?.code === DocumentValidator.LexingError)) {\r\n                return diagnostics;\r\n            }\r\n\r\n            this.processParsingErrors(parseResult, diagnostics, options);\r\n            if (options.stopAfterParsingErrors && diagnostics.some(d => d.data?.code === DocumentValidator.ParsingError)) {\r\n                return diagnostics;\r\n            }\r\n\r\n            this.processLinkingErrors(document, diagnostics, options);\r\n            if (options.stopAfterLinkingErrors && diagnostics.some(d => d.data?.code === DocumentValidator.LinkingError)) {\r\n                return diagnostics;\r\n            }\r\n        }\r\n\r\n        // Process custom validations\r\n        try {\r\n            diagnostics.push(...await this.validateAst(parseResult.value, options, cancelToken));\r\n        } catch (err) {\r\n            if (isOperationCancelled(err)) {\r\n                throw err;\r\n            }\r\n            console.error('An error occurred during validation:', err);\r\n        }\r\n\r\n        await interruptAndCheck(cancelToken);\r\n\r\n        return diagnostics;\r\n    }\r\n\r\n    protected processLexingErrors(parseResult: ParseResult, diagnostics: Diagnostic[], _options: ValidationOptions): void {\r\n        const lexerDiagnostics = [...parseResult.lexerErrors, ...parseResult.lexerReport?.diagnostics ?? []] as LexingDiagnostic[];\r\n        for (const lexerDiagnostic of lexerDiagnostics) {\r\n            const severity = lexerDiagnostic.severity ?? 'error';\r\n            const diagnostic: Diagnostic = {\r\n                severity: toDiagnosticSeverity(severity),\r\n                range: {\r\n                    start: {\r\n                        line: lexerDiagnostic.line! - 1,\r\n                        character: lexerDiagnostic.column! - 1\r\n                    },\r\n                    end: {\r\n                        line: lexerDiagnostic.line! - 1,\r\n                        character: lexerDiagnostic.column! + lexerDiagnostic.length - 1\r\n                    }\r\n                },\r\n                message: lexerDiagnostic.message,\r\n                data: toDiagnosticData(severity),\r\n                source: this.getSource()\r\n            };\r\n            diagnostics.push(diagnostic);\r\n        }\r\n    }\r\n\r\n    protected processParsingErrors(parseResult: ParseResult, diagnostics: Diagnostic[], _options: ValidationOptions): void {\r\n        for (const parserError of parseResult.parserErrors) {\r\n            let range: Range | undefined = undefined;\r\n            // We can run into the chevrotain error recovery here\r\n            // The token contained in the parser error might be automatically inserted\r\n            // In this case every position value will be `NaN`\r\n            if (isNaN(parserError.token.startOffset)) {\r\n                // Some special parser error types contain a `previousToken`\r\n                // We can simply append our diagnostic to that token\r\n                if ('previousToken' in parserError) {\r\n                    const token = (parserError as MismatchedTokenException).previousToken;\r\n                    if (!isNaN(token.startOffset)) {\r\n                        const position: Position = { line: token.endLine! - 1, character: token.endColumn! };\r\n                        range = { start: position, end: position};\r\n                    } else {\r\n                        // No valid prev token. Might be empty document or containing only hidden tokens.\r\n                        // Point to document start\r\n                        const position: Position = { line: 0, character: 0 };\r\n                        range = { start: position, end: position};\r\n                    }\r\n                }\r\n            } else {\r\n                range = tokenToRange(parserError.token);\r\n            }\r\n            if (range) {\r\n                const diagnostic: Diagnostic = {\r\n                    severity: toDiagnosticSeverity('error'),\r\n                    range,\r\n                    message: parserError.message,\r\n                    data: diagnosticData(DocumentValidator.ParsingError),\r\n                    source: this.getSource()\r\n                };\r\n                diagnostics.push(diagnostic);\r\n            }\r\n        }\r\n    }\r\n\r\n    protected processLinkingErrors(document: LangiumDocument, diagnostics: Diagnostic[], _options: ValidationOptions): void {\r\n        for (const reference of document.references) {\r\n            const linkingError = reference.error;\r\n            if (linkingError) {\r\n                const info: DiagnosticInfo<AstNode, string> = {\r\n                    node: linkingError.container,\r\n                    property: linkingError.property,\r\n                    index: linkingError.index,\r\n                    data: {\r\n                        code: DocumentValidator.LinkingError,\r\n                        containerType: linkingError.container.$type,\r\n                        property: linkingError.property,\r\n                        refText: linkingError.reference.$refText\r\n                    } satisfies LinkingErrorData\r\n                };\r\n                diagnostics.push(this.toDiagnostic('error', linkingError.message, info));\r\n            }\r\n        }\r\n    }\r\n\r\n    protected async validateAst(rootNode: AstNode, options: ValidationOptions, cancelToken = CancellationToken.None): Promise<Diagnostic[]> {\r\n        const validationItems: Diagnostic[] = [];\r\n        const acceptor: ValidationAcceptor = <N extends AstNode>(severity: ValidationSeverity, message: string, info: DiagnosticInfo<N>) => {\r\n            validationItems.push(this.toDiagnostic(severity, message, info));\r\n        };\r\n\r\n        await this.validateAstBefore(rootNode, options, acceptor, cancelToken);\r\n        await this.validateAstNodes(rootNode, options, acceptor, cancelToken);\r\n        await this.validateAstAfter(rootNode, options, acceptor, cancelToken);\r\n\r\n        return validationItems;\r\n    }\r\n\r\n    protected async validateAstBefore(rootNode: AstNode, options: ValidationOptions, acceptor: ValidationAcceptor, cancelToken = CancellationToken.None): Promise<void> {\r\n        const checksBefore = this.validationRegistry.checksBefore;\r\n        for (const checkBefore of checksBefore) {\r\n            await interruptAndCheck(cancelToken);\r\n            await checkBefore(rootNode, acceptor, options.categories ?? [], cancelToken);\r\n        }\r\n    }\r\n\r\n    protected async validateAstNodes(rootNode: AstNode, options: ValidationOptions, acceptor: ValidationAcceptor, cancelToken = CancellationToken.None): Promise<void> {\r\n        await Promise.all(streamAst(rootNode).map(async node => {\r\n            await interruptAndCheck(cancelToken);\r\n            const checks = this.validationRegistry.getChecks(node.$type, options.categories);\r\n            for (const check of checks) {\r\n                await check(node, acceptor, cancelToken);\r\n            }\r\n        }));\r\n    }\r\n\r\n    protected async validateAstAfter(rootNode: AstNode, options: ValidationOptions, acceptor: ValidationAcceptor, cancelToken = CancellationToken.None): Promise<void> {\r\n        const checksAfter = this.validationRegistry.checksAfter;\r\n        for (const checkAfter of checksAfter) {\r\n            await interruptAndCheck(cancelToken);\r\n            await checkAfter(rootNode, acceptor, options.categories ?? [], cancelToken);\r\n        }\r\n    }\r\n\r\n    protected toDiagnostic<N extends AstNode>(severity: ValidationSeverity, message: string, info: DiagnosticInfo<N, string>): Diagnostic {\r\n        return {\r\n            message,\r\n            range: getDiagnosticRange(info),\r\n            severity: toDiagnosticSeverity(severity),\r\n            code: info.code,\r\n            codeDescription: info.codeDescription,\r\n            tags: info.tags,\r\n            relatedInformation: info.relatedInformation,\r\n            data: info.data,\r\n            source: this.getSource()\r\n        };\r\n    }\r\n\r\n    protected getSource(): string | undefined {\r\n        return this.metadata.languageId;\r\n    }\r\n}\r\n\r\nexport function getDiagnosticRange<N extends AstNode>(info: DiagnosticInfo<N, string>): Range {\r\n    if (info.range) {\r\n        return info.range;\r\n    }\r\n    let cstNode: CstNode | undefined;\r\n    if (typeof info.property === 'string') {\r\n        cstNode = findNodeForProperty(info.node.$cstNode, info.property, info.index);\r\n    } else if (typeof info.keyword === 'string') {\r\n        cstNode = findNodeForKeyword(info.node.$cstNode, info.keyword, info.index);\r\n    }\r\n    cstNode ??= info.node.$cstNode;\r\n    if (!cstNode) {\r\n        return {\r\n            start: { line: 0, character: 0 },\r\n            end: { line: 0, character: 0 }\r\n        };\r\n    }\r\n    return cstNode.range;\r\n}\r\n\r\n/**\r\n * Transforms the diagnostic severity from the {@link LexingDiagnosticSeverity} format to LSP's `DiagnosticSeverity` format.\r\n *\r\n * @param severity The lexing diagnostic severity\r\n * @returns Diagnostic severity according to `vscode-languageserver-types/lib/esm/main.js#DiagnosticSeverity`\r\n */\r\nexport function toDiagnosticSeverity(severity: LexingDiagnosticSeverity): DiagnosticSeverity {\r\n    switch (severity) {\r\n        case 'error':\r\n            return 1 satisfies typeof DiagnosticSeverity.Error;\r\n        case 'warning':\r\n            return 2 satisfies typeof DiagnosticSeverity.Warning;\r\n        case 'info':\r\n            return 3 satisfies typeof DiagnosticSeverity.Information;\r\n        case 'hint':\r\n            return 4 satisfies typeof DiagnosticSeverity.Hint;\r\n        default:\r\n            throw new Error('Invalid diagnostic severity: ' + severity);\r\n    }\r\n}\r\n\r\nexport function toDiagnosticData(severity: LexingDiagnosticSeverity): DiagnosticData {\r\n    switch (severity) {\r\n        case 'error':\r\n            return diagnosticData(DocumentValidator.LexingError);\r\n        case 'warning':\r\n            return diagnosticData(DocumentValidator.LexingWarning);\r\n        case 'info':\r\n            return diagnosticData(DocumentValidator.LexingInfo);\r\n        case 'hint':\r\n            return diagnosticData(DocumentValidator.LexingHint);\r\n        default:\r\n            throw new Error('Invalid diagnostic severity: ' + severity);\r\n    }\r\n}\r\n\r\nexport namespace DocumentValidator {\r\n    export const LexingError = 'lexing-error';\r\n    export const LexingWarning = 'lexing-warning';\r\n    export const LexingInfo = 'lexing-info';\r\n    export const LexingHint = 'lexing-hint';\r\n    export const ParsingError = 'parsing-error';\r\n    export const LinkingError = 'linking-error';\r\n}\r\n\r\nexport interface LinkingErrorData extends DiagnosticData {\r\n    containerType: string\r\n    property: string\r\n    refText: string\r\n}\r\n","import castPath from './_castPath.js';\nimport isArguments from './isArguments.js';\nimport isArray from './isArray.js';\nimport isIndex from './_isIndex.js';\nimport isLength from './isLength.js';\nimport toKey from './_toKey.js';\n\n/**\n * Checks if `path` exists on `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {Array|string} path The path to check.\n * @param {Function} hasFunc The function to check properties.\n * @returns {boolean} Returns `true` if `path` exists, else `false`.\n */\nfunction hasPath(object, path, hasFunc) {\n  path = castPath(path, object);\n\n  var index = -1,\n      length = path.length,\n      result = false;\n\n  while (++index < length) {\n    var key = toKey(path[index]);\n    if (!(result = object != null && hasFunc(object, key))) {\n      break;\n    }\n    object = object[key];\n  }\n  if (result || ++index != length) {\n    return result;\n  }\n  length = object == null ? 0 : object.length;\n  return !!length && isLength(length) && isIndex(key, length) &&\n    (isArray(object) || isArguments(object));\n}\n\nexport default hasPath;\n","import SetCache from './_SetCache.js';\nimport arrayIncludes from './_arrayIncludes.js';\nimport arrayIncludesWith from './_arrayIncludesWith.js';\nimport arrayMap from './_arrayMap.js';\nimport baseUnary from './_baseUnary.js';\nimport cacheHas from './_cacheHas.js';\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/**\n * The base implementation of methods like `_.difference` without support\n * for excluding multiple arrays or iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Array} values The values to exclude.\n * @param {Function} [iteratee] The iteratee invoked per element.\n * @param {Function} [comparator] The comparator invoked per element.\n * @returns {Array} Returns the new array of filtered values.\n */\nfunction baseDifference(array, values, iteratee, comparator) {\n  var index = -1,\n      includes = arrayIncludes,\n      isCommon = true,\n      length = array.length,\n      result = [],\n      valuesLength = values.length;\n\n  if (!length) {\n    return result;\n  }\n  if (iteratee) {\n    values = arrayMap(values, baseUnary(iteratee));\n  }\n  if (comparator) {\n    includes = arrayIncludesWith;\n    isCommon = false;\n  }\n  else if (values.length >= LARGE_ARRAY_SIZE) {\n    includes = cacheHas;\n    isCommon = false;\n    values = new SetCache(values);\n  }\n  outer:\n  while (++index < length) {\n    var value = array[index],\n        computed = iteratee == null ? value : iteratee(value);\n\n    value = (comparator || value !== 0) ? value : 0;\n    if (isCommon && computed === computed) {\n      var valuesIndex = valuesLength;\n      while (valuesIndex--) {\n        if (values[valuesIndex] === computed) {\n          continue outer;\n        }\n      }\n      result.push(value);\n    }\n    else if (!includes(values, computed, comparator)) {\n      result.push(value);\n    }\n  }\n  return result;\n}\n\nexport default baseDifference;\n","import baseTimes from './_baseTimes.js';\nimport isArguments from './isArguments.js';\nimport isArray from './isArray.js';\nimport isBuffer from './isBuffer.js';\nimport isIndex from './_isIndex.js';\nimport isTypedArray from './isTypedArray.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Creates an array of the enumerable property names of the array-like `value`.\n *\n * @private\n * @param {*} value The value to query.\n * @param {boolean} inherited Specify returning inherited property names.\n * @returns {Array} Returns the array of property names.\n */\nfunction arrayLikeKeys(value, inherited) {\n  var isArr = isArray(value),\n      isArg = !isArr && isArguments(value),\n      isBuff = !isArr && !isArg && isBuffer(value),\n      isType = !isArr && !isArg && !isBuff && isTypedArray(value),\n      skipIndexes = isArr || isArg || isBuff || isType,\n      result = skipIndexes ? baseTimes(value.length, String) : [],\n      length = result.length;\n\n  for (var key in value) {\n    if ((inherited || hasOwnProperty.call(value, key)) &&\n        !(skipIndexes && (\n           // Safari 9 has enumerable `arguments.length` in strict mode.\n           key == 'length' ||\n           // Node.js 0.10 has enumerable non-index properties on buffers.\n           (isBuff && (key == 'offset' || key == 'parent')) ||\n           // PhantomJS 2 has enumerable non-index properties on typed arrays.\n           (isType && (key == 'buffer' || key == 'byteLength' || key == 'byteOffset')) ||\n           // Skip index properties.\n           isIndex(key, length)\n        ))) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\nexport default arrayLikeKeys;\n","import ListCache from './_ListCache.js';\nimport stackClear from './_stackClear.js';\nimport stackDelete from './_stackDelete.js';\nimport stackGet from './_stackGet.js';\nimport stackHas from './_stackHas.js';\nimport stackSet from './_stackSet.js';\n\n/**\n * Creates a stack cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Stack(entries) {\n  var data = this.__data__ = new ListCache(entries);\n  this.size = data.size;\n}\n\n// Add methods to `Stack`.\nStack.prototype.clear = stackClear;\nStack.prototype['delete'] = stackDelete;\nStack.prototype.get = stackGet;\nStack.prototype.has = stackHas;\nStack.prototype.set = stackSet;\n\nexport default Stack;\n","import SetCache from './_SetCache.js';\nimport arrayIncludes from './_arrayIncludes.js';\nimport arrayIncludesWith from './_arrayIncludesWith.js';\nimport cacheHas from './_cacheHas.js';\nimport createSet from './_createSet.js';\nimport setToArray from './_setToArray.js';\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/**\n * The base implementation of `_.uniqBy` without support for iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Function} [iteratee] The iteratee invoked per element.\n * @param {Function} [comparator] The comparator invoked per element.\n * @returns {Array} Returns the new duplicate free array.\n */\nfunction baseUniq(array, iteratee, comparator) {\n  var index = -1,\n      includes = arrayIncludes,\n      length = array.length,\n      isCommon = true,\n      result = [],\n      seen = result;\n\n  if (comparator) {\n    isCommon = false;\n    includes = arrayIncludesWith;\n  }\n  else if (length >= LARGE_ARRAY_SIZE) {\n    var set = iteratee ? null : createSet(array);\n    if (set) {\n      return setToArray(set);\n    }\n    isCommon = false;\n    includes = cacheHas;\n    seen = new SetCache;\n  }\n  else {\n    seen = iteratee ? [] : result;\n  }\n  outer:\n  while (++index < length) {\n    var value = array[index],\n        computed = iteratee ? iteratee(value) : value;\n\n    value = (comparator || value !== 0) ? value : 0;\n    if (isCommon && computed === computed) {\n      var seenIndex = seen.length;\n      while (seenIndex--) {\n        if (seen[seenIndex] === computed) {\n          continue outer;\n        }\n      }\n      if (iteratee) {\n        seen.push(computed);\n      }\n      result.push(value);\n    }\n    else if (!includes(seen, computed, comparator)) {\n      if (seen !== result) {\n        seen.push(computed);\n      }\n      result.push(value);\n    }\n  }\n  return result;\n}\n\nexport default baseUniq;\n","import assignValue from './_assignValue.js';\nimport copyObject from './_copyObject.js';\nimport createAssigner from './_createAssigner.js';\nimport isArrayLike from './isArrayLike.js';\nimport isPrototype from './_isPrototype.js';\nimport keys from './keys.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Assigns own enumerable string keyed properties of source objects to the\n * destination object. Source objects are applied from left to right.\n * Subsequent sources overwrite property assignments of previous sources.\n *\n * **Note:** This method mutates `object` and is loosely based on\n * [`Object.assign`](https://mdn.io/Object/assign).\n *\n * @static\n * @memberOf _\n * @since 0.10.0\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @see _.assignIn\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n * }\n *\n * function Bar() {\n *   this.c = 3;\n * }\n *\n * Foo.prototype.b = 2;\n * Bar.prototype.d = 4;\n *\n * _.assign({ 'a': 0 }, new Foo, new Bar);\n * // => { 'a': 1, 'c': 3 }\n */\nvar assign = createAssigner(function(object, source) {\n  if (isPrototype(source) || isArrayLike(source)) {\n    copyObject(source, keys(source), object);\n    return;\n  }\n  for (var key in source) {\n    if (hasOwnProperty.call(source, key)) {\n      assignValue(object, key, source[key]);\n    }\n  }\n});\n\nexport default assign;\n","import Symbol from './_Symbol.js';\nimport Uint8Array from './_Uint8Array.js';\nimport eq from './eq.js';\nimport equalArrays from './_equalArrays.js';\nimport mapToArray from './_mapToArray.js';\nimport setToArray from './_setToArray.js';\n\n/** Used to compose bitmasks for value comparisons. */\nvar COMPARE_PARTIAL_FLAG = 1,\n    COMPARE_UNORDERED_FLAG = 2;\n\n/** `Object#toString` result references. */\nvar boolTag = '[object Boolean]',\n    dateTag = '[object Date]',\n    errorTag = '[object Error]',\n    mapTag = '[object Map]',\n    numberTag = '[object Number]',\n    regexpTag = '[object RegExp]',\n    setTag = '[object Set]',\n    stringTag = '[object String]',\n    symbolTag = '[object Symbol]';\n\nvar arrayBufferTag = '[object ArrayBuffer]',\n    dataViewTag = '[object DataView]';\n\n/** Used to convert symbols to primitives and strings. */\nvar symbolProto = Symbol ? Symbol.prototype : undefined,\n    symbolValueOf = symbolProto ? symbolProto.valueOf : undefined;\n\n/**\n * A specialized version of `baseIsEqualDeep` for comparing objects of\n * the same `toStringTag`.\n *\n * **Note:** This function only supports comparing values with tags of\n * `Boolean`, `Date`, `Error`, `Number`, `RegExp`, or `String`.\n *\n * @private\n * @param {Object} object The object to compare.\n * @param {Object} other The other object to compare.\n * @param {string} tag The `toStringTag` of the objects to compare.\n * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.\n * @param {Function} customizer The function to customize comparisons.\n * @param {Function} equalFunc The function to determine equivalents of values.\n * @param {Object} stack Tracks traversed `object` and `other` objects.\n * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.\n */\nfunction equalByTag(object, other, tag, bitmask, customizer, equalFunc, stack) {\n  switch (tag) {\n    case dataViewTag:\n      if ((object.byteLength != other.byteLength) ||\n          (object.byteOffset != other.byteOffset)) {\n        return false;\n      }\n      object = object.buffer;\n      other = other.buffer;\n\n    case arrayBufferTag:\n      if ((object.byteLength != other.byteLength) ||\n          !equalFunc(new Uint8Array(object), new Uint8Array(other))) {\n        return false;\n      }\n      return true;\n\n    case boolTag:\n    case dateTag:\n    case numberTag:\n      // Coerce booleans to `1` or `0` and dates to milliseconds.\n      // Invalid dates are coerced to `NaN`.\n      return eq(+object, +other);\n\n    case errorTag:\n      return object.name == other.name && object.message == other.message;\n\n    case regexpTag:\n    case stringTag:\n      // Coerce regexes to strings and treat strings, primitives and objects,\n      // as equal. See http://www.ecma-international.org/ecma-262/7.0/#sec-regexp.prototype.tostring\n      // for more details.\n      return object == (other + '');\n\n    case mapTag:\n      var convert = mapToArray;\n\n    case setTag:\n      var isPartial = bitmask & COMPARE_PARTIAL_FLAG;\n      convert || (convert = setToArray);\n\n      if (object.size != other.size && !isPartial) {\n        return false;\n      }\n      // Assume cyclic values are equal.\n      var stacked = stack.get(object);\n      if (stacked) {\n        return stacked == other;\n      }\n      bitmask |= COMPARE_UNORDERED_FLAG;\n\n      // Recursively compare objects (susceptible to call stack limits).\n      stack.set(object, other);\n      var result = equalArrays(convert(object), convert(other), bitmask, customizer, equalFunc, stack);\n      stack['delete'](object);\n      return result;\n\n    case symbolTag:\n      if (symbolValueOf) {\n        return symbolValueOf.call(object) == symbolValueOf.call(other);\n      }\n  }\n  return false;\n}\n\nexport default equalByTag;\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { URI } from '../utils/uri-utils.js';\r\n\r\nexport interface FileSystemNode {\r\n    readonly isFile: boolean;\r\n    readonly isDirectory: boolean;\r\n    readonly uri: URI;\r\n}\r\n\r\nexport type FileSystemFilter = (node: FileSystemNode) => boolean;\r\n\r\n/**\r\n * Provides methods to interact with an abstract file system. The default implementation is based on the node.js `fs` API.\r\n */\r\nexport interface FileSystemProvider {\r\n    /**\r\n     * Reads a document asynchronously from a given URI.\r\n     * @returns The string content of the file with the specified URI.\r\n     */\r\n    readFile(uri: URI): Promise<string>;\r\n    /**\r\n     * Reads the directory information for the given URI.\r\n     * @returns The list of file system entries that are contained within the specified directory.\r\n     */\r\n    readDirectory(uri: URI): Promise<FileSystemNode[]>;\r\n}\r\n\r\nexport class EmptyFileSystemProvider implements FileSystemProvider {\r\n\r\n    readFile(): Promise<string> {\r\n        throw new Error('No file system is available.');\r\n    }\r\n\r\n    async readDirectory(): Promise<FileSystemNode[]> {\r\n        return [];\r\n    }\r\n\r\n}\r\n\r\nexport const EmptyFileSystem = {\r\n    fileSystemProvider: () => new EmptyFileSystemProvider()\r\n};\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { CstNode } from '../syntax-tree.js';\r\n\r\nexport class ErrorWithLocation extends Error {\r\n    constructor(node: CstNode | undefined, message: string) {\r\n        super(node ? `${message} at ${node.range.start.line}:${node.range.start.character}` : message);\r\n    }\r\n}\r\n\r\nexport function assertUnreachable(_: never): never {\r\n    throw new Error('Error! The input value was not handled.');\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport map from \"lodash-es/map.js\"\r\nimport filter from \"lodash-es/filter.js\"\r\nimport {\r\n    IProduction,\r\n    IProductionWithOccurrence,\r\n    TokenType,\r\n    Alternation,\r\n    NonTerminal,\r\n    Rule,\r\n    Option,\r\n    RepetitionMandatory,\r\n    Repetition,\r\n    Terminal,\r\n    Alternative,\r\n    RepetitionWithSeparator,\r\n    RepetitionMandatoryWithSeparator,\r\n    LookaheadProductionType\r\n} from \"chevrotain\"\r\n\r\nexport function buildATNKey(rule: Rule, type: LookaheadProductionType, occurrence: number): string {\r\n    return `${rule.name}_${type}_${occurrence}`;\r\n}\r\n\r\nexport interface ATN {\r\n    decisionMap: Record<string, DecisionState>\r\n    states: ATNState[]\r\n    decisionStates: DecisionState[]\r\n    ruleToStartState: Map<Rule, RuleStartState>\r\n    ruleToStopState: Map<Rule, RuleStopState>\r\n}\r\n\r\nexport const ATN_INVALID_TYPE = 0\r\nexport const ATN_BASIC = 1\r\nexport const ATN_RULE_START = 2\r\nexport const ATN_PLUS_BLOCK_START = 4\r\nexport const ATN_STAR_BLOCK_START = 5\r\n// Currently unused as the ATN is not used for lexing\r\nexport const ATN_TOKEN_START = 6\r\nexport const ATN_RULE_STOP = 7\r\nexport const ATN_BLOCK_END = 8\r\nexport const ATN_STAR_LOOP_BACK = 9\r\nexport const ATN_STAR_LOOP_ENTRY = 10\r\nexport const ATN_PLUS_LOOP_BACK = 11\r\nexport const ATN_LOOP_END = 12\r\n\r\nexport type ATNState =\r\n    | BasicState\r\n    | BasicBlockStartState\r\n    | PlusBlockStartState\r\n    | PlusLoopbackState\r\n    | StarBlockStartState\r\n    | StarLoopbackState\r\n    | StarLoopEntryState\r\n    | BlockEndState\r\n    | RuleStartState\r\n    | RuleStopState\r\n    | LoopEndState\r\n\r\nexport interface ATNBaseState {\r\n    atn: ATN\r\n    production: IProductionWithOccurrence\r\n    stateNumber: number\r\n    rule: Rule\r\n    epsilonOnlyTransitions: boolean\r\n    transitions: Transition[]\r\n    nextTokenWithinRule: number[]\r\n}\r\n\r\nexport interface BasicState extends ATNBaseState {\r\n    type: typeof ATN_BASIC\r\n}\r\n\r\nexport interface BlockStartState extends DecisionState {\r\n    end: BlockEndState\r\n}\r\n\r\nexport interface BasicBlockStartState extends BlockStartState {\r\n    type: typeof ATN_BASIC\r\n}\r\n\r\nexport interface PlusBlockStartState extends BlockStartState {\r\n    loopback: PlusLoopbackState\r\n    type: typeof ATN_PLUS_BLOCK_START\r\n}\r\n\r\nexport interface PlusLoopbackState extends DecisionState {\r\n    type: typeof ATN_PLUS_LOOP_BACK\r\n}\r\n\r\nexport interface StarBlockStartState extends BlockStartState {\r\n    type: typeof ATN_STAR_BLOCK_START\r\n}\r\n\r\nexport interface StarLoopbackState extends ATNBaseState {\r\n    type: typeof ATN_STAR_LOOP_BACK\r\n}\r\n\r\nexport interface StarLoopEntryState extends DecisionState {\r\n    loopback: StarLoopbackState\r\n    type: typeof ATN_STAR_LOOP_ENTRY\r\n}\r\n\r\nexport interface BlockEndState extends ATNBaseState {\r\n    start: BlockStartState\r\n    type: typeof ATN_BLOCK_END\r\n}\r\n\r\nexport interface DecisionState extends ATNBaseState {\r\n    decision: number\r\n}\r\n\r\nexport interface LoopEndState extends ATNBaseState {\r\n    loopback: ATNState\r\n    type: typeof ATN_LOOP_END\r\n}\r\n\r\nexport interface RuleStartState extends ATNBaseState {\r\n    stop: RuleStopState\r\n    type: typeof ATN_RULE_START\r\n}\r\n\r\nexport interface RuleStopState extends ATNBaseState {\r\n    type: typeof ATN_RULE_STOP\r\n}\r\n\r\nexport interface Transition {\r\n    target: ATNState\r\n    isEpsilon(): boolean\r\n}\r\n\r\nexport abstract class AbstractTransition implements Transition {\r\n    target: ATNState\r\n\r\n    constructor(target: ATNState) {\r\n        this.target = target\r\n    }\r\n\r\n    isEpsilon() {\r\n        return false\r\n    }\r\n}\r\n\r\nexport class AtomTransition extends AbstractTransition {\r\n    tokenType: TokenType\r\n\r\n    constructor(target: ATNState, tokenType: TokenType) {\r\n        super(target)\r\n        this.tokenType = tokenType\r\n    }\r\n}\r\n\r\nexport class EpsilonTransition extends AbstractTransition {\r\n    constructor(target: ATNState) {\r\n        super(target)\r\n    }\r\n\r\n    isEpsilon() {\r\n        return true\r\n    }\r\n}\r\n\r\nexport class RuleTransition extends AbstractTransition {\r\n    rule: Rule\r\n    followState: ATNState\r\n\r\n    constructor(ruleStart: RuleStartState, rule: Rule, followState: ATNState) {\r\n        super(ruleStart)\r\n        this.rule = rule\r\n        this.followState = followState\r\n    }\r\n\r\n    isEpsilon() {\r\n        return true\r\n    }\r\n}\r\n\r\ninterface ATNHandle {\r\n    left: ATNState\r\n    right: ATNState\r\n}\r\n\r\nexport function createATN(rules: Rule[]): ATN {\r\n    const atn: ATN = {\r\n        decisionMap: {},\r\n        decisionStates: [],\r\n        ruleToStartState: new Map(),\r\n        ruleToStopState: new Map(),\r\n        states: []\r\n    }\r\n    createRuleStartAndStopATNStates(atn, rules)\r\n    const ruleLength = rules.length\r\n    for (let i = 0; i < ruleLength; i++) {\r\n        const rule = rules[i]\r\n        const ruleBlock = block(atn, rule, rule)\r\n        if (ruleBlock === undefined) {\r\n            continue\r\n        }\r\n        buildRuleHandle(atn, rule, ruleBlock)\r\n    }\r\n    return atn\r\n}\r\n\r\nfunction createRuleStartAndStopATNStates(atn: ATN, rules: Rule[]): void {\r\n    const ruleLength = rules.length\r\n    for (let i = 0; i < ruleLength; i++) {\r\n        const rule = rules[i]\r\n        const start = newState<RuleStartState>(atn, rule, undefined, {\r\n            type: ATN_RULE_START\r\n        })\r\n        const stop = newState<RuleStopState>(atn, rule, undefined, {\r\n            type: ATN_RULE_STOP\r\n        })\r\n        start.stop = stop\r\n        atn.ruleToStartState.set(rule, start)\r\n        atn.ruleToStopState.set(rule, stop)\r\n    }\r\n}\r\n\r\nfunction atom(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    production: IProduction\r\n): ATNHandle | undefined {\r\n    if (production instanceof Terminal) {\r\n        return tokenRef(atn, rule, production.terminalType, production)\r\n    } else if (production instanceof NonTerminal) {\r\n        return ruleRef(atn, rule, production)\r\n    } else if (production instanceof Alternation) {\r\n        return alternation(atn, rule, production)\r\n    } else if (production instanceof Option) {\r\n        return option(atn, rule, production)\r\n    } else if (production instanceof Repetition) {\r\n        return repetition(atn, rule, production)\r\n    } else if (production instanceof RepetitionWithSeparator) {\r\n        return repetitionSep(atn, rule, production)\r\n    } else if (production instanceof RepetitionMandatory) {\r\n        return repetitionMandatory(atn, rule, production)\r\n    } else if (production instanceof RepetitionMandatoryWithSeparator) {\r\n        return repetitionMandatorySep(atn, rule, production)\r\n    } else {\r\n        return block(atn, rule, production as Alternative)\r\n    }\r\n}\r\n\r\nfunction repetition(atn: ATN, rule: Rule, repetition: Repetition): ATNHandle {\r\n    const starState = newState<StarBlockStartState>(atn, rule, repetition, {\r\n        type: ATN_STAR_BLOCK_START\r\n    })\r\n    defineDecisionState(atn, starState)\r\n    const handle = makeAlts(\r\n        atn,\r\n        rule,\r\n        starState,\r\n        repetition,\r\n        block(atn, rule, repetition)\r\n    )\r\n    return star(atn, rule, repetition, handle)\r\n}\r\n\r\nfunction repetitionSep(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    repetition: RepetitionWithSeparator\r\n): ATNHandle {\r\n    const starState = newState<StarBlockStartState>(atn, rule, repetition, {\r\n        type: ATN_STAR_BLOCK_START\r\n    })\r\n    defineDecisionState(atn, starState)\r\n    const handle = makeAlts(\r\n        atn,\r\n        rule,\r\n        starState,\r\n        repetition,\r\n        block(atn, rule, repetition)\r\n    )\r\n    const sep = tokenRef(atn, rule, repetition.separator, repetition)\r\n    return star(atn, rule, repetition, handle, sep)\r\n}\r\n\r\nfunction repetitionMandatory(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    repetition: RepetitionMandatory\r\n): ATNHandle {\r\n    const plusState = newState<PlusBlockStartState>(atn, rule, repetition, {\r\n        type: ATN_PLUS_BLOCK_START\r\n    })\r\n    defineDecisionState(atn, plusState)\r\n    const handle = makeAlts(\r\n        atn,\r\n        rule,\r\n        plusState,\r\n        repetition,\r\n        block(atn, rule, repetition)\r\n    )\r\n    return plus(atn, rule, repetition, handle)\r\n}\r\n\r\nfunction repetitionMandatorySep(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    repetition: RepetitionMandatoryWithSeparator\r\n): ATNHandle {\r\n    const plusState = newState<PlusBlockStartState>(atn, rule, repetition, {\r\n        type: ATN_PLUS_BLOCK_START\r\n    })\r\n    defineDecisionState(atn, plusState)\r\n    const handle = makeAlts(\r\n        atn,\r\n        rule,\r\n        plusState,\r\n        repetition,\r\n        block(atn, rule, repetition)\r\n    )\r\n    const sep = tokenRef(atn, rule, repetition.separator, repetition)\r\n    return plus(atn, rule, repetition, handle, sep)\r\n}\r\n\r\nfunction alternation(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    alternation: Alternation\r\n): ATNHandle {\r\n    const start = newState<BasicBlockStartState>(atn, rule, alternation, {\r\n        type: ATN_BASIC\r\n    })\r\n    defineDecisionState(atn, start)\r\n    const alts = map(alternation.definition, (e) => atom(atn, rule, e))\r\n    const handle = makeAlts(atn, rule, start, alternation, ...alts)\r\n    return handle\r\n}\r\n\r\nfunction option(atn: ATN, rule: Rule, option: Option): ATNHandle {\r\n    const start = newState<BasicBlockStartState>(atn, rule, option, {\r\n        type: ATN_BASIC\r\n    })\r\n    defineDecisionState(atn, start)\r\n    const handle = makeAlts(atn, rule, start, option, block(atn, rule, option))\r\n    return optional(atn, rule, option, handle)\r\n}\r\n\r\nfunction block(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    block: { definition: IProduction[] }\r\n): ATNHandle | undefined {\r\n    const handles = filter(\r\n        map(block.definition, (e) => atom(atn, rule, e)),\r\n        (e) => e !== undefined\r\n    ) as ATNHandle[]\r\n    if (handles.length === 1) {\r\n        return handles[0]\r\n    } else if (handles.length === 0) {\r\n        return undefined\r\n    } else {\r\n        return makeBlock(atn, handles)\r\n    }\r\n}\r\n\r\nfunction plus(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    plus: IProductionWithOccurrence,\r\n    handle: ATNHandle,\r\n    sep?: ATNHandle\r\n): ATNHandle {\r\n    const blkStart = handle.left as PlusBlockStartState\r\n    const blkEnd = handle.right\r\n\r\n    const loop = newState<PlusLoopbackState>(atn, rule, plus, {\r\n        type: ATN_PLUS_LOOP_BACK\r\n    })\r\n    defineDecisionState(atn, loop)\r\n    const end = newState<LoopEndState>(atn, rule, plus, {\r\n        type: ATN_LOOP_END\r\n    })\r\n    blkStart.loopback = loop\r\n    end.loopback = loop\r\n    atn.decisionMap[buildATNKey(rule, sep ? 'RepetitionMandatoryWithSeparator' : 'RepetitionMandatory', plus.idx)] = loop;\r\n    epsilon(blkEnd, loop) // block can see loop back\r\n\r\n    // Depending on whether we have a separator we put the exit transition at index 1 or 0\r\n    // This influences the chosen option in the lookahead DFA\r\n    if (sep === undefined) {\r\n        epsilon(loop, blkStart) // loop back to start\r\n        epsilon(loop, end) // exit\r\n    } else {\r\n        epsilon(loop, end) // exit\r\n        // loop back to start with separator\r\n        epsilon(loop, sep.left)\r\n        epsilon(sep.right, blkStart)\r\n    }\r\n\r\n    return {\r\n        left: blkStart,\r\n        right: end\r\n    }\r\n}\r\n\r\nfunction star(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    star: IProductionWithOccurrence,\r\n    handle: ATNHandle,\r\n    sep?: ATNHandle\r\n): ATNHandle {\r\n    const start = handle.left\r\n    const end = handle.right\r\n\r\n    const entry = newState<StarLoopEntryState>(atn, rule, star, {\r\n        type: ATN_STAR_LOOP_ENTRY\r\n    })\r\n    defineDecisionState(atn, entry)\r\n    const loopEnd = newState<LoopEndState>(atn, rule, star, {\r\n        type: ATN_LOOP_END\r\n    })\r\n    const loop = newState<StarLoopbackState>(atn, rule, star, {\r\n        type: ATN_STAR_LOOP_BACK\r\n    })\r\n    entry.loopback = loop\r\n    loopEnd.loopback = loop\r\n\r\n    epsilon(entry, start) // loop enter edge (alt 2)\r\n    epsilon(entry, loopEnd) // bypass loop edge (alt 1)\r\n    epsilon(end, loop) // block end hits loop back\r\n\r\n    if (sep !== undefined) {\r\n        epsilon(loop, loopEnd) // end loop\r\n        // loop back to start of handle using separator\r\n        epsilon(loop, sep.left)\r\n        epsilon(sep.right, start)\r\n    } else {\r\n        epsilon(loop, entry) // loop back to entry/exit decision\r\n    }\r\n\r\n    atn.decisionMap[buildATNKey(rule, sep ? 'RepetitionWithSeparator' : 'Repetition', star.idx)] = entry;\r\n    return {\r\n        left: entry,\r\n        right: loopEnd\r\n    }\r\n}\r\n\r\nfunction optional(atn: ATN, rule: Rule, optional: Option, handle: ATNHandle): ATNHandle {\r\n    const start = handle.left as DecisionState\r\n    const end = handle.right\r\n\r\n    epsilon(start, end)\r\n\r\n    atn.decisionMap[buildATNKey(rule, 'Option', optional.idx)] = start;\r\n    return handle\r\n}\r\n\r\nfunction defineDecisionState(atn: ATN, state: DecisionState): number {\r\n    atn.decisionStates.push(state)\r\n    state.decision = atn.decisionStates.length - 1\r\n    return state.decision\r\n}\r\n\r\nfunction makeAlts(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    start: BlockStartState,\r\n    production: IProductionWithOccurrence,\r\n    ...alts: (ATNHandle | undefined)[]\r\n): ATNHandle {\r\n    const end = newState<BlockEndState>(atn, rule, production, {\r\n        type: ATN_BLOCK_END,\r\n        start\r\n    })\r\n    start.end = end\r\n    for (const alt of alts) {\r\n        if (alt !== undefined) {\r\n            // hook alts up to decision block\r\n            epsilon(start, alt.left)\r\n            epsilon(alt.right, end)\r\n        } else {\r\n            epsilon(start, end)\r\n        }\r\n    }\r\n\r\n    const handle: ATNHandle = {\r\n        left: start as ATNState,\r\n        right: end\r\n    }\r\n    atn.decisionMap[buildATNKey(rule, getProdType(production), production.idx)] = start\r\n    return handle\r\n}\r\n\r\nfunction getProdType(production: IProduction): LookaheadProductionType {\r\n    if (production instanceof Alternation) {\r\n        return 'Alternation';\r\n    } else if (production instanceof Option) {\r\n        return 'Option';\r\n    } else if (production instanceof Repetition) {\r\n        return 'Repetition';\r\n    } else if (production instanceof RepetitionWithSeparator) {\r\n        return 'RepetitionWithSeparator';\r\n    } else if (production instanceof RepetitionMandatory) {\r\n        return 'RepetitionMandatory';\r\n    } else if (production instanceof RepetitionMandatoryWithSeparator) {\r\n        return 'RepetitionMandatoryWithSeparator';\r\n    } else {\r\n        throw new Error('Invalid production type encountered');\r\n    }\r\n}\r\n\r\nfunction makeBlock(atn: ATN, alts: ATNHandle[]): ATNHandle {\r\n    const altsLength = alts.length\r\n    for (let i = 0; i < altsLength - 1; i++) {\r\n        const handle = alts[i]\r\n        let transition: Transition | undefined\r\n        if (handle.left.transitions.length === 1) {\r\n            transition = handle.left.transitions[0]\r\n        }\r\n        const isRuleTransition = transition instanceof RuleTransition\r\n        const ruleTransition = transition as RuleTransition\r\n        const next = alts[i + 1].left\r\n        if (\r\n            handle.left.type === ATN_BASIC &&\r\n            handle.right.type === ATN_BASIC &&\r\n            transition !== undefined &&\r\n            ((isRuleTransition && ruleTransition.followState === handle.right) ||\r\n                transition.target === handle.right)\r\n        ) {\r\n            // we can avoid epsilon edge to next element\r\n            if (isRuleTransition) {\r\n                ruleTransition.followState = next\r\n            } else {\r\n                transition.target = next\r\n            }\r\n            removeState(atn, handle.right) // we skipped over this state\r\n        } else {\r\n            // need epsilon if previous block's right end node is complex\r\n            epsilon(handle.right, next)\r\n        }\r\n    }\r\n\r\n    const first = alts[0]\r\n    const last = alts[altsLength - 1]\r\n    return {\r\n        left: first.left,\r\n        right: last.right\r\n    }\r\n}\r\n\r\nfunction tokenRef(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    tokenType: TokenType,\r\n    production: IProductionWithOccurrence\r\n): ATNHandle {\r\n    const left = newState<BasicState>(atn, rule, production, {\r\n        type: ATN_BASIC\r\n    })\r\n    const right = newState<BasicState>(atn, rule, production, {\r\n        type: ATN_BASIC\r\n    })\r\n    addTransition(left, new AtomTransition(right, tokenType))\r\n    return {\r\n        left,\r\n        right\r\n    }\r\n}\r\n\r\nfunction ruleRef(\r\n    atn: ATN,\r\n    currentRule: Rule,\r\n    nonTerminal: NonTerminal\r\n): ATNHandle {\r\n    const rule = nonTerminal.referencedRule\r\n    const start = atn.ruleToStartState.get(rule)!\r\n    const left = newState<BasicBlockStartState>(atn, currentRule, nonTerminal, {\r\n        type: ATN_BASIC\r\n    })\r\n    const right = newState<BasicBlockStartState>(atn, currentRule, nonTerminal, {\r\n        type: ATN_BASIC\r\n    })\r\n\r\n    const call = new RuleTransition(start, rule, right)\r\n    addTransition(left, call)\r\n\r\n    return {\r\n        left,\r\n        right\r\n    }\r\n}\r\n\r\nfunction buildRuleHandle(atn: ATN, rule: Rule, block: ATNHandle): ATNHandle {\r\n    const start = atn.ruleToStartState.get(rule)!\r\n    epsilon(start, block.left)\r\n    const stop = atn.ruleToStopState.get(rule)!\r\n    epsilon(block.right, stop)\r\n    const handle: ATNHandle = {\r\n        left: start,\r\n        right: stop\r\n    }\r\n    return handle\r\n}\r\n\r\nfunction epsilon(a: ATNBaseState, b: ATNBaseState): void {\r\n    const transition = new EpsilonTransition(b as ATNState)\r\n    addTransition(a, transition)\r\n}\r\n\r\nfunction newState<T extends ATNState>(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    production: IProductionWithOccurrence | undefined,\r\n    partial: Partial<T>\r\n): T {\r\n    const t: T = {\r\n        atn,\r\n        production,\r\n        epsilonOnlyTransitions: false,\r\n        rule,\r\n        transitions: [],\r\n        nextTokenWithinRule: [],\r\n        stateNumber: atn.states.length,\r\n        ...partial\r\n    } as unknown as T\r\n    atn.states.push(t)\r\n    return t\r\n}\r\n\r\nfunction addTransition(state: ATNBaseState, transition: Transition) {\r\n    // A single ATN state can only contain epsilon transitions or non-epsilon transitions\r\n    // Because they are never mixed, only setting the property for the first transition is fine\r\n    if (state.transitions.length === 0) {\r\n        state.epsilonOnlyTransitions = transition.isEpsilon()\r\n    }\r\n    state.transitions.push(transition)\r\n}\r\n\r\nfunction removeState(atn: ATN, state: ATNState): void {\r\n    atn.states.splice(atn.states.indexOf(state), 1)\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { CodeDescription, DiagnosticRelatedInformation, DiagnosticTag, integer, Range } from 'vscode-languageserver-types';\r\nimport { assertUnreachable } from '../index.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, AstReflection, Properties } from '../syntax-tree.js';\r\nimport type { CancellationToken } from '../utils/cancellation.js';\r\nimport { MultiMap } from '../utils/collections.js';\r\nimport type { MaybePromise } from '../utils/promise-utils.js';\r\nimport { isOperationCancelled } from '../utils/promise-utils.js';\r\nimport type { Stream } from '../utils/stream.js';\r\nimport { stream } from '../utils/stream.js';\r\nimport type { DocumentSegment } from '../workspace/documents.js';\r\n\r\nexport type DiagnosticInfo<N extends AstNode, P extends string = Properties<N>> = {\r\n    /** The AST node to which the diagnostic is attached. */\r\n    node: N;\r\n    /** If a property name is given, the diagnostic is restricted to the corresponding text region. */\r\n    property?: P;\r\n    /** If the value of a keyword is given, the diagnostic will appear at its corresponding text region */\r\n    keyword?: string;\r\n    /** In case of a multi-value property (array), an index can be given to select a specific element. */\r\n    index?: number;\r\n    /** If you want to create a diagnostic independent to any property, use the range property. */\r\n    range?: Range;\r\n    /** The diagnostic's code, which usually appear in the user interface. */\r\n    code?: integer | string;\r\n    /** An optional property to describe the error code. */\r\n    codeDescription?: CodeDescription;\r\n    /** Additional metadata about the diagnostic. */\r\n    tags?: DiagnosticTag[];\r\n    /** An array of related diagnostic information, e.g. when symbol-names within a scope collide all definitions can be marked via this property. */\r\n    relatedInformation?: DiagnosticRelatedInformation[];\r\n    /** A data entry field that is preserved between a `textDocument/publishDiagnostics` notification and `textDocument/codeAction` request. */\r\n    data?: unknown;\r\n}\r\n\r\n/**\r\n * Shape of information commonly used in the `data` field of diagnostics.\r\n */\r\nexport interface DiagnosticData {\r\n    /** Diagnostic code for identifying which code action to apply. This code is _not_ shown in the user interface. */\r\n    code: string\r\n    /** Specifies where to apply the code action in the form of a `DocumentSegment`. */\r\n    actionSegment?: DocumentSegment\r\n    /** Specifies where to apply the code action in the form of a `Range`. */\r\n    actionRange?: Range\r\n}\r\n\r\n/**\r\n * Create DiagnosticData for a given diagnostic code. The result can be put into the `data` field of a DiagnosticInfo.\r\n */\r\nexport function diagnosticData(code: string): DiagnosticData {\r\n    return { code };\r\n}\r\n\r\nexport type ValidationSeverity = 'error' | 'warning' | 'info' | 'hint';\r\n\r\nexport type ValidationAcceptor = <N extends AstNode>(severity: ValidationSeverity, message: string, info: DiagnosticInfo<N>) => void\r\n\r\nexport type ValidationCheck<T extends AstNode = AstNode> = (node: T, accept: ValidationAcceptor, cancelToken: CancellationToken) => MaybePromise<void>;\r\n\r\n/**\r\n * A utility type for describing functions which will be called once before or after all the AstNodes of an AST/Langium document are validated.\r\n *\r\n * The AST is represented by its root AstNode.\r\n *\r\n * The given validation acceptor helps to report some early or lately detected issues.\r\n *\r\n * The 'categories' indicate, which validation categories are executed for all the AstNodes.\r\n * This helps to tailor the preparations/tear-down logic to the actually executed checks on the nodes.\r\n *\r\n * It is recommended to support interrupts during long-running logic with 'interruptAndCheck(cancelToken)'.\r\n */\r\nexport type ValidationPreparation = (rootNode: AstNode, accept: ValidationAcceptor, categories: ValidationCategory[], cancelToken: CancellationToken) => MaybePromise<void>;\r\n\r\n/**\r\n * A utility type for associating non-primitive AST types to corresponding validation checks. For example:\r\n *\r\n * ```ts\r\n *   const checks: ValidationChecks<StatemachineAstType> = {\r\n *       State: validator.checkStateNameStartsWithCapital\r\n *    };\r\n * ```\r\n *\r\n * If an AST type does not extend AstNode, e.g. if it describes a union of string literals, that type's name must not occur as a key in objects of type `ValidationCheck<...>`.\r\n *\r\n * @param T a type definition mapping language specific type names (keys) to the corresponding types (values)\r\n */\r\nexport type ValidationChecks<T> = {\r\n    [K in keyof T]?: T[K] extends AstNode ? ValidationCheck<T[K]> | Array<ValidationCheck<T[K]>> : never\r\n} & {\r\n    AstNode?: ValidationCheck<AstNode> | Array<ValidationCheck<AstNode>>;\r\n}\r\n\r\n/**\r\n * `fast` checks can be executed after every document change (i.e. as the user is typing). If a check\r\n * is too slow it can delay the response to document changes, yielding bad user experience. By marking\r\n * it as `slow`, it will be skipped for normal as-you-type validation. Then it's up to you when to\r\n * schedule these long-running checks: after the fast checks are done, or after saving a document,\r\n * or with an explicit command, etc.\r\n *\r\n * `built-in` checks are errors produced by the lexer, the parser, or the linker. They cannot be used\r\n * for custom validation checks.\r\n */\r\nexport type ValidationCategory = 'fast' | 'slow' | 'built-in'\r\n\r\nexport namespace ValidationCategory {\r\n    export const all: readonly ValidationCategory[] = ['fast', 'slow', 'built-in'];\r\n}\r\n\r\ntype ValidationCheckEntry = {\r\n    check: ValidationCheck\r\n    category: ValidationCategory\r\n}\r\n\r\n/**\r\n * Manages a set of `ValidationCheck`s to be applied when documents are validated.\r\n */\r\nexport class ValidationRegistry {\r\n    private readonly entries = new MultiMap<string, ValidationCheckEntry>();\r\n    private readonly reflection: AstReflection;\r\n\r\n    private entriesBefore: ValidationPreparation[] = [];\r\n    private entriesAfter: ValidationPreparation[] = [];\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.reflection = services.shared.AstReflection;\r\n    }\r\n\r\n    /**\r\n     * Register a set of validation checks. Each value in the record can be either a single validation check (i.e. a function)\r\n     * or an array of validation checks.\r\n     *\r\n     * @param checksRecord Set of validation checks to register.\r\n     * @param category Optional category for the validation checks (defaults to `'fast'`).\r\n     * @param thisObj Optional object to be used as `this` when calling the validation check functions.\r\n     */\r\n    register<T>(checksRecord: ValidationChecks<T>, thisObj: ThisParameterType<unknown> = this, category: ValidationCategory = 'fast'): void {\r\n        if (category === 'built-in') {\r\n            throw new Error(\"The 'built-in' category is reserved for lexer, parser, and linker errors.\");\r\n        }\r\n        for (const [type, ch] of Object.entries(checksRecord)) {\r\n            const callbacks = ch as ValidationCheck | ValidationCheck[];\r\n            if (Array.isArray(callbacks)) {\r\n                for (const check of callbacks) {\r\n                    const entry: ValidationCheckEntry = {\r\n                        check: this.wrapValidationException(check, thisObj),\r\n                        category\r\n                    };\r\n                    this.addEntry(type, entry);\r\n                }\r\n            } else if (typeof callbacks === 'function') {\r\n                const entry: ValidationCheckEntry = {\r\n                    check: this.wrapValidationException(callbacks, thisObj),\r\n                    category\r\n                };\r\n                this.addEntry(type, entry);\r\n            } else {\r\n                assertUnreachable(callbacks);\r\n            }\r\n        }\r\n    }\r\n\r\n    protected wrapValidationException(check: ValidationCheck, thisObj: unknown): ValidationCheck {\r\n        return async (node, accept, cancelToken) => {\r\n            await this.handleException(() => check.call(thisObj, node, accept, cancelToken), 'An error occurred during validation', accept, node);\r\n        };\r\n    }\r\n\r\n    protected async handleException(functionality: () => MaybePromise<void>, messageContext: string, accept: ValidationAcceptor, node: AstNode): Promise<void> {\r\n        try {\r\n            await functionality();\r\n        } catch (err) {\r\n            if (isOperationCancelled(err)) {\r\n                throw err;\r\n            }\r\n            console.error(`${messageContext}:`, err);\r\n            if (err instanceof Error && err.stack) {\r\n                console.error(err.stack);\r\n            }\r\n            const messageDetails = err instanceof Error ? err.message : String(err);\r\n            accept('error', `${messageContext}: ${messageDetails}`, { node });\r\n        }\r\n    }\r\n\r\n    protected addEntry(type: string, entry: ValidationCheckEntry): void {\r\n        if (type === 'AstNode') {\r\n            this.entries.add('AstNode', entry);\r\n            return;\r\n        }\r\n        for (const subtype of this.reflection.getAllSubTypes(type)) {\r\n            this.entries.add(subtype, entry);\r\n        }\r\n    }\r\n\r\n    getChecks(type: string, categories?: ValidationCategory[]): Stream<ValidationCheck> {\r\n        let checks = stream(this.entries.get(type))\r\n            .concat(this.entries.get('AstNode'));\r\n        if (categories) {\r\n            checks = checks.filter(entry => categories.includes(entry.category));\r\n        }\r\n        return checks.map(entry => entry.check);\r\n    }\r\n\r\n    /**\r\n     * Register logic which will be executed once before validating all the nodes of an AST/Langium document.\r\n     * This helps to prepare or initialize some information which are required or reusable for the following checks on the AstNodes.\r\n     *\r\n     * As an example, for validating unique fully-qualified names of nodes in the AST,\r\n     * here the map for mapping names to nodes could be established.\r\n     * During the usual checks on the nodes, they are put into this map with their name.\r\n     *\r\n     * Note that this approach makes validations stateful, which is relevant e.g. when cancelling the validation.\r\n     * Therefore it is recommended to clear stored information\r\n     * _before_ validating an AST to validate each AST unaffected from other ASTs\r\n     * AND _after_ validating the AST to free memory by information which are no longer used.\r\n     *\r\n     * @param checkBefore a set-up function which will be called once before actually validating an AST\r\n     * @param thisObj Optional object to be used as `this` when calling the validation check functions.\r\n     */\r\n    registerBeforeDocument(checkBefore: ValidationPreparation, thisObj: ThisParameterType<unknown> = this): void {\r\n        this.entriesBefore.push(this.wrapPreparationException(checkBefore, 'An error occurred during set-up of the validation', thisObj));\r\n    }\r\n\r\n    /**\r\n     * Register logic which will be executed once after validating all the nodes of an AST/Langium document.\r\n     * This helps to finally evaluate information which are collected during the checks on the AstNodes.\r\n     *\r\n     * As an example, for validating unique fully-qualified names of nodes in the AST,\r\n     * here the map with all the collected nodes and their names is checked\r\n     * and validation hints are created for all nodes with the same name.\r\n     *\r\n     * Note that this approach makes validations stateful, which is relevant e.g. when cancelling the validation.\r\n     * Therefore it is recommended to clear stored information\r\n     * _before_ validating an AST to validate each AST unaffected from other ASTs\r\n     * AND _after_ validating the AST to free memory by information which are no longer used.\r\n     *\r\n     * @param checkBefore a set-up function which will be called once before actually validating an AST\r\n     * @param thisObj Optional object to be used as `this` when calling the validation check functions.\r\n     */\r\n    registerAfterDocument(checkAfter: ValidationPreparation, thisObj: ThisParameterType<unknown> = this): void {\r\n        this.entriesAfter.push(this.wrapPreparationException(checkAfter, 'An error occurred during tear-down of the validation', thisObj));\r\n    }\r\n\r\n    protected wrapPreparationException(check: ValidationPreparation, messageContext: string, thisObj: unknown): ValidationPreparation {\r\n        return async (rootNode, accept, categories, cancelToken) => {\r\n            await this.handleException(() => check.call(thisObj, rootNode, accept, categories, cancelToken), messageContext, accept, rootNode);\r\n        };\r\n    }\r\n\r\n    get checksBefore(): ValidationPreparation[] {\r\n        return this.entriesBefore;\r\n    }\r\n\r\n    get checksAfter(): ValidationPreparation[] {\r\n        return this.entriesAfter;\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { ILexerErrorMessageProvider, ILexingError, IMultiModeLexerDefinition, IToken, TokenType, TokenTypeDictionary, TokenVocabulary } from 'chevrotain';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport { Lexer as ChevrotainLexer, defaultLexerErrorProvider } from 'chevrotain';\r\nimport type { LexingReport, TokenBuilder } from './token-builder.js';\r\n\r\nexport class DefaultLexerErrorMessageProvider implements ILexerErrorMessageProvider {\r\n\r\n    buildUnexpectedCharactersMessage(fullText: string, startOffset: number, length: number, line?: number, column?: number): string {\r\n        return defaultLexerErrorProvider.buildUnexpectedCharactersMessage(fullText, startOffset, length, line, column);\r\n    }\r\n\r\n    buildUnableToPopLexerModeMessage(token: IToken): string {\r\n        return defaultLexerErrorProvider.buildUnableToPopLexerModeMessage(token);\r\n    }\r\n}\r\n\r\nexport interface LexerResult {\r\n    /**\r\n     * A list of all tokens that were lexed from the input.\r\n     *\r\n     * Note that Langium requires the optional properties\r\n     * `startLine`, `startColumn`, `endOffset`, `endLine` and `endColumn` to be set on each token.\r\n     */\r\n    tokens: IToken[];\r\n    /**\r\n     * Contains hidden tokens, usually comments.\r\n     */\r\n    hidden: IToken[];\r\n    errors: ILexingError[];\r\n    report?: LexingReport;\r\n}\r\n\r\nexport type TokenizeMode = 'full' | 'partial';\r\n\r\nexport interface TokenizeOptions {\r\n    mode?: TokenizeMode;\r\n}\r\n\r\nexport const DEFAULT_TOKENIZE_OPTIONS: TokenizeOptions = { mode: 'full' };\r\n\r\nexport interface Lexer {\r\n    readonly definition: TokenTypeDictionary;\r\n    tokenize(text: string, options?: TokenizeOptions): LexerResult;\r\n}\r\n\r\nexport class DefaultLexer implements Lexer {\r\n\r\n    protected readonly tokenBuilder: TokenBuilder;\r\n    protected readonly errorMessageProvider: ILexerErrorMessageProvider;\r\n    protected tokenTypes: TokenTypeDictionary;\r\n    protected chevrotainLexer: ChevrotainLexer;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.errorMessageProvider = services.parser.LexerErrorMessageProvider;\r\n        this.tokenBuilder = services.parser.TokenBuilder;\r\n        const tokens = this.tokenBuilder.buildTokens(services.Grammar, {\r\n            caseInsensitive: services.LanguageMetaData.caseInsensitive\r\n        });\r\n        this.tokenTypes = this.toTokenTypeDictionary(tokens);\r\n        const lexerTokens = isTokenTypeDictionary(tokens) ? Object.values(tokens) : tokens;\r\n        const production = services.LanguageMetaData.mode === 'production';\r\n        this.chevrotainLexer = new ChevrotainLexer(lexerTokens, {\r\n            positionTracking: 'full',\r\n            skipValidations: production,\r\n            errorMessageProvider: this.errorMessageProvider\r\n        });\r\n    }\r\n\r\n    get definition(): TokenTypeDictionary {\r\n        return this.tokenTypes;\r\n    }\r\n\r\n    tokenize(text: string, _options: TokenizeOptions = DEFAULT_TOKENIZE_OPTIONS): LexerResult {\r\n        const chevrotainResult = this.chevrotainLexer.tokenize(text);\r\n        return {\r\n            tokens: chevrotainResult.tokens,\r\n            errors: chevrotainResult.errors,\r\n            hidden: chevrotainResult.groups.hidden ?? [],\r\n            report: this.tokenBuilder.flushLexingReport?.(text)\r\n        };\r\n    }\r\n\r\n    protected toTokenTypeDictionary(buildTokens: TokenVocabulary): TokenTypeDictionary {\r\n        if (isTokenTypeDictionary(buildTokens)) return buildTokens;\r\n        const tokens = isIMultiModeLexerDefinition(buildTokens) ? Object.values(buildTokens.modes).flat() : buildTokens;\r\n        const res: TokenTypeDictionary = {};\r\n        tokens.forEach(token => res[token.name] = token);\r\n        return res;\r\n    }\r\n}\r\n\r\n/**\r\n * Returns a check whether the given TokenVocabulary is TokenType array\r\n */\r\nexport function isTokenTypeArray(tokenVocabulary: TokenVocabulary): tokenVocabulary is TokenType[] {\r\n    return Array.isArray(tokenVocabulary) && (tokenVocabulary.length === 0 || 'name' in tokenVocabulary[0]);\r\n}\r\n\r\n/**\r\n * Returns a check whether the given TokenVocabulary is IMultiModeLexerDefinition\r\n */\r\nexport function isIMultiModeLexerDefinition(tokenVocabulary: TokenVocabulary): tokenVocabulary is IMultiModeLexerDefinition {\r\n    return tokenVocabulary && 'modes' in tokenVocabulary && 'defaultMode' in tokenVocabulary;\r\n}\r\n\r\n/**\r\n * Returns a check whether the given TokenVocabulary is TokenTypeDictionary\r\n */\r\nexport function isTokenTypeDictionary(tokenVocabulary: TokenVocabulary): tokenVocabulary is TokenTypeDictionary {\r\n    return !isTokenTypeArray(tokenVocabulary) && !isIMultiModeLexerDefinition(tokenVocabulary);\r\n}\r\n","import { CstNode, CstNodeLocation, IToken } from \"@chevrotain/types\";\n\n/**\n * This nodeLocation tracking is not efficient and should only be used\n * when error recovery is enabled or the Token Vector contains virtual Tokens\n * (e.g, Python Indent/Outdent)\n * As it executes the calculation for every single terminal/nonTerminal\n * and does not rely on the fact the token vector is **sorted**\n */\nexport function setNodeLocationOnlyOffset(\n  currNodeLocation: CstNodeLocation,\n  newLocationInfo: Required<Pick<IToken, \"startOffset\" | \"endOffset\">>,\n): void {\n  // First (valid) update for this cst node\n  if (isNaN(currNodeLocation.startOffset) === true) {\n    // assumption1: Token location information is either NaN or a valid number\n    // assumption2: Token location information is fully valid if it exist\n    // (both start/end offsets exist and are numbers).\n    currNodeLocation.startOffset = newLocationInfo.startOffset;\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n  }\n  // Once the startOffset has been updated with a valid number it should never receive\n  // any farther updates as the Token vector is sorted.\n  // We still have to check this this condition for every new possible location info\n  // because with error recovery enabled we may encounter invalid tokens (NaN location props)\n  else if (currNodeLocation.endOffset! < newLocationInfo.endOffset === true) {\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n  }\n}\n\n/**\n * This nodeLocation tracking is not efficient and should only be used\n * when error recovery is enabled or the Token Vector contains virtual Tokens\n * (e.g, Python Indent/Outdent)\n * As it executes the calculation for every single terminal/nonTerminal\n * and does not rely on the fact the token vector is **sorted**\n */\nexport function setNodeLocationFull(\n  currNodeLocation: CstNodeLocation,\n  newLocationInfo: CstNodeLocation,\n): void {\n  // First (valid) update for this cst node\n  if (isNaN(currNodeLocation.startOffset) === true) {\n    // assumption1: Token location information is either NaN or a valid number\n    // assumption2: Token location information is fully valid if it exist\n    // (all start/end props exist and are numbers).\n    currNodeLocation.startOffset = newLocationInfo.startOffset;\n    currNodeLocation.startColumn = newLocationInfo.startColumn;\n    currNodeLocation.startLine = newLocationInfo.startLine;\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n    currNodeLocation.endColumn = newLocationInfo.endColumn;\n    currNodeLocation.endLine = newLocationInfo.endLine;\n  }\n  // Once the start props has been updated with a valid number it should never receive\n  // any farther updates as the Token vector is sorted.\n  // We still have to check this this condition for every new possible location info\n  // because with error recovery enabled we may encounter invalid tokens (NaN location props)\n  else if (currNodeLocation.endOffset! < newLocationInfo.endOffset! === true) {\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n    currNodeLocation.endColumn = newLocationInfo.endColumn;\n    currNodeLocation.endLine = newLocationInfo.endLine;\n  }\n}\n\nexport function addTerminalToCst(\n  node: CstNode,\n  token: IToken,\n  tokenTypeName: string,\n): void {\n  if (node.children[tokenTypeName] === undefined) {\n    node.children[tokenTypeName] = [token];\n  } else {\n    node.children[tokenTypeName].push(token);\n  }\n}\n\nexport function addNoneTerminalToCst(\n  node: CstNode,\n  ruleName: string,\n  ruleResult: any,\n): void {\n  if (node.children[ruleName] === undefined) {\n    node.children[ruleName] = [ruleResult];\n  } else {\n    node.children[ruleName].push(ruleResult);\n  }\n}\n","import DataView from './_DataView.js';\nimport Map from './_Map.js';\nimport Promise from './_Promise.js';\nimport Set from './_Set.js';\nimport WeakMap from './_WeakMap.js';\nimport baseGetTag from './_baseGetTag.js';\nimport toSource from './_toSource.js';\n\n/** `Object#toString` result references. */\nvar mapTag = '[object Map]',\n    objectTag = '[object Object]',\n    promiseTag = '[object Promise]',\n    setTag = '[object Set]',\n    weakMapTag = '[object WeakMap]';\n\nvar dataViewTag = '[object DataView]';\n\n/** Used to detect maps, sets, and weakmaps. */\nvar dataViewCtorString = toSource(DataView),\n    mapCtorString = toSource(Map),\n    promiseCtorString = toSource(Promise),\n    setCtorString = toSource(Set),\n    weakMapCtorString = toSource(WeakMap);\n\n/**\n * Gets the `toStringTag` of `value`.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nvar getTag = baseGetTag;\n\n// Fallback for data views, maps, sets, and weak maps in IE 11 and promises in Node.js < 6.\nif ((DataView && getTag(new DataView(new ArrayBuffer(1))) != dataViewTag) ||\n    (Map && getTag(new Map) != mapTag) ||\n    (Promise && getTag(Promise.resolve()) != promiseTag) ||\n    (Set && getTag(new Set) != setTag) ||\n    (WeakMap && getTag(new WeakMap) != weakMapTag)) {\n  getTag = function(value) {\n    var result = baseGetTag(value),\n        Ctor = result == objectTag ? value.constructor : undefined,\n        ctorString = Ctor ? toSource(Ctor) : '';\n\n    if (ctorString) {\n      switch (ctorString) {\n        case dataViewCtorString: return dataViewTag;\n        case mapCtorString: return mapTag;\n        case promiseCtorString: return promiseTag;\n        case setCtorString: return setTag;\n        case weakMapCtorString: return weakMapTag;\n      }\n    }\n    return result;\n  };\n}\n\nexport default getTag;\n","import baseIsEqual from './_baseIsEqual.js';\nimport get from './get.js';\nimport hasIn from './hasIn.js';\nimport isKey from './_isKey.js';\nimport isStrictComparable from './_isStrictComparable.js';\nimport matchesStrictComparable from './_matchesStrictComparable.js';\nimport toKey from './_toKey.js';\n\n/** Used to compose bitmasks for value comparisons. */\nvar COMPARE_PARTIAL_FLAG = 1,\n    COMPARE_UNORDERED_FLAG = 2;\n\n/**\n * The base implementation of `_.matchesProperty` which doesn't clone `srcValue`.\n *\n * @private\n * @param {string} path The path of the property to get.\n * @param {*} srcValue The value to match.\n * @returns {Function} Returns the new spec function.\n */\nfunction baseMatchesProperty(path, srcValue) {\n  if (isKey(path) && isStrictComparable(srcValue)) {\n    return matchesStrictComparable(toKey(path), srcValue);\n  }\n  return function(object) {\n    var objValue = get(object, path);\n    return (objValue === undefined && objValue === srcValue)\n      ? hasIn(object, path)\n      : baseIsEqual(srcValue, objValue, COMPARE_PARTIAL_FLAG | COMPARE_UNORDERED_FLAG);\n  };\n}\n\nexport default baseMatchesProperty;\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\n/* eslint-disable @typescript-eslint/no-explicit-any */\r\n\r\n/**\r\n * A `Module<I>` is a description of possibly grouped service factories.\r\n *\r\n * Given a type I = { group: { service: A } },\r\n * Module<I> := { group: { service: (injector: I) => A } }\r\n *\r\n * Making `I` available during the creation of `I` allows us to create cyclic\r\n * dependencies.\r\n */\r\nexport type Module<I, T = I> = {\r\n    [K in keyof T]: Module<I, T[K]> | ((injector: I) => T[K])\r\n}\r\n\r\nexport namespace Module {\r\n    export const merge = <M1, M2, R extends M1 & M2>(m1: Module<R, M1>, m2: Module<R, M2>) => (_merge(_merge({}, m1), m2) as Module<R, M1 & M2>);\r\n}\r\n\r\n/**\r\n * Given a set of modules, the inject function returns a lazily evaluated injector\r\n * that injects dependencies into the requested service when it is requested the\r\n * first time. Subsequent requests will return the same service.\r\n *\r\n * In the case of cyclic dependencies, an Error will be thrown. This can be fixed\r\n * by injecting a provider `() => T` instead of a `T`.\r\n *\r\n * Please note that the arguments may be objects or arrays. However, the result will\r\n * be an object. Using it with for..of will have no effect.\r\n *\r\n * @param module1 first Module\r\n * @param module2 (optional) second Module\r\n * @param module3 (optional) third Module\r\n * @param module4 (optional) fourth Module\r\n * @param module5 (optional) fifth Module\r\n * @param module6 (optional) sixth Module\r\n * @param module7 (optional) seventh Module\r\n * @param module8 (optional) eighth Module\r\n * @param module9 (optional) ninth Module\r\n * @returns a new object of type I\r\n */\r\nexport function inject<I1, I2, I3, I4, I5, I6, I7, I8, I9, I extends I1 & I2 & I3 & I4 & I5 & I6 & I7 & I8 & I9>(\r\n    module1: Module<I, I1>, module2?: Module<I, I2>, module3?: Module<I, I3>, module4?: Module<I, I4>, module5?: Module<I, I5>, module6?: Module<I, I6>, module7?: Module<I, I7>, module8?: Module<I, I8>, module9?: Module<I, I9>\r\n): I {\r\n    const module = [module1, module2, module3, module4, module5, module6, module7, module8, module9].reduce(_merge, {}) as Module<I>;\r\n    return _inject(module);\r\n}\r\n\r\nconst isProxy = Symbol('isProxy');\r\n\r\n/**\r\n * Eagerly load all services in the given dependency injection container. This is sometimes\r\n * necessary because services can register event listeners in their constructors.\r\n */\r\nexport function eagerLoad<T>(item: T): T {\r\n    if (item && (item as any)[isProxy]) {\r\n        for (const value of Object.values(item)) {\r\n            eagerLoad(value);\r\n        }\r\n    }\r\n    return item;\r\n}\r\n\r\n/**\r\n * Helper function that returns an injector by creating a proxy.\r\n * Invariant: injector is of type I. If injector is undefined, then T = I.\r\n */\r\nfunction _inject<I, T>(module: Module<I, T>, injector?: any): T {\r\n    const proxy: any = new Proxy({} as any, {\r\n        deleteProperty: () => false,\r\n        set: () => {\r\n            throw new Error('Cannot set property on injected service container');\r\n        },\r\n        get: (obj, prop) => {\r\n            if (prop === isProxy) {\r\n                return true;\r\n            } else {\r\n                return _resolve(obj, prop, module, injector || proxy);\r\n            }\r\n        },\r\n        getOwnPropertyDescriptor: (obj, prop) => (_resolve(obj, prop, module, injector || proxy), Object.getOwnPropertyDescriptor(obj, prop)), // used by for..in\r\n        has: (_, prop) => prop in module, // used by ..in..\r\n        ownKeys: () => [...Object.getOwnPropertyNames(module)] // used by for..in\r\n    });\r\n    return proxy;\r\n}\r\n\r\n/**\r\n * Internally used to tag a requested dependency, directly before calling the factory.\r\n * This allows us to find cycles during instance creation.\r\n */\r\nconst __requested__ = Symbol();\r\n\r\n/**\r\n * Returns the value `obj[prop]`. If the value does not exist, yet, it is resolved from\r\n * the module description. The result of service factories is cached. Groups are\r\n * recursively proxied.\r\n *\r\n * @param obj an object holding all group proxies and services\r\n * @param prop the key of a value within obj\r\n * @param module an object containing groups and service factories\r\n * @param injector the first level proxy that provides access to all values\r\n * @returns the requested value `obj[prop]`\r\n * @throws Error if a dependency cycle is detected\r\n */\r\nfunction _resolve<I, T>(obj: any, prop: string | symbol | number, module: Module<I, T>, injector: I): T[keyof T] | undefined {\r\n    if (prop in obj) {\r\n        if (obj[prop] instanceof Error) {\r\n            throw new Error('Construction failure. Please make sure that your dependencies are constructable.', {cause: obj[prop]});\r\n        }\r\n        if (obj[prop] === __requested__) {\r\n            throw new Error('Cycle detected. Please make \"' + String(prop) + '\" lazy. Visit https://langium.org/docs/reference/configuration-services/#resolving-cyclic-dependencies');\r\n        }\r\n        return obj[prop];\r\n    } else if (prop in module) {\r\n        const value: Module<I, T[keyof T]> | ((injector: I) => T[keyof T]) = module[prop as keyof T];\r\n        obj[prop] = __requested__;\r\n        try {\r\n            obj[prop] = (typeof value === 'function') ? value(injector) : _inject(value, injector);\r\n        } catch (error) {\r\n            obj[prop] = error instanceof Error ? error : undefined;\r\n            throw error;\r\n        }\r\n        return obj[prop];\r\n    } else {\r\n        return undefined;\r\n    }\r\n}\r\n\r\n/**\r\n * Performs a deep-merge of two modules by writing source entries into the target module.\r\n *\r\n * @param target the module which is written\r\n * @param source the module which is read\r\n * @returns the target module\r\n */\r\nfunction _merge(target: Module<any>, source?: Module<any>): Module<unknown> {\r\n    if (source) {\r\n        for (const [key, value2] of Object.entries(source)) {\r\n            if (value2 !== undefined) {\r\n                const value1 = target[key];\r\n                if (value1 !== null && value2 !== null && typeof value1 === 'object' && typeof value2 === 'object') {\r\n                    target[key] = _merge(value1, value2);\r\n                } else {\r\n                    target[key] = value2;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return target;\r\n}\r\n","export function PRINT_ERROR(msg: string) {\n  /* istanbul ignore else - can't override global.console in node.js */\n  if (console && console.error) {\n    console.error(`Error: ${msg}`);\n  }\n}\n\nexport function PRINT_WARNING(msg: string) {\n  /* istanbul ignore else - can't override global.console in node.js*/\n  if (console && console.warn) {\n    // TODO: modify docs accordingly\n    console.warn(`Warning: ${msg}`);\n  }\n}\n","import { IParserConfig } from \"@chevrotain/types\";\nimport { has } from \"lodash-es\";\nimport { timer } from \"@chevrotain/utils\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\n/**\n * Trait responsible for runtime parsing errors.\n */\nexport class PerformanceTracer {\n  traceInitPerf: boolean | number;\n  traceInitMaxIdent: number;\n  traceInitIndent: number;\n\n  initPerformanceTracer(config: IParserConfig) {\n    if (has(config, \"traceInitPerf\")) {\n      const userTraceInitPerf = config.traceInitPerf;\n      const traceIsNumber = typeof userTraceInitPerf === \"number\";\n      this.traceInitMaxIdent = traceIsNumber\n        ? <number>userTraceInitPerf\n        : Infinity;\n      this.traceInitPerf = traceIsNumber\n        ? userTraceInitPerf > 0\n        : (userTraceInitPerf as boolean); // assumes end user provides the correct config value/type\n    } else {\n      this.traceInitMaxIdent = 0;\n      this.traceInitPerf = DEFAULT_PARSER_CONFIG.traceInitPerf;\n    }\n\n    this.traceInitIndent = -1;\n  }\n\n  TRACE_INIT<T>(this: MixedInParser, phaseDesc: string, phaseImpl: () => T): T {\n    // No need to optimize this using NOOP pattern because\n    // It is not called in a hot spot...\n    if (this.traceInitPerf === true) {\n      this.traceInitIndent++;\n      const indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        console.log(`${indent}--> <${phaseDesc}>`);\n      }\n      const { time, value } = timer(phaseImpl);\n      /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n      const traceMethod = time > 10 ? console.warn : console.log;\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n      }\n      this.traceInitIndent--;\n      return value;\n    } else {\n      return phaseImpl();\n    }\n  }\n}\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { ServiceRegistry } from '../service-registry.js';\r\nimport type { LangiumSharedCoreServices } from '../services.js';\r\nimport type { AstNode, AstNodeDescription, AstReflection } from '../syntax-tree.js';\r\nimport { getDocument } from '../utils/ast-utils.js';\r\nimport { ContextCache } from '../utils/caching.js';\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport type { Stream } from '../utils/stream.js';\r\nimport { stream } from '../utils/stream.js';\r\nimport type { URI } from '../utils/uri-utils.js';\r\nimport { UriUtils } from '../utils/uri-utils.js';\r\nimport type { ReferenceDescription } from './ast-descriptions.js';\r\nimport type { LangiumDocument, LangiumDocuments } from './documents.js';\r\n\r\n/**\r\n * The index manager is responsible for keeping metadata about symbols and cross-references\r\n * in the workspace. It is used to look up symbols in the global scope, mostly during linking\r\n * and completion. This service is shared between all languages of a language server.\r\n */\r\nexport interface IndexManager {\r\n\r\n    /**\r\n     * Removes the specified document URI from the index.\r\n     * Necessary when documents are deleted and not referenceable anymore.\r\n     *\r\n     * @param uri The URI of the document for which index data shall be removed\r\n     */\r\n    remove(uri: URI): void;\r\n\r\n    /**\r\n     * Updates the information about the exportable content of a document inside the index.\r\n     *\r\n     * @param document Document to be updated\r\n     * @param cancelToken Indicates when to cancel the current operation.\r\n     * @throws `OperationCanceled` if a user action occurs during execution\r\n     */\r\n    updateContent(document: LangiumDocument, cancelToken?: CancellationToken): Promise<void>;\r\n\r\n    /**\r\n     * Updates the information about the cross-references of a document inside the index.\r\n     *\r\n     * @param document Document to be updated\r\n     * @param cancelToken Indicates when to cancel the current operation.\r\n     * @throws `OperationCanceled` if a user action occurs during execution\r\n     */\r\n    updateReferences(document: LangiumDocument, cancelToken?: CancellationToken): Promise<void>;\r\n\r\n    /**\r\n     * Determine whether the given document could be affected by changes of the documents\r\n     * identified by the given URIs (second parameter). The document is typically regarded as\r\n     * affected if it contains a reference to any of the changed files.\r\n     *\r\n     * @param document Document to check whether it's affected\r\n     * @param changedUris URIs of the changed documents\r\n     */\r\n    isAffected(document: LangiumDocument, changedUris: Set<string>): boolean;\r\n\r\n    /**\r\n     * Compute a list of all exported elements, optionally filtered using a type identifier and document URIs.\r\n     *\r\n     * @param nodeType The type to filter with, or `undefined` to return descriptions of all types.\r\n     * @param uris If specified, only returns elements from the given URIs.\r\n     * @returns a `Stream` containing all globally visible nodes (of a given type).\r\n     */\r\n    allElements(nodeType?: string, uris?: Set<string>): Stream<AstNodeDescription>;\r\n\r\n    /**\r\n     * Returns all known references that are pointing to the given `targetNode`.\r\n     *\r\n     * @param targetNode the `AstNode` to look up references for\r\n     * @param astNodePath the path that points to the `targetNode` inside the document. See also `AstNodeLocator`\r\n     *\r\n     * @returns a `Stream` of references that are targeting the `targetNode`\r\n     */\r\n    findAllReferences(targetNode: AstNode, astNodePath: string): Stream<ReferenceDescription>;\r\n\r\n}\r\n\r\nexport class DefaultIndexManager implements IndexManager {\r\n\r\n    protected readonly serviceRegistry: ServiceRegistry;\r\n    protected readonly documents: LangiumDocuments;\r\n    protected readonly astReflection: AstReflection;\r\n\r\n    /**\r\n     * The symbol index stores all `AstNodeDescription` items exported by a document.\r\n     * The key used in this map is the string representation of the specific document URI.\r\n     */\r\n    protected readonly symbolIndex = new Map<string, AstNodeDescription[]>();\r\n    /**\r\n     * This is a cache for the `allElements()` method.\r\n     * It caches the descriptions from `symbolIndex` grouped by types.\r\n     */\r\n    protected readonly symbolByTypeIndex = new ContextCache<string, string, AstNodeDescription[]>();\r\n    /**\r\n     * This index keeps track of all `ReferenceDescription` items exported by a document.\r\n     * This is used to compute which elements are affected by a document change\r\n     * and for finding references to an AST node.\r\n     */\r\n    protected readonly referenceIndex = new Map<string, ReferenceDescription[]>();\r\n\r\n    constructor(services: LangiumSharedCoreServices) {\r\n        this.documents = services.workspace.LangiumDocuments;\r\n        this.serviceRegistry = services.ServiceRegistry;\r\n        this.astReflection = services.AstReflection;\r\n    }\r\n\r\n    findAllReferences(targetNode: AstNode, astNodePath: string): Stream<ReferenceDescription> {\r\n        const targetDocUri = getDocument(targetNode).uri;\r\n        const result: ReferenceDescription[] = [];\r\n        this.referenceIndex.forEach(docRefs => {\r\n            docRefs.forEach(refDescr => {\r\n                if (UriUtils.equals(refDescr.targetUri, targetDocUri) && refDescr.targetPath === astNodePath) {\r\n                    result.push(refDescr);\r\n                }\r\n            });\r\n        });\r\n        return stream(result);\r\n    }\r\n\r\n    allElements(nodeType?: string, uris?: Set<string>): Stream<AstNodeDescription> {\r\n        let documentUris = stream(this.symbolIndex.keys());\r\n        if (uris) {\r\n            documentUris = documentUris.filter(uri => !uris || uris.has(uri));\r\n        }\r\n        return documentUris\r\n            .map(uri => this.getFileDescriptions(uri, nodeType))\r\n            .flat();\r\n    }\r\n\r\n    protected getFileDescriptions(uri: string, nodeType?: string): AstNodeDescription[] {\r\n        if (!nodeType) {\r\n            return this.symbolIndex.get(uri) ?? [];\r\n        }\r\n        const descriptions = this.symbolByTypeIndex.get(uri, nodeType, () => {\r\n            const allFileDescriptions = this.symbolIndex.get(uri) ?? [];\r\n            return allFileDescriptions.filter(e => this.astReflection.isSubtype(e.type, nodeType));\r\n        });\r\n        return descriptions;\r\n    }\r\n\r\n    remove(uri: URI): void {\r\n        const uriString = uri.toString();\r\n        this.symbolIndex.delete(uriString);\r\n        this.symbolByTypeIndex.clear(uriString);\r\n        this.referenceIndex.delete(uriString);\r\n    }\r\n\r\n    async updateContent(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<void> {\r\n        const services = this.serviceRegistry.getServices(document.uri);\r\n        const exports = await services.references.ScopeComputation.computeExports(document, cancelToken);\r\n        const uri = document.uri.toString();\r\n        this.symbolIndex.set(uri, exports);\r\n        this.symbolByTypeIndex.clear(uri);\r\n    }\r\n\r\n    async updateReferences(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<void> {\r\n        const services = this.serviceRegistry.getServices(document.uri);\r\n        const indexData = await services.workspace.ReferenceDescriptionProvider.createDescriptions(document, cancelToken);\r\n        this.referenceIndex.set(document.uri.toString(), indexData);\r\n    }\r\n\r\n    isAffected(document: LangiumDocument, changedUris: Set<string>): boolean {\r\n        const references = this.referenceIndex.get(document.uri.toString());\r\n        if (!references) {\r\n            return false;\r\n        }\r\n        return references.some(ref => !ref.local && changedUris.has(ref.targetUri.toString()));\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { IOrAlt, TokenType, TokenTypeDictionary } from 'chevrotain';\r\nimport type { AbstractElement, Action, Alternatives, Condition, CrossReference, Grammar, Group, Keyword, NamedArgument, ParserRule, RuleCall, UnorderedGroup } from '../languages/generated/ast.js';\r\nimport type { BaseParser } from './langium-parser.js';\r\nimport type { AstNode } from '../syntax-tree.js';\r\nimport type { Cardinality } from '../utils/grammar-utils.js';\r\nimport { EMPTY_ALT, EOF } from 'chevrotain';\r\nimport { isAction, isAlternatives, isEndOfFile, isAssignment, isConjunction, isCrossReference, isDisjunction, isGroup, isKeyword, isNegation, isParameterReference, isParserRule, isRuleCall, isTerminalRule, isUnorderedGroup, isBooleanLiteral } from '../languages/generated/ast.js';\r\nimport { assertUnreachable, ErrorWithLocation } from '../utils/errors.js';\r\nimport { stream } from '../utils/stream.js';\r\nimport { findNameAssignment, getAllReachableRules, getTypeName } from '../utils/grammar-utils.js';\r\n\r\ntype RuleContext = {\r\n    optional: number,\r\n    consume: number,\r\n    subrule: number,\r\n    many: number,\r\n    or: number\r\n} & ParserContext;\r\n\r\ntype ParserContext = {\r\n    parser: BaseParser\r\n    tokens: TokenTypeDictionary\r\n    ruleNames: Map<AstNode, string>\r\n}\r\n\r\ntype Rule = (args: Args) => unknown;\r\n\r\ntype Args = Record<string, boolean>;\r\n\r\ntype Predicate = (args: Args) => boolean;\r\n\r\ntype Method = (args: Args) => void;\r\n\r\nexport function createParser<T extends BaseParser>(grammar: Grammar, parser: T, tokens: TokenTypeDictionary): T {\r\n    const parserContext: ParserContext = {\r\n        parser,\r\n        tokens,\r\n        ruleNames: new Map()\r\n    };\r\n    buildRules(parserContext, grammar);\r\n    return parser;\r\n}\r\n\r\nfunction buildRules(parserContext: ParserContext, grammar: Grammar): void {\r\n    const reachable = getAllReachableRules(grammar, false);\r\n    const parserRules = stream(grammar.rules).filter(isParserRule).filter(rule => reachable.has(rule));\r\n    for (const rule of parserRules) {\r\n        const ctx: RuleContext = {\r\n            ...parserContext,\r\n            consume: 1,\r\n            optional: 1,\r\n            subrule: 1,\r\n            many: 1,\r\n            or: 1\r\n        };\r\n        parserContext.parser.rule(rule, buildElement(ctx, rule.definition));\r\n    }\r\n}\r\n\r\nfunction buildElement(ctx: RuleContext, element: AbstractElement, ignoreGuard = false): Method {\r\n    let method: Method;\r\n    if (isKeyword(element)) {\r\n        method = buildKeyword(ctx, element);\r\n    } else if (isAction(element)) {\r\n        method = buildAction(ctx, element);\r\n    } else if (isAssignment(element)) {\r\n        method = buildElement(ctx, element.terminal);\r\n    } else if (isCrossReference(element)) {\r\n        method = buildCrossReference(ctx, element);\r\n    } else if (isRuleCall(element)) {\r\n        method = buildRuleCall(ctx, element);\r\n    } else if (isAlternatives(element)) {\r\n        method = buildAlternatives(ctx, element);\r\n    } else if (isUnorderedGroup(element)) {\r\n        method = buildUnorderedGroup(ctx, element);\r\n    } else if (isGroup(element)) {\r\n        method = buildGroup(ctx, element);\r\n    } else if(isEndOfFile(element)) {\r\n        const idx = ctx.consume++;\r\n        method = () => ctx.parser.consume(idx, EOF, element);\r\n    } else {\r\n        throw new ErrorWithLocation(element.$cstNode, `Unexpected element type: ${element.$type}`);\r\n    }\r\n    return wrap(ctx, ignoreGuard ? undefined : getGuardCondition(element), method, element.cardinality);\r\n}\r\n\r\nfunction buildAction(ctx: RuleContext, action: Action): Method {\r\n    const actionType = getTypeName(action);\r\n    return () => ctx.parser.action(actionType, action);\r\n}\r\n\r\nfunction buildRuleCall(ctx: RuleContext, ruleCall: RuleCall): Method {\r\n    const rule = ruleCall.rule.ref;\r\n    if (isParserRule(rule)) {\r\n        const idx = ctx.subrule++;\r\n        const fragment = rule.fragment;\r\n        const predicate = ruleCall.arguments.length > 0 ? buildRuleCallPredicate(rule, ruleCall.arguments) : () => ({});\r\n        return (args) => ctx.parser.subrule(idx, getRule(ctx, rule), fragment, ruleCall, predicate(args));\r\n    } else if (isTerminalRule(rule)) {\r\n        const idx = ctx.consume++;\r\n        const method = getToken(ctx, rule.name);\r\n        return () => ctx.parser.consume(idx, method, ruleCall);\r\n    } else if (!rule) {\r\n        throw new ErrorWithLocation(ruleCall.$cstNode, `Undefined rule: ${ruleCall.rule.$refText}`);\r\n    } else {\r\n        assertUnreachable(rule);\r\n    }\r\n}\r\n\r\nfunction buildRuleCallPredicate(rule: ParserRule, namedArgs: NamedArgument[]): (args: Args) => Args {\r\n    const predicates = namedArgs.map(e => buildPredicate(e.value));\r\n    return (args) => {\r\n        const ruleArgs: Args = {};\r\n        for (let i = 0; i < predicates.length; i++) {\r\n            const ruleTarget = rule.parameters[i];\r\n            const predicate = predicates[i];\r\n            ruleArgs[ruleTarget.name] = predicate(args);\r\n        }\r\n        return ruleArgs;\r\n    };\r\n}\r\n\r\ninterface PredicatedMethod {\r\n    ALT: Method,\r\n    GATE?: Predicate\r\n}\r\n\r\nfunction buildPredicate(condition: Condition): Predicate {\r\n    if (isDisjunction(condition)) {\r\n        const left = buildPredicate(condition.left);\r\n        const right = buildPredicate(condition.right);\r\n        return (args) => (left(args) || right(args));\r\n    } else if (isConjunction(condition)) {\r\n        const left = buildPredicate(condition.left);\r\n        const right = buildPredicate(condition.right);\r\n        return (args) => (left(args) && right(args));\r\n    } else if (isNegation(condition)) {\r\n        const value = buildPredicate(condition.value);\r\n        return (args) => !value(args);\r\n    } else if (isParameterReference(condition)) {\r\n        const name = condition.parameter.ref!.name;\r\n        return (args) => args !== undefined && args[name] === true;\r\n    } else if (isBooleanLiteral(condition)) {\r\n        const value = Boolean(condition.true);\r\n        return () => value;\r\n    }\r\n    assertUnreachable(condition);\r\n}\r\n\r\nfunction buildAlternatives(ctx: RuleContext, alternatives: Alternatives): Method {\r\n    if (alternatives.elements.length === 1) {\r\n        return buildElement(ctx, alternatives.elements[0]);\r\n    } else {\r\n        const methods: PredicatedMethod[] = [];\r\n\r\n        for (const element of alternatives.elements) {\r\n            const predicatedMethod: PredicatedMethod = {\r\n                // Since we handle the guard condition in the alternative already\r\n                // We can ignore the group guard condition inside\r\n                ALT: buildElement(ctx, element, true)\r\n            };\r\n            const guard = getGuardCondition(element);\r\n            if (guard) {\r\n                predicatedMethod.GATE = buildPredicate(guard);\r\n            }\r\n            methods.push(predicatedMethod);\r\n        }\r\n\r\n        const idx = ctx.or++;\r\n        return (args) => ctx.parser.alternatives(idx, methods.map(method => {\r\n            const alt: IOrAlt<unknown> = {\r\n                ALT: () => method.ALT(args)\r\n            };\r\n            const gate = method.GATE;\r\n            if (gate) {\r\n                alt.GATE = () => gate(args);\r\n            }\r\n            return alt;\r\n        }));\r\n    }\r\n}\r\n\r\nfunction buildUnorderedGroup(ctx: RuleContext, group: UnorderedGroup): Method {\r\n    if (group.elements.length === 1) {\r\n        return buildElement(ctx, group.elements[0]);\r\n    }\r\n    const methods: PredicatedMethod[] = [];\r\n\r\n    for (const element of group.elements) {\r\n        const predicatedMethod: PredicatedMethod = {\r\n            // Since we handle the guard condition in the alternative already\r\n            // We can ignore the group guard condition inside\r\n            ALT: buildElement(ctx, element, true)\r\n        };\r\n        const guard = getGuardCondition(element);\r\n        if (guard) {\r\n            predicatedMethod.GATE = buildPredicate(guard);\r\n        }\r\n        methods.push(predicatedMethod);\r\n    }\r\n\r\n    const orIdx = ctx.or++;\r\n\r\n    const idFunc = (groupIdx: number, lParser: BaseParser) => {\r\n        const stackId = lParser.getRuleStack().join('-');\r\n        return `uGroup_${groupIdx}_${stackId}`;\r\n    };\r\n    const alternatives: Method = (args) => ctx.parser.alternatives(orIdx, methods.map((method, idx) => {\r\n        const alt: IOrAlt<unknown> = { ALT: () => true };\r\n        const parser = ctx.parser;\r\n        alt.ALT = () => {\r\n            method.ALT(args);\r\n            if (!parser.isRecording()) {\r\n                const key = idFunc(orIdx, parser);\r\n                if (!parser.unorderedGroups.get(key)) {\r\n                    // init after clear state\r\n                    parser.unorderedGroups.set(key, []);\r\n                }\r\n                const groupState = parser.unorderedGroups.get(key)!;\r\n                if (typeof groupState?.[idx] === 'undefined') {\r\n                    // Not accessed yet\r\n                    groupState[idx] = true;\r\n                }\r\n            }\r\n        };\r\n        const gate = method.GATE;\r\n        if (gate) {\r\n            alt.GATE = () => gate(args);\r\n        } else {\r\n            alt.GATE = () => {\r\n                const trackedAlternatives = parser.unorderedGroups.get(idFunc(orIdx, parser));\r\n                const allow = !trackedAlternatives?.[idx];\r\n                return allow;\r\n            };\r\n        }\r\n        return alt;\r\n    }));\r\n    const wrapped = wrap(ctx, getGuardCondition(group), alternatives, '*');\r\n    return (args) => {\r\n        wrapped(args);\r\n        if (!ctx.parser.isRecording()) {\r\n            ctx.parser.unorderedGroups.delete(idFunc(orIdx, ctx.parser));\r\n        }\r\n    };\r\n}\r\n\r\nfunction buildGroup(ctx: RuleContext, group: Group): Method {\r\n    const methods = group.elements.map(e => buildElement(ctx, e));\r\n    return (args) => methods.forEach(method => method(args));\r\n}\r\n\r\nfunction getGuardCondition(element: AbstractElement): Condition | undefined {\r\n    if (isGroup(element)) {\r\n        return element.guardCondition;\r\n    }\r\n    return undefined;\r\n}\r\n\r\nfunction buildCrossReference(ctx: RuleContext, crossRef: CrossReference, terminal = crossRef.terminal): Method {\r\n    if (!terminal) {\r\n        if (!crossRef.type.ref) {\r\n            throw new Error('Could not resolve reference to type: ' + crossRef.type.$refText);\r\n        }\r\n        const assignment = findNameAssignment(crossRef.type.ref);\r\n        const assignTerminal = assignment?.terminal;\r\n        if (!assignTerminal) {\r\n            throw new Error('Could not find name assignment for type: ' + getTypeName(crossRef.type.ref));\r\n        }\r\n        return buildCrossReference(ctx, crossRef, assignTerminal);\r\n    } else if (isRuleCall(terminal) && isParserRule(terminal.rule.ref)) {\r\n        // The terminal is a data type rule here. Everything else will result in a validation error.\r\n        const rule = terminal.rule.ref;\r\n        const idx = ctx.subrule++;\r\n        return (args) => ctx.parser.subrule(idx, getRule(ctx, rule), false, crossRef, args);\r\n    } else if (isRuleCall(terminal) && isTerminalRule(terminal.rule.ref)) {\r\n        const idx = ctx.consume++;\r\n        const terminalRule = getToken(ctx, terminal.rule.ref.name);\r\n        return () => ctx.parser.consume(idx, terminalRule, crossRef);\r\n    } else if (isKeyword(terminal)) {\r\n        const idx = ctx.consume++;\r\n        const keyword = getToken(ctx, terminal.value);\r\n        return () => ctx.parser.consume(idx, keyword, crossRef);\r\n    }\r\n    else {\r\n        throw new Error('Could not build cross reference parser');\r\n    }\r\n}\r\n\r\nfunction buildKeyword(ctx: RuleContext, keyword: Keyword): Method {\r\n    const idx = ctx.consume++;\r\n    const token = ctx.tokens[keyword.value];\r\n    if (!token) {\r\n        throw new Error('Could not find token for keyword: ' + keyword.value);\r\n    }\r\n    return () => ctx.parser.consume(idx, token, keyword);\r\n}\r\n\r\nfunction wrap(ctx: RuleContext, guard: Condition | undefined, method: Method, cardinality: Cardinality): Method {\r\n    const gate = guard && buildPredicate(guard);\r\n\r\n    if (!cardinality) {\r\n        if (gate) {\r\n            const idx = ctx.or++;\r\n            return (args) => ctx.parser.alternatives(idx, [\r\n                {\r\n                    ALT: () => method(args),\r\n                    GATE: () => gate(args)\r\n                },\r\n                {\r\n                    ALT: EMPTY_ALT(),\r\n                    GATE: () => !gate(args)\r\n                }\r\n            ]);\r\n        } else {\r\n            return method;\r\n        }\r\n    }\r\n\r\n    if (cardinality === '*') {\r\n        const idx = ctx.many++;\r\n        return (args) => ctx.parser.many(idx, {\r\n            DEF: () => method(args),\r\n            GATE: gate ? () => gate(args) : undefined\r\n        });\r\n    } else if (cardinality === '+') {\r\n        const idx = ctx.many++;\r\n        if (gate) {\r\n            const orIdx = ctx.or++;\r\n            // In the case of a guard condition for the `+` group\r\n            // We combine it with an empty alternative\r\n            // If the condition returns true, it needs to parse at least a single iteration\r\n            // If its false, it is not allowed to parse anything\r\n            return (args) => ctx.parser.alternatives(orIdx, [\r\n                {\r\n                    ALT: () => ctx.parser.atLeastOne(idx, {\r\n                        DEF: () => method(args)\r\n                    }),\r\n                    GATE: () => gate(args)\r\n                },\r\n                {\r\n                    ALT: EMPTY_ALT(),\r\n                    GATE: () => !gate(args)\r\n                }\r\n            ]);\r\n        } else {\r\n            return (args) => ctx.parser.atLeastOne(idx, {\r\n                DEF: () => method(args),\r\n            });\r\n        }\r\n    } else if (cardinality === '?') {\r\n        const idx = ctx.optional++;\r\n        return (args) => ctx.parser.optional(idx, {\r\n            DEF: () => method(args),\r\n            GATE: gate ? () => gate(args) : undefined\r\n        });\r\n    } else {\r\n        assertUnreachable(cardinality);\r\n    }\r\n}\r\n\r\nfunction getRule(ctx: ParserContext, element: ParserRule | AbstractElement): Rule {\r\n    const name = getRuleName(ctx, element);\r\n    const rule = ctx.parser.getRule(name);\r\n    if (!rule) throw new Error(`Rule \"${name}\" not found.\"`);\r\n    return rule;\r\n}\r\n\r\nfunction getRuleName(ctx: ParserContext, element: ParserRule | AbstractElement): string {\r\n    if (isParserRule(element)) {\r\n        return element.name;\r\n    } else if (ctx.ruleNames.has(element)) {\r\n        return ctx.ruleNames.get(element)!;\r\n    } else {\r\n        let item: AstNode = element;\r\n        let parent: AstNode = item.$container!;\r\n        let ruleName: string = element.$type;\r\n        while (!isParserRule(parent)) {\r\n            if (isGroup(parent) || isAlternatives(parent) || isUnorderedGroup(parent)) {\r\n                const index = parent.elements.indexOf(item as AbstractElement);\r\n                ruleName = index.toString() + ':' + ruleName;\r\n            }\r\n            item = parent;\r\n            parent = parent.$container!;\r\n        }\r\n        const rule = parent as ParserRule;\r\n        ruleName = rule.name + ':' + ruleName;\r\n        ctx.ruleNames.set(element, ruleName);\r\n        return ruleName;\r\n    }\r\n}\r\n\r\nfunction getToken(ctx: ParserContext, name: string): TokenType {\r\n    const token = ctx.tokens[name];\r\n    if (!token) throw new Error(`Token \"${name}\" not found.\"`);\r\n    return token;\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport { Disposable } from '../utils/disposable.js';\r\nimport type { ServiceRegistry } from '../service-registry.js';\r\nimport type { LangiumSharedCoreServices } from '../services.js';\r\nimport type { AstNode } from '../syntax-tree.js';\r\nimport type { MaybePromise } from '../utils/promise-utils.js';\r\nimport type { Deferred } from '../utils/promise-utils.js';\r\nimport type { ValidationOptions } from '../validation/document-validator.js';\r\nimport type { IndexManager } from '../workspace/index-manager.js';\r\nimport type { LangiumDocument, LangiumDocuments, LangiumDocumentFactory, TextDocumentProvider } from './documents.js';\r\nimport { MultiMap } from '../utils/collections.js';\r\nimport { OperationCancelled, interruptAndCheck, isOperationCancelled } from '../utils/promise-utils.js';\r\nimport { stream } from '../utils/stream.js';\r\nimport type { URI } from '../utils/uri-utils.js';\r\nimport { ValidationCategory } from '../validation/validation-registry.js';\r\nimport { DocumentState } from './documents.js';\r\n\r\nexport interface BuildOptions {\r\n    /**\r\n     * Control the validation phase with this option:\r\n     *  - `true` enables all validation checks and forces revalidating the documents\r\n     *  - `false` or `undefined` disables all validation checks\r\n     *  - An object runs only the necessary validation checks; the `categories` property restricts this to a specific subset\r\n     */\r\n    validation?: boolean | ValidationOptions\r\n}\r\n\r\nexport interface DocumentBuildState {\r\n    /** Whether a document has completed its last build process. */\r\n    completed: boolean\r\n    /** The options used for the last build process. */\r\n    options: BuildOptions\r\n    /** Additional information about the last build result. */\r\n    result?: {\r\n        validationChecks?: ValidationCategory[]\r\n    }\r\n}\r\n\r\n/**\r\n * Shared-service for building and updating `LangiumDocument`s.\r\n */\r\nexport interface DocumentBuilder {\r\n\r\n    /** The options used for rebuilding documents after an update. */\r\n    updateBuildOptions: BuildOptions;\r\n\r\n    /**\r\n     * Execute all necessary build steps for the given documents.\r\n     *\r\n     * @param documents Set of documents to be built.\r\n     * @param options Options for the document builder.\r\n     * @param cancelToken Indicates when to cancel the current operation.\r\n     * @throws `OperationCanceled` if a user action occurs during execution\r\n     */\r\n    build<T extends AstNode>(documents: Array<LangiumDocument<T>>, options?: BuildOptions, cancelToken?: CancellationToken): Promise<void>;\r\n\r\n    /**\r\n     * This method is called when a document change is detected. It updates the state of all\r\n     * affected documents, including those with references to the changed ones, so they are rebuilt.\r\n     *\r\n     * @param changed URIs of changed or created documents\r\n     * @param deleted URIs of deleted documents\r\n     * @param cancelToken allows to cancel the current operation\r\n     * @throws `OperationCancelled` if cancellation is detected during execution\r\n     */\r\n    update(changed: URI[], deleted: URI[], cancelToken?: CancellationToken): Promise<void>;\r\n\r\n    /**\r\n     * Notify the given callback when a document update was triggered, but before any document\r\n     * is rebuilt. Listeners to this event should not perform any long-running task.\r\n     */\r\n    onUpdate(callback: DocumentUpdateListener): Disposable;\r\n\r\n    /**\r\n     * Notify the given callback when a set of documents has been built reaching the specified target state.\r\n     */\r\n    onBuildPhase(targetState: DocumentState, callback: DocumentBuildListener): Disposable;\r\n\r\n    /**\r\n     * Notify the specified callback when a document has been built reaching the specified target state.\r\n     * Unlike {@link onBuildPhase} the listener is called for every single document.\r\n     *\r\n     * There are two main advantages compared to {@link onBuildPhase}:\r\n     * 1. If the build is cancelled, {@link onDocumentPhase} will still fire for documents that have reached a specific state.\r\n     *    Meanwhile, {@link onBuildPhase} won't fire for that state.\r\n     * 2. The {@link DocumentBuilder} ensures that all {@link DocumentPhaseListener} instances are called for a built document.\r\n     *    Even if the build is cancelled before those listeners were called.\r\n     */\r\n    onDocumentPhase(targetState: DocumentState, callback: DocumentPhaseListener): Disposable;\r\n\r\n    /**\r\n     * Wait until the workspace has reached the specified state for all documents.\r\n     *\r\n     * @param state The desired state. The promise won't resolve until all documents have reached this state\r\n     * @param cancelToken Optionally allows to cancel the wait operation, disposing any listeners in the process\r\n     * @throws `OperationCancelled` if cancellation has been requested before the state has been reached\r\n     */\r\n    waitUntil(state: DocumentState, cancelToken?: CancellationToken): Promise<void>;\r\n\r\n    /**\r\n     * Wait until the document specified by the {@link uri} has reached the specified state.\r\n     *\r\n     * @param state The desired state. The promise won't resolve until the document has reached this state.\r\n     * @param uri The specified URI that points to the document. If the URI does not exist, the promise will resolve once the workspace has reached the specified state.\r\n     * @param cancelToken Optionally allows to cancel the wait operation, disposing any listeners in the process.\r\n     * @return The URI of the document that has reached the desired state, or `undefined` if the document does not exist.\r\n     * @throws `OperationCancelled` if cancellation has been requested before the state has been reached\r\n     */\r\n    waitUntil(state: DocumentState, uri?: URI, cancelToken?: CancellationToken): Promise<URI | undefined>;\r\n}\r\n\r\nexport type DocumentUpdateListener = (changed: URI[], deleted: URI[]) => void | Promise<void>\r\nexport type DocumentBuildListener = (built: LangiumDocument[], cancelToken: CancellationToken) => void | Promise<void>\r\nexport type DocumentPhaseListener = (built: LangiumDocument, cancelToken: CancellationToken) => void | Promise<void>\r\nexport class DefaultDocumentBuilder implements DocumentBuilder {\r\n\r\n    updateBuildOptions: BuildOptions = {\r\n        // Default: run only the built-in validation checks and those in the _fast_ category (includes those without category)\r\n        validation: {\r\n            categories: ['built-in', 'fast']\r\n        }\r\n    };\r\n\r\n    protected readonly langiumDocuments: LangiumDocuments;\r\n    protected readonly langiumDocumentFactory: LangiumDocumentFactory;\r\n    protected readonly textDocuments: TextDocumentProvider | undefined;\r\n    protected readonly indexManager: IndexManager;\r\n    protected readonly serviceRegistry: ServiceRegistry;\r\n    protected readonly updateListeners: DocumentUpdateListener[] = [];\r\n    protected readonly buildPhaseListeners = new MultiMap<DocumentState, DocumentBuildListener>();\r\n    protected readonly documentPhaseListeners = new MultiMap<DocumentState, DocumentPhaseListener>();\r\n    protected readonly buildState = new Map<string, DocumentBuildState>();\r\n    protected readonly documentBuildWaiters = new Map<string, Deferred<void>>();\r\n    protected currentState = DocumentState.Changed;\r\n\r\n    constructor(services: LangiumSharedCoreServices) {\r\n        this.langiumDocuments = services.workspace.LangiumDocuments;\r\n        this.langiumDocumentFactory = services.workspace.LangiumDocumentFactory;\r\n        this.textDocuments = services.workspace.TextDocuments;\r\n        this.indexManager = services.workspace.IndexManager;\r\n        this.serviceRegistry = services.ServiceRegistry;\r\n    }\r\n\r\n    async build<T extends AstNode>(documents: Array<LangiumDocument<T>>, options: BuildOptions = {}, cancelToken = CancellationToken.None): Promise<void> {\r\n        for (const document of documents) {\r\n            const key = document.uri.toString();\r\n            if (document.state === DocumentState.Validated) {\r\n                if (typeof options.validation === 'boolean' && options.validation) {\r\n                    // Force re-running all validation checks\r\n                    document.state = DocumentState.IndexedReferences;\r\n                    document.diagnostics = undefined;\r\n                    this.buildState.delete(key);\r\n                } else if (typeof options.validation === 'object') {\r\n                    const buildState = this.buildState.get(key);\r\n                    const previousCategories = buildState?.result?.validationChecks;\r\n                    if (previousCategories) {\r\n                        // Validation with explicit options was requested for a document that has already been partly validated.\r\n                        // In this case, we need to merge the previous validation categories with the new ones.\r\n                        const newCategories = options.validation.categories ?? ValidationCategory.all as ValidationCategory[];\r\n                        const categories = newCategories.filter(c => !previousCategories.includes(c));\r\n                        if (categories.length > 0) {\r\n                            this.buildState.set(key, {\r\n                                completed: false,\r\n                                options: {\r\n                                    validation: {\r\n                                        ...options.validation,\r\n                                        categories\r\n                                    }\r\n                                },\r\n                                result: buildState.result\r\n                            });\r\n                            document.state = DocumentState.IndexedReferences;\r\n                        }\r\n                    }\r\n                }\r\n            } else {\r\n                // Default: forget any previous build options\r\n                this.buildState.delete(key);\r\n            }\r\n        }\r\n        this.currentState = DocumentState.Changed;\r\n        await this.emitUpdate(documents.map(e => e.uri), []);\r\n        await this.buildDocuments(documents, options, cancelToken);\r\n    }\r\n\r\n    async update(changed: URI[], deleted: URI[], cancelToken = CancellationToken.None): Promise<void> {\r\n        this.currentState = DocumentState.Changed;\r\n        // Remove all metadata of documents that are reported as deleted\r\n        for (const deletedUri of deleted) {\r\n            this.langiumDocuments.deleteDocument(deletedUri);\r\n            this.buildState.delete(deletedUri.toString());\r\n            this.indexManager.remove(deletedUri);\r\n        }\r\n        // Set the state of all changed documents to `Changed` so they are completely rebuilt\r\n        for (const changedUri of changed) {\r\n            const invalidated = this.langiumDocuments.invalidateDocument(changedUri);\r\n            if (!invalidated) {\r\n                // We create an unparsed, invalid document.\r\n                // This will be parsed as soon as we reach the first document builder phase.\r\n                // This allows to cancel the parsing process later in case we need it.\r\n                const newDocument = this.langiumDocumentFactory.fromModel({ $type: 'INVALID' }, changedUri);\r\n                newDocument.state = DocumentState.Changed;\r\n                this.langiumDocuments.addDocument(newDocument);\r\n            }\r\n            this.buildState.delete(changedUri.toString());\r\n        }\r\n        // Set the state of all documents that should be relinked to `ComputedScopes` (if not already lower)\r\n        const allChangedUris = stream(changed).concat(deleted).map(uri => uri.toString()).toSet();\r\n        this.langiumDocuments.all\r\n            .filter(doc => !allChangedUris.has(doc.uri.toString()) && this.shouldRelink(doc, allChangedUris))\r\n            .forEach(doc => {\r\n                const linker = this.serviceRegistry.getServices(doc.uri).references.Linker;\r\n                linker.unlink(doc);\r\n                doc.state = Math.min(doc.state, DocumentState.ComputedScopes);\r\n                doc.diagnostics = undefined;\r\n            });\r\n        // Notify listeners of the update\r\n        await this.emitUpdate(changed, deleted);\r\n        // Only allow interrupting the execution after all state changes are done\r\n        await interruptAndCheck(cancelToken);\r\n\r\n        // Collect and sort all documents that we should rebuild\r\n        const rebuildDocuments = this.sortDocuments(\r\n            this.langiumDocuments.all\r\n                .filter(doc =>\r\n                    // This includes those that were reported as changed and those that we selected for relinking\r\n                    doc.state < DocumentState.Linked\r\n                    // This includes those for which a previous build has been cancelled\r\n                    || !this.buildState.get(doc.uri.toString())?.completed\r\n                )\r\n                .toArray()\r\n        );\r\n        await this.buildDocuments(rebuildDocuments, this.updateBuildOptions, cancelToken);\r\n    }\r\n\r\n    protected async emitUpdate(changed: URI[], deleted: URI[]): Promise<void> {\r\n        await Promise.all(this.updateListeners.map(listener => listener(changed, deleted)));\r\n    }\r\n\r\n    /**\r\n     * Sort the given documents by priority. By default, documents with an open text document are prioritized.\r\n     * This is useful to ensure that visible documents show their diagnostics before all other documents.\r\n     *\r\n     * This improves the responsiveness in large workspaces as users usually don't care about diagnostics\r\n     * in files that are currently not opened in the editor.\r\n     */\r\n    protected sortDocuments(documents: LangiumDocument[]): LangiumDocument[] {\r\n        let left = 0;\r\n        let right = documents.length - 1;\r\n\r\n        while (left < right) {\r\n            while (left < documents.length && this.hasTextDocument(documents[left])) {\r\n                left++;\r\n            }\r\n\r\n            while (right >= 0 && !this.hasTextDocument(documents[right])) {\r\n                right--;\r\n            }\r\n\r\n            if (left < right) {\r\n                [documents[left], documents[right]] = [documents[right], documents[left]];\r\n            }\r\n        }\r\n\r\n        return documents;\r\n    }\r\n\r\n    private hasTextDocument(doc: LangiumDocument): boolean {\r\n        return Boolean(this.textDocuments?.get(doc.uri));\r\n    }\r\n\r\n    /**\r\n     * Check whether the given document should be relinked after changes were found in the given URIs.\r\n     */\r\n    protected shouldRelink(document: LangiumDocument, changedUris: Set<string>): boolean {\r\n        // Relink documents with linking errors -- maybe those references can be resolved now\r\n        if (document.references.some(ref => ref.error !== undefined)) {\r\n            return true;\r\n        }\r\n        // Check whether the document is affected by any of the changed URIs\r\n        return this.indexManager.isAffected(document, changedUris);\r\n    }\r\n\r\n    onUpdate(callback: DocumentUpdateListener): Disposable {\r\n        this.updateListeners.push(callback);\r\n        return Disposable.create(() => {\r\n            const index = this.updateListeners.indexOf(callback);\r\n            if (index >= 0) {\r\n                this.updateListeners.splice(index, 1);\r\n            }\r\n        });\r\n    }\r\n\r\n    /**\r\n     * Build the given documents by stepping through all build phases. If a document's state indicates\r\n     * that a certain build phase is already done, the phase is skipped for that document.\r\n     *\r\n     * @param documents The documents to build.\r\n     * @param options the {@link BuildOptions} to use.\r\n     * @param cancelToken A cancellation token that can be used to cancel the build.\r\n     * @returns A promise that resolves when the build is done.\r\n     */\r\n    protected async buildDocuments(documents: LangiumDocument[], options: BuildOptions, cancelToken: CancellationToken): Promise<void> {\r\n        this.prepareBuild(documents, options);\r\n        // 0. Parse content\r\n        await this.runCancelable(documents, DocumentState.Parsed, cancelToken, doc =>\r\n            this.langiumDocumentFactory.update(doc, cancelToken)\r\n        );\r\n        // 1. Index content\r\n        await this.runCancelable(documents, DocumentState.IndexedContent, cancelToken, doc =>\r\n            this.indexManager.updateContent(doc, cancelToken)\r\n        );\r\n        // 2. Compute scopes\r\n        await this.runCancelable(documents, DocumentState.ComputedScopes, cancelToken, async doc => {\r\n            const scopeComputation = this.serviceRegistry.getServices(doc.uri).references.ScopeComputation;\r\n            doc.precomputedScopes = await scopeComputation.computeLocalScopes(doc, cancelToken);\r\n        });\r\n        // 3. Linking\r\n        await this.runCancelable(documents, DocumentState.Linked, cancelToken, doc => {\r\n            const linker = this.serviceRegistry.getServices(doc.uri).references.Linker;\r\n            return linker.link(doc, cancelToken);\r\n        });\r\n        // 4. Index references\r\n        await this.runCancelable(documents, DocumentState.IndexedReferences, cancelToken, doc =>\r\n            this.indexManager.updateReferences(doc, cancelToken)\r\n        );\r\n        // 5. Validation\r\n        const toBeValidated = documents.filter(doc => this.shouldValidate(doc));\r\n        await this.runCancelable(toBeValidated, DocumentState.Validated, cancelToken, doc =>\r\n            this.validate(doc, cancelToken)\r\n        );\r\n\r\n        // If we've made it to this point without being cancelled, we can mark the build state as completed.\r\n        for (const doc of documents) {\r\n            const state = this.buildState.get(doc.uri.toString());\r\n            if (state) {\r\n                state.completed = true;\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Runs prior to beginning the build process to update the {@link DocumentBuildState} for each document\r\n     *\r\n     * @param documents collection of documents to be built\r\n     * @param options the {@link BuildOptions} to use\r\n     */\r\n    protected prepareBuild(documents: LangiumDocument[], options: BuildOptions): void {\r\n        for (const doc of documents) {\r\n            const key = doc.uri.toString();\r\n            const state = this.buildState.get(key);\r\n            // If the document has no previous build state, we set it. If it has one, but it's already marked\r\n            // as completed, we overwrite it. If the previous build was not completed, we keep its state\r\n            // and continue where it was cancelled.\r\n            if (!state || state.completed) {\r\n                this.buildState.set(key, {\r\n                    completed: false,\r\n                    options,\r\n                    result: state?.result\r\n                });\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Runs a cancelable operation on a set of documents to bring them to a specified {@link DocumentState}.\r\n     *\r\n     * @param documents The array of documents to process.\r\n     * @param targetState The target {@link DocumentState} to bring the documents to.\r\n     * @param cancelToken A token that can be used to cancel the operation.\r\n     * @param callback A function to be called for each document.\r\n     * @returns A promise that resolves when all documents have been processed or the operation is canceled.\r\n     * @throws Will throw `OperationCancelled` if the operation is canceled via a `CancellationToken`.\r\n     */\r\n    protected async runCancelable(documents: LangiumDocument[], targetState: DocumentState, cancelToken: CancellationToken,\r\n        callback: (document: LangiumDocument) => MaybePromise<unknown>): Promise<void> {\r\n        const filtered = documents.filter(doc => doc.state < targetState);\r\n        for (const document of filtered) {\r\n            await interruptAndCheck(cancelToken);\r\n            await callback(document);\r\n            document.state = targetState;\r\n            await this.notifyDocumentPhase(document, targetState, cancelToken);\r\n        }\r\n\r\n        // Do not use `filtered` here, as that will miss documents that have previously reached the current target state\r\n        // For example, this happens in case the cancellation triggers between the processing of two documents\r\n        // Or files that were picked up during the workspace initialization\r\n        const targetStateDocs = documents.filter(doc => doc.state === targetState);\r\n        await this.notifyBuildPhase(targetStateDocs, targetState, cancelToken);\r\n        this.currentState = targetState;\r\n    }\r\n\r\n    onBuildPhase(targetState: DocumentState, callback: DocumentBuildListener): Disposable {\r\n        this.buildPhaseListeners.add(targetState, callback);\r\n        return Disposable.create(() => {\r\n            this.buildPhaseListeners.delete(targetState, callback);\r\n        });\r\n    }\r\n\r\n    onDocumentPhase(targetState: DocumentState, callback: DocumentPhaseListener): Disposable {\r\n        this.documentPhaseListeners.add(targetState, callback);\r\n        return Disposable.create(() => {\r\n            this.documentPhaseListeners.delete(targetState, callback);\r\n        });\r\n    }\r\n\r\n    waitUntil(state: DocumentState, cancelToken?: CancellationToken): Promise<void>;\r\n    waitUntil(state: DocumentState, uri?: URI, cancelToken?: CancellationToken): Promise<URI | undefined>;\r\n    waitUntil(state: DocumentState, uriOrToken?: URI | CancellationToken, cancelToken?: CancellationToken): Promise<URI | undefined | void> {\r\n        let uri: URI | undefined = undefined;\r\n        if (uriOrToken && 'path' in uriOrToken) {\r\n            uri = uriOrToken;\r\n        } else {\r\n            cancelToken = uriOrToken;\r\n        }\r\n        cancelToken ??= CancellationToken.None;\r\n        if (uri) {\r\n            const document = this.langiumDocuments.getDocument(uri);\r\n            if (document && document.state > state) {\r\n                return Promise.resolve(uri);\r\n            }\r\n        }\r\n        if (this.currentState >= state) {\r\n            return Promise.resolve(undefined);\r\n        } else if (cancelToken.isCancellationRequested) {\r\n            return Promise.reject(OperationCancelled);\r\n        }\r\n        return new Promise((resolve, reject) => {\r\n            const buildDisposable = this.onBuildPhase(state, () => {\r\n                buildDisposable.dispose();\r\n                cancelDisposable.dispose();\r\n                if (uri) {\r\n                    const document = this.langiumDocuments.getDocument(uri);\r\n                    resolve(document?.uri);\r\n                } else {\r\n                    resolve(undefined);\r\n                }\r\n            });\r\n            const cancelDisposable = cancelToken!.onCancellationRequested(() => {\r\n                buildDisposable.dispose();\r\n                cancelDisposable.dispose();\r\n                reject(OperationCancelled);\r\n            });\r\n        });\r\n    }\r\n\r\n    protected async notifyDocumentPhase(document: LangiumDocument, state: DocumentState, cancelToken: CancellationToken): Promise<void> {\r\n        const listeners = this.documentPhaseListeners.get(state);\r\n        const listenersCopy = listeners.slice();\r\n        for (const listener of listenersCopy) {\r\n            try {\r\n                await listener(document, cancelToken);\r\n            } catch (err) {\r\n                // Ignore cancellation errors\r\n                // We want to finish the listeners before throwing\r\n                if (!isOperationCancelled(err)) {\r\n                    throw err;\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    protected async notifyBuildPhase(documents: LangiumDocument[], state: DocumentState, cancelToken: CancellationToken): Promise<void> {\r\n        if (documents.length === 0) {\r\n            // Don't notify when no document has been processed\r\n            return;\r\n        }\r\n        const listeners = this.buildPhaseListeners.get(state);\r\n        const listenersCopy = listeners.slice();\r\n        for (const listener of listenersCopy) {\r\n            await interruptAndCheck(cancelToken);\r\n            await listener(documents, cancelToken);\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Determine whether the given document should be validated during a build. The default\r\n     * implementation checks the `validation` property of the build options. If it's set to `true`\r\n     * or a `ValidationOptions` object, the document is included in the validation phase.\r\n     */\r\n    protected shouldValidate(document: LangiumDocument): boolean {\r\n        return Boolean(this.getBuildOptions(document).validation);\r\n    }\r\n\r\n    /**\r\n     * Run validation checks on the given document and store the resulting diagnostics in the document.\r\n     * If the document already contains diagnostics, the new ones are added to the list.\r\n     */\r\n    protected async validate(document: LangiumDocument, cancelToken: CancellationToken): Promise<void> {\r\n        const validator = this.serviceRegistry.getServices(document.uri).validation.DocumentValidator;\r\n        const validationSetting = this.getBuildOptions(document).validation;\r\n        const options = typeof validationSetting === 'object' ? validationSetting : undefined;\r\n        const diagnostics = await validator.validateDocument(document, options, cancelToken);\r\n        if (document.diagnostics) {\r\n            document.diagnostics.push(...diagnostics);\r\n        } else {\r\n            document.diagnostics = diagnostics;\r\n        }\r\n\r\n        // Store information about the executed validation in the build state\r\n        const state = this.buildState.get(document.uri.toString());\r\n        if (state) {\r\n            state.result ??= {};\r\n            const newCategories = options?.categories ?? ValidationCategory.all;\r\n            if (state.result.validationChecks) {\r\n                state.result.validationChecks.push(...newCategories);\r\n            } else {\r\n                state.result.validationChecks = [...newCategories];\r\n            }\r\n        }\r\n    }\r\n\r\n    protected getBuildOptions(document: LangiumDocument): BuildOptions {\r\n        return this.buildState.get(document.uri.toString())?.options ?? {};\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, CstNode, GenericAstNode } from '../syntax-tree.js';\r\nimport type { Stream } from '../utils/stream.js';\r\nimport type { ReferenceDescription } from '../workspace/ast-descriptions.js';\r\nimport type { AstNodeLocator } from '../workspace/ast-node-locator.js';\r\nimport type { IndexManager } from '../workspace/index-manager.js';\r\nimport type { NameProvider } from './name-provider.js';\r\nimport type { URI } from '../utils/uri-utils.js';\r\nimport { findAssignment } from '../utils/grammar-utils.js';\r\nimport { isReference } from '../syntax-tree.js';\r\nimport { getDocument } from '../utils/ast-utils.js';\r\nimport { isChildNode, toDocumentSegment } from '../utils/cst-utils.js';\r\nimport { stream } from '../utils/stream.js';\r\nimport { UriUtils } from '../utils/uri-utils.js';\r\n\r\n/**\r\n * Language-specific service for finding references and declaration of a given `CstNode`.\r\n */\r\nexport interface References {\r\n\r\n    /**\r\n     * If the CstNode is a reference node the target CstNode will be returned.\r\n     * If the CstNode is a significant node of the CstNode this CstNode will be returned.\r\n     *\r\n     * @param sourceCstNode CstNode that points to a AstNode\r\n     */\r\n    findDeclaration(sourceCstNode: CstNode): AstNode | undefined;\r\n\r\n    /**\r\n     * If the CstNode is a reference node the target CstNode will be returned.\r\n     * If the CstNode is a significant node of the CstNode this CstNode will be returned.\r\n     *\r\n     * @param sourceCstNode CstNode that points to a AstNode\r\n     */\r\n    findDeclarationNode(sourceCstNode: CstNode): CstNode | undefined;\r\n\r\n    /**\r\n     * Finds all references to the target node as references (local references) or reference descriptions.\r\n     *\r\n     * @param targetNode Specified target node whose references should be returned\r\n     */\r\n    findReferences(targetNode: AstNode, options: FindReferencesOptions): Stream<ReferenceDescription>;\r\n}\r\n\r\nexport interface FindReferencesOptions {\r\n    /**\r\n     * @deprecated Since v1.2.0. Please use `documentUri` instead.\r\n     */\r\n    onlyLocal?: boolean;\r\n    /**\r\n     * When set, the `findReferences` method will only return references/declarations from the specified document.\r\n     */\r\n    documentUri?: URI;\r\n    /**\r\n     * Whether the returned list of references should include the declaration.\r\n     */\r\n    includeDeclaration?: boolean;\r\n}\r\n\r\nexport class DefaultReferences implements References {\r\n    protected readonly nameProvider: NameProvider;\r\n    protected readonly index: IndexManager;\r\n    protected readonly nodeLocator: AstNodeLocator;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.nameProvider = services.references.NameProvider;\r\n        this.index = services.shared.workspace.IndexManager;\r\n        this.nodeLocator = services.workspace.AstNodeLocator;\r\n    }\r\n\r\n    findDeclaration(sourceCstNode: CstNode): AstNode | undefined {\r\n        if (sourceCstNode) {\r\n            const assignment = findAssignment(sourceCstNode);\r\n            const nodeElem = sourceCstNode.astNode;\r\n            if (assignment && nodeElem) {\r\n                const reference = (nodeElem as GenericAstNode)[assignment.feature];\r\n\r\n                if (isReference(reference)) {\r\n                    return reference.ref;\r\n                } else if (Array.isArray(reference)) {\r\n                    for (const ref of reference) {\r\n                        if (isReference(ref) && ref.$refNode\r\n                            && ref.$refNode.offset <= sourceCstNode.offset\r\n                            && ref.$refNode.end >= sourceCstNode.end) {\r\n                            return ref.ref;\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n            if (nodeElem) {\r\n                const nameNode = this.nameProvider.getNameNode(nodeElem);\r\n                // Only return the targeted node in case the targeted cst node is the name node or part of it\r\n                if (nameNode && (nameNode === sourceCstNode || isChildNode(sourceCstNode, nameNode))) {\r\n                    return nodeElem;\r\n                }\r\n            }\r\n        }\r\n        return undefined;\r\n    }\r\n\r\n    findDeclarationNode(sourceCstNode: CstNode): CstNode | undefined {\r\n        const astNode = this.findDeclaration(sourceCstNode);\r\n        if (astNode?.$cstNode) {\r\n            const targetNode = this.nameProvider.getNameNode(astNode);\r\n            return targetNode ?? astNode.$cstNode;\r\n        }\r\n        return undefined;\r\n    }\r\n\r\n    findReferences(targetNode: AstNode, options: FindReferencesOptions): Stream<ReferenceDescription> {\r\n        const refs: ReferenceDescription[] = [];\r\n        if (options.includeDeclaration) {\r\n            const ref = this.getReferenceToSelf(targetNode);\r\n            if (ref) {\r\n                refs.push(ref);\r\n            }\r\n        }\r\n        let indexReferences = this.index.findAllReferences(targetNode, this.nodeLocator.getAstNodePath(targetNode));\r\n        if (options.documentUri) {\r\n            indexReferences = indexReferences.filter(ref => UriUtils.equals(ref.sourceUri, options.documentUri));\r\n        }\r\n        refs.push(...indexReferences);\r\n        return stream(refs);\r\n    }\r\n\r\n    protected getReferenceToSelf(targetNode: AstNode): ReferenceDescription | undefined {\r\n        const nameNode = this.nameProvider.getNameNode(targetNode);\r\n        if (nameNode) {\r\n            const doc = getDocument(targetNode);\r\n            const path = this.nodeLocator.getAstNodePath(targetNode);\r\n            return {\r\n                sourceUri: doc.uri,\r\n                sourcePath: path,\r\n                targetUri: doc.uri,\r\n                targetPath: path,\r\n                segment: toDocumentSegment(nameNode),\r\n                local: true\r\n            };\r\n        }\r\n        return undefined;\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021-2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { assertUnreachable } from '../utils/errors.js';\r\nimport * as ast from '../languages/generated/ast.js';\r\nimport type { AstNode, CstNode } from '../syntax-tree.js';\r\nimport { isCompositeCstNode } from '../syntax-tree.js';\r\nimport { getContainerOfType, streamAllContents } from './ast-utils.js';\r\nimport { streamCst } from './cst-utils.js';\r\nimport { escapeRegExp, isWhitespace } from './regexp-utils.js';\r\n\r\n/**\r\n * Returns the entry rule of the given grammar, if any. If the grammar file does not contain an entry rule,\r\n * the result is `undefined`.\r\n */\r\nexport function getEntryRule(grammar: ast.Grammar): ast.ParserRule | undefined {\r\n    return grammar.rules.find(e => ast.isParserRule(e) && e.entry) as ast.ParserRule;\r\n}\r\n\r\n/**\r\n * Returns all hidden terminal rules of the given grammar, if any.\r\n */\r\nexport function getHiddenRules(grammar: ast.Grammar) {\r\n    return grammar.rules.filter((e): e is ast.TerminalRule => ast.isTerminalRule(e) && e.hidden);\r\n}\r\n\r\n/**\r\n * Returns all rules that can be reached from the topmost rules of the specified grammar (entry and hidden terminal rules).\r\n *\r\n * @param grammar The grammar that contains all rules\r\n * @param allTerminals Whether or not to include terminals that are referenced only by other terminals\r\n * @returns A list of referenced parser and terminal rules. If the grammar contains no entry rule,\r\n *      this function returns all rules of the specified grammar.\r\n */\r\nexport function getAllReachableRules(grammar: ast.Grammar, allTerminals: boolean): Set<ast.AbstractRule> {\r\n    const ruleNames = new Set<string>();\r\n    const entryRule = getEntryRule(grammar);\r\n    if (!entryRule) {\r\n        return new Set(grammar.rules);\r\n    }\r\n\r\n    const topMostRules = [entryRule as ast.AbstractRule].concat(getHiddenRules(grammar));\r\n    for (const rule of topMostRules) {\r\n        ruleDfs(rule, ruleNames, allTerminals);\r\n    }\r\n\r\n    const rules = new Set<ast.AbstractRule>();\r\n    for (const rule of grammar.rules) {\r\n        if (ruleNames.has(rule.name) || (ast.isTerminalRule(rule) && rule.hidden)) {\r\n            rules.add(rule);\r\n        }\r\n    }\r\n    return rules;\r\n}\r\n\r\nfunction ruleDfs(rule: ast.AbstractRule, visitedSet: Set<string>, allTerminals: boolean): void {\r\n    visitedSet.add(rule.name);\r\n    streamAllContents(rule).forEach(node => {\r\n        if (ast.isRuleCall(node) || (allTerminals && ast.isTerminalRuleCall(node))) {\r\n            const refRule = node.rule.ref;\r\n            if (refRule && !visitedSet.has(refRule.name)) {\r\n                ruleDfs(refRule, visitedSet, allTerminals);\r\n            }\r\n        }\r\n    });\r\n}\r\n\r\n/**\r\n * Determines the grammar expression used to parse a cross-reference (usually a reference to a terminal rule).\r\n * A cross-reference can declare this expression explicitly in the form `[Type : Terminal]`, but if `Terminal`\r\n * is omitted, this function attempts to infer it from the name of the referenced `Type` (using `findNameAssignment`).\r\n *\r\n * Returns the grammar expression used to parse the given cross-reference, or `undefined` if it is not declared\r\n * and cannot be inferred.\r\n */\r\nexport function getCrossReferenceTerminal(crossRef: ast.CrossReference): ast.AbstractElement | undefined {\r\n    if (crossRef.terminal) {\r\n        return crossRef.terminal;\r\n    } else if (crossRef.type.ref) {\r\n        const nameAssigment = findNameAssignment(crossRef.type.ref);\r\n        return nameAssigment?.terminal;\r\n    }\r\n    return undefined;\r\n}\r\n\r\n/**\r\n * Determines whether the given terminal rule represents a comment. This is true if the rule is marked\r\n * as `hidden` and it does not match white space. This means every hidden token (i.e. excluded from the AST)\r\n * that contains visible characters is considered a comment.\r\n */\r\nexport function isCommentTerminal(terminalRule: ast.TerminalRule): boolean {\r\n    return terminalRule.hidden && !isWhitespace(terminalRegex(terminalRule));\r\n}\r\n\r\n/**\r\n * Find all CST nodes within the given node that contribute to the specified property.\r\n *\r\n * @param node A CST node in which to look for property assignments. If this is undefined, the result is an empty array.\r\n * @param property A property name of the constructed AST node. If this is undefined, the result is an empty array.\r\n */\r\nexport function findNodesForProperty(node: CstNode | undefined, property: string | undefined): CstNode[] {\r\n    if (!node || !property) {\r\n        return [];\r\n    }\r\n    return findNodesForPropertyInternal(node, property, node.astNode, true);\r\n}\r\n\r\n/**\r\n * Find a single CST node within the given node that contributes to the specified property.\r\n *\r\n * @param node A CST node in which to look for property assignments. If this is undefined, the result is `undefined`.\r\n * @param property A property name of the constructed AST node. If this is undefined, the result is `undefined`.\r\n * @param index If no index is specified or the index is less than zero, the first found node is returned. If the\r\n *        specified index exceeds the number of assignments to the property, the last found node is returned. Otherwise,\r\n *        the node with the specified index is returned.\r\n */\r\nexport function findNodeForProperty(node: CstNode | undefined, property: string | undefined, index?: number): CstNode | undefined {\r\n    if (!node || !property) {\r\n        return undefined;\r\n    }\r\n    const nodes = findNodesForPropertyInternal(node, property, node.astNode, true);\r\n    if (nodes.length === 0) {\r\n        return undefined;\r\n    }\r\n    if (index !== undefined) {\r\n        index = Math.max(0, Math.min(index, nodes.length - 1));\r\n    } else {\r\n        index = 0;\r\n    }\r\n    return nodes[index];\r\n}\r\n\r\nfunction findNodesForPropertyInternal(node: CstNode, property: string, element: AstNode | undefined, first: boolean): CstNode[] {\r\n    if (!first) {\r\n        const nodeFeature = getContainerOfType(node.grammarSource, ast.isAssignment);\r\n        if (nodeFeature && nodeFeature.feature === property) {\r\n            return [node];\r\n        }\r\n    }\r\n    if (isCompositeCstNode(node) && node.astNode === element) {\r\n        return node.content.flatMap(e => findNodesForPropertyInternal(e, property, element, false));\r\n    }\r\n    return [];\r\n}\r\n\r\n/**\r\n * Find all CST nodes within the given node that correspond to the specified keyword.\r\n *\r\n * @param node A CST node in which to look for keywords. If this is undefined, the result is an empty array.\r\n * @param keyword A keyword as specified in the grammar.\r\n */\r\nexport function findNodesForKeyword(node: CstNode | undefined, keyword: string): CstNode[] {\r\n    if (!node) {\r\n        return [];\r\n    }\r\n    return findNodesForKeywordInternal(node, keyword, node?.astNode);\r\n}\r\n\r\n/**\r\n * Find a single CST node within the given node that corresponds to the specified keyword.\r\n *\r\n * @param node A CST node in which to look for keywords. If this is undefined, the result is `undefined`.\r\n * @param keyword A keyword as specified in the grammar.\r\n * @param index If no index is specified or the index is less than zero, the first found node is returned. If the\r\n *        specified index exceeds the number of keyword occurrences, the last found node is returned. Otherwise,\r\n *        the node with the specified index is returned.\r\n */\r\nexport function findNodeForKeyword(node: CstNode | undefined, keyword: string, index?: number): CstNode | undefined {\r\n    if (!node) {\r\n        return undefined;\r\n    }\r\n    const nodes = findNodesForKeywordInternal(node, keyword, node?.astNode);\r\n    if (nodes.length === 0) {\r\n        return undefined;\r\n    }\r\n    if (index !== undefined) {\r\n        index = Math.max(0, Math.min(index, nodes.length - 1));\r\n    } else {\r\n        index = 0;\r\n    }\r\n    return nodes[index];\r\n}\r\n\r\nexport function findNodesForKeywordInternal(node: CstNode, keyword: string, element: AstNode | undefined): CstNode[] {\r\n    if (node.astNode !== element) {\r\n        return [];\r\n    }\r\n    if (ast.isKeyword(node.grammarSource) && node.grammarSource.value === keyword) {\r\n        return [node];\r\n    }\r\n    const treeIterator = streamCst(node).iterator();\r\n    let result: IteratorResult<CstNode>;\r\n    const keywordNodes: CstNode[] = [];\r\n    do {\r\n        result = treeIterator.next();\r\n        if (!result.done) {\r\n            const childNode = result.value;\r\n            if (childNode.astNode === element) {\r\n                if (ast.isKeyword(childNode.grammarSource) && childNode.grammarSource.value === keyword) {\r\n                    keywordNodes.push(childNode);\r\n                }\r\n            } else {\r\n                treeIterator.prune();\r\n            }\r\n        }\r\n    } while (!result.done);\r\n    return keywordNodes;\r\n}\r\n\r\n/**\r\n * If the given CST node was parsed in the context of a property assignment, the respective `Assignment` grammar\r\n * node is returned. If no assignment is found, the result is `undefined`.\r\n *\r\n * @param cstNode A CST node for which to find a property assignment.\r\n */\r\nexport function findAssignment(cstNode: CstNode): ast.Assignment | undefined {\r\n    const astNode = cstNode.astNode;\r\n    // Only search until the ast node of the parent cst node is no longer the original ast node\r\n    // This would make us jump to a preceding rule call, which contains only unrelated assignments\r\n    while (astNode === cstNode.container?.astNode) {\r\n        const assignment = getContainerOfType(cstNode.grammarSource, ast.isAssignment);\r\n        if (assignment) {\r\n            return assignment;\r\n        }\r\n        cstNode = cstNode.container;\r\n    }\r\n    return undefined;\r\n}\r\n\r\n/**\r\n * Find an assignment to the `name` property for the given grammar type. This requires the `type` to be inferred\r\n * from a parser rule, and that rule must contain an assignment to the `name` property. In all other cases,\r\n * this function returns `undefined`.\r\n */\r\nexport function findNameAssignment(type: ast.AbstractType): ast.Assignment | undefined {\r\n    let startNode: AstNode = type;\r\n    if (ast.isInferredType(startNode)) {\r\n        // for inferred types, the location to start searching for the name-assignment is different\r\n        if (ast.isAction(startNode.$container)) {\r\n            // a type which is explicitly inferred by an action: investigate the sibbling of the Action node, i.e. start searching at the Action's parent\r\n            startNode = startNode.$container.$container!;\r\n        } else if (ast.isParserRule(startNode.$container)) {\r\n            // investigate the parser rule with the explicitly inferred type\r\n            startNode = startNode.$container;\r\n        } else {\r\n            assertUnreachable(startNode.$container);\r\n        }\r\n    }\r\n    return findNameAssignmentInternal(type, startNode, new Map());\r\n}\r\n\r\nfunction findNameAssignmentInternal(type: ast.AbstractType, startNode: AstNode, cache: Map<ast.AbstractType, ast.Assignment | undefined>): ast.Assignment | undefined {\r\n    // the cache is only required to prevent infinite loops\r\n    function go(node: AstNode, refType: ast.AbstractType): ast.Assignment | undefined {\r\n        let childAssignment: ast.Assignment | undefined = undefined;\r\n        const parentAssignment = getContainerOfType(node, ast.isAssignment);\r\n        // No parent assignment implies unassigned rule call\r\n        if (!parentAssignment) {\r\n            childAssignment = findNameAssignmentInternal(refType, refType, cache);\r\n        }\r\n        cache.set(type, childAssignment);\r\n        return childAssignment;\r\n    }\r\n\r\n    if (cache.has(type)) {\r\n        return cache.get(type);\r\n    }\r\n    cache.set(type, undefined);\r\n    for (const node of streamAllContents(startNode)) {\r\n        if (ast.isAssignment(node) && node.feature.toLowerCase() === 'name') {\r\n            cache.set(type, node);\r\n            return node;\r\n        } else if (ast.isRuleCall(node) && ast.isParserRule(node.rule.ref)) {\r\n            return go(node, node.rule.ref);\r\n        } else if (ast.isSimpleType(node) && node.typeRef?.ref) {\r\n            return go(node, node.typeRef.ref);\r\n        }\r\n    }\r\n    return undefined;\r\n}\r\n\r\nexport function getActionAtElement(element: ast.AbstractElement): ast.Action | undefined {\r\n    const parent = element.$container;\r\n    if (ast.isGroup(parent)) {\r\n        const elements = parent.elements;\r\n        const index = elements.indexOf(element);\r\n        for (let i = index - 1; i >= 0; i--) {\r\n            const item = elements[i];\r\n            if (ast.isAction(item)) {\r\n                return item;\r\n            } else {\r\n                const action = streamAllContents(elements[i]).find(ast.isAction);\r\n                if (action) {\r\n                    return action;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    if (ast.isAbstractElement(parent)) {\r\n        return getActionAtElement(parent);\r\n    } else {\r\n        return undefined;\r\n    }\r\n}\r\n\r\nexport type Cardinality = '?' | '*' | '+' | undefined;\r\nexport type Operator = '=' | '+=' | '?=' | undefined;\r\n\r\nexport function isOptionalCardinality(cardinality?: Cardinality, element?: ast.AbstractElement): boolean {\r\n    return cardinality === '?' || cardinality === '*' || (ast.isGroup(element) && Boolean(element.guardCondition));\r\n}\r\n\r\nexport function isArrayCardinality(cardinality?: Cardinality): boolean {\r\n    return cardinality === '*' || cardinality === '+';\r\n}\r\n\r\nexport function isArrayOperator(operator?: Operator): boolean {\r\n    return operator === '+=';\r\n}\r\n\r\n/**\r\n * Determines whether the given parser rule is a _data type rule_, meaning that it has a\r\n * primitive return type like `number`, `boolean`, etc.\r\n */\r\nexport function isDataTypeRule(rule: ast.ParserRule): boolean {\r\n    return isDataTypeRuleInternal(rule, new Set());\r\n}\r\n\r\nfunction isDataTypeRuleInternal(rule: ast.ParserRule, visited: Set<ast.ParserRule>): boolean {\r\n    if (visited.has(rule)) {\r\n        return true;\r\n    } else {\r\n        visited.add(rule);\r\n    }\r\n    for (const node of streamAllContents(rule)) {\r\n        if (ast.isRuleCall(node)) {\r\n            if (!node.rule.ref) {\r\n                // RuleCall to unresolved rule. Don't assume `rule` is a DataType rule.\r\n                return false;\r\n            }\r\n            if (ast.isParserRule(node.rule.ref) && !isDataTypeRuleInternal(node.rule.ref, visited)) {\r\n                return false;\r\n            }\r\n        } else if (ast.isAssignment(node)) {\r\n            return false;\r\n        } else if (ast.isAction(node)) {\r\n            return false;\r\n        }\r\n    }\r\n    return Boolean(rule.definition);\r\n}\r\n\r\nexport function isDataType(type: ast.Type): boolean {\r\n    return isDataTypeInternal(type.type, new Set());\r\n}\r\n\r\nfunction isDataTypeInternal(type: ast.TypeDefinition, visited: Set<ast.TypeDefinition>): boolean {\r\n    if (visited.has(type)) {\r\n        return true;\r\n    } else {\r\n        visited.add(type);\r\n    }\r\n    if (ast.isArrayType(type)) {\r\n        return false;\r\n    } else if (ast.isReferenceType(type)) {\r\n        return false;\r\n    } else if (ast.isUnionType(type)) {\r\n        return type.types.every(e => isDataTypeInternal(e, visited));\r\n    } else if (ast.isSimpleType(type)) {\r\n        if (type.primitiveType !== undefined) {\r\n            return true;\r\n        } else if (type.stringType !== undefined) {\r\n            return true;\r\n        } else if (type.typeRef !== undefined) {\r\n            const ref = type.typeRef.ref;\r\n            if (ast.isType(ref)) {\r\n                return isDataTypeInternal(ref.type, visited);\r\n            } else {\r\n                return false;\r\n            }\r\n        } else {\r\n            return false;\r\n        }\r\n    } else {\r\n        return false;\r\n    }\r\n}\r\n\r\nexport function getExplicitRuleType(rule: ast.ParserRule): string | undefined {\r\n    if (rule.inferredType) {\r\n        return rule.inferredType.name;\r\n    } else if (rule.dataType) {\r\n        return rule.dataType;\r\n    } else if (rule.returnType) {\r\n        const refType = rule.returnType.ref;\r\n        if (refType) {\r\n            // check if we need to check Action as return type\r\n            if (ast.isParserRule(refType)) {\r\n                return refType.name;\r\n            } else if (ast.isInterface(refType) || ast.isType(refType)) {\r\n                return refType.name;\r\n            }\r\n        }\r\n    }\r\n    return undefined;\r\n}\r\n\r\nexport function getTypeName(type: ast.AbstractType | ast.Action): string {\r\n    if (ast.isParserRule(type)) {\r\n        return isDataTypeRule(type) ? type.name : getExplicitRuleType(type) ?? type.name;\r\n    } else if (ast.isInterface(type) || ast.isType(type) || ast.isReturnType(type)) {\r\n        return type.name;\r\n    } else if (ast.isAction(type)) {\r\n        const actionType = getActionType(type);\r\n        if (actionType) {\r\n            return actionType;\r\n        }\r\n    } else if (ast.isInferredType(type)) {\r\n        return type.name;\r\n    }\r\n    throw new Error('Cannot get name of Unknown Type');\r\n}\r\n\r\nexport function getActionType(action: ast.Action): string | undefined {\r\n    if (action.inferredType) {\r\n        return action.inferredType.name;\r\n    } else if (action.type?.ref) {\r\n        return getTypeName(action.type.ref);\r\n    }\r\n    return undefined; // not inferring and not referencing a valid type\r\n}\r\n\r\n/**\r\n * This function is used at development time (for code generation and the internal type system) to get the type of the AST node produced by the given rule.\r\n * For data type rules, the name of the rule is returned,\r\n * e.g. \"INT_value returns number: MY_INT;\" returns \"INT_value\".\r\n * @param rule the given rule\r\n * @returns the name of the AST node type of the rule\r\n */\r\nexport function getRuleTypeName(rule: ast.AbstractRule): string {\r\n    if (ast.isTerminalRule(rule)) {\r\n        return rule.type?.name ?? 'string';\r\n    } else {\r\n        return isDataTypeRule(rule) ? rule.name : getExplicitRuleType(rule) ?? rule.name;\r\n    }\r\n}\r\n\r\n/**\r\n * This function is used at runtime to get the actual type of the values produced by the given rule at runtime.\r\n * For data type rules, the name of the declared return type of the rule is returned (if any),\r\n * e.g. \"INT_value returns number: MY_INT;\" returns \"number\".\r\n * @param rule the given rule\r\n * @returns the name of the type of the produced values of the rule at runtime\r\n */\r\nexport function getRuleType(rule: ast.AbstractRule): string {\r\n    if (ast.isTerminalRule(rule)) {\r\n        return rule.type?.name ?? 'string';\r\n    } else {\r\n        return getExplicitRuleType(rule) ?? rule.name;\r\n    }\r\n}\r\n\r\nexport function terminalRegex(terminalRule: ast.TerminalRule): RegExp {\r\n    const flags: Flags = {\r\n        s: false,\r\n        i: false,\r\n        u: false\r\n    };\r\n    const source = abstractElementToRegex(terminalRule.definition, flags);\r\n    const flagText = Object.entries(flags).filter(([, value]) => value).map(([name]) => name).join('');\r\n    return new RegExp(source, flagText);\r\n}\r\n\r\n// Using [\\s\\S]* allows to match everything, compared to . which doesn't match line terminators\r\nconst WILDCARD = /[\\s\\S]/.source;\r\n\r\ntype Flags = {\r\n    s: boolean;\r\n    i: boolean;\r\n    u: boolean;\r\n}\r\n\r\nfunction abstractElementToRegex(element: ast.AbstractElement, flags?: Flags): string {\r\n    if (ast.isTerminalAlternatives(element)) {\r\n        return terminalAlternativesToRegex(element);\r\n    } else if (ast.isTerminalGroup(element)) {\r\n        return terminalGroupToRegex(element);\r\n    } else if (ast.isCharacterRange(element)) {\r\n        return characterRangeToRegex(element);\r\n    } else if (ast.isTerminalRuleCall(element)) {\r\n        const rule = element.rule.ref;\r\n        if (!rule) {\r\n            throw new Error('Missing rule reference.');\r\n        }\r\n        return withCardinality(abstractElementToRegex(rule.definition), {\r\n            cardinality: element.cardinality,\r\n            lookahead: element.lookahead\r\n        });\r\n    } else if (ast.isNegatedToken(element)) {\r\n        return negateTokenToRegex(element);\r\n    } else if (ast.isUntilToken(element)) {\r\n        return untilTokenToRegex(element);\r\n    } else if (ast.isRegexToken(element)) {\r\n        const lastSlash = element.regex.lastIndexOf('/');\r\n        const source = element.regex.substring(1, lastSlash);\r\n        const regexFlags = element.regex.substring(lastSlash + 1);\r\n        if (flags) {\r\n            flags.i = regexFlags.includes('i');\r\n            flags.s = regexFlags.includes('s');\r\n            flags.u = regexFlags.includes('u');\r\n        }\r\n        return withCardinality(source, {\r\n            cardinality: element.cardinality,\r\n            lookahead: element.lookahead,\r\n            wrap: false\r\n        });\r\n    } else if (ast.isWildcard(element)) {\r\n        return withCardinality(WILDCARD, {\r\n            cardinality: element.cardinality,\r\n            lookahead: element.lookahead\r\n        });\r\n    } else {\r\n        throw new Error(`Invalid terminal element: ${element?.$type}`);\r\n    }\r\n}\r\n\r\nfunction terminalAlternativesToRegex(alternatives: ast.TerminalAlternatives): string {\r\n    return withCardinality(alternatives.elements.map(e => abstractElementToRegex(e)).join('|'), {\r\n        cardinality: alternatives.cardinality,\r\n        lookahead: alternatives.lookahead\r\n    });\r\n}\r\n\r\nfunction terminalGroupToRegex(group: ast.TerminalGroup): string {\r\n    return withCardinality(group.elements.map(e => abstractElementToRegex(e)).join(''), {\r\n        cardinality: group.cardinality,\r\n        lookahead: group.lookahead\r\n    });\r\n}\r\n\r\nfunction untilTokenToRegex(until: ast.UntilToken): string {\r\n    return withCardinality(`${WILDCARD}*?${abstractElementToRegex(until.terminal)}`, {\r\n        cardinality: until.cardinality,\r\n        lookahead: until.lookahead\r\n    });\r\n}\r\n\r\nfunction negateTokenToRegex(negate: ast.NegatedToken): string {\r\n    return withCardinality(`(?!${abstractElementToRegex(negate.terminal)})${WILDCARD}*?`, {\r\n        cardinality: negate.cardinality,\r\n        lookahead: negate.lookahead\r\n    });\r\n}\r\n\r\nfunction characterRangeToRegex(range: ast.CharacterRange): string {\r\n    if (range.right) {\r\n        return withCardinality(`[${keywordToRegex(range.left)}-${keywordToRegex(range.right)}]`, {\r\n            cardinality: range.cardinality,\r\n            lookahead: range.lookahead,\r\n            wrap: false\r\n        });\r\n    }\r\n    return withCardinality(keywordToRegex(range.left), {\r\n        cardinality: range.cardinality,\r\n        lookahead: range.lookahead,\r\n        wrap: false\r\n    });\r\n}\r\n\r\nfunction keywordToRegex(keyword: ast.Keyword): string {\r\n    return escapeRegExp(keyword.value);\r\n}\r\n\r\nfunction withCardinality(regex: string, options: {\r\n    cardinality?: string\r\n    wrap?: boolean\r\n    lookahead?: string\r\n}): string {\r\n    if (options.wrap !== false || options.lookahead) {\r\n        regex = `(${options.lookahead ?? ''}${regex})`;\r\n    }\r\n    if (options.cardinality) {\r\n        return `${regex}${options.cardinality}`;\r\n    }\r\n    return regex;\r\n}\r\n","import baseKeys from './_baseKeys.js';\nimport getTag from './_getTag.js';\nimport isArguments from './isArguments.js';\nimport isArray from './isArray.js';\nimport isArrayLike from './isArrayLike.js';\nimport isBuffer from './isBuffer.js';\nimport isPrototype from './_isPrototype.js';\nimport isTypedArray from './isTypedArray.js';\n\n/** `Object#toString` result references. */\nvar mapTag = '[object Map]',\n    setTag = '[object Set]';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Checks if `value` is an empty object, collection, map, or set.\n *\n * Objects are considered empty if they have no own enumerable string keyed\n * properties.\n *\n * Array-like values such as `arguments` objects, arrays, buffers, strings, or\n * jQuery-like collections are considered empty if they have a `length` of `0`.\n * Similarly, maps and sets are considered empty if they have a `size` of `0`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is empty, else `false`.\n * @example\n *\n * _.isEmpty(null);\n * // => true\n *\n * _.isEmpty(true);\n * // => true\n *\n * _.isEmpty(1);\n * // => true\n *\n * _.isEmpty([1, 2, 3]);\n * // => false\n *\n * _.isEmpty({ 'a': 1 });\n * // => false\n */\nfunction isEmpty(value) {\n  if (value == null) {\n    return true;\n  }\n  if (isArrayLike(value) &&\n      (isArray(value) || typeof value == 'string' || typeof value.splice == 'function' ||\n        isBuffer(value) || isTypedArray(value) || isArguments(value))) {\n    return !value.length;\n  }\n  var tag = getTag(value);\n  if (tag == mapTag || tag == setTag) {\n    return !value.size;\n  }\n  if (isPrototype(value)) {\n    return !baseKeys(value).length;\n  }\n  for (var key in value) {\n    if (hasOwnProperty.call(value, key)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport default isEmpty;\n","import Stack from './_Stack.js';\nimport equalArrays from './_equalArrays.js';\nimport equalByTag from './_equalByTag.js';\nimport equalObjects from './_equalObjects.js';\nimport getTag from './_getTag.js';\nimport isArray from './isArray.js';\nimport isBuffer from './isBuffer.js';\nimport isTypedArray from './isTypedArray.js';\n\n/** Used to compose bitmasks for value comparisons. */\nvar COMPARE_PARTIAL_FLAG = 1;\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]',\n    arrayTag = '[object Array]',\n    objectTag = '[object Object]';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * A specialized version of `baseIsEqual` for arrays and objects which performs\n * deep comparisons and tracks traversed objects enabling objects with circular\n * references to be compared.\n *\n * @private\n * @param {Object} object The object to compare.\n * @param {Object} other The other object to compare.\n * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.\n * @param {Function} customizer The function to customize comparisons.\n * @param {Function} equalFunc The function to determine equivalents of values.\n * @param {Object} [stack] Tracks traversed `object` and `other` objects.\n * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.\n */\nfunction baseIsEqualDeep(object, other, bitmask, customizer, equalFunc, stack) {\n  var objIsArr = isArray(object),\n      othIsArr = isArray(other),\n      objTag = objIsArr ? arrayTag : getTag(object),\n      othTag = othIsArr ? arrayTag : getTag(other);\n\n  objTag = objTag == argsTag ? objectTag : objTag;\n  othTag = othTag == argsTag ? objectTag : othTag;\n\n  var objIsObj = objTag == objectTag,\n      othIsObj = othTag == objectTag,\n      isSameTag = objTag == othTag;\n\n  if (isSameTag && isBuffer(object)) {\n    if (!isBuffer(other)) {\n      return false;\n    }\n    objIsArr = true;\n    objIsObj = false;\n  }\n  if (isSameTag && !objIsObj) {\n    stack || (stack = new Stack);\n    return (objIsArr || isTypedArray(object))\n      ? equalArrays(object, other, bitmask, customizer, equalFunc, stack)\n      : equalByTag(object, other, objTag, bitmask, customizer, equalFunc, stack);\n  }\n  if (!(bitmask & COMPARE_PARTIAL_FLAG)) {\n    var objIsWrapped = objIsObj && hasOwnProperty.call(object, '__wrapped__'),\n        othIsWrapped = othIsObj && hasOwnProperty.call(other, '__wrapped__');\n\n    if (objIsWrapped || othIsWrapped) {\n      var objUnwrapped = objIsWrapped ? object.value() : object,\n          othUnwrapped = othIsWrapped ? other.value() : other;\n\n      stack || (stack = new Stack);\n      return equalFunc(objUnwrapped, othUnwrapped, bitmask, customizer, stack);\n    }\n  }\n  if (!isSameTag) {\n    return false;\n  }\n  stack || (stack = new Stack);\n  return equalObjects(object, other, bitmask, customizer, equalFunc, stack);\n}\n\nexport default baseIsEqualDeep;\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, AstNodeDescription } from '../syntax-tree.js';\r\nimport type { IndexManager } from '../workspace/index-manager.js';\r\nimport type { CommentProvider } from './comment-provider.js';\r\nimport type { JSDocTag } from './jsdoc.js';\r\nimport { getDocument } from '../utils/ast-utils.js';\r\nimport { isJSDoc, parseJSDoc } from './jsdoc.js';\r\n\r\n/**\r\n * Provides documentation for AST nodes.\r\n */\r\nexport interface DocumentationProvider {\r\n    /**\r\n     * Returns a markdown documentation string for the specified AST node.\r\n     *\r\n     * The default implementation `JSDocDocumentationProvider` will inspect the comment associated with the specified node.\r\n     */\r\n    getDocumentation(node: AstNode): string | undefined;\r\n}\r\n\r\nexport class JSDocDocumentationProvider implements DocumentationProvider {\r\n\r\n    protected readonly indexManager: IndexManager;\r\n    protected readonly commentProvider: CommentProvider;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.indexManager = services.shared.workspace.IndexManager;\r\n        this.commentProvider = services.documentation.CommentProvider;\r\n    }\r\n\r\n    getDocumentation(node: AstNode): string | undefined {\r\n        const comment = this.commentProvider.getComment(node);\r\n        if (comment && isJSDoc(comment)) {\r\n            const parsedJSDoc = parseJSDoc(comment);\r\n            return parsedJSDoc.toMarkdown({\r\n                renderLink: (link, display) => {\r\n                    return this.documentationLinkRenderer(node, link, display);\r\n                },\r\n                renderTag: (tag) => {\r\n                    return this.documentationTagRenderer(node, tag);\r\n                }\r\n            });\r\n        }\r\n        return undefined;\r\n    }\r\n\r\n    protected documentationLinkRenderer(node: AstNode, name: string, display: string): string | undefined {\r\n        const description = this.findNameInPrecomputedScopes(node, name) ?? this.findNameInGlobalScope(node, name);\r\n        if (description && description.nameSegment) {\r\n            const line = description.nameSegment.range.start.line + 1;\r\n            const character = description.nameSegment.range.start.character + 1;\r\n            const uri = description.documentUri.with({ fragment: `L${line},${character}` });\r\n            return `[${display}](${uri.toString()})`;\r\n        } else {\r\n            return undefined;\r\n        }\r\n    }\r\n\r\n    protected documentationTagRenderer(_node: AstNode, _tag: JSDocTag): string | undefined {\r\n        // Fall back to the default tag rendering\r\n        return undefined;\r\n    }\r\n\r\n    protected findNameInPrecomputedScopes(node: AstNode, name: string): AstNodeDescription | undefined {\r\n        const document = getDocument(node);\r\n        const precomputed = document.precomputedScopes;\r\n        if (!precomputed) {\r\n            return undefined;\r\n        }\r\n        let currentNode: AstNode | undefined = node;\r\n        do {\r\n            const allDescriptions = precomputed.get(currentNode);\r\n            const description = allDescriptions.find(e => e.name === name);\r\n            if (description) {\r\n                return description;\r\n            }\r\n            currentNode = currentNode.$container;\r\n        } while (currentNode);\r\n\r\n        return undefined;\r\n    }\r\n\r\n    protected findNameInGlobalScope(node: AstNode, name: string): AstNodeDescription | undefined {\r\n        const description = this.indexManager.allElements().find(e => e.name === name);\r\n        return description;\r\n    }\r\n}\r\n","import {\n  ILookaheadStrategy,\n  ILookaheadValidationError,\n  IOrAlt,\n  OptionalProductionType,\n  Rule,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { flatMap, isEmpty } from \"lodash-es\";\nimport { defaultGrammarValidatorErrorProvider } from \"../errors_public.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser/parser.js\";\nimport {\n  validateAmbiguousAlternationAlternatives,\n  validateEmptyOrAlternative,\n  validateNoLeftRecursion,\n  validateSomeNonEmptyLookaheadPath,\n} from \"./checks.js\";\nimport {\n  buildAlternativesLookAheadFunc,\n  buildLookaheadFuncForOptionalProd,\n  buildLookaheadFuncForOr,\n  buildSingleAlternativeLookaheadFunction,\n  getProdType,\n} from \"./lookahead.js\";\nimport { IParserDefinitionError } from \"./types.js\";\n\nexport class LLkLookaheadStrategy implements ILookaheadStrategy {\n  readonly maxLookahead: number;\n\n  constructor(options?: { maxLookahead?: number }) {\n    this.maxLookahead =\n      options?.maxLookahead ?? DEFAULT_PARSER_CONFIG.maxLookahead;\n  }\n\n  validate(options: {\n    rules: Rule[];\n    tokenTypes: TokenType[];\n    grammarName: string;\n  }): ILookaheadValidationError[] {\n    const leftRecursionErrors = this.validateNoLeftRecursion(options.rules);\n\n    if (isEmpty(leftRecursionErrors)) {\n      const emptyAltErrors = this.validateEmptyOrAlternatives(options.rules);\n      const ambiguousAltsErrors = this.validateAmbiguousAlternationAlternatives(\n        options.rules,\n        this.maxLookahead,\n      );\n      const emptyRepetitionErrors = this.validateSomeNonEmptyLookaheadPath(\n        options.rules,\n        this.maxLookahead,\n      );\n      const allErrors = [\n        ...leftRecursionErrors,\n        ...emptyAltErrors,\n        ...ambiguousAltsErrors,\n        ...emptyRepetitionErrors,\n      ];\n      return allErrors;\n    }\n    return leftRecursionErrors;\n  }\n\n  validateNoLeftRecursion(rules: Rule[]): IParserDefinitionError[] {\n    return flatMap(rules, (currTopRule) =>\n      validateNoLeftRecursion(\n        currTopRule,\n        currTopRule,\n        defaultGrammarValidatorErrorProvider,\n      ),\n    );\n  }\n\n  validateEmptyOrAlternatives(rules: Rule[]): IParserDefinitionError[] {\n    return flatMap(rules, (currTopRule) =>\n      validateEmptyOrAlternative(\n        currTopRule,\n        defaultGrammarValidatorErrorProvider,\n      ),\n    );\n  }\n\n  validateAmbiguousAlternationAlternatives(\n    rules: Rule[],\n    maxLookahead: number,\n  ): IParserDefinitionError[] {\n    return flatMap(rules, (currTopRule) =>\n      validateAmbiguousAlternationAlternatives(\n        currTopRule,\n        maxLookahead,\n        defaultGrammarValidatorErrorProvider,\n      ),\n    );\n  }\n\n  validateSomeNonEmptyLookaheadPath(\n    rules: Rule[],\n    maxLookahead: number,\n  ): IParserDefinitionError[] {\n    return validateSomeNonEmptyLookaheadPath(\n      rules,\n      maxLookahead,\n      defaultGrammarValidatorErrorProvider,\n    );\n  }\n\n  buildLookaheadForAlternation(options: {\n    prodOccurrence: number;\n    rule: Rule;\n    maxLookahead: number;\n    hasPredicates: boolean;\n    dynamicTokensEnabled: boolean;\n  }): (orAlts?: IOrAlt<any>[] | undefined) => number | undefined {\n    return buildLookaheadFuncForOr(\n      options.prodOccurrence,\n      options.rule,\n      options.maxLookahead,\n      options.hasPredicates,\n      options.dynamicTokensEnabled,\n      buildAlternativesLookAheadFunc,\n    );\n  }\n\n  buildLookaheadForOptional(options: {\n    prodOccurrence: number;\n    prodType: OptionalProductionType;\n    rule: Rule;\n    maxLookahead: number;\n    dynamicTokensEnabled: boolean;\n  }): () => boolean {\n    return buildLookaheadFuncForOptionalProd(\n      options.prodOccurrence,\n      options.rule,\n      options.maxLookahead,\n      options.dynamicTokensEnabled,\n      getProdType(options.prodType),\n      buildSingleAlternativeLookaheadFunction,\n    );\n  }\n}\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { CustomPatternMatcherFunc, ILexingError, TokenPattern, TokenType, TokenVocabulary } from 'chevrotain';\r\nimport type { AbstractRule, Grammar, Keyword, TerminalRule } from '../languages/generated/ast.js';\r\nimport type { Stream } from '../utils/stream.js';\r\nimport { Lexer } from 'chevrotain';\r\nimport { isKeyword, isParserRule, isTerminalRule } from '../languages/generated/ast.js';\r\nimport { streamAllContents } from '../utils/ast-utils.js';\r\nimport { getAllReachableRules, terminalRegex } from '../utils/grammar-utils.js';\r\nimport { getCaseInsensitivePattern, isWhitespace, partialMatches } from '../utils/regexp-utils.js';\r\nimport { stream } from '../utils/stream.js';\r\n\r\nexport interface TokenBuilderOptions {\r\n    caseInsensitive?: boolean\r\n}\r\n\r\nexport interface TokenBuilder {\r\n    buildTokens(grammar: Grammar, options?: TokenBuilderOptions): TokenVocabulary;\r\n    /**\r\n     * Produces a lexing report for the given text that was just tokenized using the tokens provided by this builder.\r\n     *\r\n     * @param text The text that was tokenized.\r\n     */\r\n    flushLexingReport?(text: string): LexingReport;\r\n}\r\n\r\n/**\r\n * A custom lexing report that can be produced by the token builder during the lexing process.\r\n * Adopters need to ensure that the any custom fields are serializable so they can be sent across worker threads.\r\n */\r\nexport interface LexingReport {\r\n    diagnostics: LexingDiagnostic[];\r\n}\r\n\r\nexport type LexingDiagnosticSeverity = 'error' | 'warning' | 'info' | 'hint';\r\n\r\nexport interface LexingDiagnostic extends ILexingError {\r\n    severity?: LexingDiagnosticSeverity;\r\n}\r\n\r\nexport class DefaultTokenBuilder implements TokenBuilder {\r\n    /**\r\n     * The list of diagnostics stored during the lexing process of a single text.\r\n     */\r\n    protected diagnostics: LexingDiagnostic[] = [];\r\n\r\n    buildTokens(grammar: Grammar, options?: TokenBuilderOptions): TokenVocabulary {\r\n        const reachableRules = stream(getAllReachableRules(grammar, false));\r\n        const terminalTokens: TokenType[] = this.buildTerminalTokens(reachableRules);\r\n        const tokens: TokenType[] = this.buildKeywordTokens(reachableRules, terminalTokens, options);\r\n\r\n        terminalTokens.forEach(terminalToken => {\r\n            const pattern = terminalToken.PATTERN;\r\n            if (typeof pattern === 'object' && pattern && 'test' in pattern && isWhitespace(pattern)) {\r\n                tokens.unshift(terminalToken);\r\n            } else {\r\n                tokens.push(terminalToken);\r\n            }\r\n        });\r\n        // We don't need to add the EOF token explicitly.\r\n        // It is automatically available at the end of the token stream.\r\n        return tokens;\r\n    }\r\n\r\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\r\n    flushLexingReport(text: string): LexingReport {\r\n        return { diagnostics: this.popDiagnostics() };\r\n    }\r\n\r\n    protected popDiagnostics(): LexingDiagnostic[] {\r\n        const diagnostics = [...this.diagnostics];\r\n        this.diagnostics = [];\r\n        return diagnostics;\r\n    }\r\n\r\n    protected buildTerminalTokens(rules: Stream<AbstractRule>): TokenType[] {\r\n        return rules.filter(isTerminalRule).filter(e => !e.fragment)\r\n            .map(terminal => this.buildTerminalToken(terminal)).toArray();\r\n    }\r\n\r\n    protected buildTerminalToken(terminal: TerminalRule): TokenType {\r\n        const regex = terminalRegex(terminal);\r\n        const pattern = this.requiresCustomPattern(regex) ? this.regexPatternFunction(regex) : regex;\r\n        const tokenType: TokenType = {\r\n            name: terminal.name,\r\n            PATTERN: pattern,\r\n        };\r\n        if (typeof pattern === 'function') {\r\n            tokenType.LINE_BREAKS = true;\r\n        }\r\n        if (terminal.hidden) {\r\n            // Only skip tokens that are able to accept whitespace\r\n            tokenType.GROUP = isWhitespace(regex) ? Lexer.SKIPPED : 'hidden';\r\n        }\r\n        return tokenType;\r\n    }\r\n\r\n    protected requiresCustomPattern(regex: RegExp): boolean {\r\n        if (regex.flags.includes('u') || regex.flags.includes('s')) {\r\n            // Unicode and dotall regexes are not supported by Chevrotain.\r\n            return true;\r\n        } else if (regex.source.includes('?<=') || regex.source.includes('?<!')) {\r\n            // Negative and positive lookbehind are not supported by Chevrotain yet.\r\n            return true;\r\n        } else {\r\n            return false;\r\n        }\r\n    }\r\n\r\n    protected regexPatternFunction(regex: RegExp): CustomPatternMatcherFunc {\r\n        const stickyRegex = new RegExp(regex, regex.flags + 'y');\r\n        return (text, offset) => {\r\n            stickyRegex.lastIndex = offset;\r\n            const execResult = stickyRegex.exec(text);\r\n            return execResult;\r\n        };\r\n    }\r\n\r\n    protected buildKeywordTokens(rules: Stream<AbstractRule>, terminalTokens: TokenType[], options?: TokenBuilderOptions): TokenType[] {\r\n        return rules\r\n            // We filter by parser rules, since keywords in terminal rules get transformed into regex and are not actual tokens\r\n            .filter(isParserRule)\r\n            .flatMap(rule => streamAllContents(rule).filter(isKeyword))\r\n            .distinct(e => e.value).toArray()\r\n            // Sort keywords by descending length\r\n            .sort((a, b) => b.value.length - a.value.length)\r\n            .map(keyword => this.buildKeywordToken(keyword, terminalTokens, Boolean(options?.caseInsensitive)));\r\n    }\r\n\r\n    protected buildKeywordToken(keyword: Keyword, terminalTokens: TokenType[], caseInsensitive: boolean): TokenType {\r\n        const keywordPattern = this.buildKeywordPattern(keyword, caseInsensitive);\r\n        const tokenType: TokenType = {\r\n            name: keyword.value,\r\n            PATTERN: keywordPattern,\r\n            LONGER_ALT: this.findLongerAlt(keyword, terminalTokens)\r\n        };\r\n\r\n        if (typeof keywordPattern === 'function') {\r\n            tokenType.LINE_BREAKS = true;\r\n        }\r\n\r\n        return tokenType;\r\n    }\r\n\r\n    protected buildKeywordPattern(keyword: Keyword, caseInsensitive: boolean): TokenPattern {\r\n        return caseInsensitive ?\r\n            new RegExp(getCaseInsensitivePattern(keyword.value)) :\r\n            keyword.value;\r\n    }\r\n\r\n    protected findLongerAlt(keyword: Keyword, terminalTokens: TokenType[]): TokenType[] {\r\n        return terminalTokens.reduce((longerAlts: TokenType[], token) => {\r\n            const pattern = token?.PATTERN as RegExp;\r\n            if (pattern?.source && partialMatches('^' + pattern.source + '$', keyword.value)) {\r\n                longerAlts.push(token);\r\n            }\r\n            return longerAlts;\r\n        }, []);\r\n    }\r\n}\r\n","// Lookahead keys are 32Bit integers in the form\n// TTTTTTTT-ZZZZZZZZZZZZ-YYYY-XXXXXXXX\n// XXXX -> Occurrence Index bitmap.\n// YYYY -> DSL Method Type bitmap.\n// ZZZZZZZZZZZZZZZ -> Rule short Index bitmap.\n// TTTTTTTTT -> alternation alternative index bitmap\n\nexport const BITS_FOR_METHOD_TYPE = 4;\nexport const BITS_FOR_OCCURRENCE_IDX = 8;\nexport const BITS_FOR_RULE_IDX = 12;\n// TODO: validation, this means that there may at most 2^8 --> 256 alternatives for an alternation.\nexport const BITS_FOR_ALT_IDX = 8;\n\n// short string used as part of mapping keys.\n// being short improves the performance when composing KEYS for maps out of these\n// The 5 - 8 bits (16 possible values, are reserved for the DSL method indices)\nexport const OR_IDX = 1 << BITS_FOR_OCCURRENCE_IDX;\nexport const OPTION_IDX = 2 << BITS_FOR_OCCURRENCE_IDX;\nexport const MANY_IDX = 3 << BITS_FOR_OCCURRENCE_IDX;\nexport const AT_LEAST_ONE_IDX = 4 << BITS_FOR_OCCURRENCE_IDX;\nexport const MANY_SEP_IDX = 5 << BITS_FOR_OCCURRENCE_IDX;\nexport const AT_LEAST_ONE_SEP_IDX = 6 << BITS_FOR_OCCURRENCE_IDX;\n\n// this actually returns a number, but it is always used as a string (object prop key)\nexport function getKeyForAutomaticLookahead(\n  ruleIdx: number,\n  dslMethodIdx: number,\n  occurrence: number,\n): number {\n  return occurrence | dslMethodIdx | ruleIdx;\n}\n\nconst BITS_START_FOR_ALT_IDX = 32 - BITS_FOR_ALT_IDX;\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport { LangiumCompletionParser } from './langium-parser.js';\r\nimport { createParser } from './parser-builder-base.js';\r\n\r\nexport function createCompletionParser(services: LangiumCoreServices): LangiumCompletionParser {\r\n    const grammar = services.Grammar;\r\n    const lexer = services.parser.Lexer;\r\n    const parser = new LangiumCompletionParser(services);\r\n    createParser(grammar, parser, lexer.definition);\r\n    parser.finalize();\r\n    return parser;\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021-2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, AstNodeDescription, AstReflection, ReferenceInfo } from '../syntax-tree.js';\r\nimport type { Stream } from '../utils/stream.js';\r\nimport type { AstNodeDescriptionProvider } from '../workspace/ast-descriptions.js';\r\nimport type { IndexManager } from '../workspace/index-manager.js';\r\nimport type { NameProvider } from './name-provider.js';\r\nimport type { Scope, ScopeOptions} from './scope.js';\r\nimport { MapScope, StreamScope } from './scope.js';\r\nimport { getDocument } from '../utils/ast-utils.js';\r\nimport { stream } from '../utils/stream.js';\r\nimport { WorkspaceCache } from '../utils/caching.js';\r\n\r\n/**\r\n * Language-specific service for determining the scope of target elements visible in a specific cross-reference context.\r\n */\r\nexport interface ScopeProvider {\r\n\r\n    /**\r\n     * Return a scope describing what elements are visible for the given AST node and cross-reference\r\n     * identifier.\r\n     *\r\n     * @param context Information about the reference for which a scope is requested.\r\n     */\r\n    getScope(context: ReferenceInfo): Scope;\r\n\r\n}\r\n\r\nexport class DefaultScopeProvider implements ScopeProvider {\r\n\r\n    protected readonly reflection: AstReflection;\r\n    protected readonly nameProvider: NameProvider;\r\n    protected readonly descriptions: AstNodeDescriptionProvider;\r\n    protected readonly indexManager: IndexManager;\r\n\r\n    protected readonly globalScopeCache: WorkspaceCache<string, Scope>;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.reflection = services.shared.AstReflection;\r\n        this.nameProvider = services.references.NameProvider;\r\n        this.descriptions = services.workspace.AstNodeDescriptionProvider;\r\n        this.indexManager = services.shared.workspace.IndexManager;\r\n        this.globalScopeCache = new WorkspaceCache<string, Scope>(services.shared);\r\n    }\r\n\r\n    getScope(context: ReferenceInfo): Scope {\r\n        const scopes: Array<Stream<AstNodeDescription>> = [];\r\n        const referenceType = this.reflection.getReferenceType(context);\r\n\r\n        const precomputed = getDocument(context.container).precomputedScopes;\r\n        if (precomputed) {\r\n            let currentNode: AstNode | undefined = context.container;\r\n            do {\r\n                const allDescriptions = precomputed.get(currentNode);\r\n                if (allDescriptions.length > 0) {\r\n                    scopes.push(stream(allDescriptions).filter(\r\n                        desc => this.reflection.isSubtype(desc.type, referenceType)));\r\n                }\r\n                currentNode = currentNode.$container;\r\n            } while (currentNode);\r\n        }\r\n\r\n        let result: Scope = this.getGlobalScope(referenceType, context);\r\n        for (let i = scopes.length - 1; i >= 0; i--) {\r\n            result = this.createScope(scopes[i], result);\r\n        }\r\n        return result;\r\n    }\r\n\r\n    /**\r\n     * Create a scope for the given collection of AST node descriptions.\r\n     */\r\n    protected createScope(elements: Iterable<AstNodeDescription>, outerScope?: Scope, options?: ScopeOptions): Scope {\r\n        return new StreamScope(stream(elements), outerScope, options);\r\n    }\r\n\r\n    /**\r\n     * Create a scope for the given collection of AST nodes, which need to be transformed into respective\r\n     * descriptions first. This is done using the `NameProvider` and `AstNodeDescriptionProvider` services.\r\n     */\r\n    protected createScopeForNodes(elements: Iterable<AstNode>, outerScope?: Scope, options?: ScopeOptions): Scope {\r\n        const s = stream(elements).map(e => {\r\n            const name = this.nameProvider.getName(e);\r\n            if (name) {\r\n                return this.descriptions.createDescription(e, name);\r\n            }\r\n            return undefined;\r\n        }).nonNullable();\r\n        return new StreamScope(s, outerScope, options);\r\n    }\r\n\r\n    /**\r\n     * Create a global scope filtered for the given reference type.\r\n     */\r\n    protected getGlobalScope(referenceType: string, _context: ReferenceInfo): Scope {\r\n        return this.globalScopeCache.get(referenceType, () => new MapScope(this.indexManager.allElements(referenceType)));\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { AstNode } from '../syntax-tree.js';\r\n\r\n/**\r\n * Language-specific service for locating an `AstNode` in a document.\r\n */\r\nexport interface AstNodeLocator {\r\n\r\n    /**\r\n     * Creates a path represented by a `string` that identifies an `AstNode` inside its document.\r\n     * It must be possible to retrieve exactly the same `AstNode` from the document using this path.\r\n     *\r\n     * @param node The `AstNode` for which to create the path.\r\n     * @returns a path represented by a `string` that identifies `node` inside its document.\r\n     * @see AstNodeLocator.getAstNode\r\n     */\r\n    getAstNodePath(node: AstNode): string;\r\n\r\n    /**\r\n     * Locates an `AstNode` inside another node by following the given path.\r\n     *\r\n     * @param node Parent element.\r\n     * @param path Describes how to locate the `AstNode` inside the given `node`.\r\n     * @returns The `AstNode` located under the given path, or `undefined` if the path cannot be resolved.\r\n     * @see AstNodeLocator.getAstNodePath\r\n     */\r\n    getAstNode<T extends AstNode = AstNode>(node: AstNode, path: string): T | undefined;\r\n\r\n}\r\n\r\nexport class DefaultAstNodeLocator implements AstNodeLocator {\r\n    protected segmentSeparator = '/';\r\n    protected indexSeparator = '@';\r\n\r\n    getAstNodePath(node: AstNode): string {\r\n        if (node.$container) {\r\n            const containerPath = this.getAstNodePath(node.$container);\r\n            const newSegment = this.getPathSegment(node);\r\n            const nodePath = containerPath + this.segmentSeparator + newSegment;\r\n            return nodePath;\r\n        }\r\n        return '';\r\n    }\r\n\r\n    protected getPathSegment({ $containerProperty, $containerIndex }: AstNode): string {\r\n        if (!$containerProperty) {\r\n            throw new Error(\"Missing '$containerProperty' in AST node.\");\r\n        }\r\n        if ($containerIndex !== undefined) {\r\n            return $containerProperty + this.indexSeparator + $containerIndex;\r\n        }\r\n        return $containerProperty;\r\n    }\r\n\r\n    getAstNode<T extends AstNode = AstNode>(node: AstNode, path: string): T | undefined {\r\n        const segments = path.split(this.segmentSeparator);\r\n        return segments.reduce((previousValue, currentValue) => {\r\n            if (!previousValue || currentValue.length === 0) {\r\n                return previousValue;\r\n            }\r\n            const propertyIndex = currentValue.indexOf(this.indexSeparator);\r\n            if (propertyIndex > 0) {\r\n                const property = currentValue.substring(0, propertyIndex);\r\n                const arrayIndex = parseInt(currentValue.substring(propertyIndex + 1));\r\n                const array = (previousValue as unknown as Record<string, AstNode[]>)[property];\r\n                return array?.[arrayIndex];\r\n            }\r\n            return (previousValue as unknown as Record<string, AstNode>)[currentValue];\r\n        }, node) as T;\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { CancellationToken, CancellationTokenSource, type AbstractCancellationTokenSource } from '../utils/cancellation.js';\r\n\r\nexport type MaybePromise<T> = T | Promise<T>\r\n\r\n/**\r\n * Delays the execution of the current code to the next tick of the event loop.\r\n * Don't call this method directly in a tight loop to prevent too many promises from being created.\r\n */\r\nexport function delayNextTick(): Promise<void> {\r\n    return new Promise(resolve => {\r\n        // In case we are running in a non-node environment, `setImmediate` isn't available.\r\n        // Using `setTimeout` of the browser API accomplishes the same result.\r\n        if (typeof setImmediate === 'undefined') {\r\n            setTimeout(resolve, 0);\r\n        } else {\r\n            setImmediate(resolve);\r\n        }\r\n    });\r\n}\r\n\r\nlet lastTick = 0;\r\nlet globalInterruptionPeriod = 10;\r\n\r\n/**\r\n * Reset the global interruption period and create a cancellation token source.\r\n */\r\nexport function startCancelableOperation(): AbstractCancellationTokenSource {\r\n    lastTick = performance.now();\r\n    return new CancellationTokenSource();\r\n}\r\n\r\n/**\r\n * Change the period duration for `interruptAndCheck` to the given number of milliseconds.\r\n * The default value is 10ms.\r\n */\r\nexport function setInterruptionPeriod(period: number): void {\r\n    globalInterruptionPeriod = period;\r\n}\r\n\r\n/**\r\n * This symbol may be thrown in an asynchronous context by any Langium service that receives\r\n * a `CancellationToken`. This means that the promise returned by such a service is rejected with\r\n * this symbol as rejection reason.\r\n */\r\nexport const OperationCancelled = Symbol('OperationCancelled');\r\n\r\n/**\r\n * Use this in a `catch` block to check whether the thrown object indicates that the operation\r\n * has been cancelled.\r\n */\r\nexport function isOperationCancelled(err: unknown): err is typeof OperationCancelled {\r\n    return err === OperationCancelled;\r\n}\r\n\r\n/**\r\n * This function does two things:\r\n *  1. Check the elapsed time since the last call to this function or to `startCancelableOperation`. If the predefined\r\n *     period (configured with `setInterruptionPeriod`) is exceeded, execution is delayed with `delayNextTick`.\r\n *  2. If the predefined period is not met yet or execution is resumed after an interruption, the given cancellation\r\n *     token is checked, and if cancellation is requested, `OperationCanceled` is thrown.\r\n *\r\n * All services in Langium that receive a `CancellationToken` may potentially call this function, so the\r\n * `CancellationToken` must be caught (with an `async` try-catch block or a `catch` callback attached to\r\n * the promise) to avoid that event being exposed as an error.\r\n */\r\nexport async function interruptAndCheck(token: CancellationToken): Promise<void> {\r\n    if (token === CancellationToken.None) {\r\n        // Early exit in case cancellation was disabled by the caller\r\n        return;\r\n    }\r\n    const current = performance.now();\r\n    if (current - lastTick >= globalInterruptionPeriod) {\r\n        lastTick = current;\r\n        await delayNextTick();\r\n        // prevent calling delayNextTick every iteration of loop\r\n        // where delayNextTick takes up the majority or all of the\r\n        // globalInterruptionPeriod itself\r\n        lastTick = performance.now();\r\n    }\r\n    if (token.isCancellationRequested) {\r\n        throw OperationCancelled;\r\n    }\r\n}\r\n\r\n/**\r\n * Simple implementation of the deferred pattern.\r\n * An object that exposes a promise and functions to resolve and reject it.\r\n */\r\nexport class Deferred<T = void> {\r\n    resolve: (value: T) => this;\r\n    reject: (err?: unknown) => this;\r\n\r\n    promise = new Promise<T>((resolve, reject) => {\r\n        this.resolve = (arg) => {\r\n            resolve(arg);\r\n            return this;\r\n        };\r\n        this.reject = (err) => {\r\n            reject(err);\r\n            return this;\r\n        };\r\n    });\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nexport interface Disposable {\r\n    /**\r\n     * Dispose this object.\r\n     */\r\n    dispose(): void;\r\n}\r\n\r\nexport interface AsyncDisposable {\r\n    /**\r\n     * Dispose this object.\r\n     */\r\n    dispose(): Promise<void>;\r\n}\r\n\r\nexport namespace Disposable {\r\n    export function create(callback: () => Promise<void>): AsyncDisposable;\r\n    export function create(callback: () => void): Disposable;\r\n    export function create(callback: () => void | Promise<void>): Disposable | AsyncDisposable {\r\n        return {\r\n            dispose: async () => await callback()\r\n        };\r\n    }\r\n}\r\n","import {\n  compact,\n  filter,\n  forEach,\n  isArray,\n  isEmpty,\n  isFunction,\n  isUndefined,\n  keys,\n  map,\n} from \"lodash-es\";\nimport { defineNameProp } from \"../../lang/lang_extensions.js\";\nimport { CstNode, ICstVisitor } from \"@chevrotain/types\";\n\nexport function defaultVisit<IN>(ctx: any, param: IN): void {\n  const childrenNames = keys(ctx);\n  const childrenNamesLength = childrenNames.length;\n  for (let i = 0; i < childrenNamesLength; i++) {\n    const currChildName = childrenNames[i];\n    const currChildArray = ctx[currChildName];\n    const currChildArrayLength = currChildArray.length;\n    for (let j = 0; j < currChildArrayLength; j++) {\n      const currChild: any = currChildArray[j];\n      // distinction between Tokens Children and CstNode children\n      if (currChild.tokenTypeIdx === undefined) {\n        this[currChild.name](currChild.children, param);\n      }\n    }\n  }\n  // defaultVisit does not support generic out param\n}\n\nexport function createBaseSemanticVisitorConstructor(\n  grammarName: string,\n  ruleNames: string[],\n): {\n  new (...args: any[]): ICstVisitor<any, any>;\n} {\n  const derivedConstructor: any = function () {};\n\n  // can be overwritten according to:\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/\n  // name?redirectlocale=en-US&redirectslug=JavaScript%2FReference%2FGlobal_Objects%2FFunction%2Fname\n  defineNameProp(derivedConstructor, grammarName + \"BaseSemantics\");\n\n  const semanticProto = {\n    visit: function (cstNode: CstNode | CstNode[], param: any) {\n      // enables writing more concise visitor methods when CstNode has only a single child\n      if (isArray(cstNode)) {\n        // A CST Node's children dictionary can never have empty arrays as values\n        // If a key is defined there will be at least one element in the corresponding value array.\n        cstNode = cstNode[0];\n      }\n\n      // enables passing optional CstNodes concisely.\n      if (isUndefined(cstNode)) {\n        return undefined;\n      }\n\n      return this[cstNode.name](cstNode.children, param);\n    },\n\n    validateVisitor: function () {\n      const semanticDefinitionErrors = validateVisitor(this, ruleNames);\n      if (!isEmpty(semanticDefinitionErrors)) {\n        const errorMessages = map(\n          semanticDefinitionErrors,\n          (currDefError) => currDefError.msg,\n        );\n        throw Error(\n          `Errors Detected in CST Visitor <${this.constructor.name}>:\\n\\t` +\n            `${errorMessages.join(\"\\n\\n\").replace(/\\n/g, \"\\n\\t\")}`,\n        );\n      }\n    },\n  };\n\n  derivedConstructor.prototype = semanticProto;\n  derivedConstructor.prototype.constructor = derivedConstructor;\n\n  derivedConstructor._RULE_NAMES = ruleNames;\n\n  return derivedConstructor;\n}\n\nexport function createBaseVisitorConstructorWithDefaults(\n  grammarName: string,\n  ruleNames: string[],\n  baseConstructor: Function,\n): {\n  new (...args: any[]): ICstVisitor<any, any>;\n} {\n  const derivedConstructor: any = function () {};\n\n  // can be overwritten according to:\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/\n  // name?redirectlocale=en-US&redirectslug=JavaScript%2FReference%2FGlobal_Objects%2FFunction%2Fname\n  defineNameProp(derivedConstructor, grammarName + \"BaseSemanticsWithDefaults\");\n\n  const withDefaultsProto = Object.create(baseConstructor.prototype);\n  forEach(ruleNames, (ruleName) => {\n    withDefaultsProto[ruleName] = defaultVisit;\n  });\n\n  derivedConstructor.prototype = withDefaultsProto;\n  derivedConstructor.prototype.constructor = derivedConstructor;\n\n  return derivedConstructor;\n}\n\nexport enum CstVisitorDefinitionError {\n  REDUNDANT_METHOD,\n  MISSING_METHOD,\n}\n\nexport interface IVisitorDefinitionError {\n  msg: string;\n  type: CstVisitorDefinitionError;\n  methodName: string;\n}\n\nexport function validateVisitor(\n  visitorInstance: ICstVisitor<unknown, unknown>,\n  ruleNames: string[],\n): IVisitorDefinitionError[] {\n  const missingErrors = validateMissingCstMethods(visitorInstance, ruleNames);\n\n  return missingErrors;\n}\n\nexport function validateMissingCstMethods(\n  visitorInstance: ICstVisitor<unknown, unknown>,\n  ruleNames: string[],\n): IVisitorDefinitionError[] {\n  const missingRuleNames = filter(ruleNames, (currRuleName) => {\n    return isFunction((visitorInstance as any)[currRuleName]) === false;\n  });\n\n  const errors: IVisitorDefinitionError[] = map(\n    missingRuleNames,\n    (currRuleName) => {\n      return {\n        msg: `Missing visitor method: <${currRuleName}> on ${<any>(\n          visitorInstance.constructor.name\n        )} CST Visitor.`,\n        type: CstVisitorDefinitionError.MISSING_METHOD,\n        methodName: currRuleName,\n      };\n    },\n  );\n\n  return compact<IVisitorDefinitionError>(errors);\n}\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { Stream } from './stream.js';\r\nimport { Reduction, stream } from './stream.js';\r\n\r\n/**\r\n * A multimap is a variation of a Map that has potentially multiple values for every key.\r\n */\r\nexport class MultiMap<K, V> {\r\n\r\n    private map = new Map<K, V[]>();\r\n\r\n    constructor()\r\n    constructor(elements: Array<[K, V]>)\r\n    constructor(elements?: Array<[K, V]>) {\r\n        if (elements) {\r\n            for (const [key, value] of elements) {\r\n                this.add(key, value);\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * The total number of values in the multimap.\r\n     */\r\n    get size(): number {\r\n        return Reduction.sum(stream(this.map.values()).map(a => a.length));\r\n    }\r\n\r\n    /**\r\n     * Clear all entries in the multimap.\r\n     */\r\n    clear(): void {\r\n        this.map.clear();\r\n    }\r\n\r\n    /**\r\n     * Operates differently depending on whether a `value` is given:\r\n     *  * With a value, this method deletes the specific key / value pair from the multimap.\r\n     *  * Without a value, all values associated with the given key are deleted.\r\n     *\r\n     * @returns `true` if a value existed and has been removed, or `false` if the specified\r\n     *     key / value does not exist.\r\n     */\r\n    delete(key: K, value?: V): boolean {\r\n        if (value === undefined) {\r\n            return this.map.delete(key);\r\n        } else {\r\n            const values = this.map.get(key);\r\n            if (values) {\r\n                const index = values.indexOf(value);\r\n                if (index >= 0) {\r\n                    if (values.length === 1) {\r\n                        this.map.delete(key);\r\n                    } else {\r\n                        values.splice(index, 1);\r\n                    }\r\n                    return true;\r\n                }\r\n            }\r\n            return false;\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Returns an array of all values associated with the given key. If no value exists,\r\n     * an empty array is returned.\r\n     *\r\n     * _Note:_ The returned array is assumed not to be modified. Use the `set` method to add a\r\n     * value and `delete` to remove a value from the multimap.\r\n     */\r\n    get(key: K): readonly V[] {\r\n        return this.map.get(key) ?? [];\r\n    }\r\n\r\n    /**\r\n     * Operates differently depending on whether a `value` is given:\r\n     *  * With a value, this method returns `true` if the specific key / value pair is present in the multimap.\r\n     *  * Without a value, this method returns `true` if the given key is present in the multimap.\r\n     */\r\n    has(key: K, value?: V): boolean {\r\n        if (value === undefined) {\r\n            return this.map.has(key);\r\n        } else {\r\n            const values = this.map.get(key);\r\n            if (values) {\r\n                return values.indexOf(value) >= 0;\r\n            }\r\n            return false;\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Add the given key / value pair to the multimap.\r\n     */\r\n    add(key: K, value: V): this {\r\n        if (this.map.has(key)) {\r\n            this.map.get(key)!.push(value);\r\n        } else {\r\n            this.map.set(key, [value]);\r\n        }\r\n        return this;\r\n    }\r\n\r\n    /**\r\n     * Add the given set of key / value pairs to the multimap.\r\n     */\r\n    addAll(key: K, values: Iterable<V>): this {\r\n        if (this.map.has(key)) {\r\n            this.map.get(key)!.push(...values);\r\n        } else {\r\n            this.map.set(key, Array.from(values));\r\n        }\r\n        return this;\r\n    }\r\n\r\n    /**\r\n     * Invokes the given callback function for every key / value pair in the multimap.\r\n     */\r\n    forEach(callbackfn: (value: V, key: K, map: this) => void): void {\r\n        this.map.forEach((array, key) =>\r\n            array.forEach(value => callbackfn(value, key, this))\r\n        );\r\n    }\r\n\r\n    /**\r\n     * Returns an iterator of key, value pairs for every entry in the map.\r\n     */\r\n    [Symbol.iterator](): Iterator<[K, V]> {\r\n        return this.entries().iterator();\r\n    }\r\n\r\n    /**\r\n     * Returns a stream of key, value pairs for every entry in the map.\r\n     */\r\n    entries(): Stream<[K, V]> {\r\n        return stream(this.map.entries())\r\n            .flatMap(([key, array]) => array.map(value => [key, value] as [K, V]));\r\n    }\r\n\r\n    /**\r\n     * Returns a stream of keys in the map.\r\n     */\r\n    keys(): Stream<K> {\r\n        return stream(this.map.keys());\r\n    }\r\n\r\n    /**\r\n     * Returns a stream of values in the map.\r\n     */\r\n    values(): Stream<V> {\r\n        return stream(this.map.values()).flat();\r\n    }\r\n\r\n    /**\r\n     * Returns a stream of key, value set pairs for every key in the map.\r\n     */\r\n    entriesGroupedByKey(): Stream<[K, V[]]> {\r\n        return stream(this.map.entries());\r\n    }\r\n\r\n}\r\n\r\nexport class BiMap<K, V> {\r\n\r\n    private map = new Map<K, V>();\r\n    private inverse = new Map<V, K>();\r\n\r\n    get size(): number {\r\n        return this.map.size;\r\n    }\r\n\r\n    constructor()\r\n    constructor(elements: Array<[K, V]>)\r\n    constructor(elements?: Array<[K, V]>) {\r\n        if (elements) {\r\n            for (const [key, value] of elements) {\r\n                this.set(key, value);\r\n            }\r\n        }\r\n    }\r\n\r\n    clear(): void {\r\n        this.map.clear();\r\n        this.inverse.clear();\r\n    }\r\n\r\n    set(key: K, value: V): this {\r\n        this.map.set(key, value);\r\n        this.inverse.set(value, key);\r\n        return this;\r\n    }\r\n\r\n    get(key: K): V | undefined {\r\n        return this.map.get(key);\r\n    }\r\n\r\n    getKey(value: V): K | undefined {\r\n        return this.inverse.get(value);\r\n    }\r\n\r\n    delete(key: K): boolean {\r\n        const value = this.map.get(key);\r\n        if (value !== undefined) {\r\n            this.map.delete(key);\r\n            this.inverse.delete(value);\r\n            return true;\r\n        }\r\n        return false;\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { InitializeParams, InitializedParams } from 'vscode-languageserver-protocol';\r\nimport type { WorkspaceFolder } from 'vscode-languageserver-types';\r\nimport type { ServiceRegistry } from '../service-registry.js';\r\nimport type { LangiumSharedCoreServices } from '../services.js';\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport { Deferred, interruptAndCheck } from '../utils/promise-utils.js';\r\nimport { URI, UriUtils } from '../utils/uri-utils.js';\r\nimport type { BuildOptions, DocumentBuilder } from './document-builder.js';\r\nimport type { LangiumDocument, LangiumDocuments } from './documents.js';\r\nimport type { FileSystemNode, FileSystemProvider } from './file-system-provider.js';\r\nimport type { WorkspaceLock } from './workspace-lock.js';\r\n\r\n// export type WorkspaceFolder from 'vscode-languageserver-types' for convenience,\r\n//  is supposed to avoid confusion as 'WorkspaceFolder' might accidentally be imported via 'vscode-languageclient'\r\nexport type { WorkspaceFolder };\r\n\r\n/**\r\n * The workspace manager is responsible for finding source files in the workspace.\r\n * This service is shared between all languages of a language server.\r\n */\r\nexport interface WorkspaceManager {\r\n\r\n    /** The options used for the initial workspace build. */\r\n    initialBuildOptions: BuildOptions | undefined;\r\n\r\n    /**\r\n     * A promise that resolves when the workspace manager is ready to be used.\r\n     * Use this to ensure that the workspace manager has finished its initialization.\r\n     */\r\n    readonly ready: Promise<void>;\r\n\r\n    /**\r\n     * The workspace folders of the current workspace.\r\n     * Available only after the `ready` promise resolves.\r\n     */\r\n    get workspaceFolders(): readonly WorkspaceFolder[] | undefined;\r\n\r\n    /**\r\n     * When used in a language server context, this method is called when the server receives\r\n     * the `initialize` request.\r\n     */\r\n    initialize(params: InitializeParams): void;\r\n\r\n    /**\r\n     * When used in a language server context, this method is called when the server receives\r\n     * the `initialized` notification.\r\n     */\r\n    initialized(params: InitializedParams): Promise<void>;\r\n\r\n    /**\r\n     * Does the initial indexing of workspace folders.\r\n     * Collects information about exported and referenced AstNodes in\r\n     * each language file and stores it locally.\r\n     *\r\n     * @param folders The set of workspace folders to be indexed.\r\n     * @param cancelToken A cancellation token that can be used to cancel the operation.\r\n     *\r\n     * @throws OperationCancelled if a cancellation event has been detected\r\n     */\r\n    initializeWorkspace(folders: WorkspaceFolder[], cancelToken?: CancellationToken): Promise<void>;\r\n\r\n}\r\n\r\nexport class DefaultWorkspaceManager implements WorkspaceManager {\r\n\r\n    initialBuildOptions: BuildOptions = {};\r\n\r\n    protected readonly serviceRegistry: ServiceRegistry;\r\n    protected readonly langiumDocuments: LangiumDocuments;\r\n    protected readonly documentBuilder: DocumentBuilder;\r\n    protected readonly fileSystemProvider: FileSystemProvider;\r\n    protected readonly mutex: WorkspaceLock;\r\n    protected readonly _ready = new Deferred<void>();\r\n    protected folders?: WorkspaceFolder[];\r\n\r\n    constructor(services: LangiumSharedCoreServices) {\r\n        this.serviceRegistry = services.ServiceRegistry;\r\n        this.langiumDocuments = services.workspace.LangiumDocuments;\r\n        this.documentBuilder = services.workspace.DocumentBuilder;\r\n        this.fileSystemProvider = services.workspace.FileSystemProvider;\r\n        this.mutex = services.workspace.WorkspaceLock;\r\n    }\r\n\r\n    get ready(): Promise<void> {\r\n        return this._ready.promise;\r\n    }\r\n\r\n    get workspaceFolders(): readonly WorkspaceFolder[] | undefined {\r\n        return this.folders;\r\n    }\r\n\r\n    initialize(params: InitializeParams): void {\r\n        this.folders = params.workspaceFolders ?? undefined;\r\n    }\r\n\r\n    initialized(_params: InitializedParams): Promise<void> {\r\n        // Initialize the workspace even if there are no workspace folders\r\n        // We still want to load additional documents (language library or similar) during initialization\r\n        return this.mutex.write(token => this.initializeWorkspace(this.folders ?? [], token));\r\n    }\r\n\r\n    async initializeWorkspace(folders: WorkspaceFolder[], cancelToken = CancellationToken.None): Promise<void> {\r\n        const documents = await this.performStartup(folders);\r\n        // Only after creating all documents do we check whether we need to cancel the initialization\r\n        // The document builder will later pick up on all unprocessed documents\r\n        await interruptAndCheck(cancelToken);\r\n        await this.documentBuilder.build(documents, this.initialBuildOptions, cancelToken);\r\n    }\r\n\r\n    /**\r\n     * Performs the uninterruptable startup sequence of the workspace manager.\r\n     * This methods loads all documents in the workspace and other documents and returns them.\r\n     */\r\n    protected async performStartup(folders: WorkspaceFolder[]): Promise<LangiumDocument[]> {\r\n        const fileExtensions = this.serviceRegistry.all.flatMap(e => e.LanguageMetaData.fileExtensions);\r\n        const documents: LangiumDocument[] = [];\r\n        const collector = (document: LangiumDocument) => {\r\n            documents.push(document);\r\n            if (!this.langiumDocuments.hasDocument(document.uri)) {\r\n                this.langiumDocuments.addDocument(document);\r\n            }\r\n        };\r\n        // Even though we don't await the initialization of the workspace manager,\r\n        // we can still assume that all library documents and file documents are loaded by the time we start building documents.\r\n        // The mutex prevents anything from performing a workspace build until we check the cancellation token\r\n        await this.loadAdditionalDocuments(folders, collector);\r\n        await Promise.all(\r\n            folders.map(wf => [wf, this.getRootFolder(wf)] as [WorkspaceFolder, URI])\r\n                .map(async entry => this.traverseFolder(...entry, fileExtensions, collector))\r\n        );\r\n        this._ready.resolve();\r\n        return documents;\r\n    }\r\n\r\n    /**\r\n     * Load all additional documents that shall be visible in the context of the given workspace\r\n     * folders and add them to the collector. This can be used to include built-in libraries of\r\n     * your language, which can be either loaded from provided files or constructed in memory.\r\n     */\r\n    protected loadAdditionalDocuments(_folders: WorkspaceFolder[], _collector: (document: LangiumDocument) => void): Promise<void> {\r\n        return Promise.resolve();\r\n    }\r\n\r\n    /**\r\n     * Determine the root folder of the source documents in the given workspace folder.\r\n     * The default implementation returns the URI of the workspace folder, but you can override\r\n     * this to return a subfolder like `src` instead.\r\n     */\r\n    protected getRootFolder(workspaceFolder: WorkspaceFolder): URI {\r\n        return URI.parse(workspaceFolder.uri);\r\n    }\r\n\r\n    /**\r\n     * Traverse the file system folder identified by the given URI and its subfolders. All\r\n     * contained files that match the file extensions are added to the collector.\r\n     */\r\n    protected async traverseFolder(workspaceFolder: WorkspaceFolder, folderPath: URI, fileExtensions: string[], collector: (document: LangiumDocument) => void): Promise<void> {\r\n        const content = await this.fileSystemProvider.readDirectory(folderPath);\r\n        await Promise.all(content.map(async entry => {\r\n            if (this.includeEntry(workspaceFolder, entry, fileExtensions)) {\r\n                if (entry.isDirectory) {\r\n                    await this.traverseFolder(workspaceFolder, entry.uri, fileExtensions, collector);\r\n                } else if (entry.isFile) {\r\n                    const document = await this.langiumDocuments.getOrCreateDocument(entry.uri);\r\n                    collector(document);\r\n                }\r\n            }\r\n        }));\r\n    }\r\n\r\n    /**\r\n     * Determine whether the given folder entry shall be included while indexing the workspace.\r\n     */\r\n    protected includeEntry(_workspaceFolder: WorkspaceFolder, entry: FileSystemNode, fileExtensions: string[]): boolean {\r\n        const name = UriUtils.basename(entry.uri);\r\n        if (name.startsWith('.')) {\r\n            return false;\r\n        }\r\n        if (entry.isDirectory) {\r\n            return name !== 'node_modules' && name !== 'out';\r\n        } else if (entry.isFile) {\r\n            const extname = UriUtils.extname(entry.uri);\r\n            return fileExtensions.includes(extname);\r\n        }\r\n        return false;\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { IToken, TokenType } from 'chevrotain';\r\nimport type { Range } from 'vscode-languageserver-types';\r\nimport type { AbstractElement } from '../languages/generated/ast.js';\r\nimport type { AstNode, CompositeCstNode, CstNode, LeafCstNode, RootCstNode } from '../syntax-tree.js';\r\nimport { Position } from 'vscode-languageserver-types';\r\nimport { tokenToRange } from '../utils/cst-utils.js';\r\n\r\nexport class CstNodeBuilder {\r\n\r\n    private rootNode!: RootCstNodeImpl;\r\n    private nodeStack: CompositeCstNodeImpl[] = [];\r\n\r\n    get current(): CompositeCstNodeImpl {\r\n        return this.nodeStack[this.nodeStack.length - 1] ?? this.rootNode;\r\n    }\r\n\r\n    buildRootNode(input: string): RootCstNode {\r\n        this.rootNode = new RootCstNodeImpl(input);\r\n        this.rootNode.root = this.rootNode;\r\n        this.nodeStack = [this.rootNode];\r\n        return this.rootNode;\r\n    }\r\n\r\n    buildCompositeNode(feature: AbstractElement): CompositeCstNode {\r\n        const compositeNode = new CompositeCstNodeImpl();\r\n        compositeNode.grammarSource = feature;\r\n        compositeNode.root = this.rootNode;\r\n        this.current.content.push(compositeNode);\r\n        this.nodeStack.push(compositeNode);\r\n        return compositeNode;\r\n    }\r\n\r\n    buildLeafNode(token: IToken, feature?: AbstractElement): LeafCstNode {\r\n        const leafNode = new LeafCstNodeImpl(token.startOffset, token.image.length, tokenToRange(token), token.tokenType, !feature);\r\n        leafNode.grammarSource = feature;\r\n        leafNode.root = this.rootNode;\r\n        this.current.content.push(leafNode);\r\n        return leafNode;\r\n    }\r\n\r\n    removeNode(node: CstNode): void {\r\n        const parent = node.container;\r\n        if (parent) {\r\n            const index = parent.content.indexOf(node);\r\n            if (index >= 0) {\r\n                parent.content.splice(index, 1);\r\n            }\r\n        }\r\n    }\r\n\r\n    addHiddenNodes(tokens: IToken[]): void {\r\n        const nodes: LeafCstNode[] = [];\r\n        for (const token of tokens) {\r\n            const leafNode = new LeafCstNodeImpl(token.startOffset, token.image.length, tokenToRange(token), token.tokenType, true);\r\n            leafNode.root = this.rootNode;\r\n            nodes.push(leafNode);\r\n        }\r\n        let current: CompositeCstNode = this.current;\r\n        let added = false;\r\n        // If we are within a composite node, we add the hidden nodes to the content\r\n        if (current.content.length > 0) {\r\n            current.content.push(...nodes);\r\n            return;\r\n        }\r\n        // Otherwise we are at a newly created node\r\n        // Instead of adding the hidden nodes here, we search for the first parent node with content\r\n        while (current.container) {\r\n            const index = current.container.content.indexOf(current);\r\n            if (index > 0) {\r\n                // Add the hidden nodes before the current node\r\n                current.container.content.splice(index, 0, ...nodes);\r\n                added = true;\r\n                break;\r\n            }\r\n            current = current.container;\r\n        }\r\n        // If we arrive at the root node, we add the hidden nodes at the beginning\r\n        // This is the case if the hidden nodes are the first nodes in the tree\r\n        if (!added) {\r\n            this.rootNode.content.unshift(...nodes);\r\n        }\r\n    }\r\n\r\n    construct(item: { $type: string | symbol | undefined, $cstNode: CstNode }): void {\r\n        const current: CstNode = this.current;\r\n        // The specified item could be a datatype ($type is symbol) or a fragment ($type is undefined)\r\n        // Only if the $type is a string, we actually assign the element\r\n        if (typeof item.$type === 'string') {\r\n            this.current.astNode = <AstNode>item;\r\n        }\r\n        item.$cstNode = current;\r\n        const node = this.nodeStack.pop();\r\n        // Empty composite nodes are not valid\r\n        // Simply remove the node from the tree\r\n        if (node?.content.length === 0) {\r\n            this.removeNode(node);\r\n        }\r\n    }\r\n}\r\n\r\nexport abstract class AbstractCstNode implements CstNode {\r\n    abstract get offset(): number;\r\n    abstract get length(): number;\r\n    abstract get end(): number;\r\n    abstract get range(): Range;\r\n\r\n    container?: CompositeCstNode;\r\n    grammarSource?: AbstractElement;\r\n    root: RootCstNode;\r\n    private _astNode?: AstNode;\r\n\r\n    /** @deprecated use `container` instead. */\r\n    get parent(): CompositeCstNode | undefined {\r\n        return this.container;\r\n    }\r\n\r\n    /** @deprecated use `grammarSource` instead. */\r\n    get feature(): AbstractElement | undefined {\r\n        return this.grammarSource;\r\n    }\r\n\r\n    get hidden(): boolean {\r\n        return false;\r\n    }\r\n\r\n    get astNode(): AstNode {\r\n        const node = typeof this._astNode?.$type === 'string' ? this._astNode : this.container?.astNode;\r\n        if (!node) {\r\n            throw new Error('This node has no associated AST element');\r\n        }\r\n        return node;\r\n    }\r\n\r\n    set astNode(value: AstNode | undefined) {\r\n        this._astNode = value;\r\n    }\r\n\r\n    /** @deprecated use `astNode` instead. */\r\n    get element(): AstNode {\r\n        return this.astNode;\r\n    }\r\n\r\n    get text(): string {\r\n        return this.root.fullText.substring(this.offset, this.end);\r\n    }\r\n}\r\n\r\nexport class LeafCstNodeImpl extends AbstractCstNode implements LeafCstNode {\r\n    get offset(): number {\r\n        return this._offset;\r\n    }\r\n\r\n    get length(): number {\r\n        return this._length;\r\n    }\r\n\r\n    get end(): number {\r\n        return this._offset + this._length;\r\n    }\r\n\r\n    override get hidden(): boolean {\r\n        return this._hidden;\r\n    }\r\n\r\n    get tokenType(): TokenType {\r\n        return this._tokenType;\r\n    }\r\n\r\n    get range(): Range {\r\n        return this._range;\r\n    }\r\n\r\n    private _hidden: boolean;\r\n    private _offset: number;\r\n    private _length: number;\r\n    private _range: Range;\r\n    private _tokenType: TokenType;\r\n\r\n    constructor(offset: number, length: number, range: Range, tokenType: TokenType, hidden = false) {\r\n        super();\r\n        this._hidden = hidden;\r\n        this._offset = offset;\r\n        this._tokenType = tokenType;\r\n        this._length = length;\r\n        this._range = range;\r\n    }\r\n}\r\n\r\nexport class CompositeCstNodeImpl extends AbstractCstNode implements CompositeCstNode {\r\n    readonly content: CstNode[] = new CstNodeContainer(this);\r\n    private _rangeCache?: Range;\r\n\r\n    /** @deprecated use `content` instead. */\r\n    get children(): CstNode[] {\r\n        return this.content;\r\n    }\r\n\r\n    get offset(): number {\r\n        return this.firstNonHiddenNode?.offset ?? 0;\r\n    }\r\n\r\n    get length(): number {\r\n        return this.end - this.offset;\r\n    }\r\n\r\n    get end(): number {\r\n        return this.lastNonHiddenNode?.end ?? 0;\r\n    }\r\n\r\n    get range(): Range {\r\n        const firstNode = this.firstNonHiddenNode;\r\n        const lastNode = this.lastNonHiddenNode;\r\n        if (firstNode && lastNode) {\r\n            if (this._rangeCache === undefined) {\r\n                const { range: firstRange } = firstNode;\r\n                const { range: lastRange } = lastNode;\r\n                this._rangeCache = { start: firstRange.start, end: lastRange.end.line < firstRange.start.line ? firstRange.start : lastRange.end };\r\n            }\r\n            return this._rangeCache;\r\n        } else {\r\n            return { start: Position.create(0, 0), end: Position.create(0, 0) };\r\n        }\r\n    }\r\n\r\n    private get firstNonHiddenNode(): CstNode | undefined {\r\n        for (const child of this.content) {\r\n            if (!child.hidden) {\r\n                return child;\r\n            }\r\n        }\r\n        return this.content[0];\r\n    }\r\n\r\n    private get lastNonHiddenNode(): CstNode | undefined {\r\n        for (let i = this.content.length - 1; i >= 0; i--) {\r\n            const child = this.content[i];\r\n            if (!child.hidden) {\r\n                return child;\r\n            }\r\n        }\r\n        return this.content[this.content.length - 1];\r\n    }\r\n}\r\n\r\nclass CstNodeContainer extends Array<CstNode> {\r\n    readonly parent: CompositeCstNode;\r\n\r\n    constructor(parent: CompositeCstNode) {\r\n        super();\r\n        this.parent = parent;\r\n        Object.setPrototypeOf(this, CstNodeContainer.prototype);\r\n    }\r\n\r\n    override push(...items: CstNode[]): number {\r\n        this.addParents(items);\r\n        return super.push(...items);\r\n    }\r\n\r\n    override unshift(...items: CstNode[]): number {\r\n        this.addParents(items);\r\n        return super.unshift(...items);\r\n    }\r\n\r\n    override splice(start: number, count: number, ...items: CstNode[]): CstNode[] {\r\n        this.addParents(items);\r\n        return super.splice(start, count, ...items);\r\n    }\r\n\r\n    private addParents(items: CstNode[]): void {\r\n        for (const item of items) {\r\n            (<AbstractCstNode>item).container = this.parent;\r\n        }\r\n    }\r\n}\r\n\r\nexport class RootCstNodeImpl extends CompositeCstNodeImpl implements RootCstNode {\r\n    private _text = '';\r\n\r\n    override get text(): string {\r\n        return this._text.substring(this.offset, this.end);\r\n    }\r\n\r\n    get fullText(): string {\r\n        return this._text;\r\n    }\r\n\r\n    constructor(input?: string) {\r\n        super();\r\n        this._text = input ?? '';\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { URI } from '../utils/uri-utils.js';\r\nimport type { NameProvider } from '../references/name-provider.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, AstNodeDescription, ReferenceInfo } from '../syntax-tree.js';\r\nimport type { AstNodeLocator } from './ast-node-locator.js';\r\nimport type { DocumentSegment, LangiumDocument } from './documents.js';\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport { isLinkingError } from '../syntax-tree.js';\r\nimport { getDocument, streamAst, streamReferences } from '../utils/ast-utils.js';\r\nimport { toDocumentSegment } from '../utils/cst-utils.js';\r\nimport { interruptAndCheck } from '../utils/promise-utils.js';\r\nimport { UriUtils } from '../utils/uri-utils.js';\r\n\r\n/**\r\n * Language-specific service for creating descriptions of AST nodes to be used for cross-reference resolutions.\r\n */\r\nexport interface AstNodeDescriptionProvider {\r\n\r\n    /**\r\n     * Create a description for the given AST node. This service method is typically used while indexing\r\n     * the contents of a document and during scope computation.\r\n     *\r\n     * @param node An AST node.\r\n     * @param name The name to be used to refer to the AST node. By default, this is determined by the\r\n     *     `NameProvider` service, but alternative names may be provided according to the semantics\r\n     *     of your language.\r\n     * @param document The document containing the AST node. If omitted, it is taken from the root AST node.\r\n     */\r\n    createDescription(node: AstNode, name: string | undefined, document?: LangiumDocument): AstNodeDescription;\r\n\r\n}\r\n\r\nexport class DefaultAstNodeDescriptionProvider implements AstNodeDescriptionProvider {\r\n\r\n    protected readonly astNodeLocator: AstNodeLocator;\r\n    protected readonly nameProvider: NameProvider;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.astNodeLocator = services.workspace.AstNodeLocator;\r\n        this.nameProvider = services.references.NameProvider;\r\n    }\r\n\r\n    createDescription(node: AstNode, name: string | undefined, document?: LangiumDocument): AstNodeDescription {\r\n        const doc = document ?? getDocument(node);\r\n        name ??= this.nameProvider.getName(node);\r\n        const path = this.astNodeLocator.getAstNodePath(node);\r\n        if (!name) {\r\n            throw new Error(`Node at path ${path} has no name.`);\r\n        }\r\n        let nameNodeSegment: DocumentSegment | undefined;\r\n        const nameSegmentGetter = () => nameNodeSegment ??= toDocumentSegment(this.nameProvider.getNameNode(node) ?? node.$cstNode);\r\n        return {\r\n            node,\r\n            name,\r\n            get nameSegment() {\r\n                return nameSegmentGetter();\r\n            },\r\n            selectionSegment: toDocumentSegment(node.$cstNode),\r\n            type: node.$type,\r\n            documentUri: doc.uri,\r\n            path\r\n        };\r\n    }\r\n\r\n}\r\n\r\n/**\r\n * Describes a cross-reference within a document or between two documents.\r\n */\r\nexport interface ReferenceDescription {\r\n    /** URI of the document that holds a reference */\r\n    sourceUri: URI\r\n    /** Path to AstNode that holds a reference */\r\n    sourcePath: string\r\n    /** Target document uri */\r\n    targetUri: URI\r\n    /** Path to the target AstNode inside the document */\r\n    targetPath: string\r\n    /** Segment of the reference text. */\r\n    segment: DocumentSegment\r\n    /** Marks a local reference i.e. a cross reference inside a document.   */\r\n    local?: boolean\r\n}\r\n\r\n/**\r\n * Language-specific service to create descriptions of all cross-references in a document. These are used by the `IndexManager`\r\n * to determine which documents are affected and should be rebuilt when a document is changed.\r\n */\r\nexport interface ReferenceDescriptionProvider {\r\n    /**\r\n     * Create descriptions of all cross-references found in the given document. These descriptions are\r\n     * gathered by the `IndexManager` and stored in the global index so they can be considered when\r\n     * a document change is reported by the client.\r\n     *\r\n     * @param document The document in which to gather cross-references.\r\n     * @param cancelToken Indicates when to cancel the current operation.\r\n     * @throws `OperationCanceled` if a user action occurs during execution\r\n     */\r\n    createDescriptions(document: LangiumDocument, cancelToken?: CancellationToken): Promise<ReferenceDescription[]>;\r\n}\r\n\r\nexport class DefaultReferenceDescriptionProvider implements ReferenceDescriptionProvider {\r\n\r\n    protected readonly nodeLocator: AstNodeLocator;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.nodeLocator = services.workspace.AstNodeLocator;\r\n    }\r\n\r\n    async createDescriptions(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<ReferenceDescription[]> {\r\n        const descr: ReferenceDescription[] = [];\r\n        const rootNode = document.parseResult.value;\r\n        for (const astNode of streamAst(rootNode)) {\r\n            await interruptAndCheck(cancelToken);\r\n            streamReferences(astNode).filter(refInfo => !isLinkingError(refInfo)).forEach(refInfo => {\r\n                // TODO: Consider logging a warning or throw an exception when DocumentState is < than Linked\r\n                const description = this.createDescription(refInfo);\r\n                if (description) {\r\n                    descr.push(description);\r\n                }\r\n            });\r\n        }\r\n        return descr;\r\n    }\r\n\r\n    protected createDescription(refInfo: ReferenceInfo): ReferenceDescription | undefined {\r\n        const targetNodeDescr = refInfo.reference.$nodeDescription;\r\n        const refCstNode = refInfo.reference.$refNode;\r\n        if (!targetNodeDescr || !refCstNode) {\r\n            return undefined;\r\n        }\r\n        const docUri = getDocument(refInfo.container).uri;\r\n        return {\r\n            sourceUri: docUri,\r\n            sourcePath: this.nodeLocator.getAstNodePath(refInfo.container),\r\n            targetUri: targetNodeDescr.documentUri,\r\n            targetPath: targetNodeDescr.path,\r\n            segment: toDocumentSegment(refCstNode),\r\n            local: UriUtils.equals(targetNodeDescr.documentUri, docUri)\r\n        };\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { URI, Utils } from 'vscode-uri';\r\n\r\nexport { URI };\r\n\r\nexport namespace UriUtils {\r\n\r\n    export const basename = Utils.basename;\r\n    export const dirname = Utils.dirname;\r\n    export const extname = Utils.extname;\r\n    export const joinPath = Utils.joinPath;\r\n    export const resolvePath = Utils.resolvePath;\r\n\r\n    export function equals(a?: URI | string, b?: URI | string): boolean {\r\n        return a?.toString() === b?.toString();\r\n    }\r\n\r\n    export function relative(from: URI | string, to: URI | string): string {\r\n        const fromPath = typeof from === 'string' ? from : from.path;\r\n        const toPath = typeof to === 'string' ? to : to.path;\r\n        const fromParts = fromPath.split('/').filter(e => e.length > 0);\r\n        const toParts = toPath.split('/').filter(e => e.length > 0);\r\n        let i = 0;\r\n        for (; i < fromParts.length; i++) {\r\n            if (fromParts[i] !== toParts[i]) {\r\n                break;\r\n            }\r\n        }\r\n        const backPart = '../'.repeat(fromParts.length - i);\r\n        const toPart = toParts.slice(i).join('/');\r\n        return backPart + toPart;\r\n    }\r\n\r\n    export function normalize(uri: URI | string): string {\r\n        return URI.parse(uri.toString()).toString();\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { Emitter } from '../utils/event.js';\r\nimport type {\r\n    ConfigurationItem,\r\n    DidChangeConfigurationParams,\r\n    DidChangeConfigurationRegistrationOptions,\r\n    Disposable,\r\n    Event,\r\n    InitializeParams,\r\n    InitializedParams\r\n} from 'vscode-languageserver-protocol';\r\nimport type { ServiceRegistry } from '../service-registry.js';\r\nimport type { LangiumSharedCoreServices } from '../services.js';\r\nimport { Deferred } from '../utils/promise-utils.js';\r\n\r\n/* eslint-disable @typescript-eslint/no-explicit-any */\r\n\r\nexport interface ConfigurationProvider {\r\n\r\n    /**\r\n     * A promise that resolves when the configuration provider is ready to be used.\r\n     */\r\n    readonly ready: Promise<void>;\r\n\r\n    /**\r\n     * When used in a language server context, this method is called when the server receives\r\n     * the `initialize` request.\r\n     */\r\n    initialize(params: InitializeParams): void;\r\n\r\n    /**\r\n     * When used in a language server context, this method is called when the server receives\r\n     * the `initialized` notification.\r\n     */\r\n    initialized(params: ConfigurationInitializedParams): Promise<void>;\r\n\r\n    /**\r\n     * Returns a configuration value stored for the given language.\r\n     *\r\n     * @param language The language id\r\n     * @param configuration Configuration name\r\n     */\r\n    getConfiguration(language: string, configuration: string): Promise<any>;\r\n\r\n    /**\r\n     *  Updates the cached configurations using the `change` notification parameters.\r\n     *\r\n     * @param change The parameters of a change configuration notification.\r\n     * `settings` property of the change object could be expressed as `Record<string, Record<string, any>>`\r\n     */\r\n    updateConfiguration(change: DidChangeConfigurationParams): void;\r\n\r\n    /**\r\n     * Get notified after a configuration section has been updated.\r\n     */\r\n    onConfigurationSectionUpdate(callback: ConfigurationSectionUpdateListener): Disposable\r\n}\r\n\r\nexport interface ConfigurationInitializedParams extends InitializedParams {\r\n    register?: (params: DidChangeConfigurationRegistrationOptions) => void,\r\n    fetchConfiguration?: (configuration: ConfigurationItem[]) => Promise<any>\r\n}\r\n\r\nexport interface ConfigurationSectionUpdate {\r\n    /**\r\n     * The name of the configuration section that has been updated.\r\n     */\r\n    section: string;\r\n\r\n    /**\r\n     * The updated configuration section.\r\n     */\r\n    configuration: any;\r\n}\r\n\r\nexport type ConfigurationSectionUpdateListener = (update: ConfigurationSectionUpdate) => void;\r\n\r\n/**\r\n * Base configuration provider for building up other configuration providers\r\n */\r\nexport class DefaultConfigurationProvider implements ConfigurationProvider {\r\n\r\n    protected readonly serviceRegistry: ServiceRegistry;\r\n    protected readonly _ready = new Deferred<void>();\r\n    protected settings: Record<string, Record<string, any>> = {};\r\n    protected workspaceConfig = false;\r\n    protected onConfigurationSectionUpdateEmitter = new Emitter<ConfigurationSectionUpdate>();\r\n\r\n    constructor(services: LangiumSharedCoreServices) {\r\n        this.serviceRegistry = services.ServiceRegistry;\r\n    }\r\n\r\n    get ready(): Promise<void> {\r\n        return this._ready.promise;\r\n    }\r\n\r\n    initialize(params: InitializeParams): void {\r\n        this.workspaceConfig = params.capabilities.workspace?.configuration ?? false;\r\n    }\r\n\r\n    async initialized(params: ConfigurationInitializedParams): Promise<void> {\r\n        if (this.workspaceConfig) {\r\n            if (params.register) {\r\n                // params.register(...) is a function to be provided by the calling language server for the sake of\r\n                //  decoupling this implementation from the concrete LSP implementations, specifically the LSP Connection\r\n\r\n                const languages = this.serviceRegistry.all;\r\n                params.register({\r\n                    // Listen to configuration changes for all languages\r\n                    section: languages.map(lang => this.toSectionName(lang.LanguageMetaData.languageId))\r\n                });\r\n            }\r\n\r\n            if (params.fetchConfiguration) {\r\n                // params.fetchConfiguration(...) is a function to be provided by the calling language server for the sake of\r\n                //  decoupling this implementation from the concrete LSP implementations, specifically the LSP Connection\r\n                const configToUpdate = this.serviceRegistry.all.map(lang => <ConfigurationItem>{\r\n                    // Fetch the configuration changes for all languages\r\n                    section: this.toSectionName(lang.LanguageMetaData.languageId)\r\n                });\r\n\r\n                // get workspace configurations (default scope URI)\r\n                const configs = await params.fetchConfiguration(configToUpdate);\r\n                configToUpdate.forEach((conf, idx) => {\r\n                    this.updateSectionConfiguration(conf.section!, configs[idx]);\r\n                });\r\n            }\r\n        }\r\n        this._ready.resolve();\r\n    }\r\n\r\n    /**\r\n     *  Updates the cached configurations using the `change` notification parameters.\r\n     *\r\n     * @param change The parameters of a change configuration notification.\r\n     * `settings` property of the change object could be expressed as `Record<string, Record<string, any>>`\r\n     */\r\n    updateConfiguration(change: DidChangeConfigurationParams): void {\r\n        if (!change.settings) {\r\n            return;\r\n        }\r\n        Object.keys(change.settings).forEach(section => {\r\n            const configuration = change.settings[section];\r\n            this.updateSectionConfiguration(section, configuration);\r\n            this.onConfigurationSectionUpdateEmitter.fire({ section, configuration });\r\n        });\r\n    }\r\n\r\n    protected updateSectionConfiguration(section: string, configuration: any): void {\r\n        this.settings[section] = configuration;\r\n    }\r\n\r\n    /**\r\n    * Returns a configuration value stored for the given language.\r\n    *\r\n    * @param language The language id\r\n    * @param configuration Configuration name\r\n    */\r\n    async getConfiguration(language: string, configuration: string): Promise<any> {\r\n        await this.ready;\r\n\r\n        const sectionName = this.toSectionName(language);\r\n        if (this.settings[sectionName]) {\r\n            return this.settings[sectionName][configuration];\r\n        }\r\n    }\r\n\r\n    protected toSectionName(languageId: string): string {\r\n        return `${languageId}`;\r\n    }\r\n\r\n    get onConfigurationSectionUpdate(): Event<ConfigurationSectionUpdate> {\r\n        return this.onConfigurationSectionUpdateEmitter.event;\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { AstNodeDescription } from '../syntax-tree.js';\r\nimport type { Stream } from '../utils/stream.js';\r\nimport { EMPTY_STREAM, stream } from '../utils/stream.js';\r\n\r\n/**\r\n * A scope describes what target elements are visible from a specific cross-reference context.\r\n */\r\nexport interface Scope {\r\n\r\n    /**\r\n     * Find a target element matching the given name. If no element is found, `undefined` is returned.\r\n     * If multiple matching elements are present, the selection of the returned element should be done\r\n     * according to the semantics of your language. Usually it is the element that is most closely defined.\r\n     *\r\n     * @param name Name of the cross-reference target as it appears in the source text.\r\n     */\r\n    getElement(name: string): AstNodeDescription | undefined;\r\n\r\n    /**\r\n     * Create a stream of all elements in the scope. This is used to compute completion proposals to be\r\n     * shown in the editor.\r\n     */\r\n    getAllElements(): Stream<AstNodeDescription>;\r\n\r\n}\r\n\r\nexport interface ScopeOptions {\r\n    caseInsensitive?: boolean;\r\n}\r\n\r\n/**\r\n * The default scope implementation is based on a `Stream`. It has an optional _outer scope_ describing\r\n * the next level of elements, which are queried when a target element is not found in the stream provided\r\n * to this scope.\r\n */\r\nexport class StreamScope implements Scope {\r\n    readonly elements: Stream<AstNodeDescription>;\r\n    readonly outerScope?: Scope;\r\n    readonly caseInsensitive: boolean;\r\n\r\n    constructor(elements: Stream<AstNodeDescription>, outerScope?: Scope, options?: ScopeOptions) {\r\n        this.elements = elements;\r\n        this.outerScope = outerScope;\r\n        this.caseInsensitive = options?.caseInsensitive ?? false;\r\n    }\r\n\r\n    getAllElements(): Stream<AstNodeDescription> {\r\n        if (this.outerScope) {\r\n            return this.elements.concat(this.outerScope.getAllElements());\r\n        } else {\r\n            return this.elements;\r\n        }\r\n    }\r\n\r\n    getElement(name: string): AstNodeDescription | undefined {\r\n        const local = this.caseInsensitive\r\n            ? this.elements.find(e => e.name.toLowerCase() === name.toLowerCase())\r\n            : this.elements.find(e => e.name === name);\r\n        if (local) {\r\n            return local;\r\n        }\r\n        if (this.outerScope) {\r\n            return this.outerScope.getElement(name);\r\n        }\r\n        return undefined;\r\n    }\r\n}\r\n\r\nexport class MapScope implements Scope {\r\n    readonly elements: Map<string, AstNodeDescription>;\r\n    readonly outerScope?: Scope;\r\n    readonly caseInsensitive: boolean;\r\n\r\n    constructor(elements: Iterable<AstNodeDescription>, outerScope?: Scope, options?: ScopeOptions) {\r\n        this.elements = new Map();\r\n        this.caseInsensitive = options?.caseInsensitive ?? false;\r\n        for (const element of elements) {\r\n            const name = this.caseInsensitive\r\n                ? element.name.toLowerCase()\r\n                : element.name;\r\n            this.elements.set(name, element);\r\n        }\r\n        this.outerScope = outerScope;\r\n    }\r\n\r\n    getElement(name: string): AstNodeDescription | undefined {\r\n        const localName = this.caseInsensitive ? name.toLowerCase() : name;\r\n        const local = this.elements.get(localName);\r\n        if (local) {\r\n            return local;\r\n        }\r\n        if (this.outerScope) {\r\n            return this.outerScope.getElement(name);\r\n        }\r\n        return undefined;\r\n    }\r\n\r\n    getAllElements(): Stream<AstNodeDescription> {\r\n        let elementStream = stream(this.elements.values());\r\n        if (this.outerScope) {\r\n            elementStream = elementStream.concat(this.outerScope.getAllElements());\r\n        }\r\n        return elementStream;\r\n    }\r\n\r\n}\r\n\r\nexport const EMPTY_SCOPE: Scope = {\r\n    getElement(): undefined {\r\n        return undefined;\r\n    },\r\n    getAllElements(): Stream<AstNodeDescription> {\r\n        return EMPTY_STREAM;\r\n    }\r\n};\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\n/* eslint-disable @typescript-eslint/no-explicit-any */\r\nimport type { DSLMethodOpts, ILexingError, IOrAlt, IParserErrorMessageProvider, IRecognitionException, IToken, TokenType, TokenVocabulary } from 'chevrotain';\r\nimport type { AbstractElement, Action, Assignment, ParserRule } from '../languages/generated/ast.js';\r\nimport type { Linker } from '../references/linker.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, AstReflection, CompositeCstNode, CstNode } from '../syntax-tree.js';\r\nimport type { Lexer, LexerResult } from './lexer.js';\r\nimport type { IParserConfig } from './parser-config.js';\r\nimport type { ValueConverter } from './value-converter.js';\r\nimport { defaultParserErrorProvider, EmbeddedActionsParser, LLkLookaheadStrategy } from 'chevrotain';\r\nimport { LLStarLookaheadStrategy } from 'chevrotain-allstar';\r\nimport { isAssignment, isCrossReference, isKeyword } from '../languages/generated/ast.js';\r\nimport { getExplicitRuleType, isDataTypeRule } from '../utils/grammar-utils.js';\r\nimport { assignMandatoryProperties, getContainerOfType, linkContentToContainer } from '../utils/ast-utils.js';\r\nimport { CstNodeBuilder } from './cst-node-builder.js';\r\nimport type { LexingReport } from './token-builder.js';\r\n\r\nexport type ParseResult<T = AstNode> = {\r\n    value: T,\r\n    parserErrors: IRecognitionException[],\r\n    lexerErrors: ILexingError[],\r\n    lexerReport?: LexingReport\r\n}\r\n\r\nexport const DatatypeSymbol = Symbol('Datatype');\r\n\r\ninterface DataTypeNode {\r\n    $cstNode: CompositeCstNode\r\n    /** Instead of a string, this node is uniquely identified by the `Datatype` symbol */\r\n    $type: symbol\r\n    /** Used as a storage for all parsed terminals, keywords and sub-datatype rules */\r\n    value: string\r\n}\r\n\r\nfunction isDataTypeNode(node: { $type: string | symbol | undefined }): node is DataTypeNode {\r\n    return node.$type === DatatypeSymbol;\r\n}\r\n\r\ntype RuleResult = (args: Args) => any;\r\n\r\ntype Args = Record<string, boolean>;\r\n\r\ntype RuleImpl = (args: Args) => any;\r\n\r\ninterface AssignmentElement {\r\n    assignment?: Assignment\r\n    isCrossRef: boolean\r\n}\r\n\r\n/**\r\n * Base interface for all parsers. Mainly used by the `parser-builder-base.ts` to perform work on different kinds of parsers.\r\n * The main use cases are:\r\n * * AST parser: Based on a string, create an AST for the current grammar\r\n * * Completion parser: Based on a partial string, identify the current position of the input within the grammar\r\n */\r\nexport interface BaseParser {\r\n    /**\r\n     * Adds a new parser rule to the parser\r\n     */\r\n    rule(rule: ParserRule, impl: RuleImpl): RuleResult;\r\n    /**\r\n     * Returns the executable rule function for the specified rule name\r\n     */\r\n    getRule(name: string): RuleResult | undefined;\r\n    /**\r\n     * Performs alternatives parsing (the `|` operation in EBNF/Langium)\r\n     */\r\n    alternatives(idx: number, choices: Array<IOrAlt<any>>): void;\r\n    /**\r\n     * Parses the callback as optional (the `?` operation in EBNF/Langium)\r\n     */\r\n    optional(idx: number, callback: DSLMethodOpts<unknown>): void;\r\n    /**\r\n     * Parses the callback 0 or more times (the `*` operation in EBNF/Langium)\r\n     */\r\n    many(idx: number, callback: DSLMethodOpts<unknown>): void;\r\n    /**\r\n     * Parses the callback 1 or more times (the `+` operation in EBNF/Langium)\r\n     */\r\n    atLeastOne(idx: number, callback: DSLMethodOpts<unknown>): void;\r\n    /**\r\n     * Consumes a specific token type from the token input stream.\r\n     * Requires a unique index within the rule for a specific token type.\r\n     */\r\n    consume(idx: number, tokenType: TokenType, feature: AbstractElement): void;\r\n    /**\r\n     * Invokes the executable function for a given parser rule.\r\n     * Requires a unique index within the rule for a specific sub rule.\r\n     * Arguments can be supplied to the rule invocation for semantic predicates\r\n     */\r\n    subrule(idx: number, rule: RuleResult, fragment: boolean, feature: AbstractElement, args: Args): void;\r\n    /**\r\n     * Executes a grammar action that modifies the currently active AST node\r\n     */\r\n    action($type: string, action: Action): void;\r\n    /**\r\n     * Finishes construction of the current AST node. Only used by the AST parser.\r\n     */\r\n    construct(): unknown;\r\n    /**\r\n     * Whether the parser is currently actually in use or in \"recording mode\".\r\n     * Recording mode is activated once when the parser is analyzing itself.\r\n     * During this phase, no input exists and therefore no AST should be constructed\r\n     */\r\n    isRecording(): boolean;\r\n    /**\r\n     * Current state of the unordered groups\r\n     */\r\n    get unorderedGroups(): Map<string, boolean[]>;\r\n    /**\r\n     * The rule stack indicates the indices of rules that are currently invoked,\r\n     * in order of their invocation.\r\n     */\r\n    getRuleStack(): number[];\r\n}\r\n\r\nconst ruleSuffix = '\\u200B';\r\nconst withRuleSuffix = (name: string): string => name.endsWith(ruleSuffix) ? name : name + ruleSuffix;\r\n\r\nexport abstract class AbstractLangiumParser implements BaseParser {\r\n\r\n    protected readonly lexer: Lexer;\r\n    protected readonly wrapper: ChevrotainWrapper;\r\n    protected _unorderedGroups: Map<string, boolean[]> = new Map<string, boolean[]>();\r\n\r\n    protected allRules = new Map<string, RuleResult>();\r\n    protected mainRule!: RuleResult;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.lexer = services.parser.Lexer;\r\n        const tokens = this.lexer.definition;\r\n        const production = services.LanguageMetaData.mode === 'production';\r\n        this.wrapper = new ChevrotainWrapper(tokens, {\r\n            ...services.parser.ParserConfig,\r\n            skipValidations: production,\r\n            errorMessageProvider: services.parser.ParserErrorMessageProvider\r\n        });\r\n    }\r\n\r\n    alternatives(idx: number, choices: Array<IOrAlt<any>>): void {\r\n        this.wrapper.wrapOr(idx, choices);\r\n    }\r\n\r\n    optional(idx: number, callback: DSLMethodOpts<unknown>): void {\r\n        this.wrapper.wrapOption(idx, callback);\r\n    }\r\n\r\n    many(idx: number, callback: DSLMethodOpts<unknown>): void {\r\n        this.wrapper.wrapMany(idx, callback);\r\n    }\r\n\r\n    atLeastOne(idx: number, callback: DSLMethodOpts<unknown>): void {\r\n        this.wrapper.wrapAtLeastOne(idx, callback);\r\n    }\r\n\r\n    abstract rule(rule: ParserRule, impl: RuleImpl): RuleResult;\r\n    abstract consume(idx: number, tokenType: TokenType, feature: AbstractElement): void;\r\n    abstract subrule(idx: number, rule: RuleResult, fragment: boolean, feature: AbstractElement, args: Args): void;\r\n    abstract action($type: string, action: Action): void;\r\n    abstract construct(): unknown;\r\n\r\n    getRule(name: string): RuleResult | undefined {\r\n        return this.allRules.get(name);\r\n    }\r\n\r\n    isRecording(): boolean {\r\n        return this.wrapper.IS_RECORDING;\r\n    }\r\n\r\n    get unorderedGroups(): Map<string, boolean[]> {\r\n        return this._unorderedGroups;\r\n    }\r\n\r\n    getRuleStack(): number[] {\r\n        return (this.wrapper as any).RULE_STACK;\r\n    }\r\n\r\n    finalize(): void {\r\n        this.wrapper.wrapSelfAnalysis();\r\n    }\r\n}\r\n\r\nexport interface ParserOptions {\r\n    rule?: string\r\n}\r\n\r\nexport class LangiumParser extends AbstractLangiumParser {\r\n    private readonly linker: Linker;\r\n    private readonly converter: ValueConverter;\r\n    private readonly astReflection: AstReflection;\r\n    private readonly nodeBuilder = new CstNodeBuilder();\r\n    private lexerResult?: LexerResult;\r\n    private stack: any[] = [];\r\n    private assignmentMap = new Map<AbstractElement, AssignmentElement | undefined>();\r\n\r\n    private get current(): any {\r\n        return this.stack[this.stack.length - 1];\r\n    }\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        super(services);\r\n        this.linker = services.references.Linker;\r\n        this.converter = services.parser.ValueConverter;\r\n        this.astReflection = services.shared.AstReflection;\r\n    }\r\n\r\n    rule(rule: ParserRule, impl: RuleImpl): RuleResult {\r\n        const type = this.computeRuleType(rule);\r\n        const ruleMethod = this.wrapper.DEFINE_RULE(withRuleSuffix(rule.name), this.startImplementation(type, impl).bind(this));\r\n        this.allRules.set(rule.name, ruleMethod);\r\n        if (rule.entry) {\r\n            this.mainRule = ruleMethod;\r\n        }\r\n        return ruleMethod;\r\n    }\r\n\r\n    private computeRuleType(rule: ParserRule): string | symbol | undefined {\r\n        if (rule.fragment) {\r\n            return undefined;\r\n        } else if (isDataTypeRule(rule)) {\r\n            return DatatypeSymbol;\r\n        } else {\r\n            const explicit = getExplicitRuleType(rule);\r\n            return explicit ?? rule.name;\r\n        }\r\n    }\r\n\r\n    parse<T extends AstNode = AstNode>(input: string, options: ParserOptions = {}): ParseResult<T> {\r\n        this.nodeBuilder.buildRootNode(input);\r\n        const lexerResult = this.lexerResult = this.lexer.tokenize(input);\r\n        this.wrapper.input = lexerResult.tokens;\r\n        const ruleMethod = options.rule ? this.allRules.get(options.rule) : this.mainRule;\r\n        if (!ruleMethod) {\r\n            throw new Error(options.rule ? `No rule found with name '${options.rule}'` : 'No main rule available.');\r\n        }\r\n        const result = ruleMethod.call(this.wrapper, {});\r\n        this.nodeBuilder.addHiddenNodes(lexerResult.hidden);\r\n        this.unorderedGroups.clear();\r\n        this.lexerResult = undefined;\r\n        return {\r\n            value: result,\r\n            lexerErrors: lexerResult.errors,\r\n            lexerReport: lexerResult.report,\r\n            parserErrors: this.wrapper.errors\r\n        };\r\n    }\r\n\r\n    private startImplementation($type: string | symbol | undefined, implementation: RuleImpl): RuleImpl {\r\n        return (args) => {\r\n            // Only create a new AST node in case the calling rule is not a fragment rule\r\n            const createNode = !this.isRecording() && $type !== undefined;\r\n            if (createNode) {\r\n                const node: any = { $type };\r\n                this.stack.push(node);\r\n                if ($type === DatatypeSymbol) {\r\n                    node.value = '';\r\n                }\r\n            }\r\n            let result: unknown;\r\n            try {\r\n                result = implementation(args);\r\n            } catch (err) {\r\n                result = undefined;\r\n            }\r\n            if (result === undefined && createNode) {\r\n                result = this.construct();\r\n            }\r\n            return result;\r\n        };\r\n    }\r\n\r\n    private extractHiddenTokens(token: IToken): IToken[] {\r\n        const hiddenTokens = this.lexerResult!.hidden;\r\n        if (!hiddenTokens.length) {\r\n            return [];\r\n        }\r\n        const offset = token.startOffset;\r\n        for (let i = 0; i < hiddenTokens.length; i++) {\r\n            const token = hiddenTokens[i];\r\n            if (token.startOffset > offset) {\r\n                return hiddenTokens.splice(0, i);\r\n            }\r\n        }\r\n        return hiddenTokens.splice(0, hiddenTokens.length);\r\n    }\r\n\r\n    consume(idx: number, tokenType: TokenType, feature: AbstractElement): void {\r\n        const token = this.wrapper.wrapConsume(idx, tokenType);\r\n        if (!this.isRecording() && this.isValidToken(token)) {\r\n            const hiddenTokens = this.extractHiddenTokens(token);\r\n            this.nodeBuilder.addHiddenNodes(hiddenTokens);\r\n            const leafNode = this.nodeBuilder.buildLeafNode(token, feature);\r\n            const { assignment, isCrossRef } = this.getAssignment(feature);\r\n            const current = this.current;\r\n            if (assignment) {\r\n                const convertedValue = isKeyword(feature) ? token.image : this.converter.convert(token.image, leafNode);\r\n                this.assign(assignment.operator, assignment.feature, convertedValue, leafNode, isCrossRef);\r\n            } else if (isDataTypeNode(current)) {\r\n                let text = token.image;\r\n                if (!isKeyword(feature)) {\r\n                    text = this.converter.convert(text, leafNode).toString();\r\n                }\r\n                current.value += text;\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Most consumed parser tokens are valid. However there are two cases in which they are not valid:\r\n     *\r\n     * 1. They were inserted during error recovery by the parser. These tokens don't really exist and should not be further processed\r\n     * 2. They contain invalid token ranges. This might include the special EOF token, or other tokens produced by invalid token builders.\r\n     */\r\n    private isValidToken(token: IToken): boolean {\r\n        return !token.isInsertedInRecovery && !isNaN(token.startOffset) && typeof token.endOffset === 'number' && !isNaN(token.endOffset);\r\n    }\r\n\r\n    subrule(idx: number, rule: RuleResult, fragment: boolean, feature: AbstractElement, args: Args): void {\r\n        let cstNode: CompositeCstNode | undefined;\r\n        if (!this.isRecording() && !fragment) {\r\n            // We only want to create a new CST node if the subrule actually creates a new AST node.\r\n            // In other cases like calls of fragment rules the current CST/AST is populated further.\r\n            // Note that skipping this initialization and leaving cstNode unassigned also skips the subrule assignment later on.\r\n            // This is intended, as fragment rules only enrich the current AST node\r\n            cstNode = this.nodeBuilder.buildCompositeNode(feature);\r\n        }\r\n        const subruleResult = this.wrapper.wrapSubrule(idx, rule, args) as any;\r\n        if (!this.isRecording() && cstNode && cstNode.length > 0) {\r\n            this.performSubruleAssignment(subruleResult, feature, cstNode);\r\n        }\r\n    }\r\n\r\n    private performSubruleAssignment(result: any, feature: AbstractElement, cstNode: CompositeCstNode): void {\r\n        const { assignment, isCrossRef } = this.getAssignment(feature);\r\n        if (assignment) {\r\n            this.assign(assignment.operator, assignment.feature, result, cstNode, isCrossRef);\r\n        } else if (!assignment) {\r\n            // If we call a subrule without an assignment we either:\r\n            // 1. append the result of the subrule (data type rule)\r\n            // 2. override the current object with the newly parsed object\r\n            // If the current element is an AST node and the result of the subrule\r\n            // is a data type rule, we can safely discard the results.\r\n            const current = this.current;\r\n            if (isDataTypeNode(current)) {\r\n                current.value += result.toString();\r\n            } else if (typeof result === 'object' && result) {\r\n                const object = this.assignWithoutOverride(result, current);\r\n                const newItem = object;\r\n                this.stack.pop();\r\n                this.stack.push(newItem);\r\n            }\r\n        }\r\n    }\r\n\r\n    action($type: string, action: Action): void {\r\n        if (!this.isRecording()) {\r\n            let last = this.current;\r\n            if (action.feature && action.operator) {\r\n                last = this.construct();\r\n                this.nodeBuilder.removeNode(last.$cstNode);\r\n                const node = this.nodeBuilder.buildCompositeNode(action);\r\n                node.content.push(last.$cstNode);\r\n                const newItem = { $type };\r\n                this.stack.push(newItem);\r\n                this.assign(action.operator, action.feature, last, last.$cstNode, false);\r\n            } else {\r\n                last.$type = $type;\r\n            }\r\n        }\r\n    }\r\n\r\n    construct(): unknown {\r\n        if (this.isRecording()) {\r\n            return undefined;\r\n        }\r\n        const obj = this.current;\r\n        linkContentToContainer(obj);\r\n        this.nodeBuilder.construct(obj);\r\n        this.stack.pop();\r\n        if (isDataTypeNode(obj)) {\r\n            return this.converter.convert(obj.value, obj.$cstNode);\r\n        } else {\r\n            assignMandatoryProperties(this.astReflection, obj);\r\n        }\r\n        return obj;\r\n    }\r\n\r\n    private getAssignment(feature: AbstractElement): AssignmentElement {\r\n        if (!this.assignmentMap.has(feature)) {\r\n            const assignment = getContainerOfType(feature, isAssignment);\r\n            this.assignmentMap.set(feature, {\r\n                assignment: assignment,\r\n                isCrossRef: assignment ? isCrossReference(assignment.terminal) : false\r\n            });\r\n        }\r\n        return this.assignmentMap.get(feature)!;\r\n    }\r\n\r\n    private assign(operator: string, feature: string, value: unknown, cstNode: CstNode, isCrossRef: boolean): void {\r\n        const obj = this.current;\r\n        let item: unknown;\r\n        if (isCrossRef && typeof value === 'string') {\r\n            item = this.linker.buildReference(obj, feature, cstNode, value);\r\n        } else {\r\n            item = value;\r\n        }\r\n        switch (operator) {\r\n            case '=': {\r\n                obj[feature] = item;\r\n                break;\r\n            }\r\n            case '?=': {\r\n                obj[feature] = true;\r\n                break;\r\n            }\r\n            case '+=': {\r\n                if (!Array.isArray(obj[feature])) {\r\n                    obj[feature] = [];\r\n                }\r\n                obj[feature].push(item);\r\n            }\r\n        }\r\n    }\r\n\r\n    private assignWithoutOverride(target: any, source: any): any {\r\n        for (const [name, existingValue] of Object.entries(source)) {\r\n            const newValue = target[name];\r\n            if (newValue === undefined) {\r\n                target[name] = existingValue;\r\n            } else if (Array.isArray(newValue) && Array.isArray(existingValue)) {\r\n                existingValue.push(...newValue);\r\n                target[name] = existingValue;\r\n            }\r\n        }\r\n        // The target was parsed from a unassigned subrule\r\n        // After the subrule construction, it received a cst node\r\n        // This CST node will later be overriden by the cst node builder\r\n        // To prevent references to stale AST nodes in the CST,\r\n        // we need to remove the reference here\r\n        const targetCstNode = target.$cstNode;\r\n        if (targetCstNode) {\r\n            targetCstNode.astNode = undefined;\r\n            target.$cstNode = undefined;\r\n        }\r\n        return target;\r\n    }\r\n\r\n    get definitionErrors(): IParserDefinitionError[] {\r\n        return this.wrapper.definitionErrors;\r\n    }\r\n}\r\n\r\nexport interface IParserDefinitionError {\r\n    message: string\r\n    type: number\r\n    ruleName?: string\r\n}\r\n\r\nexport abstract class AbstractParserErrorMessageProvider implements IParserErrorMessageProvider {\r\n\r\n    buildMismatchTokenMessage(options: {\r\n        expected: TokenType\r\n        actual: IToken\r\n        previous: IToken\r\n        ruleName: string\r\n    }): string {\r\n        return defaultParserErrorProvider.buildMismatchTokenMessage(options);\r\n    }\r\n\r\n    buildNotAllInputParsedMessage(options: {\r\n        firstRedundant: IToken\r\n        ruleName: string\r\n    }): string {\r\n        return defaultParserErrorProvider.buildNotAllInputParsedMessage(options);\r\n    }\r\n\r\n    buildNoViableAltMessage(options: {\r\n        expectedPathsPerAlt: TokenType[][][]\r\n        actual: IToken[]\r\n        previous: IToken\r\n        customUserDescription: string\r\n        ruleName: string\r\n    }): string {\r\n        return defaultParserErrorProvider.buildNoViableAltMessage(options);\r\n    }\r\n\r\n    buildEarlyExitMessage(options: {\r\n        expectedIterationPaths: TokenType[][]\r\n        actual: IToken[]\r\n        previous: IToken\r\n        customUserDescription: string\r\n        ruleName: string\r\n    }): string {\r\n        return defaultParserErrorProvider.buildEarlyExitMessage(options);\r\n    }\r\n\r\n}\r\n\r\nexport class LangiumParserErrorMessageProvider extends AbstractParserErrorMessageProvider {\r\n\r\n    override buildMismatchTokenMessage({ expected, actual }: {\r\n        expected: TokenType\r\n        actual: IToken\r\n        previous: IToken\r\n        ruleName: string\r\n    }): string {\r\n        const expectedMsg = expected.LABEL\r\n            ? '`' + expected.LABEL + '`'\r\n            : expected.name.endsWith(':KW')\r\n                ? `keyword '${expected.name.substring(0, expected.name.length - 3)}'`\r\n                : `token of type '${expected.name}'`;\r\n        return `Expecting ${expectedMsg} but found \\`${actual.image}\\`.`;\r\n    }\r\n\r\n    override buildNotAllInputParsedMessage({ firstRedundant }: {\r\n        firstRedundant: IToken\r\n        ruleName: string\r\n    }): string {\r\n        return `Expecting end of file but found \\`${firstRedundant.image}\\`.`;\r\n    }\r\n}\r\n\r\nexport interface CompletionParserResult {\r\n    tokens: IToken[]\r\n    elementStack: AbstractElement[]\r\n    tokenIndex: number\r\n}\r\n\r\nexport class LangiumCompletionParser extends AbstractLangiumParser {\r\n    private tokens: IToken[] = [];\r\n\r\n    private elementStack: AbstractElement[] = [];\r\n    private lastElementStack: AbstractElement[] = [];\r\n    private nextTokenIndex = 0;\r\n    private stackSize = 0;\r\n\r\n    action(): void {\r\n        // NOOP\r\n    }\r\n\r\n    construct(): unknown {\r\n        // NOOP\r\n        return undefined;\r\n    }\r\n\r\n    parse(input: string): CompletionParserResult {\r\n        this.resetState();\r\n        const tokens = this.lexer.tokenize(input, { mode: 'partial' });\r\n        this.tokens = tokens.tokens;\r\n        this.wrapper.input = [...this.tokens];\r\n        this.mainRule.call(this.wrapper, {});\r\n        this.unorderedGroups.clear();\r\n        return {\r\n            tokens: this.tokens,\r\n            elementStack: [...this.lastElementStack],\r\n            tokenIndex: this.nextTokenIndex\r\n        };\r\n    }\r\n\r\n    rule(rule: ParserRule, impl: RuleImpl): RuleResult {\r\n        const ruleMethod = this.wrapper.DEFINE_RULE(withRuleSuffix(rule.name), this.startImplementation(impl).bind(this));\r\n        this.allRules.set(rule.name, ruleMethod);\r\n        if (rule.entry) {\r\n            this.mainRule = ruleMethod;\r\n        }\r\n        return ruleMethod;\r\n    }\r\n\r\n    private resetState(): void {\r\n        this.elementStack = [];\r\n        this.lastElementStack = [];\r\n        this.nextTokenIndex = 0;\r\n        this.stackSize = 0;\r\n    }\r\n\r\n    private startImplementation(implementation: RuleImpl): RuleImpl {\r\n        return (args) => {\r\n            const size = this.keepStackSize();\r\n            try {\r\n                implementation(args);\r\n            } finally {\r\n                this.resetStackSize(size);\r\n            }\r\n        };\r\n    }\r\n\r\n    private removeUnexpectedElements(): void {\r\n        this.elementStack.splice(this.stackSize);\r\n    }\r\n\r\n    keepStackSize(): number {\r\n        const size = this.elementStack.length;\r\n        this.stackSize = size;\r\n        return size;\r\n    }\r\n\r\n    resetStackSize(size: number): void {\r\n        this.removeUnexpectedElements();\r\n        this.stackSize = size;\r\n    }\r\n\r\n    consume(idx: number, tokenType: TokenType, feature: AbstractElement): void {\r\n        this.wrapper.wrapConsume(idx, tokenType);\r\n        if (!this.isRecording()) {\r\n            this.lastElementStack = [...this.elementStack, feature];\r\n            this.nextTokenIndex = this.currIdx + 1;\r\n        }\r\n    }\r\n\r\n    subrule(idx: number, rule: RuleResult, fragment: boolean, feature: AbstractElement, args: Args): void {\r\n        this.before(feature);\r\n        this.wrapper.wrapSubrule(idx, rule, args);\r\n        this.after(feature);\r\n    }\r\n\r\n    before(element: AbstractElement): void {\r\n        if (!this.isRecording()) {\r\n            this.elementStack.push(element);\r\n        }\r\n    }\r\n\r\n    after(element: AbstractElement): void {\r\n        if (!this.isRecording()) {\r\n            const index = this.elementStack.lastIndexOf(element);\r\n            if (index >= 0) {\r\n                this.elementStack.splice(index);\r\n            }\r\n        }\r\n    }\r\n\r\n    get currIdx(): number {\r\n        return (this.wrapper as any).currIdx;\r\n    }\r\n}\r\n\r\nconst defaultConfig: IParserConfig = {\r\n    recoveryEnabled: true,\r\n    nodeLocationTracking: 'full',\r\n    skipValidations: true,\r\n    errorMessageProvider: new LangiumParserErrorMessageProvider()\r\n};\r\n\r\n/**\r\n * This class wraps the embedded actions parser of chevrotain and exposes protected methods.\r\n * This way, we can build the `LangiumParser` as a composition.\r\n */\r\nclass ChevrotainWrapper extends EmbeddedActionsParser {\r\n\r\n    // This array is set in the base implementation of Chevrotain.\r\n    definitionErrors: IParserDefinitionError[];\r\n\r\n    constructor(tokens: TokenVocabulary, config: IParserConfig) {\r\n        const useDefaultLookahead = config && 'maxLookahead' in config;\r\n        super(tokens, {\r\n            ...defaultConfig,\r\n            lookaheadStrategy: useDefaultLookahead\r\n                ? new LLkLookaheadStrategy({ maxLookahead: config.maxLookahead })\r\n                : new LLStarLookaheadStrategy({\r\n                    // If validations are skipped, don't log the lookahead warnings\r\n                    logging: config.skipValidations ? () => { } : undefined\r\n                }),\r\n            ...config,\r\n        });\r\n    }\r\n\r\n    get IS_RECORDING(): boolean {\r\n        return this.RECORDING_PHASE;\r\n    }\r\n\r\n    DEFINE_RULE(name: string, impl: RuleImpl): RuleResult {\r\n        return this.RULE(name, impl);\r\n    }\r\n\r\n    wrapSelfAnalysis(): void {\r\n        this.performSelfAnalysis();\r\n    }\r\n\r\n    wrapConsume(idx: number, tokenType: TokenType): IToken {\r\n        return this.consume(idx, tokenType);\r\n    }\r\n\r\n    wrapSubrule(idx: number, rule: RuleResult, args: Args): unknown {\r\n        return this.subrule(idx, rule, {\r\n            ARGS: [args]\r\n        });\r\n    }\r\n\r\n    wrapOr(idx: number, choices: Array<IOrAlt<any>>): void {\r\n        this.or(idx, choices);\r\n    }\r\n\r\n    wrapOption(idx: number, callback: DSLMethodOpts<unknown>): void {\r\n        this.option(idx, callback);\r\n    }\r\n\r\n    wrapMany(idx: number, callback: DSLMethodOpts<unknown>): void {\r\n        this.many(idx, callback);\r\n    }\r\n\r\n    wrapAtLeastOne(idx: number, callback: DSLMethodOpts<unknown>): void {\r\n        this.atLeastOne(idx, callback);\r\n    }\r\n}\r\n","import { END_OF_FILE } from \"../parser.js\";\nimport { IToken } from \"@chevrotain/types\";\nimport { MixedInParser } from \"./parser_traits.js\";\n\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\nexport class LexerAdapter {\n  tokVector: IToken[];\n  tokVectorLength: number;\n  currIdx: number;\n\n  initLexerAdapter() {\n    this.tokVector = [];\n    this.tokVectorLength = 0;\n    this.currIdx = -1;\n  }\n\n  set input(newInput: IToken[]) {\n    // @ts-ignore - `this parameter` not supported in setters/getters\n    //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n    if (this.selfAnalysisDone !== true) {\n      throw Error(\n        `Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.`,\n      );\n    }\n    // @ts-ignore - `this parameter` not supported in setters/getters\n    //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n    this.reset();\n    this.tokVector = newInput;\n    this.tokVectorLength = newInput.length;\n  }\n\n  get input(): IToken[] {\n    return this.tokVector;\n  }\n\n  // skips a token and returns the next token\n  SKIP_TOKEN(this: MixedInParser): IToken {\n    if (this.currIdx <= this.tokVector.length - 2) {\n      this.consumeToken();\n      return this.LA(1);\n    } else {\n      return END_OF_FILE;\n    }\n  }\n\n  // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n  // or lexers dependent on parser context.\n  LA(this: MixedInParser, howMuch: number): IToken {\n    const soughtIdx = this.currIdx + howMuch;\n    if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n      return END_OF_FILE;\n    } else {\n      return this.tokVector[soughtIdx];\n    }\n  }\n\n  consumeToken(this: MixedInParser) {\n    this.currIdx++;\n  }\n\n  exportLexerState(this: MixedInParser): number {\n    return this.currIdx;\n  }\n\n  importLexerState(this: MixedInParser, newState: number) {\n    this.currIdx = newState;\n  }\n\n  resetLexerState(this: MixedInParser): void {\n    this.currIdx = -1;\n  }\n\n  moveToTerminatedState(this: MixedInParser): void {\n    this.currIdx = this.tokVector.length - 1;\n  }\n\n  getLexerPosition(this: MixedInParser): number {\n    return this.exportLexerState();\n  }\n}\n","// based on: https://github.com/petkaantonov/bluebird/blob/b97c0d2d487e8c5076e8bd897e0dcd4622d31846/src/util.js#L201-L216\nexport function toFastProperties(toBecomeFast: any) {\n  function FakeConstructor() {}\n\n  // If our object is used as a constructor, it would receive\n  FakeConstructor.prototype = toBecomeFast;\n  const fakeInstance = new (FakeConstructor as any)();\n\n  function fakeAccess() {\n    return typeof fakeInstance.bar;\n  }\n\n  // help V8 understand this is a \"real\" prototype by actually using\n  // the fake instance.\n  fakeAccess();\n  fakeAccess();\n\n  // Always true condition to suppress the Firefox warning of unreachable\n  // code after a return statement.\n  if (1) return toBecomeFast;\n\n  // Eval prevents optimization of this method (even though this is dead code)\n  // - https://esbuild.github.io/content-types/#direct-eval\n  /* istanbul ignore next */\n  // tslint:disable-next-line\n  (0, eval)(toBecomeFast);\n}\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport { DefaultNameRegexp } from '../utils/cst-utils.js';\r\nimport { isCommentTerminal, terminalRegex } from '../utils/grammar-utils.js';\r\nimport { isMultilineComment } from '../utils/regexp-utils.js';\r\nimport { isTerminalRule } from './generated/ast.js';\r\n\r\nexport interface GrammarConfig {\r\n    /**\r\n     * Lists all rule names which are classified as multiline comment rules\r\n     */\r\n    multilineCommentRules: string[]\r\n    /**\r\n     * A regular expression which matches characters of names\r\n     */\r\n    nameRegexp: RegExp\r\n}\r\n\r\n/**\r\n * Create the default grammar configuration (used by `createDefaultModule`). This can be overridden in a\r\n * language-specific module.\r\n */\r\nexport function createGrammarConfig(services: LangiumCoreServices): GrammarConfig {\r\n    const rules: string[] = [];\r\n    const grammar = services.Grammar;\r\n    for (const rule of grammar.rules) {\r\n        if (isTerminalRule(rule) && isCommentTerminal(rule) && isMultilineComment(terminalRegex(rule))) {\r\n            rules.push(rule.name);\r\n        }\r\n    }\r\n    return {\r\n        multilineCommentRules: rules,\r\n        nameRegexp: DefaultNameRegexp\r\n    };\r\n}\r\n","import {\n  AtLeastOneSepMethodOpts,\n  ConsumeMethodOpts,\n  DSLMethodOpts,\n  DSLMethodOptsWithErr,\n  GrammarAction,\n  IOrAlt,\n  IRuleConfig,\n  ISerializedGast,\n  IToken,\n  ManySepMethodOpts,\n  OrMethodOpts,\n  SubruleMethodOpts,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { includes, values } from \"lodash-es\";\nimport { isRecognitionException } from \"../../exceptions_public.js\";\nimport { DEFAULT_RULE_CONFIG, ParserDefinitionErrorType } from \"../parser.js\";\nimport { defaultGrammarValidatorErrorProvider } from \"../../errors_public.js\";\nimport { validateRuleIsOverridden } from \"../../grammar/checks.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { Rule, serializeGrammar } from \"@chevrotain/gast\";\nimport { IParserDefinitionError } from \"../../grammar/types.js\";\nimport { ParserMethodInternal } from \"../types.js\";\n\n/**\n * This trait is responsible for implementing the public API\n * for defining Chevrotain parsers, i.e:\n * - CONSUME\n * - RULE\n * - OPTION\n * - ...\n */\nexport class RecognizerApi {\n  ACTION<T>(this: MixedInParser, impl: () => T): T {\n    return impl.call(this);\n  }\n\n  consume(\n    this: MixedInParser,\n    idx: number,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, idx, options);\n  }\n\n  subrule<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    idx: number,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, idx, options);\n  }\n\n  option<OUT>(\n    this: MixedInParser,\n    idx: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, idx);\n  }\n\n  or(\n    this: MixedInParser,\n    idx: number,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<any>,\n  ): any {\n    return this.orInternal(altsOrOpts, idx);\n  }\n\n  many(\n    this: MixedInParser,\n    idx: number,\n    actionORMethodDef: GrammarAction<any> | DSLMethodOpts<any>,\n  ): void {\n    return this.manyInternal(idx, actionORMethodDef);\n  }\n\n  atLeastOne(\n    this: MixedInParser,\n    idx: number,\n    actionORMethodDef: GrammarAction<any> | DSLMethodOptsWithErr<any>,\n  ): void {\n    return this.atLeastOneInternal(idx, actionORMethodDef);\n  }\n\n  CONSUME(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 0, options);\n  }\n\n  CONSUME1(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 1, options);\n  }\n\n  CONSUME2(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 2, options);\n  }\n\n  CONSUME3(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 3, options);\n  }\n\n  CONSUME4(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 4, options);\n  }\n\n  CONSUME5(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 5, options);\n  }\n\n  CONSUME6(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 6, options);\n  }\n\n  CONSUME7(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 7, options);\n  }\n\n  CONSUME8(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 8, options);\n  }\n\n  CONSUME9(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 9, options);\n  }\n\n  SUBRULE<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 0, options);\n  }\n\n  SUBRULE1<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 1, options);\n  }\n\n  SUBRULE2<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 2, options);\n  }\n\n  SUBRULE3<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 3, options);\n  }\n\n  SUBRULE4<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 4, options);\n  }\n\n  SUBRULE5<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 5, options);\n  }\n\n  SUBRULE6<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 6, options);\n  }\n\n  SUBRULE7<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 7, options);\n  }\n\n  SUBRULE8<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 8, options);\n  }\n\n  SUBRULE9<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 9, options);\n  }\n\n  OPTION<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 0);\n  }\n\n  OPTION1<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 1);\n  }\n\n  OPTION2<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 2);\n  }\n\n  OPTION3<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 3);\n  }\n\n  OPTION4<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 4);\n  }\n\n  OPTION5<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 5);\n  }\n\n  OPTION6<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 6);\n  }\n\n  OPTION7<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 7);\n  }\n\n  OPTION8<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 8);\n  }\n\n  OPTION9<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 9);\n  }\n\n  OR<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 0);\n  }\n\n  OR1<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 1);\n  }\n\n  OR2<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 2);\n  }\n\n  OR3<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 3);\n  }\n\n  OR4<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 4);\n  }\n\n  OR5<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 5);\n  }\n\n  OR6<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 6);\n  }\n\n  OR7<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 7);\n  }\n\n  OR8<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 8);\n  }\n\n  OR9<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 9);\n  }\n\n  MANY<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(0, actionORMethodDef);\n  }\n\n  MANY1<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(1, actionORMethodDef);\n  }\n\n  MANY2<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(2, actionORMethodDef);\n  }\n\n  MANY3<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(3, actionORMethodDef);\n  }\n\n  MANY4<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(4, actionORMethodDef);\n  }\n\n  MANY5<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(5, actionORMethodDef);\n  }\n\n  MANY6<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(6, actionORMethodDef);\n  }\n\n  MANY7<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(7, actionORMethodDef);\n  }\n\n  MANY8<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(8, actionORMethodDef);\n  }\n\n  MANY9<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(9, actionORMethodDef);\n  }\n\n  MANY_SEP<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(0, options);\n  }\n\n  MANY_SEP1<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(1, options);\n  }\n\n  MANY_SEP2<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(2, options);\n  }\n\n  MANY_SEP3<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(3, options);\n  }\n\n  MANY_SEP4<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(4, options);\n  }\n\n  MANY_SEP5<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(5, options);\n  }\n\n  MANY_SEP6<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(6, options);\n  }\n\n  MANY_SEP7<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(7, options);\n  }\n\n  MANY_SEP8<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(8, options);\n  }\n\n  MANY_SEP9<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(9, options);\n  }\n\n  AT_LEAST_ONE<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(0, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE1<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    return this.atLeastOneInternal(1, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE2<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(2, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE3<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(3, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE4<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(4, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE5<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(5, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE6<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(6, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE7<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(7, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE8<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(8, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE9<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(9, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE_SEP<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(0, options);\n  }\n\n  AT_LEAST_ONE_SEP1<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(1, options);\n  }\n\n  AT_LEAST_ONE_SEP2<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(2, options);\n  }\n\n  AT_LEAST_ONE_SEP3<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(3, options);\n  }\n\n  AT_LEAST_ONE_SEP4<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(4, options);\n  }\n\n  AT_LEAST_ONE_SEP5<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(5, options);\n  }\n\n  AT_LEAST_ONE_SEP6<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(6, options);\n  }\n\n  AT_LEAST_ONE_SEP7<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(7, options);\n  }\n\n  AT_LEAST_ONE_SEP8<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(8, options);\n  }\n\n  AT_LEAST_ONE_SEP9<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(9, options);\n  }\n\n  RULE<T>(\n    this: MixedInParser,\n    name: string,\n    implementation: (...implArgs: any[]) => T,\n    config: IRuleConfig<T> = DEFAULT_RULE_CONFIG,\n  ): (idxInCallingRule?: number, ...args: any[]) => T | any {\n    if (includes(this.definedRulesNames, name)) {\n      const errMsg =\n        defaultGrammarValidatorErrorProvider.buildDuplicateRuleNameError({\n          topLevelRule: name,\n          grammarName: this.className,\n        });\n\n      const error = {\n        message: errMsg,\n        type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n        ruleName: name,\n      };\n      this.definitionErrors.push(error);\n    }\n\n    this.definedRulesNames.push(name);\n\n    const ruleImplementation = this.defineRule(name, implementation, config);\n    (this as any)[name] = ruleImplementation;\n    return ruleImplementation;\n  }\n\n  OVERRIDE_RULE<T>(\n    this: MixedInParser,\n    name: string,\n    impl: (...implArgs: any[]) => T,\n    config: IRuleConfig<T> = DEFAULT_RULE_CONFIG,\n  ): (idxInCallingRule?: number, ...args: any[]) => T {\n    const ruleErrors: IParserDefinitionError[] = validateRuleIsOverridden(\n      name,\n      this.definedRulesNames,\n      this.className,\n    );\n    this.definitionErrors = this.definitionErrors.concat(ruleErrors);\n\n    const ruleImplementation = this.defineRule(name, impl, config);\n    (this as any)[name] = ruleImplementation;\n    return ruleImplementation;\n  }\n\n  BACKTRACK<T>(\n    this: MixedInParser,\n    grammarRule: (...args: any[]) => T,\n    args?: any[],\n  ): () => boolean {\n    return function () {\n      // save org state\n      this.isBackTrackingStack.push(1);\n      const orgState = this.saveRecogState();\n      try {\n        grammarRule.apply(this, args);\n        // if no exception was thrown we have succeed parsing the rule.\n        return true;\n      } catch (e) {\n        if (isRecognitionException(e)) {\n          return false;\n        } else {\n          throw e;\n        }\n      } finally {\n        this.reloadRecogState(orgState);\n        this.isBackTrackingStack.pop();\n      }\n    };\n  }\n\n  // GAST export APIs\n  public getGAstProductions(this: MixedInParser): Record<string, Rule> {\n    return this.gastProductionsCache;\n  }\n\n  public getSerializedGastProductions(this: MixedInParser): ISerializedGast[] {\n    return serializeGrammar(values(this.gastProductionsCache));\n  }\n}\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\n/**\r\n * A stream is a read-only sequence of values. While the contents of an array can be accessed\r\n * both sequentially and randomly (via index), a stream allows only sequential access.\r\n *\r\n * The advantage of this is that a stream can be evaluated lazily, so it does not require\r\n * to store intermediate values. This can boost performance when a large sequence is\r\n * processed via filtering, mapping etc. and accessed at most once. However, lazy\r\n * evaluation means that all processing is repeated when you access the sequence multiple\r\n * times; in such a case, it may be better to store the resulting sequence into an array.\r\n */\r\nexport interface Stream<T> extends Iterable<T> {\r\n\r\n    /**\r\n     * Returns an iterator for this stream. This is the same as calling the `Symbol.iterator` function property.\r\n     */\r\n    iterator(): IterableIterator<T>;\r\n\r\n    /**\r\n     * Determines whether this stream contains no elements.\r\n     */\r\n    isEmpty(): boolean;\r\n\r\n    /**\r\n     * Determines the number of elements in this stream.\r\n     */\r\n    count(): number;\r\n\r\n    /**\r\n     * Collects all elements of this stream into an array.\r\n     */\r\n    toArray(): T[];\r\n\r\n    /**\r\n     * Collects all elements of this stream into a Set.\r\n     */\r\n    toSet(): Set<T>;\r\n\r\n    /**\r\n     * Collects all elements of this stream into a Map, applying the provided functions to determine keys and values.\r\n     *\r\n     * @param keyFn The function to derive map keys. If omitted, the stream elements are used as keys.\r\n     * @param valueFn The function to derive map values. If omitted, the stream elements are used as values.\r\n     */\r\n    toMap<K = T, V = T>(keyFn?: (e: T) => K, valueFn?: (e: T) => V): Map<K, V>;\r\n\r\n    /**\r\n     * Returns a string representation of a stream.\r\n     */\r\n    toString(): string;\r\n\r\n    /**\r\n     * Combines two streams by returning a new stream that yields all elements of this stream and the other stream.\r\n     *\r\n     * @param other Stream to be concatenated with this one.\r\n     */\r\n    concat<T2>(other: Iterable<T2>): Stream<T | T2>;\r\n\r\n    /**\r\n     * Adds all elements of the stream into a string, separated by the specified separator string.\r\n     *\r\n     * @param separator A string used to separate one element of the stream from the next in the resulting string.\r\n     *        If omitted, the steam elements are separated with a comma.\r\n     */\r\n    join(separator?: string): string\r\n\r\n    /**\r\n     * Returns the index of the first occurrence of a value in the stream, or -1 if it is not present.\r\n     *\r\n     * @param searchElement The value to locate in the array.\r\n     * @param fromIndex The stream index at which to begin the search. If fromIndex is omitted, the search\r\n     *        starts at index 0.\r\n     */\r\n    indexOf(searchElement: T, fromIndex?: number): number;\r\n\r\n    /**\r\n     * Determines whether all members of the stream satisfy the specified test.\r\n     *\r\n     * @param predicate This method calls the predicate function for each element in the stream until the\r\n     *        predicate returns a value which is coercible to the Boolean value `false`, or until the end\r\n     *        of the stream.\r\n     */\r\n    every<S extends T>(predicate: (value: T) => value is S): this is Stream<S>;\r\n    every(predicate: (value: T) => unknown): boolean;\r\n\r\n    /**\r\n     * Determines whether any member of the stream satisfies the specified test.\r\n     *\r\n     * @param predicate This method calls the predicate function for each element in the stream until the\r\n     *        predicate returns a value which is coercible to the Boolean value `true`, or until the end\r\n     *        of the stream.\r\n     */\r\n    some(predicate: (value: T) => unknown): boolean;\r\n\r\n    /**\r\n     * Performs the specified action for each element in the stream.\r\n     *\r\n     * @param callbackfn Function called once for each element in the stream.\r\n     */\r\n    forEach(callbackfn: (value: T, index: number) => void): void;\r\n\r\n    /**\r\n     * Returns a stream that yields the results of calling the specified callback function on each element\r\n     * of the stream. The function is called when the resulting stream elements are actually accessed, so\r\n     * accessing the resulting stream multiple times means the function is also called multiple times for\r\n     * each element of the stream.\r\n     *\r\n     * @param callbackfn Lazily evaluated function mapping stream elements.\r\n     */\r\n    map<U>(callbackfn: (value: T) => U): Stream<U>;\r\n\r\n    /**\r\n     * Returns the elements of the stream that meet the condition specified in a callback function.\r\n     * The function is called when the resulting stream elements are actually accessed, so accessing the\r\n     * resulting stream multiple times means the function is also called multiple times for each element\r\n     * of the stream.\r\n     *\r\n     * @param predicate Lazily evaluated function checking a condition on stream elements.\r\n     */\r\n    filter<S extends T>(predicate: (value: T) => value is S): Stream<S>;\r\n    filter(predicate: (value: T) => unknown): Stream<T>;\r\n\r\n    /**\r\n     * Returns the elements of the stream that are _non-nullable_, which means they are neither `undefined`\r\n     * nor `null`.\r\n     */\r\n    nonNullable(): Stream<NonNullable<T>>;\r\n\r\n    /**\r\n     * Calls the specified callback function for all elements in the stream. The return value of the\r\n     * callback function is the accumulated result, and is provided as an argument in the next call to\r\n     * the callback function.\r\n     *\r\n     * @param callbackfn This method calls the function once for each element in the stream, providing\r\n     *        the previous and current values of the reduction.\r\n     * @param initialValue If specified, `initialValue` is used as the initial value to start the\r\n     *        accumulation. The first call to the function provides this value as an argument instead\r\n     *        of a stream value.\r\n     */\r\n    reduce(callbackfn: (previousValue: T, currentValue: T) => T): T | undefined;\r\n    reduce<U = T>(callbackfn: (previousValue: U, currentValue: T) => U, initialValue: U): U;\r\n\r\n    /**\r\n     * Calls the specified callback function for all elements in the stream, in descending order.\r\n     * The return value of the callback function is the accumulated result, and is provided as an\r\n     * argument in the next call to the callback function.\r\n     *\r\n     * @param callbackfn This method calls the function once for each element in the stream, providing\r\n     *        the previous and current values of the reduction.\r\n     * @param initialValue If specified, `initialValue` is used as the initial value to start the\r\n     *        accumulation. The first call to the function provides this value as an argument instead\r\n     *        of an array value.\r\n     */\r\n    reduceRight(callbackfn: (previousValue: T, currentValue: T) => T): T | undefined;\r\n    reduceRight<U = T>(callbackfn: (previousValue: U, currentValue: T) => U, initialValue: U): U;\r\n\r\n    /**\r\n     * Returns the value of the first element in the stream that meets the condition, or `undefined`\r\n     * if there is no such element.\r\n     *\r\n     * @param predicate This method calls `predicate` once for each element of the stream, in ascending\r\n     *        order, until it finds one where `predicate` returns a value which is coercible to the\r\n     *        Boolean value `true`.\r\n     */\r\n    find<S extends T>(predicate: (value: T) => value is S): S | undefined;\r\n    find(predicate: (value: T) => unknown): T | undefined;\r\n\r\n    /**\r\n     * Returns the index of the first element in the stream that meets the condition, or `-1`\r\n     * if there is no such element.\r\n     *\r\n     * @param predicate This method calls `predicate` once for each element of the stream, in ascending\r\n     *        order, until it finds one where `predicate` returns a value which is coercible to the\r\n     *        Boolean value `true`.\r\n     */\r\n    findIndex(predicate: (value: T) => unknown): number;\r\n\r\n    /**\r\n     * Determines whether the stream includes a certain element, returning `true` or `false` as appropriate.\r\n     *\r\n     * @param searchElement The element to search for.\r\n     */\r\n    includes(searchElement: T): boolean;\r\n\r\n    /**\r\n     * Calls a defined callback function on each element of the stream and then flattens the result into\r\n     * a new stream. This is identical to a `map` followed by `flat` with depth 1.\r\n     *\r\n     * @param callbackfn Lazily evaluated function mapping stream elements.\r\n     */\r\n    flatMap<U>(callbackfn: (value: T) => U | Iterable<U>): Stream<U>;\r\n\r\n    /**\r\n     * Returns a new stream with all sub-stream or sub-array elements concatenated into it recursively up\r\n     * to the specified depth.\r\n     *\r\n     * @param depth The maximum recursion depth. Defaults to 1.\r\n     */\r\n    flat<D extends number = 1>(depth?: D): FlatStream<T, D>;\r\n\r\n    /**\r\n     * Returns the first element in the stream, or `undefined` if the stream is empty.\r\n     */\r\n    head(): T | undefined;\r\n\r\n    /**\r\n     * Returns a stream that skips the first `skipCount` elements from this stream.\r\n     *\r\n     * @param skipCount The number of elements to skip. If this is larger than the number of elements in\r\n     *        the stream, an empty stream is returned. Defaults to 1.\r\n     */\r\n    tail(skipCount?: number): Stream<T>;\r\n\r\n    /**\r\n     * Returns a stream consisting of the elements of this stream, truncated to be no longer than `maxSize`\r\n     * in length.\r\n     *\r\n     * @param maxSize The number of elements the stream should be limited to\r\n     */\r\n    limit(maxSize: number): Stream<T>;\r\n\r\n    /**\r\n     * Returns a stream containing only the distinct elements from this stream.\r\n     * Equality is determined with the same rules as a standard `Set`.\r\n     *\r\n     * @param by A function returning the key used to check equality with a previous stream element.\r\n     *        If omitted, the stream elements themselves are used for comparison.\r\n     */\r\n    distinct<Key = T>(by?: (element: T) => Key): Stream<T>;\r\n\r\n    /**\r\n     * Returns a stream that contains all elements that don't exist in the {@link other} iterable.\r\n     * Equality is determined with the same rules as a standard `Set`.\r\n     * @param other The elements that should be exluded from this stream.\r\n     * @param key A function returning the key used to check quality.\r\n     *        If omitted, the stream elements themselves are used for comparison.\r\n     */\r\n    exclude<Key = T>(other: Iterable<T>, key?: (element: T) => Key): Stream<T>;\r\n\r\n}\r\n\r\nexport type FlatStream<T, Depth extends number> = {\r\n    'done': Stream<T>,\r\n    'recur': T extends Iterable<infer Content>\r\n        ? FlatStream<Content, MinusOne<Depth>>\r\n        : Stream<T>\r\n}[Depth extends 0 ? 'done' : 'recur'];\r\n\r\nexport type MinusOne<N extends number> = [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20][N];\r\n\r\n/**\r\n * The default implementation of `Stream` works with two input functions:\r\n *  - The first function creates the initial state of an iteration.\r\n *  - The second function gets the current state as argument and returns an `IteratorResult`.\r\n */\r\nexport class StreamImpl<S, T> implements Stream<T> {\r\n    protected readonly startFn: () => S;\r\n    protected readonly nextFn: (state: S) => IteratorResult<T>;\r\n\r\n    constructor(startFn: () => S, nextFn: (state: S) => IteratorResult<T, undefined>) {\r\n        this.startFn = startFn;\r\n        this.nextFn = nextFn;\r\n    }\r\n\r\n    iterator(): IterableIterator<T> {\r\n        const iterator = {\r\n            state: this.startFn(),\r\n            next: () => this.nextFn(iterator.state),\r\n            [Symbol.iterator]: () => iterator\r\n        };\r\n        return iterator;\r\n    }\r\n\r\n    [Symbol.iterator](): Iterator<T> {\r\n        return this.iterator();\r\n    }\r\n\r\n    isEmpty(): boolean {\r\n        const iterator = this.iterator();\r\n        return Boolean(iterator.next().done);\r\n    }\r\n\r\n    count(): number {\r\n        const iterator = this.iterator();\r\n        let count = 0;\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            count++;\r\n            next = iterator.next();\r\n        }\r\n        return count;\r\n    }\r\n\r\n    toArray(): T[] {\r\n        const result: T[] = [];\r\n        const iterator = this.iterator();\r\n        let next: IteratorResult<T>;\r\n        do {\r\n            next = iterator.next();\r\n            if (next.value !== undefined) {\r\n                result.push(next.value);\r\n            }\r\n        } while (!next.done);\r\n        return result;\r\n    }\r\n\r\n    toSet(): Set<T> {\r\n        return new Set(this);\r\n    }\r\n\r\n    toMap<K = T, V = T>(keyFn?: (e: T) => K, valueFn?: (e: T) => V): Map<K, V> {\r\n        const entryStream = this.map(element => <[K, V]>[\r\n            keyFn ? keyFn(element) : element,\r\n            valueFn ? valueFn(element) : element\r\n        ]);\r\n        return new Map(entryStream);\r\n    }\r\n\r\n    toString(): string {\r\n        return this.join();\r\n    }\r\n\r\n    concat<T2>(other: Iterable<T2>): Stream<T | T2> {\r\n        return new StreamImpl<{ first: S, firstDone: boolean, iterator: Iterator<T2, unknown, undefined> }, T | T2>(\r\n            () => ({ first: this.startFn(), firstDone: false, iterator: other[Symbol.iterator]() }),\r\n            state => {\r\n                let result: IteratorResult<T | T2>;\r\n                if (!state.firstDone) {\r\n                    do {\r\n                        result = this.nextFn(state.first);\r\n                        if (!result.done) {\r\n                            return result;\r\n                        }\r\n                    } while (!result.done);\r\n                    state.firstDone = true;\r\n                }\r\n                do {\r\n                    result = state.iterator.next();\r\n                    if (!result.done) {\r\n                        return result;\r\n                    }\r\n                } while (!result.done);\r\n                return DONE_RESULT;\r\n            }\r\n        );\r\n    }\r\n\r\n    join(separator = ','): string {\r\n        const iterator = this.iterator();\r\n        let value = '';\r\n        let result: IteratorResult<T>;\r\n        let addSeparator = false;\r\n        do {\r\n            result = iterator.next();\r\n            if (!result.done) {\r\n                if (addSeparator) {\r\n                    value += separator;\r\n                }\r\n                value += toString(result.value);\r\n            }\r\n            addSeparator = true;\r\n        } while (!result.done);\r\n        return value;\r\n    }\r\n\r\n    indexOf(searchElement: T, fromIndex = 0): number {\r\n        const iterator = this.iterator();\r\n        let index = 0;\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            if (index >= fromIndex && next.value === searchElement) {\r\n                return index;\r\n            }\r\n            next = iterator.next();\r\n            index++;\r\n        }\r\n        return -1;\r\n    }\r\n\r\n    // In the following definition the '& this' part in the return type is important\r\n    // _and_ the order within 'Stream<U> & this' is crucial!\r\n    // Otherwise Typescript would infer the type of 'this' as 'StreamImpl<S, T> & Stream<U>'\r\n    // (or '<subClass of StreamImpl<S, T> & Stream<U>') and usages like\r\n    // ```\r\n    //  const stream = new StreamImpl(...);\r\n    //  ... stream.every(<typeGuard>) & stream....\r\n    // ```\r\n    // cannot benefit from '<typeGuard>', as Typescript would priorize the signatures\r\n    // of 'StreamImpl<S, T>' (i.e. those of 'Stream<T>') over those of 'Stream<U>'.\r\n    // With the order of 'Stream<U> & this' the signatures of 'Stream<U>' get precedence.\r\n    every<U extends T>(predicate: (value: T) => value is U): this is Stream<U> & this;\r\n    every(predicate: (value: T) => unknown): boolean;\r\n    every(predicate: (value: T) => unknown): boolean {\r\n        const iterator = this.iterator();\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            if (!predicate(next.value)) {\r\n                return false;\r\n            }\r\n            next = iterator.next();\r\n        }\r\n        return true;\r\n    }\r\n\r\n    some(predicate: (value: T) => unknown): boolean {\r\n        const iterator = this.iterator();\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            if (predicate(next.value)) {\r\n                return true;\r\n            }\r\n            next = iterator.next();\r\n        }\r\n        return false;\r\n    }\r\n\r\n    forEach(callbackfn: (value: T, index: number) => void): void {\r\n        const iterator = this.iterator();\r\n        let index = 0;\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            callbackfn(next.value, index);\r\n            next = iterator.next();\r\n            index++;\r\n        }\r\n    }\r\n\r\n    map<U>(callbackfn: (value: T) => U): Stream<U> {\r\n        return new StreamImpl<S, U>(\r\n            this.startFn,\r\n            (state) => {\r\n                const { done, value } = this.nextFn(state);\r\n                if (done) {\r\n                    return DONE_RESULT;\r\n                } else {\r\n                    return { done: false, value: callbackfn(value) };\r\n                }\r\n            }\r\n        );\r\n    }\r\n\r\n    // for remarks on the return type definition refer to 'every<U extends T>(...)'\r\n    filter<U extends T>(predicate: (value: T) => value is U): Stream<U> & this;\r\n    filter(predicate: (value: T) => unknown): Stream<T> & this;\r\n    filter(predicate: (value: T) => unknown): Stream<T> {\r\n        return new StreamImpl<S, T>(\r\n            this.startFn,\r\n            state => {\r\n                let result: IteratorResult<T>;\r\n                do {\r\n                    result = this.nextFn(state);\r\n                    if (!result.done && predicate(result.value)) {\r\n                        return result;\r\n                    }\r\n                } while (!result.done);\r\n                return DONE_RESULT;\r\n            }\r\n        );\r\n    }\r\n\r\n    nonNullable(): Stream<NonNullable<T>> {\r\n        return this.filter(e => e !== undefined && e !== null) as Stream<NonNullable<T>>;\r\n    }\r\n\r\n    reduce(callbackfn: (previousValue: T, currentValue: T) => T): T | undefined;\r\n    reduce<U = T>(callbackfn: (previousValue: U, currentValue: T) => U, initialValue: U): U;\r\n    reduce<U>(callbackfn: (previousValue: U | T, currentValue: T) => U, initialValue?: U): U | T | undefined {\r\n        const iterator = this.iterator();\r\n        let previousValue: U | T | undefined = initialValue;\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            if (previousValue === undefined) {\r\n                previousValue = next.value;\r\n            } else {\r\n                previousValue = callbackfn(previousValue, next.value);\r\n            }\r\n            next = iterator.next();\r\n        }\r\n        return previousValue;\r\n    }\r\n\r\n    reduceRight(callbackfn: (previousValue: T, currentValue: T) => T): T | undefined;\r\n    reduceRight<U = T>(callbackfn: (previousValue: U, currentValue: T) => U, initialValue: U): U;\r\n    reduceRight<U>(callbackfn: (previousValue: U | T, currentValue: T) => U, initialValue?: U): U | T | undefined {\r\n        return this.recursiveReduce(this.iterator(), callbackfn, initialValue);\r\n    }\r\n\r\n    protected recursiveReduce<U>(iterator: Iterator<T>, callbackfn: (previousValue: U | T, currentValue: T) => U, initialValue?: U): U | T | undefined {\r\n        const next = iterator.next();\r\n        if (next.done) {\r\n            return initialValue;\r\n        }\r\n        const previousValue = this.recursiveReduce(iterator, callbackfn, initialValue);\r\n        if (previousValue === undefined) {\r\n            return next.value;\r\n        }\r\n        return callbackfn(previousValue, next.value);\r\n    }\r\n\r\n    find<S extends T>(predicate: (value: T) => value is S): S | undefined;\r\n    find(predicate: (value: T) => unknown): T | undefined;\r\n    find(predicate: (value: T) => unknown): T | undefined {\r\n        const iterator = this.iterator();\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            if (predicate(next.value)) {\r\n                return next.value;\r\n            }\r\n            next = iterator.next();\r\n        }\r\n        return undefined;\r\n    }\r\n\r\n    findIndex(predicate: (value: T) => unknown): number {\r\n        const iterator = this.iterator();\r\n        let index = 0;\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            if (predicate(next.value)) {\r\n                return index;\r\n            }\r\n            next = iterator.next();\r\n            index++;\r\n        }\r\n        return -1;\r\n    }\r\n\r\n    includes(searchElement: T): boolean {\r\n        const iterator = this.iterator();\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            if (next.value === searchElement) {\r\n                return true;\r\n            }\r\n            next = iterator.next();\r\n        }\r\n        return false;\r\n    }\r\n\r\n    flatMap<U>(callbackfn: (value: T) => U | Iterable<U>): Stream<U> {\r\n        type FlatMapState = { this: S, iterator?: Iterator<U, undefined> }\r\n        return new StreamImpl<FlatMapState, U>(\r\n            () => ({ this: this.startFn() }),\r\n            (state) => {\r\n                do {\r\n                    if (state.iterator) {\r\n                        const next = state.iterator.next();\r\n                        if (next.done) {\r\n                            state.iterator = undefined;\r\n                        } else {\r\n                            return next;\r\n                        }\r\n                    }\r\n                    const { done, value } = this.nextFn(state.this);\r\n                    if (!done) {\r\n                        const mapped = callbackfn(value);\r\n                        if (isIterable(mapped)) {\r\n                            state.iterator = mapped[Symbol.iterator]();\r\n                        } else {\r\n                            return { done: false, value: mapped };\r\n                        }\r\n                    }\r\n                } while (state.iterator);\r\n                return DONE_RESULT;\r\n            }\r\n        );\r\n    }\r\n\r\n    flat<D extends number = 1>(depth?: D): FlatStream<T, D> {\r\n        if (depth === undefined) {\r\n            depth = 1 as D;\r\n        }\r\n        if (depth <= 0) {\r\n            return this as unknown as FlatStream<T, D>;\r\n        }\r\n        const stream = depth > 1 ? this.flat(depth - 1) as unknown as StreamImpl<S, T> : this;\r\n        type FlatMapState = { this: S, iterator?: Iterator<T, undefined> }\r\n        return new StreamImpl<FlatMapState, T>(\r\n            () => ({ this: stream.startFn() }),\r\n            (state) => {\r\n                do {\r\n                    if (state.iterator) {\r\n                        const next = state.iterator.next();\r\n                        if (next.done) {\r\n                            state.iterator = undefined;\r\n                        } else {\r\n                            return next;\r\n                        }\r\n                    }\r\n                    const { done, value } = stream.nextFn(state.this);\r\n                    if (!done) {\r\n                        if (isIterable(value)) {\r\n                            state.iterator = value[Symbol.iterator]() as Iterator<T>;\r\n                        } else {\r\n                            return { done: false, value: value };\r\n                        }\r\n                    }\r\n                } while (state.iterator);\r\n                return DONE_RESULT;\r\n            }\r\n        ) as unknown as FlatStream<T, D>;\r\n    }\r\n\r\n    head(): T | undefined {\r\n        const iterator = this.iterator();\r\n        const result = iterator.next();\r\n        if (result.done) {\r\n            return undefined;\r\n        }\r\n        return result.value;\r\n    }\r\n\r\n    tail(skipCount = 1): Stream<T> {\r\n        return new StreamImpl<S, T>(\r\n            () => {\r\n                const state = this.startFn();\r\n                for (let i = 0; i < skipCount; i++) {\r\n                    const next = this.nextFn(state);\r\n                    if (next.done) {\r\n                        return state;\r\n                    }\r\n                }\r\n                return state;\r\n            },\r\n            this.nextFn\r\n        );\r\n    }\r\n\r\n    limit(maxSize: number): Stream<T> {\r\n        return new StreamImpl<{ size: number, state: S }, T>(\r\n            () => ({ size: 0, state: this.startFn() }),\r\n            state => {\r\n                state.size++;\r\n                if (state.size > maxSize) {\r\n                    return DONE_RESULT;\r\n                }\r\n                return this.nextFn(state.state);\r\n            }\r\n        );\r\n    }\r\n\r\n    distinct<Key = T>(by?: (element: T) => Key): Stream<T> {\r\n        return new StreamImpl<{ set: Set<Key | T>, internalState: S }, T>(\r\n            () => ({ set: new Set<Key | T>(), internalState: this.startFn() }),\r\n            state => {\r\n                let result: IteratorResult<T>;\r\n                do {\r\n                    result = this.nextFn(state.internalState);\r\n                    if (!result.done) {\r\n                        const value = by ? by(result.value) : result.value;\r\n                        if (!state.set.has(value)) {\r\n                            state.set.add(value);\r\n                            return result;\r\n                        }\r\n                    }\r\n                } while (!result.done);\r\n                return DONE_RESULT;\r\n            }\r\n        );\r\n    }\r\n\r\n    exclude<Key = T>(other: Iterable<T>, key?: (element: T) => Key): Stream<T> {\r\n        const otherKeySet = new Set<Key | T>();\r\n        for (const item of other) {\r\n            const value = key ? key(item) : item;\r\n            otherKeySet.add(value);\r\n        }\r\n        return this.filter(e => {\r\n            const ownKey = key ? key(e) : e;\r\n            return !otherKeySet.has(ownKey);\r\n        });\r\n    }\r\n}\r\n\r\nfunction toString(item: unknown): string {\r\n    if (typeof item === 'string') {\r\n        return item as string;\r\n    }\r\n    if (typeof item === 'undefined') {\r\n        return 'undefined';\r\n    }\r\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n    if (typeof (item as any).toString === 'function') {\r\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n        return (item as any).toString();\r\n    }\r\n    return Object.prototype.toString.call(item);\r\n}\r\n\r\nfunction isIterable<T>(obj: unknown): obj is Iterable<T> {\r\n    return !!obj && typeof (obj as Iterable<T>)[Symbol.iterator] === 'function';\r\n}\r\n\r\n/**\r\n * An empty stream of any type.\r\n */\r\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\r\nexport const EMPTY_STREAM: Stream<any> = new StreamImpl<undefined, any>(() => undefined, () => DONE_RESULT);\r\n\r\n/**\r\n * Use this `IteratorResult` when implementing a `StreamImpl` to indicate that there are no more elements in the stream.\r\n */\r\nexport const DONE_RESULT: IteratorReturnResult<undefined> = Object.freeze({ done: true, value: undefined });\r\n\r\n/**\r\n * Create a stream from one or more iterables or array-likes.\r\n */\r\nexport function stream<T>(...collections: Array<Iterable<T> | ArrayLike<T>>): Stream<T> {\r\n    if (collections.length === 1) {\r\n        const collection = collections[0];\r\n        if (collection instanceof StreamImpl) {\r\n            return collection as Stream<T>;\r\n        }\r\n        if (isIterable(collection)) {\r\n            return new StreamImpl<Iterator<T, undefined>, T>(\r\n                () => collection[Symbol.iterator](),\r\n                (iterator) => iterator.next()\r\n            );\r\n        }\r\n        if (typeof collection.length === 'number') {\r\n            return new StreamImpl<{ index: number }, T>(\r\n                () => ({ index: 0 }),\r\n                (state) => {\r\n                    if (state.index < collection.length) {\r\n                        return { done: false, value: collection[state.index++] };\r\n                    } else {\r\n                        return DONE_RESULT;\r\n                    }\r\n                }\r\n            );\r\n        }\r\n    }\r\n    if (collections.length > 1) {\r\n        type State = { collIndex: number, iterator?: Iterator<T, undefined>, array?: ArrayLike<T>, arrIndex: number };\r\n        return new StreamImpl<State, T>(\r\n            () => ({ collIndex: 0, arrIndex: 0 }),\r\n            (state) => {\r\n                do {\r\n                    if (state.iterator) {\r\n                        const next = state.iterator.next();\r\n                        if (!next.done) {\r\n                            return next;\r\n                        }\r\n                        state.iterator = undefined;\r\n                    }\r\n                    if (state.array) {\r\n                        if (state.arrIndex < state.array.length) {\r\n                            return { done: false, value: state.array[state.arrIndex++] };\r\n                        }\r\n                        state.array = undefined;\r\n                        state.arrIndex = 0;\r\n                    }\r\n                    if (state.collIndex < collections.length) {\r\n                        const collection = collections[state.collIndex++];\r\n                        if (isIterable(collection)) {\r\n                            state.iterator = collection[Symbol.iterator]();\r\n                        } else if (collection && typeof collection.length === 'number') {\r\n                            state.array = collection;\r\n                        }\r\n                    }\r\n                } while (state.iterator || state.array || state.collIndex < collections.length);\r\n                return DONE_RESULT;\r\n            }\r\n        );\r\n    }\r\n    return EMPTY_STREAM;\r\n}\r\n\r\n/**\r\n * A tree iterator adds the ability to prune the current iteration.\r\n */\r\nexport interface TreeIterator<T> extends IterableIterator<T> {\r\n    /**\r\n     * Skip the whole subtree below the last returned element. The iteration continues as if that\r\n     * element had no children.\r\n     */\r\n    prune(): void\r\n}\r\n\r\n/**\r\n * A tree stream is used to stream the elements of a tree, for example an AST or CST.\r\n */\r\nexport interface TreeStream<T> extends Stream<T> {\r\n    iterator(): TreeIterator<T>\r\n}\r\n\r\n/**\r\n * The default implementation of `TreeStream` takes a root element and a function that computes the\r\n * children of its argument. Whether the root node included in the stream is controlled with the\r\n * `includeRoot` option, which defaults to `false`.\r\n */\r\nexport class TreeStreamImpl<T>\r\n    extends StreamImpl<{ iterators: Array<Iterator<T>>, pruned: boolean }, T>\r\n    implements TreeStream<T> {\r\n\r\n    constructor(root: T, children: (node: T) => Iterable<T>, options?: { includeRoot?: boolean }) {\r\n        super(\r\n            () => ({\r\n                iterators: options?.includeRoot ? [[root][Symbol.iterator]()] : [children(root)[Symbol.iterator]()],\r\n                pruned: false\r\n            }),\r\n            state => {\r\n                if (state.pruned) {\r\n                    state.iterators.pop();\r\n                    state.pruned = false;\r\n                }\r\n                while (state.iterators.length > 0) {\r\n                    const iterator = state.iterators[state.iterators.length - 1];\r\n                    const next = iterator.next();\r\n                    if (next.done) {\r\n                        state.iterators.pop();\r\n                    } else {\r\n                        state.iterators.push(children(next.value)[Symbol.iterator]());\r\n                        return next;\r\n                    }\r\n                }\r\n                return DONE_RESULT;\r\n            }\r\n        );\r\n    }\r\n\r\n    override iterator(): TreeIterator<T> {\r\n        const iterator = {\r\n            state: this.startFn(),\r\n            next: () => this.nextFn(iterator.state),\r\n            prune: () => {\r\n                iterator.state.pruned = true;\r\n            },\r\n            [Symbol.iterator]: () => iterator\r\n        };\r\n        return iterator;\r\n    }\r\n}\r\n\r\n/**\r\n * A set of utility functions that reduce a stream to a single value.\r\n */\r\nexport namespace Reduction {\r\n\r\n    /**\r\n     * Compute the sum of a number stream.\r\n     */\r\n    export function sum(stream: Stream<number>): number {\r\n        return stream.reduce((a, b) => a + b, 0);\r\n    }\r\n\r\n    /**\r\n     * Compute the product of a number stream.\r\n     */\r\n    export function product(stream: Stream<number>): number {\r\n        return stream.reduce((a, b) => a * b, 0);\r\n    }\r\n\r\n    /**\r\n     * Compute the minimum of a number stream. Returns `undefined` if the stream is empty.\r\n     */\r\n    export function min(stream: Stream<number>): number | undefined {\r\n        return stream.reduce((a, b) => Math.min(a, b));\r\n    }\r\n\r\n    /**\r\n     * Compute the maximum of a number stream. Returns `undefined` if the stream is empty.\r\n     */\r\n    export function max(stream: Stream<number>): number | undefined {\r\n        return stream.reduce((a, b) => Math.max(a, b));\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices, LangiumSharedCoreServices } from './services.js';\r\nimport type { TextDocumentProvider } from './workspace/documents.js';\r\nimport { UriUtils, type URI } from './utils/uri-utils.js';\r\n\r\n/**\r\n * The service registry provides access to the language-specific {@link LangiumCoreServices} optionally including LSP-related services.\r\n * These are resolved via the URI of a text document.\r\n */\r\nexport interface ServiceRegistry {\r\n\r\n    /**\r\n     * Register a language via its injected services.\r\n     */\r\n    register(language: LangiumCoreServices): void;\r\n\r\n    /**\r\n     * Retrieve the language-specific services for the given URI. In case only one language is\r\n     * registered, it may be used regardless of the URI format.\r\n     */\r\n    getServices(uri: URI): LangiumCoreServices;\r\n\r\n    /**\r\n     * Check whether services are available for the given URI.\r\n     */\r\n    hasServices(uri: URI): boolean;\r\n\r\n    /**\r\n     * The full set of registered language services.\r\n     */\r\n    readonly all: readonly LangiumCoreServices[];\r\n}\r\n\r\n/**\r\n * Generic registry for Langium services, but capable of being used with extending service sets as well (such as the lsp-complete LangiumCoreServices set)\r\n */\r\nexport class DefaultServiceRegistry implements ServiceRegistry {\r\n\r\n    protected singleton?: LangiumCoreServices;\r\n    protected readonly languageIdMap = new Map<string, LangiumCoreServices>();\r\n    protected readonly fileExtensionMap = new Map<string, LangiumCoreServices>();\r\n\r\n    /**\r\n     * @deprecated Use the new `fileExtensionMap` (or `languageIdMap`) property instead.\r\n     */\r\n    protected get map(): Map<string, LangiumCoreServices> | undefined {\r\n        return this.fileExtensionMap;\r\n    }\r\n\r\n    protected readonly textDocuments?: TextDocumentProvider;\r\n\r\n    constructor(services?: LangiumSharedCoreServices) {\r\n        this.textDocuments = services?.workspace.TextDocuments;\r\n    }\r\n\r\n    register(language: LangiumCoreServices): void {\r\n        const data = language.LanguageMetaData;\r\n        for (const ext of data.fileExtensions) {\r\n            if (this.fileExtensionMap.has(ext)) {\r\n                console.warn(`The file extension ${ext} is used by multiple languages. It is now assigned to '${data.languageId}'.`);\r\n            }\r\n            this.fileExtensionMap.set(ext, language);\r\n        }\r\n        this.languageIdMap.set(data.languageId, language);\r\n        if (this.languageIdMap.size === 1) {\r\n            this.singleton = language;\r\n        } else {\r\n            this.singleton = undefined;\r\n        }\r\n    }\r\n\r\n    getServices(uri: URI): LangiumCoreServices {\r\n        if (this.singleton !== undefined) {\r\n            return this.singleton;\r\n        }\r\n        if (this.languageIdMap.size === 0) {\r\n            throw new Error('The service registry is empty. Use `register` to register the services of a language.');\r\n        }\r\n        const languageId = this.textDocuments?.get(uri)?.languageId;\r\n        if (languageId !== undefined) {\r\n            const services = this.languageIdMap.get(languageId);\r\n            if (services) {\r\n                return services;\r\n            }\r\n        }\r\n        const ext = UriUtils.extname(uri);\r\n        const services = this.fileExtensionMap.get(ext);\r\n        if (!services) {\r\n            if (languageId) {\r\n                throw new Error(`The service registry contains no services for the extension '${ext}' for language '${languageId}'.`);\r\n            } else {\r\n                throw new Error(`The service registry contains no services for the extension '${ext}'.`);\r\n            }\r\n        }\r\n        return services;\r\n    }\r\n\r\n    hasServices(uri: URI): boolean {\r\n        try {\r\n            this.getServices(uri);\r\n            return true;\r\n        } catch {\r\n            return false;\r\n        }\r\n    }\r\n\r\n    get all(): readonly LangiumCoreServices[] {\r\n        return Array.from(this.languageIdMap.values());\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\n/**\r\n * Re-export 'TextDocument' from 'vscode-languageserver-textdocument' for convenience,\r\n *  including both type _and_ symbol (namespace), as we here and there also refer to the symbol,\r\n *  the overhead is very small, just a few kilobytes.\r\n * Everything else of that package (at the time contributing) is also defined\r\n *  in 'vscode-languageserver-protocol' or 'vscode-languageserver-types'.\r\n */\r\nexport { TextDocument } from 'vscode-languageserver-textdocument';\r\n\r\nimport type { Diagnostic, Range } from 'vscode-languageserver-types';\r\nimport type { FileSystemProvider } from './file-system-provider.js';\r\nimport type { ParseResult, ParserOptions } from '../parser/langium-parser.js';\r\nimport type { ServiceRegistry } from '../service-registry.js';\r\nimport type { LangiumSharedCoreServices } from '../services.js';\r\nimport type { AstNode, AstNodeDescription, Mutable, Reference } from '../syntax-tree.js';\r\nimport type { MultiMap } from '../utils/collections.js';\r\nimport type { Stream } from '../utils/stream.js';\r\nimport { TextDocument } from './documents.js';\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport { stream } from '../utils/stream.js';\r\nimport { URI } from '../utils/uri-utils.js';\r\n\r\n/**\r\n * A Langium document holds the parse result (AST and CST) and any additional state that is derived\r\n * from the AST, e.g. the result of scope precomputation.\r\n */\r\nexport interface LangiumDocument<T extends AstNode = AstNode> {\r\n    /** The Uniform Resource Identifier (URI) of the document */\r\n    readonly uri: URI;\r\n    /** The text document used to convert between offsets and positions */\r\n    readonly textDocument: TextDocument;\r\n    /** The current state of the document */\r\n    state: DocumentState;\r\n    /** The parse result holds the Abstract Syntax Tree (AST) and potentially also parser / lexer errors */\r\n    parseResult: ParseResult<T>;\r\n    /** Result of the scope precomputation phase */\r\n    precomputedScopes?: PrecomputedScopes;\r\n    /** An array of all cross-references found in the AST while linking */\r\n    references: Reference[];\r\n    /** Result of the validation phase */\r\n    diagnostics?: Diagnostic[]\r\n}\r\n\r\n/**\r\n * A document is subject to several phases that are run in predefined order. Any state value implies that\r\n * smaller state values are finished as well.\r\n */\r\nexport enum DocumentState {\r\n    /**\r\n     * The text content has changed and needs to be parsed again. The AST held by this outdated\r\n     * document instance is no longer valid.\r\n     */\r\n    Changed = 0,\r\n    /**\r\n     * An AST has been created from the text content. The document structure can be traversed,\r\n     * but cross-references cannot be resolved yet. If necessary, the structure can be manipulated\r\n     * at this stage as a preprocessing step.\r\n     */\r\n    Parsed = 1,\r\n    /**\r\n     * The `IndexManager` service has processed AST nodes of this document. This means the\r\n     * exported symbols are available in the global scope and can be resolved from other documents.\r\n     */\r\n    IndexedContent = 2,\r\n    /**\r\n     * The `ScopeComputation` service has processed this document. This means the local symbols\r\n     * are stored in a MultiMap so they can be looked up by the `ScopeProvider` service.\r\n     * Once a document has reached this state, you may follow every reference - it will lazily\r\n     * resolve its `ref` property and yield either the target AST node or `undefined` in case\r\n     * the target is not in scope.\r\n     */\r\n    ComputedScopes = 3,\r\n    /**\r\n     * The `Linker` service has processed this document. All outgoing references have been\r\n     * resolved or marked as erroneous.\r\n     */\r\n    Linked = 4,\r\n    /**\r\n     * The `IndexManager` service has processed AST node references of this document. This is\r\n     * necessary to determine which documents are affected by a change in one of the workspace\r\n     * documents.\r\n     */\r\n    IndexedReferences = 5,\r\n    /**\r\n     * The `DocumentValidator` service has processed this document. The language server listens\r\n     * to the results of this phase and sends diagnostics to the client.\r\n     */\r\n    Validated = 6\r\n}\r\n\r\n/**\r\n * Result of the scope precomputation phase (`ScopeComputation` service).\r\n * It maps every AST node to the set of symbols that are visible in the subtree of that node.\r\n */\r\nexport type PrecomputedScopes = MultiMap<AstNode, AstNodeDescription>\r\n\r\nexport interface DocumentSegment {\r\n    readonly range: Range\r\n    readonly offset: number\r\n    readonly length: number\r\n    readonly end: number\r\n}\r\n\r\n/**\r\n * Surrogate definition of the `TextDocuments` interface from the `vscode-languageserver` package.\r\n * No implementation object is expected to be offered by `LangiumCoreServices`, but only by `LangiumLSPServices`.\r\n */\r\nexport type TextDocumentProvider = {\r\n    get(uri: string | URI): TextDocument | undefined\r\n}\r\n\r\n/**\r\n * Shared service for creating `LangiumDocument` instances.\r\n *\r\n * Register a custom implementation if special (additional) behavior is required for your language(s).\r\n * Note: If you specialize {@link fromString} or {@link fromTextDocument} you probably might want to\r\n * specialize {@link update}, too!\r\n */\r\nexport interface LangiumDocumentFactory {\r\n    /**\r\n     * Create a Langium document from a `TextDocument` (usually associated with a file).\r\n     */\r\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri?: URI, options?: ParserOptions): LangiumDocument<T>;\r\n    /**\r\n     * Create a Langium document from a `TextDocument` asynchronously. This action can be cancelled if a cancellable parser implementation has been provided.\r\n     */\r\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri: URI | undefined, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>;\r\n\r\n    /**\r\n     * Create an Langium document from an in-memory string.\r\n     */\r\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI, options?: ParserOptions): LangiumDocument<T>;\r\n    /**\r\n     * Create a Langium document from an in-memory string asynchronously. This action can be cancelled if a cancellable parser implementation has been provided.\r\n     */\r\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>;\r\n\r\n    /**\r\n     * Create an Langium document from a model that has been constructed in memory.\r\n     */\r\n    fromModel<T extends AstNode = AstNode>(model: T, uri: URI): LangiumDocument<T>;\r\n\r\n    /**\r\n     * Create an Langium document from a specified `URI`. The factory will use the `FileSystemAccess` service to read the file.\r\n     */\r\n    fromUri<T extends AstNode = AstNode>(uri: URI, cancellationToken?: CancellationToken): Promise<LangiumDocument<T>>;\r\n\r\n    /**\r\n     * Update the given document after changes in the corresponding textual representation.\r\n     * Method is called by the document builder after it has been requested to build an existing\r\n     * document and the document's state is {@link DocumentState.Changed}.\r\n     * The text parsing is expected to be done the same way as in {@link fromTextDocument}\r\n     * and {@link fromString}.\r\n     */\r\n    update<T extends AstNode = AstNode>(document: LangiumDocument<T>, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>\r\n}\r\n\r\nexport class DefaultLangiumDocumentFactory implements LangiumDocumentFactory {\r\n\r\n    protected readonly serviceRegistry: ServiceRegistry;\r\n    protected readonly textDocuments?: TextDocumentProvider;\r\n    protected readonly fileSystemProvider: FileSystemProvider;\r\n\r\n    constructor(services: LangiumSharedCoreServices) {\r\n        this.serviceRegistry = services.ServiceRegistry;\r\n        this.textDocuments = services.workspace.TextDocuments;\r\n        this.fileSystemProvider = services.workspace.FileSystemProvider;\r\n    }\r\n\r\n    async fromUri<T extends AstNode = AstNode>(uri: URI, cancellationToken = CancellationToken.None): Promise<LangiumDocument<T>> {\r\n        const content = await this.fileSystemProvider.readFile(uri);\r\n        return this.createAsync<T>(uri, content, cancellationToken);\r\n    }\r\n\r\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri?: URI, options?: ParserOptions): LangiumDocument<T>;\r\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri: URI | undefined, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>;\r\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri?: URI, token?: CancellationToken | ParserOptions): LangiumDocument<T> | Promise<LangiumDocument<T>> {\r\n        uri = uri ?? URI.parse(textDocument.uri);\r\n        if (CancellationToken.is(token)) {\r\n            return this.createAsync<T>(uri, textDocument, token);\r\n        } else {\r\n            return this.create<T>(uri, textDocument, token);\r\n        }\r\n    }\r\n\r\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI, options?: ParserOptions): LangiumDocument<T>;\r\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>;\r\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI, token?: CancellationToken | ParserOptions): LangiumDocument<T> | Promise<LangiumDocument<T>> {\r\n        if (CancellationToken.is(token)) {\r\n            return this.createAsync<T>(uri, text, token);\r\n        } else {\r\n            return this.create<T>(uri, text, token);\r\n        }\r\n    }\r\n\r\n    fromModel<T extends AstNode = AstNode>(model: T, uri: URI): LangiumDocument<T> {\r\n        return this.create<T>(uri, { $model: model });\r\n    }\r\n\r\n    protected create<T extends AstNode = AstNode>(uri: URI, content: string | TextDocument | { $model: T }, options?: ParserOptions): LangiumDocument<T> {\r\n        if (typeof content === 'string') {\r\n            const parseResult = this.parse<T>(uri, content, options);\r\n            return this.createLangiumDocument<T>(parseResult, uri, undefined, content);\r\n\r\n        } else if ('$model' in content) {\r\n            const parseResult = { value: content.$model, parserErrors: [], lexerErrors: [] };\r\n            return this.createLangiumDocument<T>(parseResult, uri);\r\n\r\n        } else {\r\n            const parseResult = this.parse<T>(uri, content.getText(), options);\r\n            return this.createLangiumDocument(parseResult, uri, content);\r\n        }\r\n    }\r\n\r\n    protected async createAsync<T extends AstNode = AstNode>(uri: URI, content: string | TextDocument, cancelToken: CancellationToken): Promise<LangiumDocument<T>> {\r\n        if (typeof content === 'string') {\r\n            const parseResult = await this.parseAsync<T>(uri, content, cancelToken);\r\n            return this.createLangiumDocument<T>(parseResult, uri, undefined, content);\r\n        } else {\r\n            const parseResult = await this.parseAsync<T>(uri, content.getText(), cancelToken);\r\n            return this.createLangiumDocument(parseResult, uri, content);\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Create a LangiumDocument from a given parse result.\r\n     *\r\n     * A TextDocument is created on demand if it is not provided as argument here. Usually this\r\n     * should not be necessary because the main purpose of the TextDocument is to convert between\r\n     * text ranges and offsets, which is done solely in LSP request handling.\r\n     *\r\n     * With the introduction of {@link update} below this method is supposed to be mainly called\r\n     * during workspace initialization and on addition/recognition of new files, while changes in\r\n     * existing documents are processed via {@link update}.\r\n     */\r\n    protected createLangiumDocument<T extends AstNode = AstNode>(parseResult: ParseResult<T>, uri: URI, textDocument?: TextDocument, text?: string): LangiumDocument<T> {\r\n        let document: LangiumDocument<T>;\r\n        if (textDocument) {\r\n            document = {\r\n                parseResult,\r\n                uri,\r\n                state: DocumentState.Parsed,\r\n                references: [],\r\n                textDocument\r\n            };\r\n        } else {\r\n            const textDocumentGetter = this.createTextDocumentGetter(uri, text);\r\n            document = {\r\n                parseResult,\r\n                uri,\r\n                state: DocumentState.Parsed,\r\n                references: [],\r\n                get textDocument() {\r\n                    return textDocumentGetter();\r\n                }\r\n            };\r\n        }\r\n        (parseResult.value as Mutable<AstNode>).$document = document;\r\n        return document;\r\n    }\r\n\r\n    async update<T extends AstNode = AstNode>(document: Mutable<LangiumDocument<T>>, cancellationToken: CancellationToken): Promise<LangiumDocument<T>> {\r\n        // The CST full text property contains the original text that was used to create the AST.\r\n        const oldText = document.parseResult.value.$cstNode?.root.fullText;\r\n        const textDocument = this.textDocuments?.get(document.uri.toString());\r\n        const text = textDocument ? textDocument.getText() : await this.fileSystemProvider.readFile(document.uri);\r\n\r\n        if (textDocument) {\r\n            Object.defineProperty(\r\n                document,\r\n                'textDocument',\r\n                {\r\n                    value: textDocument\r\n                }\r\n            );\r\n        } else {\r\n            const textDocumentGetter = this.createTextDocumentGetter(document.uri, text);\r\n            Object.defineProperty(\r\n                document,\r\n                'textDocument',\r\n                {\r\n                    get: textDocumentGetter\r\n                }\r\n            );\r\n        }\r\n\r\n        // Some of these documents can be pretty large, so parsing them again can be quite expensive.\r\n        // Therefore, we only parse if the text has actually changed.\r\n        if (oldText !== text) {\r\n            document.parseResult = await this.parseAsync(document.uri, text, cancellationToken);\r\n            (document.parseResult.value as Mutable<AstNode>).$document = document;\r\n        }\r\n        document.state = DocumentState.Parsed;\r\n        return document;\r\n    }\r\n\r\n    protected parse<T extends AstNode>(uri: URI, text: string, options?: ParserOptions): ParseResult<T> {\r\n        const services = this.serviceRegistry.getServices(uri);\r\n        return services.parser.LangiumParser.parse<T>(text, options);\r\n    }\r\n\r\n    protected parseAsync<T extends AstNode>(uri: URI, text: string, cancellationToken: CancellationToken): Promise<ParseResult<T>> {\r\n        const services = this.serviceRegistry.getServices(uri);\r\n        return services.parser.AsyncParser.parse<T>(text, cancellationToken);\r\n    }\r\n\r\n    protected createTextDocumentGetter(uri: URI, text?: string): () => TextDocument {\r\n        const serviceRegistry = this.serviceRegistry;\r\n        let textDoc: TextDocument | undefined = undefined;\r\n        return () => {\r\n            return textDoc ??= TextDocument.create(\r\n                uri.toString(), serviceRegistry.getServices(uri).LanguageMetaData.languageId, 0, text ?? ''\r\n            );\r\n        };\r\n    }\r\n}\r\n\r\n/**\r\n * Shared service for managing Langium documents.\r\n */\r\nexport interface LangiumDocuments {\r\n\r\n    /**\r\n     * A stream of all documents managed under this service.\r\n     */\r\n    readonly all: Stream<LangiumDocument>\r\n\r\n    /**\r\n     * Manage a new document under this service.\r\n     * @throws an error if a document with the same URI is already present.\r\n     */\r\n    addDocument(document: LangiumDocument): void;\r\n\r\n    /**\r\n     * Retrieve the document with the given URI, if present. Otherwise returns `undefined`.\r\n     */\r\n    getDocument(uri: URI): LangiumDocument | undefined;\r\n\r\n    /**\r\n     * Retrieve the document with the given URI. If not present, a new one will be created using the file system access.\r\n     * The new document will be added to the list of documents managed under this service.\r\n     */\r\n    getOrCreateDocument(uri: URI, cancellationToken?: CancellationToken): Promise<LangiumDocument>;\r\n\r\n    /**\r\n     * Creates a new document with the given URI and text content.\r\n     * The new document is automatically added to this service and can be retrieved using {@link getDocument}.\r\n     *\r\n     * @throws an error if a document with the same URI is already present.\r\n     */\r\n    createDocument(uri: URI, text: string): LangiumDocument;\r\n\r\n    /**\r\n     * Creates a new document with the given URI and text content asynchronously.\r\n     * The process can be interrupted with a cancellation token.\r\n     * The new document is automatically added to this service and can be retrieved using {@link getDocument}.\r\n     *\r\n     * @throws an error if a document with the same URI is already present.\r\n     */\r\n    createDocument(uri: URI, text: string, cancellationToken: CancellationToken): Promise<LangiumDocument>;\r\n\r\n    /**\r\n     * Returns `true` if a document with the given URI is managed under this service.\r\n     */\r\n    hasDocument(uri: URI): boolean;\r\n\r\n    /**\r\n     * Flag the document with the given URI as `Changed`, if present, meaning that its content\r\n     * is no longer valid. The content (parseResult) stays untouched, while internal data may\r\n     * be dropped to reduce memory footprint.\r\n     *\r\n     * @returns the affected {@link LangiumDocument} if existing for convenience\r\n     */\r\n    invalidateDocument(uri: URI): LangiumDocument | undefined;\r\n\r\n    /**\r\n     * Remove the document with the given URI, if present, and mark it as `Changed`, meaning\r\n     * that its content is no longer valid. The next call to `getOrCreateDocument` with the same\r\n     * URI will create a new document instance.\r\n     *\r\n     * @returns the affected {@link LangiumDocument} if existing for convenience\r\n     */\r\n    deleteDocument(uri: URI): LangiumDocument | undefined;\r\n}\r\n\r\nexport class DefaultLangiumDocuments implements LangiumDocuments {\r\n\r\n    protected readonly langiumDocumentFactory: LangiumDocumentFactory;\r\n    protected readonly serviceRegistry: ServiceRegistry;\r\n\r\n    protected readonly documentMap: Map<string, LangiumDocument> = new Map();\r\n\r\n    constructor(services: LangiumSharedCoreServices) {\r\n        this.langiumDocumentFactory = services.workspace.LangiumDocumentFactory;\r\n        this.serviceRegistry = services.ServiceRegistry;\r\n    }\r\n\r\n    get all(): Stream<LangiumDocument> {\r\n        return stream(this.documentMap.values());\r\n    }\r\n\r\n    addDocument(document: LangiumDocument): void {\r\n        const uriString = document.uri.toString();\r\n        if (this.documentMap.has(uriString)) {\r\n            throw new Error(`A document with the URI '${uriString}' is already present.`);\r\n        }\r\n        this.documentMap.set(uriString, document);\r\n    }\r\n\r\n    getDocument(uri: URI): LangiumDocument | undefined {\r\n        const uriString = uri.toString();\r\n        return this.documentMap.get(uriString);\r\n    }\r\n\r\n    async getOrCreateDocument(uri: URI, cancellationToken?: CancellationToken): Promise<LangiumDocument> {\r\n        let document = this.getDocument(uri);\r\n        if (document) {\r\n            return document;\r\n        }\r\n        document = await this.langiumDocumentFactory.fromUri(uri, cancellationToken);\r\n        this.addDocument(document);\r\n        return document;\r\n    }\r\n\r\n    createDocument(uri: URI, text: string): LangiumDocument;\r\n    createDocument(uri: URI, text: string, cancellationToken: CancellationToken): Promise<LangiumDocument>;\r\n    createDocument(uri: URI, text: string, cancellationToken?: CancellationToken): LangiumDocument | Promise<LangiumDocument> {\r\n        if (cancellationToken) {\r\n            return this.langiumDocumentFactory.fromString(text, uri, cancellationToken).then(document => {\r\n                this.addDocument(document);\r\n                return document;\r\n            });\r\n        } else {\r\n            const document = this.langiumDocumentFactory.fromString(text, uri);\r\n            this.addDocument(document);\r\n            return document;\r\n        }\r\n    }\r\n\r\n    hasDocument(uri: URI): boolean {\r\n        return this.documentMap.has(uri.toString());\r\n    }\r\n\r\n    invalidateDocument(uri: URI): LangiumDocument | undefined {\r\n        const uriString = uri.toString();\r\n        const langiumDoc = this.documentMap.get(uriString);\r\n        if (langiumDoc) {\r\n            const linker = this.serviceRegistry.getServices(uri).references.Linker;\r\n            linker.unlink(langiumDoc);\r\n            langiumDoc.state = DocumentState.Changed;\r\n            langiumDoc.precomputedScopes = undefined;\r\n            langiumDoc.diagnostics = undefined;\r\n        }\r\n        return langiumDoc;\r\n    }\r\n\r\n    deleteDocument(uri: URI): LangiumDocument | undefined {\r\n        const uriString = uri.toString();\r\n        const langiumDoc = this.documentMap.get(uriString);\r\n        if (langiumDoc) {\r\n            langiumDoc.state = DocumentState.Changed;\r\n            this.documentMap.delete(uriString);\r\n        }\r\n        return langiumDoc;\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport map from \"lodash-es/map.js\"\r\nimport { ATNState, DecisionState } from \"./atn.js\"\r\n\r\nexport interface DFA {\r\n  start?: DFAState\r\n  states: Record<string, DFAState>\r\n  decision: number\r\n  atnStartState: DecisionState\r\n}\r\n\r\nexport interface DFAState {\r\n  configs: ATNConfigSet\r\n  edges: Record<number, DFAState>\r\n  isAcceptState: boolean\r\n  prediction: number\r\n}\r\n\r\nexport const DFA_ERROR = {} as DFAState\r\n\r\nexport interface ATNConfig {\r\n  state: ATNState\r\n  alt: number\r\n  stack: ATNState[]\r\n}\r\n\r\nexport class ATNConfigSet {\r\n  private map: Record<string, number> = {}\r\n  private configs: ATNConfig[] = []\r\n\r\n  uniqueAlt: number | undefined\r\n\r\n  get size(): number {\r\n    return this.configs.length\r\n  }\r\n\r\n  finalize(): void {\r\n    // Empties the map to free up memory\r\n    this.map = {}\r\n  }\r\n\r\n  add(config: ATNConfig): void {\r\n    const key = getATNConfigKey(config)\r\n    // Only add configs which don't exist in our map already\r\n    // While this does not influence the actual algorithm, adding them anyway would massively increase memory consumption\r\n    if (!(key in this.map)) {\r\n      this.map[key] = this.configs.length\r\n      this.configs.push(config)\r\n    }\r\n  }\r\n\r\n  get elements(): readonly ATNConfig[] {\r\n    return this.configs\r\n  }\r\n\r\n  get alts(): number[] {\r\n    return map(this.configs, (e) => e.alt)\r\n  }\r\n\r\n  get key(): string {\r\n    let value = \"\"\r\n    for (const k in this.map) {\r\n      value += k + \":\"\r\n    }\r\n    return value\r\n  }\r\n}\r\n\r\nexport function getATNConfigKey(config: ATNConfig, alt = true) {\r\n  return `${alt ? `a${config.alt}` : \"\"}s${\r\n    config.state.stateNumber\r\n  }:${config.stack.map((e) => e.stateNumber.toString()).join(\"_\")}`\r\n}\r\n","import Stack from './_Stack.js';\nimport arrayEach from './_arrayEach.js';\nimport assignValue from './_assignValue.js';\nimport baseAssign from './_baseAssign.js';\nimport baseAssignIn from './_baseAssignIn.js';\nimport cloneBuffer from './_cloneBuffer.js';\nimport copyArray from './_copyArray.js';\nimport copySymbols from './_copySymbols.js';\nimport copySymbolsIn from './_copySymbolsIn.js';\nimport getAllKeys from './_getAllKeys.js';\nimport getAllKeysIn from './_getAllKeysIn.js';\nimport getTag from './_getTag.js';\nimport initCloneArray from './_initCloneArray.js';\nimport initCloneByTag from './_initCloneByTag.js';\nimport initCloneObject from './_initCloneObject.js';\nimport isArray from './isArray.js';\nimport isBuffer from './isBuffer.js';\nimport isMap from './isMap.js';\nimport isObject from './isObject.js';\nimport isSet from './isSet.js';\nimport keys from './keys.js';\nimport keysIn from './keysIn.js';\n\n/** Used to compose bitmasks for cloning. */\nvar CLONE_DEEP_FLAG = 1,\n    CLONE_FLAT_FLAG = 2,\n    CLONE_SYMBOLS_FLAG = 4;\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]',\n    arrayTag = '[object Array]',\n    boolTag = '[object Boolean]',\n    dateTag = '[object Date]',\n    errorTag = '[object Error]',\n    funcTag = '[object Function]',\n    genTag = '[object GeneratorFunction]',\n    mapTag = '[object Map]',\n    numberTag = '[object Number]',\n    objectTag = '[object Object]',\n    regexpTag = '[object RegExp]',\n    setTag = '[object Set]',\n    stringTag = '[object String]',\n    symbolTag = '[object Symbol]',\n    weakMapTag = '[object WeakMap]';\n\nvar arrayBufferTag = '[object ArrayBuffer]',\n    dataViewTag = '[object DataView]',\n    float32Tag = '[object Float32Array]',\n    float64Tag = '[object Float64Array]',\n    int8Tag = '[object Int8Array]',\n    int16Tag = '[object Int16Array]',\n    int32Tag = '[object Int32Array]',\n    uint8Tag = '[object Uint8Array]',\n    uint8ClampedTag = '[object Uint8ClampedArray]',\n    uint16Tag = '[object Uint16Array]',\n    uint32Tag = '[object Uint32Array]';\n\n/** Used to identify `toStringTag` values supported by `_.clone`. */\nvar cloneableTags = {};\ncloneableTags[argsTag] = cloneableTags[arrayTag] =\ncloneableTags[arrayBufferTag] = cloneableTags[dataViewTag] =\ncloneableTags[boolTag] = cloneableTags[dateTag] =\ncloneableTags[float32Tag] = cloneableTags[float64Tag] =\ncloneableTags[int8Tag] = cloneableTags[int16Tag] =\ncloneableTags[int32Tag] = cloneableTags[mapTag] =\ncloneableTags[numberTag] = cloneableTags[objectTag] =\ncloneableTags[regexpTag] = cloneableTags[setTag] =\ncloneableTags[stringTag] = cloneableTags[symbolTag] =\ncloneableTags[uint8Tag] = cloneableTags[uint8ClampedTag] =\ncloneableTags[uint16Tag] = cloneableTags[uint32Tag] = true;\ncloneableTags[errorTag] = cloneableTags[funcTag] =\ncloneableTags[weakMapTag] = false;\n\n/**\n * The base implementation of `_.clone` and `_.cloneDeep` which tracks\n * traversed objects.\n *\n * @private\n * @param {*} value The value to clone.\n * @param {boolean} bitmask The bitmask flags.\n *  1 - Deep clone\n *  2 - Flatten inherited properties\n *  4 - Clone symbols\n * @param {Function} [customizer] The function to customize cloning.\n * @param {string} [key] The key of `value`.\n * @param {Object} [object] The parent object of `value`.\n * @param {Object} [stack] Tracks traversed objects and their clone counterparts.\n * @returns {*} Returns the cloned value.\n */\nfunction baseClone(value, bitmask, customizer, key, object, stack) {\n  var result,\n      isDeep = bitmask & CLONE_DEEP_FLAG,\n      isFlat = bitmask & CLONE_FLAT_FLAG,\n      isFull = bitmask & CLONE_SYMBOLS_FLAG;\n\n  if (customizer) {\n    result = object ? customizer(value, key, object, stack) : customizer(value);\n  }\n  if (result !== undefined) {\n    return result;\n  }\n  if (!isObject(value)) {\n    return value;\n  }\n  var isArr = isArray(value);\n  if (isArr) {\n    result = initCloneArray(value);\n    if (!isDeep) {\n      return copyArray(value, result);\n    }\n  } else {\n    var tag = getTag(value),\n        isFunc = tag == funcTag || tag == genTag;\n\n    if (isBuffer(value)) {\n      return cloneBuffer(value, isDeep);\n    }\n    if (tag == objectTag || tag == argsTag || (isFunc && !object)) {\n      result = (isFlat || isFunc) ? {} : initCloneObject(value);\n      if (!isDeep) {\n        return isFlat\n          ? copySymbolsIn(value, baseAssignIn(result, value))\n          : copySymbols(value, baseAssign(result, value));\n      }\n    } else {\n      if (!cloneableTags[tag]) {\n        return object ? value : {};\n      }\n      result = initCloneByTag(value, tag, isDeep);\n    }\n  }\n  // Check for circular references and return its corresponding clone.\n  stack || (stack = new Stack);\n  var stacked = stack.get(value);\n  if (stacked) {\n    return stacked;\n  }\n  stack.set(value, result);\n\n  if (isSet(value)) {\n    value.forEach(function(subValue) {\n      result.add(baseClone(subValue, bitmask, customizer, subValue, value, stack));\n    });\n  } else if (isMap(value)) {\n    value.forEach(function(subValue, key) {\n      result.set(key, baseClone(subValue, bitmask, customizer, key, value, stack));\n    });\n  }\n\n  var keysFunc = isFull\n    ? (isFlat ? getAllKeysIn : getAllKeys)\n    : (isFlat ? keysIn : keys);\n\n  var props = isArr ? undefined : keysFunc(value);\n  arrayEach(props || value, function(subValue, key) {\n    if (props) {\n      key = subValue;\n      subValue = value[key];\n    }\n    // Recursively populate clone (susceptible to call stack limits).\n    assignValue(result, key, baseClone(subValue, bitmask, customizer, key, value, stack));\n  });\n  return result;\n}\n\nexport default baseClone;\n","/******************************************************************************\r\n * This file was generated by langium-cli 3.3.0.\r\n * DO NOT EDIT MANUALLY!\r\n ******************************************************************************/\r\n\r\n/* eslint-disable */\r\nimport type { AstNode, Reference, ReferenceInfo, TypeMetaData } from '../../syntax-tree.js';\r\nimport { AbstractAstReflection } from '../../syntax-tree.js';\r\n\r\nexport const LangiumGrammarTerminals = {\r\n    ID: /\\^?[_a-zA-Z][\\w_]*/,\r\n    STRING: /\"(\\\\.|[^\"\\\\])*\"|'(\\\\.|[^'\\\\])*'/,\r\n    NUMBER: /NaN|-?((\\d*\\.\\d+|\\d+)([Ee][+-]?\\d+)?|Infinity)/,\r\n    RegexLiteral: /\\/(?![*+?])(?:[^\\r\\n\\[/\\\\]|\\\\.|\\[(?:[^\\r\\n\\]\\\\]|\\\\.)*\\])+\\/[a-z]*/,\r\n    WS: /\\s+/,\r\n    ML_COMMENT: /\\/\\*[\\s\\S]*?\\*\\//,\r\n    SL_COMMENT: /\\/\\/[^\\n\\r]*/,\r\n};\r\n\r\nexport type LangiumGrammarTerminalNames = keyof typeof LangiumGrammarTerminals;\r\n\r\nexport type LangiumGrammarKeywordNames = \r\n    | \"!\"\r\n    | \"&\"\r\n    | \"(\"\r\n    | \")\"\r\n    | \"*\"\r\n    | \"+\"\r\n    | \"+=\"\r\n    | \",\"\r\n    | \"->\"\r\n    | \".\"\r\n    | \"..\"\r\n    | \":\"\r\n    | \";\"\r\n    | \"<\"\r\n    | \"=\"\r\n    | \"=>\"\r\n    | \">\"\r\n    | \"?\"\r\n    | \"?!\"\r\n    | \"?<!\"\r\n    | \"?<=\"\r\n    | \"?=\"\r\n    | \"@\"\r\n    | \"Date\"\r\n    | \"EOF\"\r\n    | \"[\"\r\n    | \"]\"\r\n    | \"bigint\"\r\n    | \"boolean\"\r\n    | \"current\"\r\n    | \"entry\"\r\n    | \"extends\"\r\n    | \"false\"\r\n    | \"fragment\"\r\n    | \"grammar\"\r\n    | \"hidden\"\r\n    | \"import\"\r\n    | \"infer\"\r\n    | \"infers\"\r\n    | \"interface\"\r\n    | \"number\"\r\n    | \"returns\"\r\n    | \"string\"\r\n    | \"terminal\"\r\n    | \"true\"\r\n    | \"type\"\r\n    | \"with\"\r\n    | \"{\"\r\n    | \"|\"\r\n    | \"}\";\r\n\r\nexport type LangiumGrammarTokenNames = LangiumGrammarTerminalNames | LangiumGrammarKeywordNames;\r\n\r\nexport type AbstractRule = ParserRule | TerminalRule;\r\n\r\nexport const AbstractRule = 'AbstractRule';\r\n\r\nexport function isAbstractRule(item: unknown): item is AbstractRule {\r\n    return reflection.isInstance(item, AbstractRule);\r\n}\r\n\r\nexport type AbstractType = InferredType | Interface | ParserRule | Type;\r\n\r\nexport const AbstractType = 'AbstractType';\r\n\r\nexport function isAbstractType(item: unknown): item is AbstractType {\r\n    return reflection.isInstance(item, AbstractType);\r\n}\r\n\r\nexport type Condition = BooleanLiteral | Conjunction | Disjunction | Negation | ParameterReference;\r\n\r\nexport const Condition = 'Condition';\r\n\r\nexport function isCondition(item: unknown): item is Condition {\r\n    return reflection.isInstance(item, Condition);\r\n}\r\n\r\nexport type FeatureName = 'current' | 'entry' | 'extends' | 'false' | 'fragment' | 'grammar' | 'hidden' | 'import' | 'infer' | 'infers' | 'interface' | 'returns' | 'terminal' | 'true' | 'type' | 'with' | PrimitiveType | string;\r\n\r\nexport function isFeatureName(item: unknown): item is FeatureName {\r\n    return isPrimitiveType(item) || item === 'current' || item === 'entry' || item === 'extends' || item === 'false' || item === 'fragment' || item === 'grammar' || item === 'hidden' || item === 'import' || item === 'interface' || item === 'returns' || item === 'terminal' || item === 'true' || item === 'type' || item === 'infer' || item === 'infers' || item === 'with' || (typeof item === 'string' && (/\\^?[_a-zA-Z][\\w_]*/.test(item)));\r\n}\r\n\r\nexport type PrimitiveType = 'Date' | 'bigint' | 'boolean' | 'number' | 'string';\r\n\r\nexport function isPrimitiveType(item: unknown): item is PrimitiveType {\r\n    return item === 'string' || item === 'number' || item === 'boolean' || item === 'Date' || item === 'bigint';\r\n}\r\n\r\nexport type TypeDefinition = ArrayType | ReferenceType | SimpleType | UnionType;\r\n\r\nexport const TypeDefinition = 'TypeDefinition';\r\n\r\nexport function isTypeDefinition(item: unknown): item is TypeDefinition {\r\n    return reflection.isInstance(item, TypeDefinition);\r\n}\r\n\r\nexport type ValueLiteral = ArrayLiteral | BooleanLiteral | NumberLiteral | StringLiteral;\r\n\r\nexport const ValueLiteral = 'ValueLiteral';\r\n\r\nexport function isValueLiteral(item: unknown): item is ValueLiteral {\r\n    return reflection.isInstance(item, ValueLiteral);\r\n}\r\n\r\nexport interface AbstractElement extends AstNode {\r\n    readonly $type: 'AbstractElement' | 'Action' | 'Alternatives' | 'Assignment' | 'CharacterRange' | 'CrossReference' | 'EndOfFile' | 'Group' | 'Keyword' | 'NegatedToken' | 'RegexToken' | 'RuleCall' | 'TerminalAlternatives' | 'TerminalGroup' | 'TerminalRuleCall' | 'UnorderedGroup' | 'UntilToken' | 'Wildcard';\r\n    cardinality?: '*' | '+' | '?';\r\n    lookahead?: '?!' | '?<!' | '?<=' | '?=';\r\n}\r\n\r\nexport const AbstractElement = 'AbstractElement';\r\n\r\nexport function isAbstractElement(item: unknown): item is AbstractElement {\r\n    return reflection.isInstance(item, AbstractElement);\r\n}\r\n\r\nexport interface ArrayLiteral extends AstNode {\r\n    readonly $container: ArrayLiteral | TypeAttribute;\r\n    readonly $type: 'ArrayLiteral';\r\n    elements: Array<ValueLiteral>;\r\n}\r\n\r\nexport const ArrayLiteral = 'ArrayLiteral';\r\n\r\nexport function isArrayLiteral(item: unknown): item is ArrayLiteral {\r\n    return reflection.isInstance(item, ArrayLiteral);\r\n}\r\n\r\nexport interface ArrayType extends AstNode {\r\n    readonly $container: ArrayType | ReferenceType | Type | TypeAttribute | UnionType;\r\n    readonly $type: 'ArrayType';\r\n    elementType: TypeDefinition;\r\n}\r\n\r\nexport const ArrayType = 'ArrayType';\r\n\r\nexport function isArrayType(item: unknown): item is ArrayType {\r\n    return reflection.isInstance(item, ArrayType);\r\n}\r\n\r\nexport interface BooleanLiteral extends AstNode {\r\n    readonly $container: ArrayLiteral | Conjunction | Disjunction | Group | NamedArgument | Negation | TypeAttribute;\r\n    readonly $type: 'BooleanLiteral';\r\n    true: boolean;\r\n}\r\n\r\nexport const BooleanLiteral = 'BooleanLiteral';\r\n\r\nexport function isBooleanLiteral(item: unknown): item is BooleanLiteral {\r\n    return reflection.isInstance(item, BooleanLiteral);\r\n}\r\n\r\nexport interface Conjunction extends AstNode {\r\n    readonly $container: Conjunction | Disjunction | Group | NamedArgument | Negation;\r\n    readonly $type: 'Conjunction';\r\n    left: Condition;\r\n    right: Condition;\r\n}\r\n\r\nexport const Conjunction = 'Conjunction';\r\n\r\nexport function isConjunction(item: unknown): item is Conjunction {\r\n    return reflection.isInstance(item, Conjunction);\r\n}\r\n\r\nexport interface Disjunction extends AstNode {\r\n    readonly $container: Conjunction | Disjunction | Group | NamedArgument | Negation;\r\n    readonly $type: 'Disjunction';\r\n    left: Condition;\r\n    right: Condition;\r\n}\r\n\r\nexport const Disjunction = 'Disjunction';\r\n\r\nexport function isDisjunction(item: unknown): item is Disjunction {\r\n    return reflection.isInstance(item, Disjunction);\r\n}\r\n\r\nexport interface Grammar extends AstNode {\r\n    readonly $type: 'Grammar';\r\n    definesHiddenTokens: boolean;\r\n    hiddenTokens: Array<Reference<AbstractRule>>;\r\n    imports: Array<GrammarImport>;\r\n    interfaces: Array<Interface>;\r\n    isDeclared: boolean;\r\n    name?: string;\r\n    rules: Array<AbstractRule>;\r\n    types: Array<Type>;\r\n    usedGrammars: Array<Reference<Grammar>>;\r\n}\r\n\r\nexport const Grammar = 'Grammar';\r\n\r\nexport function isGrammar(item: unknown): item is Grammar {\r\n    return reflection.isInstance(item, Grammar);\r\n}\r\n\r\nexport interface GrammarImport extends AstNode {\r\n    readonly $container: Grammar;\r\n    readonly $type: 'GrammarImport';\r\n    path: string;\r\n}\r\n\r\nexport const GrammarImport = 'GrammarImport';\r\n\r\nexport function isGrammarImport(item: unknown): item is GrammarImport {\r\n    return reflection.isInstance(item, GrammarImport);\r\n}\r\n\r\nexport interface InferredType extends AstNode {\r\n    readonly $container: Action | ParserRule;\r\n    readonly $type: 'InferredType';\r\n    name: string;\r\n}\r\n\r\nexport const InferredType = 'InferredType';\r\n\r\nexport function isInferredType(item: unknown): item is InferredType {\r\n    return reflection.isInstance(item, InferredType);\r\n}\r\n\r\nexport interface Interface extends AstNode {\r\n    readonly $container: Grammar;\r\n    readonly $type: 'Interface';\r\n    attributes: Array<TypeAttribute>;\r\n    name: string;\r\n    superTypes: Array<Reference<AbstractType>>;\r\n}\r\n\r\nexport const Interface = 'Interface';\r\n\r\nexport function isInterface(item: unknown): item is Interface {\r\n    return reflection.isInstance(item, Interface);\r\n}\r\n\r\nexport interface NamedArgument extends AstNode {\r\n    readonly $container: RuleCall;\r\n    readonly $type: 'NamedArgument';\r\n    calledByName: boolean;\r\n    parameter?: Reference<Parameter>;\r\n    value: Condition;\r\n}\r\n\r\nexport const NamedArgument = 'NamedArgument';\r\n\r\nexport function isNamedArgument(item: unknown): item is NamedArgument {\r\n    return reflection.isInstance(item, NamedArgument);\r\n}\r\n\r\nexport interface Negation extends AstNode {\r\n    readonly $container: Conjunction | Disjunction | Group | NamedArgument | Negation;\r\n    readonly $type: 'Negation';\r\n    value: Condition;\r\n}\r\n\r\nexport const Negation = 'Negation';\r\n\r\nexport function isNegation(item: unknown): item is Negation {\r\n    return reflection.isInstance(item, Negation);\r\n}\r\n\r\nexport interface NumberLiteral extends AstNode {\r\n    readonly $container: ArrayLiteral | TypeAttribute;\r\n    readonly $type: 'NumberLiteral';\r\n    value: number;\r\n}\r\n\r\nexport const NumberLiteral = 'NumberLiteral';\r\n\r\nexport function isNumberLiteral(item: unknown): item is NumberLiteral {\r\n    return reflection.isInstance(item, NumberLiteral);\r\n}\r\n\r\nexport interface Parameter extends AstNode {\r\n    readonly $container: ParserRule;\r\n    readonly $type: 'Parameter';\r\n    name: string;\r\n}\r\n\r\nexport const Parameter = 'Parameter';\r\n\r\nexport function isParameter(item: unknown): item is Parameter {\r\n    return reflection.isInstance(item, Parameter);\r\n}\r\n\r\nexport interface ParameterReference extends AstNode {\r\n    readonly $container: Conjunction | Disjunction | Group | NamedArgument | Negation;\r\n    readonly $type: 'ParameterReference';\r\n    parameter: Reference<Parameter>;\r\n}\r\n\r\nexport const ParameterReference = 'ParameterReference';\r\n\r\nexport function isParameterReference(item: unknown): item is ParameterReference {\r\n    return reflection.isInstance(item, ParameterReference);\r\n}\r\n\r\nexport interface ParserRule extends AstNode {\r\n    readonly $container: Grammar;\r\n    readonly $type: 'ParserRule';\r\n    dataType?: PrimitiveType;\r\n    definesHiddenTokens: boolean;\r\n    definition: AbstractElement;\r\n    entry: boolean;\r\n    fragment: boolean;\r\n    hiddenTokens: Array<Reference<AbstractRule>>;\r\n    inferredType?: InferredType;\r\n    name: string;\r\n    parameters: Array<Parameter>;\r\n    returnType?: Reference<AbstractType>;\r\n    wildcard: boolean;\r\n}\r\n\r\nexport const ParserRule = 'ParserRule';\r\n\r\nexport function isParserRule(item: unknown): item is ParserRule {\r\n    return reflection.isInstance(item, ParserRule);\r\n}\r\n\r\nexport interface ReferenceType extends AstNode {\r\n    readonly $container: ArrayType | ReferenceType | Type | TypeAttribute | UnionType;\r\n    readonly $type: 'ReferenceType';\r\n    referenceType: TypeDefinition;\r\n}\r\n\r\nexport const ReferenceType = 'ReferenceType';\r\n\r\nexport function isReferenceType(item: unknown): item is ReferenceType {\r\n    return reflection.isInstance(item, ReferenceType);\r\n}\r\n\r\nexport interface ReturnType extends AstNode {\r\n    readonly $container: TerminalRule;\r\n    readonly $type: 'ReturnType';\r\n    name: PrimitiveType | string;\r\n}\r\n\r\nexport const ReturnType = 'ReturnType';\r\n\r\nexport function isReturnType(item: unknown): item is ReturnType {\r\n    return reflection.isInstance(item, ReturnType);\r\n}\r\n\r\nexport interface SimpleType extends AstNode {\r\n    readonly $container: ArrayType | ReferenceType | Type | TypeAttribute | UnionType;\r\n    readonly $type: 'SimpleType';\r\n    primitiveType?: PrimitiveType;\r\n    stringType?: string;\r\n    typeRef?: Reference<AbstractType>;\r\n}\r\n\r\nexport const SimpleType = 'SimpleType';\r\n\r\nexport function isSimpleType(item: unknown): item is SimpleType {\r\n    return reflection.isInstance(item, SimpleType);\r\n}\r\n\r\nexport interface StringLiteral extends AstNode {\r\n    readonly $container: ArrayLiteral | TypeAttribute;\r\n    readonly $type: 'StringLiteral';\r\n    value: string;\r\n}\r\n\r\nexport const StringLiteral = 'StringLiteral';\r\n\r\nexport function isStringLiteral(item: unknown): item is StringLiteral {\r\n    return reflection.isInstance(item, StringLiteral);\r\n}\r\n\r\nexport interface TerminalRule extends AstNode {\r\n    readonly $container: Grammar;\r\n    readonly $type: 'TerminalRule';\r\n    definition: AbstractElement;\r\n    fragment: boolean;\r\n    hidden: boolean;\r\n    name: string;\r\n    type?: ReturnType;\r\n}\r\n\r\nexport const TerminalRule = 'TerminalRule';\r\n\r\nexport function isTerminalRule(item: unknown): item is TerminalRule {\r\n    return reflection.isInstance(item, TerminalRule);\r\n}\r\n\r\nexport interface Type extends AstNode {\r\n    readonly $container: Grammar;\r\n    readonly $type: 'Type';\r\n    name: string;\r\n    type: TypeDefinition;\r\n}\r\n\r\nexport const Type = 'Type';\r\n\r\nexport function isType(item: unknown): item is Type {\r\n    return reflection.isInstance(item, Type);\r\n}\r\n\r\nexport interface TypeAttribute extends AstNode {\r\n    readonly $container: Interface;\r\n    readonly $type: 'TypeAttribute';\r\n    defaultValue?: ValueLiteral;\r\n    isOptional: boolean;\r\n    name: FeatureName;\r\n    type: TypeDefinition;\r\n}\r\n\r\nexport const TypeAttribute = 'TypeAttribute';\r\n\r\nexport function isTypeAttribute(item: unknown): item is TypeAttribute {\r\n    return reflection.isInstance(item, TypeAttribute);\r\n}\r\n\r\nexport interface UnionType extends AstNode {\r\n    readonly $container: ArrayType | ReferenceType | Type | TypeAttribute | UnionType;\r\n    readonly $type: 'UnionType';\r\n    types: Array<TypeDefinition>;\r\n}\r\n\r\nexport const UnionType = 'UnionType';\r\n\r\nexport function isUnionType(item: unknown): item is UnionType {\r\n    return reflection.isInstance(item, UnionType);\r\n}\r\n\r\nexport interface Action extends AbstractElement {\r\n    readonly $type: 'Action';\r\n    feature?: FeatureName;\r\n    inferredType?: InferredType;\r\n    operator?: '+=' | '=';\r\n    type?: Reference<AbstractType>;\r\n}\r\n\r\nexport const Action = 'Action';\r\n\r\nexport function isAction(item: unknown): item is Action {\r\n    return reflection.isInstance(item, Action);\r\n}\r\n\r\nexport interface Alternatives extends AbstractElement {\r\n    readonly $type: 'Alternatives';\r\n    elements: Array<AbstractElement>;\r\n}\r\n\r\nexport const Alternatives = 'Alternatives';\r\n\r\nexport function isAlternatives(item: unknown): item is Alternatives {\r\n    return reflection.isInstance(item, Alternatives);\r\n}\r\n\r\nexport interface Assignment extends AbstractElement {\r\n    readonly $type: 'Assignment';\r\n    feature: FeatureName;\r\n    operator: '+=' | '=' | '?=';\r\n    terminal: AbstractElement;\r\n}\r\n\r\nexport const Assignment = 'Assignment';\r\n\r\nexport function isAssignment(item: unknown): item is Assignment {\r\n    return reflection.isInstance(item, Assignment);\r\n}\r\n\r\nexport interface CharacterRange extends AbstractElement {\r\n    readonly $type: 'CharacterRange';\r\n    left: Keyword;\r\n    right?: Keyword;\r\n}\r\n\r\nexport const CharacterRange = 'CharacterRange';\r\n\r\nexport function isCharacterRange(item: unknown): item is CharacterRange {\r\n    return reflection.isInstance(item, CharacterRange);\r\n}\r\n\r\nexport interface CrossReference extends AbstractElement {\r\n    readonly $type: 'CrossReference';\r\n    deprecatedSyntax: boolean;\r\n    terminal?: AbstractElement;\r\n    type: Reference<AbstractType>;\r\n}\r\n\r\nexport const CrossReference = 'CrossReference';\r\n\r\nexport function isCrossReference(item: unknown): item is CrossReference {\r\n    return reflection.isInstance(item, CrossReference);\r\n}\r\n\r\nexport interface EndOfFile extends AbstractElement {\r\n    readonly $type: 'EndOfFile';\r\n}\r\n\r\nexport const EndOfFile = 'EndOfFile';\r\n\r\nexport function isEndOfFile(item: unknown): item is EndOfFile {\r\n    return reflection.isInstance(item, EndOfFile);\r\n}\r\n\r\nexport interface Group extends AbstractElement {\r\n    readonly $type: 'Group';\r\n    elements: Array<AbstractElement>;\r\n    guardCondition?: Condition;\r\n}\r\n\r\nexport const Group = 'Group';\r\n\r\nexport function isGroup(item: unknown): item is Group {\r\n    return reflection.isInstance(item, Group);\r\n}\r\n\r\nexport interface Keyword extends AbstractElement {\r\n    readonly $container: CharacterRange;\r\n    readonly $type: 'Keyword';\r\n    value: string;\r\n}\r\n\r\nexport const Keyword = 'Keyword';\r\n\r\nexport function isKeyword(item: unknown): item is Keyword {\r\n    return reflection.isInstance(item, Keyword);\r\n}\r\n\r\nexport interface NegatedToken extends AbstractElement {\r\n    readonly $type: 'NegatedToken';\r\n    terminal: AbstractElement;\r\n}\r\n\r\nexport const NegatedToken = 'NegatedToken';\r\n\r\nexport function isNegatedToken(item: unknown): item is NegatedToken {\r\n    return reflection.isInstance(item, NegatedToken);\r\n}\r\n\r\nexport interface RegexToken extends AbstractElement {\r\n    readonly $type: 'RegexToken';\r\n    regex: string;\r\n}\r\n\r\nexport const RegexToken = 'RegexToken';\r\n\r\nexport function isRegexToken(item: unknown): item is RegexToken {\r\n    return reflection.isInstance(item, RegexToken);\r\n}\r\n\r\nexport interface RuleCall extends AbstractElement {\r\n    readonly $type: 'RuleCall';\r\n    arguments: Array<NamedArgument>;\r\n    rule: Reference<AbstractRule>;\r\n}\r\n\r\nexport const RuleCall = 'RuleCall';\r\n\r\nexport function isRuleCall(item: unknown): item is RuleCall {\r\n    return reflection.isInstance(item, RuleCall);\r\n}\r\n\r\nexport interface TerminalAlternatives extends AbstractElement {\r\n    readonly $type: 'TerminalAlternatives';\r\n    elements: Array<AbstractElement>;\r\n}\r\n\r\nexport const TerminalAlternatives = 'TerminalAlternatives';\r\n\r\nexport function isTerminalAlternatives(item: unknown): item is TerminalAlternatives {\r\n    return reflection.isInstance(item, TerminalAlternatives);\r\n}\r\n\r\nexport interface TerminalGroup extends AbstractElement {\r\n    readonly $type: 'TerminalGroup';\r\n    elements: Array<AbstractElement>;\r\n}\r\n\r\nexport const TerminalGroup = 'TerminalGroup';\r\n\r\nexport function isTerminalGroup(item: unknown): item is TerminalGroup {\r\n    return reflection.isInstance(item, TerminalGroup);\r\n}\r\n\r\nexport interface TerminalRuleCall extends AbstractElement {\r\n    readonly $type: 'TerminalRuleCall';\r\n    rule: Reference<TerminalRule>;\r\n}\r\n\r\nexport const TerminalRuleCall = 'TerminalRuleCall';\r\n\r\nexport function isTerminalRuleCall(item: unknown): item is TerminalRuleCall {\r\n    return reflection.isInstance(item, TerminalRuleCall);\r\n}\r\n\r\nexport interface UnorderedGroup extends AbstractElement {\r\n    readonly $type: 'UnorderedGroup';\r\n    elements: Array<AbstractElement>;\r\n}\r\n\r\nexport const UnorderedGroup = 'UnorderedGroup';\r\n\r\nexport function isUnorderedGroup(item: unknown): item is UnorderedGroup {\r\n    return reflection.isInstance(item, UnorderedGroup);\r\n}\r\n\r\nexport interface UntilToken extends AbstractElement {\r\n    readonly $type: 'UntilToken';\r\n    terminal: AbstractElement;\r\n}\r\n\r\nexport const UntilToken = 'UntilToken';\r\n\r\nexport function isUntilToken(item: unknown): item is UntilToken {\r\n    return reflection.isInstance(item, UntilToken);\r\n}\r\n\r\nexport interface Wildcard extends AbstractElement {\r\n    readonly $type: 'Wildcard';\r\n}\r\n\r\nexport const Wildcard = 'Wildcard';\r\n\r\nexport function isWildcard(item: unknown): item is Wildcard {\r\n    return reflection.isInstance(item, Wildcard);\r\n}\r\n\r\nexport type LangiumGrammarAstType = {\r\n    AbstractElement: AbstractElement\r\n    AbstractRule: AbstractRule\r\n    AbstractType: AbstractType\r\n    Action: Action\r\n    Alternatives: Alternatives\r\n    ArrayLiteral: ArrayLiteral\r\n    ArrayType: ArrayType\r\n    Assignment: Assignment\r\n    BooleanLiteral: BooleanLiteral\r\n    CharacterRange: CharacterRange\r\n    Condition: Condition\r\n    Conjunction: Conjunction\r\n    CrossReference: CrossReference\r\n    Disjunction: Disjunction\r\n    EndOfFile: EndOfFile\r\n    Grammar: Grammar\r\n    GrammarImport: GrammarImport\r\n    Group: Group\r\n    InferredType: InferredType\r\n    Interface: Interface\r\n    Keyword: Keyword\r\n    NamedArgument: NamedArgument\r\n    NegatedToken: NegatedToken\r\n    Negation: Negation\r\n    NumberLiteral: NumberLiteral\r\n    Parameter: Parameter\r\n    ParameterReference: ParameterReference\r\n    ParserRule: ParserRule\r\n    ReferenceType: ReferenceType\r\n    RegexToken: RegexToken\r\n    ReturnType: ReturnType\r\n    RuleCall: RuleCall\r\n    SimpleType: SimpleType\r\n    StringLiteral: StringLiteral\r\n    TerminalAlternatives: TerminalAlternatives\r\n    TerminalGroup: TerminalGroup\r\n    TerminalRule: TerminalRule\r\n    TerminalRuleCall: TerminalRuleCall\r\n    Type: Type\r\n    TypeAttribute: TypeAttribute\r\n    TypeDefinition: TypeDefinition\r\n    UnionType: UnionType\r\n    UnorderedGroup: UnorderedGroup\r\n    UntilToken: UntilToken\r\n    ValueLiteral: ValueLiteral\r\n    Wildcard: Wildcard\r\n}\r\n\r\nexport class LangiumGrammarAstReflection extends AbstractAstReflection {\r\n\r\n    getAllTypes(): string[] {\r\n        return [AbstractElement, AbstractRule, AbstractType, Action, Alternatives, ArrayLiteral, ArrayType, Assignment, BooleanLiteral, CharacterRange, Condition, Conjunction, CrossReference, Disjunction, EndOfFile, Grammar, GrammarImport, Group, InferredType, Interface, Keyword, NamedArgument, NegatedToken, Negation, NumberLiteral, Parameter, ParameterReference, ParserRule, ReferenceType, RegexToken, ReturnType, RuleCall, SimpleType, StringLiteral, TerminalAlternatives, TerminalGroup, TerminalRule, TerminalRuleCall, Type, TypeAttribute, TypeDefinition, UnionType, UnorderedGroup, UntilToken, ValueLiteral, Wildcard];\r\n    }\r\n\r\n    protected override computeIsSubtype(subtype: string, supertype: string): boolean {\r\n        switch (subtype) {\r\n            case Action:\r\n            case Alternatives:\r\n            case Assignment:\r\n            case CharacterRange:\r\n            case CrossReference:\r\n            case EndOfFile:\r\n            case Group:\r\n            case Keyword:\r\n            case NegatedToken:\r\n            case RegexToken:\r\n            case RuleCall:\r\n            case TerminalAlternatives:\r\n            case TerminalGroup:\r\n            case TerminalRuleCall:\r\n            case UnorderedGroup:\r\n            case UntilToken:\r\n            case Wildcard: {\r\n                return this.isSubtype(AbstractElement, supertype);\r\n            }\r\n            case ArrayLiteral:\r\n            case NumberLiteral:\r\n            case StringLiteral: {\r\n                return this.isSubtype(ValueLiteral, supertype);\r\n            }\r\n            case ArrayType:\r\n            case ReferenceType:\r\n            case SimpleType:\r\n            case UnionType: {\r\n                return this.isSubtype(TypeDefinition, supertype);\r\n            }\r\n            case BooleanLiteral: {\r\n                return this.isSubtype(Condition, supertype) || this.isSubtype(ValueLiteral, supertype);\r\n            }\r\n            case Conjunction:\r\n            case Disjunction:\r\n            case Negation:\r\n            case ParameterReference: {\r\n                return this.isSubtype(Condition, supertype);\r\n            }\r\n            case InferredType:\r\n            case Interface:\r\n            case Type: {\r\n                return this.isSubtype(AbstractType, supertype);\r\n            }\r\n            case ParserRule: {\r\n                return this.isSubtype(AbstractRule, supertype) || this.isSubtype(AbstractType, supertype);\r\n            }\r\n            case TerminalRule: {\r\n                return this.isSubtype(AbstractRule, supertype);\r\n            }\r\n            default: {\r\n                return false;\r\n            }\r\n        }\r\n    }\r\n\r\n    getReferenceType(refInfo: ReferenceInfo): string {\r\n        const referenceId = `${refInfo.container.$type}:${refInfo.property}`;\r\n        switch (referenceId) {\r\n            case 'Action:type':\r\n            case 'CrossReference:type':\r\n            case 'Interface:superTypes':\r\n            case 'ParserRule:returnType':\r\n            case 'SimpleType:typeRef': {\r\n                return AbstractType;\r\n            }\r\n            case 'Grammar:hiddenTokens':\r\n            case 'ParserRule:hiddenTokens':\r\n            case 'RuleCall:rule': {\r\n                return AbstractRule;\r\n            }\r\n            case 'Grammar:usedGrammars': {\r\n                return Grammar;\r\n            }\r\n            case 'NamedArgument:parameter':\r\n            case 'ParameterReference:parameter': {\r\n                return Parameter;\r\n            }\r\n            case 'TerminalRuleCall:rule': {\r\n                return TerminalRule;\r\n            }\r\n            default: {\r\n                throw new Error(`${referenceId} is not a valid reference id.`);\r\n            }\r\n        }\r\n    }\r\n\r\n    getTypeMetaData(type: string): TypeMetaData {\r\n        switch (type) {\r\n            case AbstractElement: {\r\n                return {\r\n                    name: AbstractElement,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            case ArrayLiteral: {\r\n                return {\r\n                    name: ArrayLiteral,\r\n                    properties: [\r\n                        { name: 'elements', defaultValue: [] }\r\n                    ]\r\n                };\r\n            }\r\n            case ArrayType: {\r\n                return {\r\n                    name: ArrayType,\r\n                    properties: [\r\n                        { name: 'elementType' }\r\n                    ]\r\n                };\r\n            }\r\n            case BooleanLiteral: {\r\n                return {\r\n                    name: BooleanLiteral,\r\n                    properties: [\r\n                        { name: 'true', defaultValue: false }\r\n                    ]\r\n                };\r\n            }\r\n            case Conjunction: {\r\n                return {\r\n                    name: Conjunction,\r\n                    properties: [\r\n                        { name: 'left' },\r\n                        { name: 'right' }\r\n                    ]\r\n                };\r\n            }\r\n            case Disjunction: {\r\n                return {\r\n                    name: Disjunction,\r\n                    properties: [\r\n                        { name: 'left' },\r\n                        { name: 'right' }\r\n                    ]\r\n                };\r\n            }\r\n            case Grammar: {\r\n                return {\r\n                    name: Grammar,\r\n                    properties: [\r\n                        { name: 'definesHiddenTokens', defaultValue: false },\r\n                        { name: 'hiddenTokens', defaultValue: [] },\r\n                        { name: 'imports', defaultValue: [] },\r\n                        { name: 'interfaces', defaultValue: [] },\r\n                        { name: 'isDeclared', defaultValue: false },\r\n                        { name: 'name' },\r\n                        { name: 'rules', defaultValue: [] },\r\n                        { name: 'types', defaultValue: [] },\r\n                        { name: 'usedGrammars', defaultValue: [] }\r\n                    ]\r\n                };\r\n            }\r\n            case GrammarImport: {\r\n                return {\r\n                    name: GrammarImport,\r\n                    properties: [\r\n                        { name: 'path' }\r\n                    ]\r\n                };\r\n            }\r\n            case InferredType: {\r\n                return {\r\n                    name: InferredType,\r\n                    properties: [\r\n                        { name: 'name' }\r\n                    ]\r\n                };\r\n            }\r\n            case Interface: {\r\n                return {\r\n                    name: Interface,\r\n                    properties: [\r\n                        { name: 'attributes', defaultValue: [] },\r\n                        { name: 'name' },\r\n                        { name: 'superTypes', defaultValue: [] }\r\n                    ]\r\n                };\r\n            }\r\n            case NamedArgument: {\r\n                return {\r\n                    name: NamedArgument,\r\n                    properties: [\r\n                        { name: 'calledByName', defaultValue: false },\r\n                        { name: 'parameter' },\r\n                        { name: 'value' }\r\n                    ]\r\n                };\r\n            }\r\n            case Negation: {\r\n                return {\r\n                    name: Negation,\r\n                    properties: [\r\n                        { name: 'value' }\r\n                    ]\r\n                };\r\n            }\r\n            case NumberLiteral: {\r\n                return {\r\n                    name: NumberLiteral,\r\n                    properties: [\r\n                        { name: 'value' }\r\n                    ]\r\n                };\r\n            }\r\n            case Parameter: {\r\n                return {\r\n                    name: Parameter,\r\n                    properties: [\r\n                        { name: 'name' }\r\n                    ]\r\n                };\r\n            }\r\n            case ParameterReference: {\r\n                return {\r\n                    name: ParameterReference,\r\n                    properties: [\r\n                        { name: 'parameter' }\r\n                    ]\r\n                };\r\n            }\r\n            case ParserRule: {\r\n                return {\r\n                    name: ParserRule,\r\n                    properties: [\r\n                        { name: 'dataType' },\r\n                        { name: 'definesHiddenTokens', defaultValue: false },\r\n                        { name: 'definition' },\r\n                        { name: 'entry', defaultValue: false },\r\n                        { name: 'fragment', defaultValue: false },\r\n                        { name: 'hiddenTokens', defaultValue: [] },\r\n                        { name: 'inferredType' },\r\n                        { name: 'name' },\r\n                        { name: 'parameters', defaultValue: [] },\r\n                        { name: 'returnType' },\r\n                        { name: 'wildcard', defaultValue: false }\r\n                    ]\r\n                };\r\n            }\r\n            case ReferenceType: {\r\n                return {\r\n                    name: ReferenceType,\r\n                    properties: [\r\n                        { name: 'referenceType' }\r\n                    ]\r\n                };\r\n            }\r\n            case ReturnType: {\r\n                return {\r\n                    name: ReturnType,\r\n                    properties: [\r\n                        { name: 'name' }\r\n                    ]\r\n                };\r\n            }\r\n            case SimpleType: {\r\n                return {\r\n                    name: SimpleType,\r\n                    properties: [\r\n                        { name: 'primitiveType' },\r\n                        { name: 'stringType' },\r\n                        { name: 'typeRef' }\r\n                    ]\r\n                };\r\n            }\r\n            case StringLiteral: {\r\n                return {\r\n                    name: StringLiteral,\r\n                    properties: [\r\n                        { name: 'value' }\r\n                    ]\r\n                };\r\n            }\r\n            case TerminalRule: {\r\n                return {\r\n                    name: TerminalRule,\r\n                    properties: [\r\n                        { name: 'definition' },\r\n                        { name: 'fragment', defaultValue: false },\r\n                        { name: 'hidden', defaultValue: false },\r\n                        { name: 'name' },\r\n                        { name: 'type' }\r\n                    ]\r\n                };\r\n            }\r\n            case Type: {\r\n                return {\r\n                    name: Type,\r\n                    properties: [\r\n                        { name: 'name' },\r\n                        { name: 'type' }\r\n                    ]\r\n                };\r\n            }\r\n            case TypeAttribute: {\r\n                return {\r\n                    name: TypeAttribute,\r\n                    properties: [\r\n                        { name: 'defaultValue' },\r\n                        { name: 'isOptional', defaultValue: false },\r\n                        { name: 'name' },\r\n                        { name: 'type' }\r\n                    ]\r\n                };\r\n            }\r\n            case UnionType: {\r\n                return {\r\n                    name: UnionType,\r\n                    properties: [\r\n                        { name: 'types', defaultValue: [] }\r\n                    ]\r\n                };\r\n            }\r\n            case Action: {\r\n                return {\r\n                    name: Action,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'feature' },\r\n                        { name: 'inferredType' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'operator' },\r\n                        { name: 'type' }\r\n                    ]\r\n                };\r\n            }\r\n            case Alternatives: {\r\n                return {\r\n                    name: Alternatives,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'elements', defaultValue: [] },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            case Assignment: {\r\n                return {\r\n                    name: Assignment,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'feature' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'operator' },\r\n                        { name: 'terminal' }\r\n                    ]\r\n                };\r\n            }\r\n            case CharacterRange: {\r\n                return {\r\n                    name: CharacterRange,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'left' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'right' }\r\n                    ]\r\n                };\r\n            }\r\n            case CrossReference: {\r\n                return {\r\n                    name: CrossReference,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'deprecatedSyntax', defaultValue: false },\r\n                        { name: 'lookahead' },\r\n                        { name: 'terminal' },\r\n                        { name: 'type' }\r\n                    ]\r\n                };\r\n            }\r\n            case EndOfFile: {\r\n                return {\r\n                    name: EndOfFile,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            case Group: {\r\n                return {\r\n                    name: Group,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'elements', defaultValue: [] },\r\n                        { name: 'guardCondition' },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            case Keyword: {\r\n                return {\r\n                    name: Keyword,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'value' }\r\n                    ]\r\n                };\r\n            }\r\n            case NegatedToken: {\r\n                return {\r\n                    name: NegatedToken,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'terminal' }\r\n                    ]\r\n                };\r\n            }\r\n            case RegexToken: {\r\n                return {\r\n                    name: RegexToken,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'regex' }\r\n                    ]\r\n                };\r\n            }\r\n            case RuleCall: {\r\n                return {\r\n                    name: RuleCall,\r\n                    properties: [\r\n                        { name: 'arguments', defaultValue: [] },\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'rule' }\r\n                    ]\r\n                };\r\n            }\r\n            case TerminalAlternatives: {\r\n                return {\r\n                    name: TerminalAlternatives,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'elements', defaultValue: [] },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            case TerminalGroup: {\r\n                return {\r\n                    name: TerminalGroup,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'elements', defaultValue: [] },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            case TerminalRuleCall: {\r\n                return {\r\n                    name: TerminalRuleCall,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'rule' }\r\n                    ]\r\n                };\r\n            }\r\n            case UnorderedGroup: {\r\n                return {\r\n                    name: UnorderedGroup,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'elements', defaultValue: [] },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            case UntilToken: {\r\n                return {\r\n                    name: UntilToken,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'terminal' }\r\n                    ]\r\n                };\r\n            }\r\n            case Wildcard: {\r\n                return {\r\n                    name: Wildcard,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            default: {\r\n                return {\r\n                    name: type,\r\n                    properties: []\r\n                };\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\nexport const reflection = new LangiumGrammarAstReflection();\r\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { Disposable } from './disposable.js';\r\nimport type { URI } from './uri-utils.js';\r\nimport type { LangiumSharedCoreServices } from '../services.js';\r\nimport type { DocumentState } from '../workspace/documents.js';\r\n\r\nexport abstract class DisposableCache implements Disposable {\r\n\r\n    protected toDispose: Disposable[] = [];\r\n    protected isDisposed = false;\r\n\r\n    onDispose(disposable: Disposable): void {\r\n        this.toDispose.push(disposable);\r\n    }\r\n\r\n    dispose(): void {\r\n        this.throwIfDisposed();\r\n        this.clear();\r\n        this.isDisposed = true;\r\n        this.toDispose.forEach(disposable => disposable.dispose());\r\n    }\r\n\r\n    protected throwIfDisposed(): void {\r\n        if (this.isDisposed) {\r\n            throw new Error('This cache has already been disposed');\r\n        }\r\n    }\r\n\r\n    abstract clear(): void;\r\n}\r\n\r\nexport class SimpleCache<K, V> extends DisposableCache {\r\n    protected readonly cache = new Map<K, V>();\r\n\r\n    has(key: K): boolean {\r\n        this.throwIfDisposed();\r\n        return this.cache.has(key);\r\n    }\r\n\r\n    set(key: K, value: V): void {\r\n        this.throwIfDisposed();\r\n        this.cache.set(key, value);\r\n    }\r\n\r\n    get(key: K): V | undefined;\r\n    get(key: K, provider: () => V): V;\r\n    get(key: K, provider?: () => V): V | undefined {\r\n        this.throwIfDisposed();\r\n        if (this.cache.has(key)) {\r\n            return this.cache.get(key);\r\n        } else if (provider) {\r\n            const value = provider();\r\n            this.cache.set(key, value);\r\n            return value;\r\n        } else {\r\n            return undefined;\r\n        }\r\n    }\r\n\r\n    delete(key: K): boolean {\r\n        this.throwIfDisposed();\r\n        return this.cache.delete(key);\r\n    }\r\n\r\n    clear(): void {\r\n        this.throwIfDisposed();\r\n        this.cache.clear();\r\n    }\r\n}\r\n\r\nexport class ContextCache<Context, Key, Value, ContextKey = Context> extends DisposableCache {\r\n\r\n    private readonly cache = new Map<ContextKey | Context, Map<Key, Value>>();\r\n    private readonly converter: (input: Context) => ContextKey | Context;\r\n\r\n    constructor(converter?: (input: Context) => ContextKey) {\r\n        super();\r\n        this.converter = converter ?? (value => value);\r\n    }\r\n\r\n    has(contextKey: Context, key: Key): boolean {\r\n        this.throwIfDisposed();\r\n        return this.cacheForContext(contextKey).has(key);\r\n    }\r\n\r\n    set(contextKey: Context, key: Key, value: Value): void {\r\n        this.throwIfDisposed();\r\n        this.cacheForContext(contextKey).set(key, value);\r\n    }\r\n\r\n    get(contextKey: Context, key: Key): Value | undefined;\r\n    get(contextKey: Context, key: Key, provider: () => Value): Value;\r\n    get(contextKey: Context, key: Key, provider?: () => Value): Value | undefined {\r\n        this.throwIfDisposed();\r\n        const contextCache = this.cacheForContext(contextKey);\r\n        if (contextCache.has(key)) {\r\n            return contextCache.get(key);\r\n        } else if (provider) {\r\n            const value = provider();\r\n            contextCache.set(key, value);\r\n            return value;\r\n        } else {\r\n            return undefined;\r\n        }\r\n    }\r\n\r\n    delete(contextKey: Context, key: Key): boolean {\r\n        this.throwIfDisposed();\r\n        return this.cacheForContext(contextKey).delete(key);\r\n    }\r\n\r\n    clear(): void;\r\n    clear(contextKey: Context): void;\r\n    clear(contextKey?: Context): void {\r\n        this.throwIfDisposed();\r\n        if (contextKey) {\r\n            const mapKey = this.converter(contextKey);\r\n            this.cache.delete(mapKey);\r\n        } else {\r\n            this.cache.clear();\r\n        }\r\n    }\r\n\r\n    protected cacheForContext(contextKey: Context): Map<Key, Value> {\r\n        const mapKey = this.converter(contextKey);\r\n        let documentCache = this.cache.get(mapKey);\r\n        if (!documentCache) {\r\n            documentCache = new Map();\r\n            this.cache.set(mapKey, documentCache);\r\n        }\r\n        return documentCache;\r\n    }\r\n}\r\n\r\n/**\r\n * Every key/value pair in this cache is scoped to a document.\r\n * If this document is changed or deleted, all associated key/value pairs are deleted.\r\n */\r\nexport class DocumentCache<K, V> extends ContextCache<URI | string, K, V, string> {\r\n\r\n    /**\r\n     * Creates a new document cache.\r\n     *\r\n     * @param sharedServices Service container instance to hook into document lifecycle events.\r\n     * @param state Optional document state on which the cache should evict.\r\n     * If not provided, the cache will evict on `DocumentBuilder#onUpdate`.\r\n     * *Deleted* documents are considered in both cases.\r\n     *\r\n     * Providing a state here will use `DocumentBuilder#onDocumentPhase` instead,\r\n     * which triggers on all documents that have been affected by this change, assuming that the\r\n     * state is `DocumentState.Linked` or a later state.\r\n     */\r\n    constructor(sharedServices: LangiumSharedCoreServices, state?: DocumentState) {\r\n        super(uri => uri.toString());\r\n        if (state) {\r\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onDocumentPhase(state, document => {\r\n                this.clear(document.uri.toString());\r\n            }));\r\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((_changed, deleted) => {\r\n                for (const uri of deleted) { // react only on deleted documents\r\n                    this.clear(uri);\r\n                }\r\n            }));\r\n        } else {\r\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((changed, deleted) => {\r\n                const allUris = changed.concat(deleted); // react on both changed and deleted documents\r\n                for (const uri of allUris) {\r\n                    this.clear(uri);\r\n                }\r\n            }));\r\n        }\r\n    }\r\n}\r\n\r\n/**\r\n * Every key/value pair in this cache is scoped to the whole workspace.\r\n * If any document in the workspace is added, changed or deleted, the whole cache is evicted.\r\n */\r\nexport class WorkspaceCache<K, V> extends SimpleCache<K, V> {\r\n\r\n    /**\r\n     * Creates a new workspace cache.\r\n     *\r\n     * @param sharedServices Service container instance to hook into document lifecycle events.\r\n     * @param state Optional document state on which the cache should evict.\r\n     * If not provided, the cache will evict on `DocumentBuilder#onUpdate`.\r\n     * *Deleted* documents are considered in both cases.\r\n     */\r\n    constructor(sharedServices: LangiumSharedCoreServices, state?: DocumentState) {\r\n        super();\r\n        if (state) {\r\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onBuildPhase(state, () => {\r\n                this.clear();\r\n            }));\r\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((_changed, deleted) => {\r\n                if (deleted.length > 0) { // react only on deleted documents\r\n                    this.clear();\r\n                }\r\n            }));\r\n        } else {\r\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate(() => { // react on both changed and deleted documents\r\n                this.clear();\r\n            }));\r\n        }\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { CancellationToken } from '../utils/cancellation.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode } from '../syntax-tree.js';\r\nimport type { LangiumParser, ParseResult } from './langium-parser.js';\r\nimport type { Hydrator } from '../serializer/hydrator.js';\r\nimport type { Event } from '../utils/event.js';\r\nimport { Deferred, OperationCancelled } from '../utils/promise-utils.js';\r\nimport { Emitter } from '../utils/event.js';\r\n\r\n/**\r\n * Async parser that allows cancellation of the current parsing process.\r\n *\r\n * @remarks\r\n * The sync parser implementation is blocking the event loop, which can become quite problematic for large files.\r\n * The default implementation is not actually async. It just wraps the sync parser in a promise. A real implementation would create worker threads or web workers to offload the parsing work.\r\n */\r\nexport interface AsyncParser {\r\n    /**\r\n     * Parses the given text and returns the parse result.\r\n     *\r\n     * @param text The text to parse.\r\n     * @param cancelToken A cancellation token that can be used to cancel the parsing process.\r\n     * @returns A promise that resolves to the parse result.\r\n     *\r\n     * @throws `OperationCancelled` if the parsing process is cancelled.\r\n     */\r\n    parse<T extends AstNode>(text: string, cancelToken: CancellationToken): Promise<ParseResult<T>>;\r\n}\r\n\r\n/**\r\n * Default implementation of the async parser which simply wraps the sync parser in a promise.\r\n *\r\n * @remarks\r\n * A real implementation would create worker threads or web workers to offload the parsing work.\r\n */\r\nexport class DefaultAsyncParser implements AsyncParser {\r\n\r\n    protected readonly syncParser: LangiumParser;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.syncParser = services.parser.LangiumParser;\r\n    }\r\n\r\n    parse<T extends AstNode>(text: string, _cancelToken: CancellationToken): Promise<ParseResult<T>> {\r\n        return Promise.resolve(this.syncParser.parse<T>(text));\r\n    }\r\n}\r\n\r\nexport abstract class AbstractThreadedAsyncParser implements AsyncParser {\r\n\r\n    /**\r\n     * The thread count determines how many threads are used to parse files in parallel.\r\n     * The default value is 8. Decreasing this value increases startup performance, but decreases parallel parsing performance.\r\n     */\r\n    protected threadCount = 8;\r\n    /**\r\n     * The termination delay determines how long the parser waits for a thread to finish after a cancellation request.\r\n     * The default value is 200(ms).\r\n     */\r\n    protected terminationDelay = 200;\r\n    protected workerPool: ParserWorker[] = [];\r\n    protected queue: Array<Deferred<ParserWorker>> = [];\r\n\r\n    protected readonly hydrator: Hydrator;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.hydrator = services.serializer.Hydrator;\r\n    }\r\n\r\n    protected initializeWorkers(): void {\r\n        while (this.workerPool.length < this.threadCount) {\r\n            const worker = this.createWorker();\r\n            worker.onReady(() => {\r\n                if (this.queue.length > 0) {\r\n                    const deferred = this.queue.shift();\r\n                    if (deferred) {\r\n                        worker.lock();\r\n                        deferred.resolve(worker);\r\n                    }\r\n                }\r\n            });\r\n            this.workerPool.push(worker);\r\n        }\r\n    }\r\n\r\n    async parse<T extends AstNode>(text: string, cancelToken: CancellationToken): Promise<ParseResult<T>> {\r\n        const worker = await this.acquireParserWorker(cancelToken);\r\n        const deferred = new Deferred<ParseResult<T>>();\r\n        let timeout: NodeJS.Timeout | undefined;\r\n        // If the cancellation token is requested, we wait for a certain time before terminating the worker.\r\n        // Since the cancellation token lives longer than the parsing process, we need to dispose the event listener.\r\n        // Otherwise, we might accidentally terminate the worker after the parsing process has finished.\r\n        const cancellation = cancelToken.onCancellationRequested(() => {\r\n            timeout = setTimeout(() => {\r\n                this.terminateWorker(worker);\r\n            }, this.terminationDelay);\r\n        });\r\n        worker.parse(text).then(result => {\r\n            const hydrated = this.hydrator.hydrate<T>(result);\r\n            deferred.resolve(hydrated);\r\n        }).catch(err => {\r\n            deferred.reject(err);\r\n        }).finally(() => {\r\n            cancellation.dispose();\r\n            clearTimeout(timeout);\r\n        });\r\n        return deferred.promise;\r\n    }\r\n\r\n    protected terminateWorker(worker: ParserWorker): void {\r\n        worker.terminate();\r\n        const index = this.workerPool.indexOf(worker);\r\n        if (index >= 0) {\r\n            this.workerPool.splice(index, 1);\r\n        }\r\n    }\r\n\r\n    protected async acquireParserWorker(cancelToken: CancellationToken): Promise<ParserWorker> {\r\n        this.initializeWorkers();\r\n        for (const worker of this.workerPool) {\r\n            if (worker.ready) {\r\n                worker.lock();\r\n                return worker;\r\n            }\r\n        }\r\n        const deferred = new Deferred<ParserWorker>();\r\n        cancelToken.onCancellationRequested(() => {\r\n            const index = this.queue.indexOf(deferred);\r\n            if (index >= 0) {\r\n                this.queue.splice(index, 1);\r\n            }\r\n            deferred.reject(OperationCancelled);\r\n        });\r\n        this.queue.push(deferred);\r\n        return deferred.promise;\r\n    }\r\n\r\n    protected abstract createWorker(): ParserWorker;\r\n}\r\n\r\nexport type WorkerMessagePost = (message: unknown) => void;\r\nexport type WorkerMessageCallback = (cb: (message: unknown) => void) => void;\r\n\r\nexport class ParserWorker {\r\n\r\n    protected readonly sendMessage: WorkerMessagePost;\r\n    protected readonly _terminate: () => void;\r\n    protected readonly onReadyEmitter = new Emitter<void>();\r\n\r\n    protected deferred = new Deferred<ParseResult>();\r\n    protected _ready = true;\r\n    protected _parsing = false;\r\n\r\n    get ready(): boolean {\r\n        return this._ready;\r\n    }\r\n\r\n    get onReady(): Event<void> {\r\n        return this.onReadyEmitter.event;\r\n    }\r\n\r\n    constructor(sendMessage: WorkerMessagePost, onMessage: WorkerMessageCallback, onError: WorkerMessageCallback, terminate: () => void) {\r\n        this.sendMessage = sendMessage;\r\n        this._terminate = terminate;\r\n        onMessage(result => {\r\n            const parseResult = result as ParseResult;\r\n            this.deferred.resolve(parseResult);\r\n            this.unlock();\r\n        });\r\n        onError(error => {\r\n            this.deferred.reject(error);\r\n            this.unlock();\r\n        });\r\n    }\r\n\r\n    terminate(): void {\r\n        this.deferred.reject(OperationCancelled);\r\n        this._terminate();\r\n    }\r\n\r\n    lock(): void {\r\n        this._ready = false;\r\n    }\r\n\r\n    unlock(): void {\r\n        this._parsing = false;\r\n        this._ready = true;\r\n        this.onReadyEmitter.fire();\r\n    }\r\n\r\n    parse(text: string): Promise<ParseResult> {\r\n        if (this._parsing) {\r\n            throw new Error('Parser worker is busy');\r\n        }\r\n        this._parsing = true;\r\n        this.deferred = new Deferred();\r\n        this.sendMessage(text);\r\n        return this.deferred.promise;\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021-2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, AstNodeDescription } from '../syntax-tree.js';\r\nimport type { AstNodeDescriptionProvider } from '../workspace/ast-descriptions.js';\r\nimport type { LangiumDocument, PrecomputedScopes } from '../workspace/documents.js';\r\nimport type { NameProvider } from './name-provider.js';\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport { streamAllContents, streamContents } from '../utils/ast-utils.js';\r\nimport { MultiMap } from '../utils/collections.js';\r\nimport { interruptAndCheck } from '../utils/promise-utils.js';\r\n\r\n/**\r\n * Language-specific service for precomputing global and local scopes. The service methods are executed\r\n * as the first and second phase in the `DocumentBuilder`.\r\n */\r\nexport interface ScopeComputation {\r\n\r\n    /**\r\n     * Creates descriptions of all AST nodes that shall be exported into the _global_ scope from the given\r\n     * document. These descriptions are gathered by the `IndexManager` and stored in the global index so\r\n     * they can be referenced from other documents.\r\n     *\r\n     * _Note:_ You should not resolve any cross-references in this service method. Cross-reference resolution\r\n     * depends on the scope computation phase to be completed (`computeScope` method), which runs after the\r\n     * initial indexing where this method is used.\r\n     *\r\n     * @param document The document from which to gather exported AST nodes.\r\n     * @param cancelToken Indicates when to cancel the current operation.\r\n     * @throws `OperationCanceled` if a user action occurs during execution\r\n     */\r\n    computeExports(document: LangiumDocument, cancelToken?: CancellationToken): Promise<AstNodeDescription[]>;\r\n\r\n    /**\r\n     * Precomputes the _local_ scopes for a document, which are necessary for the default way of\r\n     * resolving references to symbols in the same document. The result is a multimap assigning a\r\n     * set of AST node descriptions to every level of the AST. These data are used by the `ScopeProvider`\r\n     * service to determine which target nodes are visible in the context of a specific cross-reference.\r\n     *\r\n     * _Note:_ You should not resolve any cross-references in this service method. Cross-reference\r\n     * resolution depends on the scope computation phase to be completed.\r\n     *\r\n     * @param document The document in which to compute scopes.\r\n     * @param cancelToken Indicates when to cancel the current operation.\r\n     * @throws `OperationCanceled` if a user action occurs during execution\r\n     */\r\n    computeLocalScopes(document: LangiumDocument, cancelToken?: CancellationToken): Promise<PrecomputedScopes>;\r\n\r\n}\r\n\r\n/**\r\n * The default scope computation creates and collectes descriptions of the AST nodes to be exported into the\r\n * _global_ scope from the given document. By default those are the document's root AST node and its directly\r\n * contained child nodes.\r\n *\r\n * Besides, it gathers all AST nodes that have a name (according to the `NameProvider` service) and includes them\r\n * in the local scope of their particular container nodes. As a result, for every cross-reference in the AST,\r\n * target elements from the same level (siblings) and further up towards the root (parents and siblings of parents)\r\n * are visible. Elements being nested inside lower levels (children, children of siblings and parents' siblings)\r\n * are _invisible_ by default, but that can be changed by customizing this service.\r\n */\r\nexport class DefaultScopeComputation implements ScopeComputation {\r\n\r\n    protected readonly nameProvider: NameProvider;\r\n    protected readonly descriptions: AstNodeDescriptionProvider;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.nameProvider = services.references.NameProvider;\r\n        this.descriptions = services.workspace.AstNodeDescriptionProvider;\r\n    }\r\n\r\n    async computeExports(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<AstNodeDescription[]> {\r\n        return this.computeExportsForNode(document.parseResult.value, document, undefined, cancelToken);\r\n    }\r\n\r\n    /**\r\n     * Creates {@link AstNodeDescription AstNodeDescriptions} for the given {@link AstNode parentNode} and its children.\r\n     * The list of children to be considered is determined by the function parameter {@link children}.\r\n     * By default only the direct children of {@link parentNode} are visited, nested nodes are not exported.\r\n     *\r\n     * @param parentNode AST node to be exported, i.e., of which an {@link AstNodeDescription} shall be added to the returned list.\r\n     * @param document The document containing the AST node to be exported.\r\n     * @param children A function called with {@link parentNode} as single argument and returning an {@link Iterable} supplying the children to be visited, which must be directly or transitively contained in {@link parentNode}.\r\n     * @param cancelToken Indicates when to cancel the current operation.\r\n     * @throws `OperationCancelled` if a user action occurs during execution.\r\n     * @returns A list of {@link AstNodeDescription AstNodeDescriptions} to be published to index.\r\n     */\r\n    async computeExportsForNode(parentNode: AstNode, document: LangiumDocument<AstNode>, children: (root: AstNode) => Iterable<AstNode> = streamContents, cancelToken: CancellationToken = CancellationToken.None): Promise<AstNodeDescription[]> {\r\n        const exports: AstNodeDescription[] = [];\r\n\r\n        this.exportNode(parentNode, exports, document);\r\n        for (const node of children(parentNode)) {\r\n            await interruptAndCheck(cancelToken);\r\n            this.exportNode(node, exports, document);\r\n        }\r\n        return exports;\r\n    }\r\n\r\n    /**\r\n     * Add a single node to the list of exports if it has a name. Override this method to change how\r\n     * symbols are exported, e.g. by modifying their exported name.\r\n     */\r\n    protected exportNode(node: AstNode, exports: AstNodeDescription[], document: LangiumDocument): void {\r\n        const name = this.nameProvider.getName(node);\r\n        if (name) {\r\n            exports.push(this.descriptions.createDescription(node, name, document));\r\n        }\r\n    }\r\n\r\n    async computeLocalScopes(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<PrecomputedScopes> {\r\n        const rootNode = document.parseResult.value;\r\n        const scopes = new MultiMap<AstNode, AstNodeDescription>();\r\n        // Here we navigate the full AST - local scopes shall be available in the whole document\r\n        for (const node of streamAllContents(rootNode)) {\r\n            await interruptAndCheck(cancelToken);\r\n            this.processNode(node, document, scopes);\r\n        }\r\n        return scopes;\r\n    }\r\n\r\n    /**\r\n     * Process a single node during scopes computation. The default implementation makes the node visible\r\n     * in the subtree of its container (if the node has a name). Override this method to change this,\r\n     * e.g. by increasing the visibility to a higher level in the AST.\r\n     */\r\n    protected processNode(node: AstNode, document: LangiumDocument, scopes: PrecomputedScopes): void {\r\n        const container = node.$container;\r\n        if (container) {\r\n            const name = this.nameProvider.getName(node);\r\n            if (name) {\r\n                scopes.add(container, this.descriptions.createDescription(node, name, document));\r\n            }\r\n        }\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { IToken } from '@chevrotain/types';\r\nimport type { Range } from 'vscode-languageserver-types';\r\nimport type { CstNode, CompositeCstNode, LeafCstNode } from '../syntax-tree.js';\r\nimport type { DocumentSegment } from '../workspace/documents.js';\r\nimport type { Stream, TreeStream } from './stream.js';\r\nimport { isCompositeCstNode, isLeafCstNode, isRootCstNode } from '../syntax-tree.js';\r\nimport { TreeStreamImpl } from './stream.js';\r\n\r\n/**\r\n * Create a stream of all CST nodes that are directly and indirectly contained in the given root node,\r\n * including the root node itself.\r\n */\r\nexport function streamCst(node: CstNode): TreeStream<CstNode> {\r\n    return new TreeStreamImpl(node, element => {\r\n        if (isCompositeCstNode(element)) {\r\n            return element.content;\r\n        } else {\r\n            return [];\r\n        }\r\n    }, { includeRoot: true });\r\n}\r\n\r\n/**\r\n * Create a stream of all leaf nodes that are directly and indirectly contained in the given root node.\r\n */\r\nexport function flattenCst(node: CstNode): Stream<LeafCstNode> {\r\n    return streamCst(node).filter(isLeafCstNode);\r\n}\r\n\r\n/**\r\n * Determines whether the specified cst node is a child of the specified parent node.\r\n */\r\nexport function isChildNode(child: CstNode, parent: CstNode): boolean {\r\n    while (child.container) {\r\n        child = child.container;\r\n        if (child === parent) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}\r\n\r\nexport function tokenToRange(token: IToken): Range {\r\n    // Chevrotain uses 1-based indices everywhere\r\n    // So we subtract 1 from every value to align with the LSP\r\n    return {\r\n        start: {\r\n            character: token.startColumn! - 1,\r\n            line: token.startLine! - 1\r\n        },\r\n        end: {\r\n            character: token.endColumn!, // endColumn uses the correct index\r\n            line: token.endLine! - 1\r\n        }\r\n    };\r\n}\r\n\r\nexport function toDocumentSegment(node: CstNode): DocumentSegment;\r\nexport function toDocumentSegment(node?: CstNode): DocumentSegment | undefined;\r\nexport function toDocumentSegment(node?: CstNode): DocumentSegment | undefined {\r\n    if (!node) {\r\n        return undefined;\r\n    }\r\n    const { offset, end, range } = node;\r\n    return {\r\n        range,\r\n        offset,\r\n        end,\r\n        length: end - offset\r\n    };\r\n}\r\n\r\nexport enum RangeComparison {\r\n    Before = 0,\r\n    After = 1,\r\n    OverlapFront = 2,\r\n    OverlapBack = 3,\r\n    Inside = 4,\r\n    Outside = 5,\r\n}\r\n\r\nexport function compareRange(range: Range, to: Range): RangeComparison {\r\n    if (range.end.line < to.start.line || (range.end.line === to.start.line && range.end.character <= to.start.character)) {\r\n        return RangeComparison.Before;\r\n    } else if (range.start.line > to.end.line || (range.start.line === to.end.line && range.start.character >= to.end.character)) {\r\n        return RangeComparison.After;\r\n    }\r\n    const startInside = range.start.line > to.start.line || (range.start.line === to.start.line && range.start.character >= to.start.character);\r\n    const endInside = range.end.line < to.end.line || (range.end.line === to.end.line && range.end.character <= to.end.character);\r\n    if (startInside && endInside) {\r\n        return RangeComparison.Inside;\r\n    } else if (startInside) {\r\n        return RangeComparison.OverlapBack;\r\n    } else if (endInside) {\r\n        return RangeComparison.OverlapFront;\r\n    } else {\r\n        return RangeComparison.Outside;\r\n    }\r\n}\r\n\r\nexport function inRange(range: Range, to: Range): boolean {\r\n    const comparison = compareRange(range, to);\r\n    return comparison > RangeComparison.After;\r\n}\r\n\r\n// The \\p{L} regex matches any unicode letter character, i.e. characters from non-english alphabets\r\n// Together with \\w it matches any kind of character which can commonly appear in IDs\r\nexport const DefaultNameRegexp = /^[\\w\\p{L}]$/u;\r\n\r\n/**\r\n * Performs `findLeafNodeAtOffset` with a minor difference: When encountering a character that matches the `nameRegexp` argument,\r\n * it will instead return the leaf node at the `offset - 1` position.\r\n *\r\n * For LSP services, users expect that the declaration of an element is available if the cursor is directly after the element.\r\n */\r\nexport function findDeclarationNodeAtOffset(cstNode: CstNode | undefined, offset: number, nameRegexp = DefaultNameRegexp): LeafCstNode | undefined {\r\n    if (cstNode) {\r\n        if (offset > 0) {\r\n            const localOffset = offset - cstNode.offset;\r\n            const textAtOffset = cstNode.text.charAt(localOffset);\r\n            if (!nameRegexp.test(textAtOffset)) {\r\n                offset--;\r\n            }\r\n        }\r\n        return findLeafNodeAtOffset(cstNode, offset);\r\n    }\r\n    return undefined;\r\n}\r\n\r\nexport function findCommentNode(cstNode: CstNode | undefined, commentNames: string[]): CstNode | undefined {\r\n    if (cstNode) {\r\n        const previous = getPreviousNode(cstNode, true);\r\n        if (previous && isCommentNode(previous, commentNames)) {\r\n            return previous;\r\n        }\r\n        if (isRootCstNode(cstNode)) {\r\n            // Go from the first non-hidden node through all nodes in reverse order\r\n            // We do this to find the comment node which directly precedes the root node\r\n            const endIndex = cstNode.content.findIndex(e => !e.hidden);\r\n            for (let i = endIndex - 1; i >= 0; i--) {\r\n                const child = cstNode.content[i];\r\n                if (isCommentNode(child, commentNames)) {\r\n                    return child;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return undefined;\r\n}\r\n\r\nexport function isCommentNode(cstNode: CstNode, commentNames: string[]): boolean {\r\n    return isLeafCstNode(cstNode) && commentNames.includes(cstNode.tokenType.name);\r\n}\r\n\r\n/**\r\n * Finds the leaf CST node at the specified 0-based string offset.\r\n * Note that the given offset will be within the range of the returned leaf node.\r\n *\r\n * If the offset does not point to a CST node (but just white space), this method will return `undefined`.\r\n *\r\n * @param node The CST node to search through.\r\n * @param offset The specified offset.\r\n * @returns The CST node at the specified offset.\r\n */\r\nexport function findLeafNodeAtOffset(node: CstNode, offset: number): LeafCstNode | undefined {\r\n    if (isLeafCstNode(node)) {\r\n        return node;\r\n    } else if (isCompositeCstNode(node)) {\r\n        const searchResult = binarySearch(node, offset, false);\r\n        if (searchResult) {\r\n            return findLeafNodeAtOffset(searchResult, offset);\r\n        }\r\n    }\r\n    return undefined;\r\n}\r\n\r\n/**\r\n * Finds the leaf CST node at the specified 0-based string offset.\r\n * If no CST node exists at the specified position, it will return the leaf node before it.\r\n *\r\n * If there is no leaf node before the specified offset, this method will return `undefined`.\r\n *\r\n * @param node The CST node to search through.\r\n * @param offset The specified offset.\r\n * @returns The CST node closest to the specified offset.\r\n */\r\nexport function findLeafNodeBeforeOffset(node: CstNode, offset: number): LeafCstNode | undefined {\r\n    if (isLeafCstNode(node)) {\r\n        return node;\r\n    } else if (isCompositeCstNode(node)) {\r\n        const searchResult = binarySearch(node, offset, true);\r\n        if (searchResult) {\r\n            return findLeafNodeBeforeOffset(searchResult, offset);\r\n        }\r\n    }\r\n    return undefined;\r\n}\r\n\r\nfunction binarySearch(node: CompositeCstNode, offset: number, closest: boolean): CstNode | undefined {\r\n    let left = 0;\r\n    let right = node.content.length - 1;\r\n    let closestNode: CstNode | undefined = undefined;\r\n\r\n    while (left <= right) {\r\n        const middle = Math.floor((left + right) / 2);\r\n        const middleNode = node.content[middle];\r\n\r\n        if (middleNode.offset <= offset && middleNode.end > offset) {\r\n            // Found an exact match\r\n            return middleNode;\r\n        }\r\n\r\n        if (middleNode.end <= offset) {\r\n            // Update the closest node (less than offset) and move to the right half\r\n            closestNode = closest ? middleNode : undefined;\r\n            left = middle + 1;\r\n        } else {\r\n            // Move to the left half\r\n            right = middle - 1;\r\n        }\r\n    }\r\n\r\n    return closestNode;\r\n}\r\n\r\nexport function getPreviousNode(node: CstNode, hidden = true): CstNode | undefined {\r\n    while (node.container) {\r\n        const parent = node.container;\r\n        let index = parent.content.indexOf(node);\r\n        while (index > 0) {\r\n            index--;\r\n            const previous = parent.content[index];\r\n            if (hidden || !previous.hidden) {\r\n                return previous;\r\n            }\r\n        }\r\n        node = parent;\r\n    }\r\n    return undefined;\r\n}\r\n\r\nexport function getNextNode(node: CstNode, hidden = true): CstNode | undefined {\r\n    while (node.container) {\r\n        const parent = node.container;\r\n        let index = parent.content.indexOf(node);\r\n        const last = parent.content.length - 1;\r\n        while (index < last) {\r\n            index++;\r\n            const next = parent.content[index];\r\n            if (hidden || !next.hidden) {\r\n                return next;\r\n            }\r\n        }\r\n        node = parent;\r\n    }\r\n    return undefined;\r\n}\r\n\r\nexport function getStartlineNode(node: CstNode): CstNode {\r\n    if (node.range.start.character === 0) {\r\n        return node;\r\n    }\r\n    const line = node.range.start.line;\r\n    let last = node;\r\n    let index: number | undefined;\r\n    while (node.container) {\r\n        const parent = node.container;\r\n        const selfIndex = index ?? parent.content.indexOf(node);\r\n        if (selfIndex === 0) {\r\n            node = parent;\r\n            index = undefined;\r\n        } else {\r\n            index = selfIndex - 1;\r\n            node = parent.content[index];\r\n        }\r\n        if (node.range.start.line !== line) {\r\n            break;\r\n        }\r\n        last = node;\r\n    }\r\n    return last;\r\n}\r\n\r\nexport function getInteriorNodes(start: CstNode, end: CstNode): CstNode[] {\r\n    const commonParent = getCommonParent(start, end);\r\n    if (!commonParent) {\r\n        return [];\r\n    }\r\n    return commonParent.parent.content.slice(commonParent.a + 1, commonParent.b);\r\n}\r\n\r\nfunction getCommonParent(a: CstNode, b: CstNode): CommonParent | undefined {\r\n    const aParents = getParentChain(a);\r\n    const bParents = getParentChain(b);\r\n    let current: CommonParent | undefined;\r\n    for (let i = 0; i < aParents.length && i < bParents.length; i++) {\r\n        const aParent = aParents[i];\r\n        const bParent = bParents[i];\r\n        if (aParent.parent === bParent.parent) {\r\n            current = {\r\n                parent: aParent.parent,\r\n                a: aParent.index,\r\n                b: bParent.index\r\n            };\r\n        } else {\r\n            break;\r\n        }\r\n    }\r\n    return current;\r\n}\r\n\r\ninterface CommonParent {\r\n    parent: CompositeCstNode\r\n    a: number\r\n    b: number\r\n}\r\n\r\nfunction getParentChain(node: CstNode): ParentLink[] {\r\n    const chain: ParentLink[] = [];\r\n    while (node.container) {\r\n        const parent = node.container;\r\n        const index = parent.content.indexOf(node);\r\n        chain.push({\r\n            parent,\r\n            index\r\n        });\r\n        node = parent;\r\n    }\r\n    return chain.reverse();\r\n}\r\n\r\ninterface ParentLink {\r\n    parent: CompositeCstNode\r\n    index: number\r\n}\r\n","import { includes } from \"lodash-es\";\nimport {\n  IRecognitionException,\n  IRecognizerContext,\n  IToken,\n} from \"@chevrotain/types\";\n\nconst MISMATCHED_TOKEN_EXCEPTION = \"MismatchedTokenException\";\nconst NO_VIABLE_ALT_EXCEPTION = \"NoViableAltException\";\nconst EARLY_EXIT_EXCEPTION = \"EarlyExitException\";\nconst NOT_ALL_INPUT_PARSED_EXCEPTION = \"NotAllInputParsedException\";\n\nconst RECOGNITION_EXCEPTION_NAMES = [\n  MISMATCHED_TOKEN_EXCEPTION,\n  NO_VIABLE_ALT_EXCEPTION,\n  EARLY_EXIT_EXCEPTION,\n  NOT_ALL_INPUT_PARSED_EXCEPTION,\n];\n\nObject.freeze(RECOGNITION_EXCEPTION_NAMES);\n\n// hacks to bypass no support for custom Errors in javascript/typescript\nexport function isRecognitionException(error: Error) {\n  // can't do instanceof on hacked custom js exceptions\n  return includes(RECOGNITION_EXCEPTION_NAMES, error.name);\n}\n\nabstract class RecognitionException\n  extends Error\n  implements IRecognitionException\n{\n  context: IRecognizerContext;\n  resyncedTokens: IToken[] = [];\n\n  protected constructor(\n    message: string,\n    public token: IToken,\n  ) {\n    super(message);\n\n    // fix prototype chain when typescript target is ES5\n    Object.setPrototypeOf(this, new.target.prototype);\n\n    /* istanbul ignore next - V8 workaround to remove constructor from stacktrace when typescript target is ES5 */\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n  }\n}\n\nexport class MismatchedTokenException extends RecognitionException {\n  constructor(\n    message: string,\n    token: IToken,\n    public previousToken: IToken,\n  ) {\n    super(message, token);\n    this.name = MISMATCHED_TOKEN_EXCEPTION;\n  }\n}\n\nexport class NoViableAltException extends RecognitionException {\n  constructor(\n    message: string,\n    token: IToken,\n    public previousToken: IToken,\n  ) {\n    super(message, token);\n    this.name = NO_VIABLE_ALT_EXCEPTION;\n  }\n}\n\nexport class NotAllInputParsedException extends RecognitionException {\n  constructor(message: string, token: IToken) {\n    super(message, token);\n    this.name = NOT_ALL_INPUT_PARSED_EXCEPTION;\n  }\n}\n\nexport class EarlyExitException extends RecognitionException {\n  constructor(\n    message: string,\n    token: IToken,\n    public previousToken: IToken,\n  ) {\n    super(message, token);\n    this.name = EARLY_EXIT_EXCEPTION;\n  }\n}\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { Range } from 'vscode-languageserver-types';\r\nimport type { AstNode, AstReflection, CstNode, GenericAstNode, Mutable, PropertyType, Reference, ReferenceInfo } from '../syntax-tree.js';\r\nimport type { Stream, TreeStream } from './stream.js';\r\nimport type { LangiumDocument } from '../workspace/documents.js';\r\nimport { isAstNode, isReference } from '../syntax-tree.js';\r\nimport { DONE_RESULT, stream, StreamImpl, TreeStreamImpl } from './stream.js';\r\nimport { inRange } from './cst-utils.js';\r\n\r\n/**\r\n * Link the `$container` and other related properties of every AST node that is directly contained\r\n * in the given `node`.\r\n */\r\nexport function linkContentToContainer(node: AstNode): void {\r\n    for (const [name, value] of Object.entries(node)) {\r\n        if (!name.startsWith('$')) {\r\n            if (Array.isArray(value)) {\r\n                value.forEach((item, index) => {\r\n                    if (isAstNode(item)) {\r\n                        (item as Mutable<AstNode>).$container = node;\r\n                        (item as Mutable<AstNode>).$containerProperty = name;\r\n                        (item as Mutable<AstNode>).$containerIndex = index;\r\n                    }\r\n                });\r\n            } else if (isAstNode(value)) {\r\n                (value as Mutable<AstNode>).$container = node;\r\n                (value as Mutable<AstNode>).$containerProperty = name;\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n/**\r\n * Walk along the hierarchy of containers from the given AST node to the root and return the first\r\n * node that matches the type predicate. If the start node itself matches, it is returned.\r\n * If no container matches, `undefined` is returned.\r\n */\r\nexport function getContainerOfType<T extends AstNode>(node: AstNode | undefined, typePredicate: (n: AstNode) => n is T): T | undefined {\r\n    let item = node;\r\n    while (item) {\r\n        if (typePredicate(item)) {\r\n            return item;\r\n        }\r\n        item = item.$container;\r\n    }\r\n    return undefined;\r\n}\r\n\r\n/**\r\n * Walk along the hierarchy of containers from the given AST node to the root and check for existence\r\n * of a container that matches the given predicate. The start node is included in the checks.\r\n */\r\nexport function hasContainerOfType(node: AstNode | undefined, predicate: (n: AstNode) => boolean): boolean {\r\n    let item = node;\r\n    while (item) {\r\n        if (predicate(item)) {\r\n            return true;\r\n        }\r\n        item = item.$container;\r\n    }\r\n    return false;\r\n}\r\n\r\n/**\r\n * Retrieve the document in which the given AST node is contained. A reference to the document is\r\n * usually held by the root node of the AST.\r\n *\r\n * @throws an error if the node is not contained in a document.\r\n */\r\nexport function getDocument<T extends AstNode = AstNode>(node: AstNode): LangiumDocument<T> {\r\n    const rootNode = findRootNode(node);\r\n    const result = rootNode.$document;\r\n    if (!result) {\r\n        throw new Error('AST node has no document.');\r\n    }\r\n    return result as LangiumDocument<T>;\r\n}\r\n\r\n/**\r\n * Returns the root node of the given AST node by following the `$container` references.\r\n */\r\nexport function findRootNode(node: AstNode): AstNode {\r\n    while (node.$container) {\r\n        node = node.$container;\r\n    }\r\n    return node;\r\n}\r\n\r\nexport interface AstStreamOptions {\r\n    /**\r\n     * Optional target range that the nodes in the stream need to intersect\r\n     */\r\n    range?: Range\r\n}\r\n\r\n/**\r\n * Create a stream of all AST nodes that are directly contained in the given node. This includes\r\n * single-valued as well as multi-valued (array) properties.\r\n */\r\nexport function streamContents(node: AstNode, options?: AstStreamOptions): Stream<AstNode> {\r\n    if (!node) {\r\n        throw new Error('Node must be an AstNode.');\r\n    }\r\n    const range = options?.range;\r\n    type State = { keys: string[], keyIndex: number, arrayIndex: number };\r\n    return new StreamImpl<State, AstNode>(() => ({\r\n        keys: Object.keys(node),\r\n        keyIndex: 0,\r\n        arrayIndex: 0\r\n    }), state => {\r\n        while (state.keyIndex < state.keys.length) {\r\n            const property = state.keys[state.keyIndex];\r\n            if (!property.startsWith('$')) {\r\n                const value = (node as GenericAstNode)[property];\r\n                if (isAstNode(value)) {\r\n                    state.keyIndex++;\r\n                    if (isAstNodeInRange(value, range)) {\r\n                        return { done: false, value };\r\n                    }\r\n                } else if (Array.isArray(value)) {\r\n                    while (state.arrayIndex < value.length) {\r\n                        const index = state.arrayIndex++;\r\n                        const element = value[index];\r\n                        if (isAstNode(element) && isAstNodeInRange(element, range)) {\r\n                            return { done: false, value: element };\r\n                        }\r\n                    }\r\n                    state.arrayIndex = 0;\r\n                }\r\n            }\r\n            state.keyIndex++;\r\n        }\r\n        return DONE_RESULT;\r\n    });\r\n}\r\n\r\n/**\r\n * Create a stream of all AST nodes that are directly and indirectly contained in the given root node.\r\n * This does not include the root node itself.\r\n */\r\nexport function streamAllContents(root: AstNode, options?: AstStreamOptions): TreeStream<AstNode> {\r\n    if (!root) {\r\n        throw new Error('Root node must be an AstNode.');\r\n    }\r\n    return new TreeStreamImpl(root, node => streamContents(node, options));\r\n}\r\n\r\n/**\r\n * Create a stream of all AST nodes that are directly and indirectly contained in the given root node,\r\n * including the root node itself.\r\n */\r\nexport function streamAst(root: AstNode, options?: AstStreamOptions): TreeStream<AstNode> {\r\n    if (!root) {\r\n        throw new Error('Root node must be an AstNode.');\r\n    } else if (options?.range && !isAstNodeInRange(root, options.range)) {\r\n        // Return an empty stream if the root node isn't in range\r\n        return new TreeStreamImpl(root, () => []);\r\n    }\r\n    return new TreeStreamImpl(root, node => streamContents(node, options), { includeRoot: true });\r\n}\r\n\r\nfunction isAstNodeInRange(astNode: AstNode, range?: Range): boolean {\r\n    if (!range) {\r\n        return true;\r\n    }\r\n    const nodeRange = astNode.$cstNode?.range;\r\n    if (!nodeRange) {\r\n        return false;\r\n    }\r\n    return inRange(nodeRange, range);\r\n}\r\n\r\n/**\r\n * Create a stream of all cross-references that are held by the given AST node. This includes\r\n * single-valued as well as multi-valued (array) properties.\r\n */\r\nexport function streamReferences(node: AstNode): Stream<ReferenceInfo> {\r\n    type State = { keys: string[], keyIndex: number, arrayIndex: number };\r\n    return new StreamImpl<State, ReferenceInfo>(() => ({\r\n        keys: Object.keys(node),\r\n        keyIndex: 0,\r\n        arrayIndex: 0\r\n    }), state => {\r\n        while (state.keyIndex < state.keys.length) {\r\n            const property = state.keys[state.keyIndex];\r\n            if (!property.startsWith('$')) {\r\n                const value = (node as GenericAstNode)[property];\r\n                if (isReference(value)) {\r\n                    state.keyIndex++;\r\n                    return { done: false, value: { reference: value, container: node, property } };\r\n                } else if (Array.isArray(value)) {\r\n                    while (state.arrayIndex < value.length) {\r\n                        const index = state.arrayIndex++;\r\n                        const element = value[index];\r\n                        if (isReference(element)) {\r\n                            return { done: false, value: { reference: element, container: node, property, index } };\r\n                        }\r\n                    }\r\n                    state.arrayIndex = 0;\r\n                }\r\n            }\r\n            state.keyIndex++;\r\n        }\r\n        return DONE_RESULT;\r\n    });\r\n}\r\n\r\n/**\r\n * Returns a Stream of references to the target node from the AstNode tree\r\n *\r\n * @param targetNode AstNode we are looking for\r\n * @param lookup AstNode where we search for references. If not provided, the root node of the document is used as the default value\r\n */\r\nexport function findLocalReferences(targetNode: AstNode, lookup = getDocument(targetNode).parseResult.value): Stream<Reference> {\r\n    const refs: Reference[] = [];\r\n    streamAst(lookup).forEach(node => {\r\n        streamReferences(node).forEach(refInfo => {\r\n            if (refInfo.reference.ref === targetNode) {\r\n                refs.push(refInfo.reference);\r\n            }\r\n        });\r\n    });\r\n    return stream(refs);\r\n}\r\n\r\n/**\r\n * Assigns all mandatory AST properties to the specified node.\r\n *\r\n * @param reflection Reflection object used to gather mandatory properties for the node.\r\n * @param node Specified node is modified in place and properties are directly assigned.\r\n */\r\nexport function assignMandatoryProperties(reflection: AstReflection, node: AstNode): void {\r\n    const typeMetaData = reflection.getTypeMetaData(node.$type);\r\n    const genericNode = node as GenericAstNode;\r\n    for (const property of typeMetaData.properties) {\r\n        // Only set the value if the property is not already set and if it has a default value\r\n        if (property.defaultValue !== undefined && genericNode[property.name] === undefined) {\r\n            genericNode[property.name] = copyDefaultValue(property.defaultValue);\r\n        }\r\n    }\r\n}\r\n\r\nfunction copyDefaultValue(propertyType: PropertyType): PropertyType {\r\n    if (Array.isArray(propertyType)) {\r\n        return [...propertyType.map(copyDefaultValue)];\r\n    } else {\r\n        return propertyType;\r\n    }\r\n}\r\n\r\n/**\r\n * Creates a deep copy of the specified AST node.\r\n * The resulting copy will only contain semantically relevant information, such as the `$type` property and AST properties.\r\n *\r\n * References are copied without resolved cross reference. The specified function is used to rebuild them.\r\n */\r\nexport function copyAstNode<T extends AstNode = AstNode>(node: T, buildReference: (node: AstNode, property: string, refNode: CstNode | undefined, refText: string) => Reference<AstNode>): T {\r\n    const copy: GenericAstNode = { $type: node.$type };\r\n\r\n    for (const [name, value] of Object.entries(node)) {\r\n        if (!name.startsWith('$')) {\r\n            if (isAstNode(value)) {\r\n                copy[name] = copyAstNode(value, buildReference);\r\n            } else if (isReference(value)) {\r\n                copy[name] = buildReference(\r\n                    copy,\r\n                    name,\r\n                    value.$refNode,\r\n                    value.$refText\r\n                );\r\n            } else if (Array.isArray(value)) {\r\n                const copiedArray: unknown[] = [];\r\n                for (const element of value) {\r\n                    if (isAstNode(element)) {\r\n                        copiedArray.push(copyAstNode(element, buildReference));\r\n                    } else if (isReference(element)) {\r\n                        copiedArray.push(\r\n                            buildReference(\r\n                                copy,\r\n                                name,\r\n                                element.$refNode,\r\n                                element.$refText\r\n                            )\r\n                        );\r\n                    } else {\r\n                        copiedArray.push(element);\r\n                    }\r\n                }\r\n                copy[name] = copiedArray;\r\n            } else {\r\n                copy[name] = value;\r\n            }\r\n        }\r\n    }\r\n\r\n    linkContentToContainer(copy);\r\n    return copy as unknown as T;\r\n}\r\n"],"names":["JSON","stringify","normalizeStringPosix","path","allowAboveRoot","code","res","lastSegmentLength","lastSlash","dots","i","length","charCodeAt","lastSlashIndex","lastIndexOf","slice","posix","resolve","cwd","resolvedPath","resolvedAbsolute","arguments","undefined","process","assertPath","normalize","isAbsolute","trailingSeparator","join","joined","arg","relative","from","to","fromStart","fromEnd","fromLen","toStart","toLen","lastCommonSep","fromCode","out","_makeLong","dirname","hasRoot","end","matchedSlash","basename","ext","TypeError","start","extIdx","firstNonSlashEnd","extname","startDot","startPart","preDotState","format","pathObject","sep","dir","root","base","name","_format","parse","ret","delimiter","win32","module","exports","__webpack_module_cache__","__webpack_require__","moduleId","cachedModule","__webpack_modules__","d","definition","key","o","Object","defineProperty","enumerable","get","obj","prop","prototype","hasOwnProperty","call","r","Symbol","toStringTag","value","isWindows","platform","navigator","userAgent","indexOf","_schemePattern","_singleSlashStart","_doubleSlashStart","_validateUri","_strict","scheme","Error","authority","query","fragment","test","_empty","_slash","_regexp","URI","isUri","thing","fsPath","with","toString","schemeOrData","this","_schemeFix","_referenceResolution","uriToFsPath","change","Uri","match","exec","percentDecode","file","replace","idx","substring","components","result","skipEncoding","_asFormatted","toJSON","revive","data","_formatted","external","_fsPath","_sep","_pathSepMarker","$mid","encodeTable","encodeURIComponentFast","uriComponent","isPath","isAuthority","nativeEncodePos","pos","encodeURIComponent","charAt","substr","escaped","encodeURIComponentMinimal","uri","keepDriveLetterCasing","toLowerCase","encoder","userinfo","String","fromCharCode","decodeURIComponentGraceful","str","decodeURIComponent","_rEncodedAsHex","posixPath","slash","Utils","joinPath","paths","resolvePath","slashAdded"],"mappings":"iJAMI,EACJ,SAAS,IACL,QAAa,IAAT,EACA,KADoB,CACd,AAAI,MAAM,CAAC,sCAAsC,CAAC,EAE5D,OAAO,CACX,CAPA,OAAO,cAAc,CAAC,EAAS,aAAc,CAAE,OAAO,CAAK,GAevD,AACD,IAAQ,GAAD,AAAO,EAAC,CAAC,EADX,OAAO,CANX,EAMc,OANL,AAAQ,CAAG,EAChB,QAAY,IAAR,EACA,KADmB,CACT,AAAJ,MAAU,CAAC,qCAAqC,CAAC,EAE3D,EAAO,CACX,EAGJ,EAAQ,OAAO,CAAG,gCCXlB,SAAS,EAAO,CAAK,EACjB,MAAO,AAAiB,iBAAV,GAAsB,aAAiB,MACzD,CAcA,SAAS,EAAM,CAAK,EAChB,OAAO,MAAM,OAAO,CAAC,EACzB,CAxBA,OAAO,cAAc,CAAC,EAAS,aAAc,CAAE,OAAO,CAAK,GAC3D,EAAQ,WAAW,CAAG,EAAQ,KAAK,CAAG,EAAQ,IAAI,CAAG,EAAQ,KAAK,CAAG,EAAQ,MAAM,CAAG,EAAQ,MAAM,CAAG,EAAQ,OAAO,CAAG,KAAK,EAI9H,EAAQ,OAAO,CAHf,EAGkB,OAHT,AAAQ,CAAK,EAClB,OAAiB,IAAV,IAA4B,IAAV,CAC7B,EAKA,EAAQ,MAAM,CAAG,EAIjB,EAAQ,MAAM,CAHd,EAGiB,OAHR,AAAO,CAAK,EACjB,MAAwB,UAAjB,OAAO,GAAsB,aAAiB,MACzD,EAKA,EAAQ,KAAK,CAHb,EAGgB,OAHP,AAAM,CAAK,EAChB,OAAO,aAAiB,KAC5B,EAKA,EAAQ,IAAI,CAHZ,EAGe,OAHN,AAAK,CAAK,EACf,MAAwB,YAAjB,OAAO,CAClB,EAKA,EAAQ,KAAK,CAAG,EAIhB,EAAQ,WAAW,CAHnB,EAGsB,OAHb,AAAY,CAAK,EACtB,OAAO,EAAM,IAAU,EAAM,KAAK,CAAC,GAAQ,EAAO,GACtD,oCCzBI,EACO,KAAK,GAJhB,OAAO,cAAc,CAAC,EAAS,aAAc,CAAE,OAAO,CAAK,GAC3D,EAAQ,OAAO,CAAG,EAAQ,KAAK,CAAG,KAAK,EACvC,IAAM,EAAA,EAAA,CAAA,CAAA,SAKH,IAAU,EAAQ,GAAT,EAAc,CAAG,EAAQ,EAAC,CAAC,CAF7B,EAAc,CAAE,UAAY,CAAE,EACpC,EAAM,IAAI,CAAG,WAAc,OAAO,CAAa,CAEnD,OAAM,EACF,IAAI,CAAQ,CAAE,EAAU,IAAI,CAAE,CAAM,CAAE,CAC7B,IAAI,CAAC,UAAU,EAAE,CAClB,IAAI,CAAC,UAAU,CAAG,EAAE,CACpB,IAAI,CAAC,SAAS,CAAG,EAAE,EAEvB,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,GACrB,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,GAChB,MAAM,OAAO,CAAC,IACd,EAAO,GADgB,CACZ,CAAC,CAAE,QAAS,IAAM,IAAI,CAAC,MAAM,CAAC,EAAU,EAAS,EAEpE,CACA,OAAO,CAAQ,CAAE,EAAU,IAAI,CAAE,CAC7B,GAAI,CAAC,IAAI,CAAC,UAAU,CAChB,CADkB,MAGtB,IAAI,EAAoC,GACxC,IAAK,IAAI,EAAI,EAAG,EAAM,IAAI,CAAC,UAAU,CAAC,MAAM,CAAE,EAAI,EAAK,IAAK,AACxD,GAAI,IAAI,CAAC,UAAU,CAAC,EAAE,GAAK,EACvB,GAAI,IAAI,CADyB,AACxB,SAAS,CAAC,EAAE,GAAK,EAAS,CAE/B,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC,EAAG,GAC1B,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,EAAG,GACzB,MACJ,MAEI,CADC,EACmC,EAIhD,GAAI,EACA,MAAM,AAAI,MAAM,qBADmB,+DAG3C,CACA,OAAO,GAAG,CAAI,CAAE,CACZ,GAAI,CAAC,IAAI,CAAC,UAAU,CAChB,CADkB,KACX,EAAE,CAEb,IAAM,EAAM,EAAE,CAAE,EAAY,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,GAAI,EAAW,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,GACtF,IAAK,IAAI,EAAI,EAAG,EAAM,EAAU,MAAM,CAAE,EAAI,EAAK,IAAK,AAClD,GAAI,CACA,EAAI,IAAI,CAAC,CAAS,CAAC,EAAE,CAAC,KAAK,CAAC,CAAQ,CAAC,EAAE,CAAE,GAC7C,CACA,MAAO,EAAG,CAEN,CAAC,EAAG,EAAM,OAAA,AAAO,IAAI,OAAO,CAAC,KAAK,CAAC,EACvC,CAEJ,OAAO,CACX,CACA,SAAU,CACN,MAAO,CAAC,IAAI,CAAC,UAAU,EAA+B,IAA3B,IAAI,CAAC,UAAU,CAAC,MAAM,AACrD,CACA,SAAU,CACN,IAAI,CAAC,UAAU,MAAG,EAClB,IAAI,CAAC,SAAS,MAAG,CACrB,CACJ,CACA,MAAM,EACF,YAAY,CAAQ,CAAE,CAClB,IAAI,CAAC,QAAQ,CAAG,CACpB,CAKA,IAAI,OAAQ,CA6BR,OA5BK,AAAD,IAAK,CAAC,MAAM,EAAE,CACd,IAAI,CAAC,MAAM,CAAG,CAAC,EAAU,EAAU,KAC3B,AAAC,IAAI,CAAC,UAAU,EAAE,CAClB,IAAI,CAAC,UAAU,CAAG,IAAI,CAAA,EAEtB,IAAI,CAAC,QAAQ,EAAI,IAAI,CAAC,QAAQ,CAAC,kBAAkB,EAAI,IAAI,CAAC,UAAU,CAAC,OAAO,IAAI,AAChF,IAAI,CAAC,QAAQ,CAAC,kBAAkB,CAAC,IAAI,EAEzC,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC,EAAU,GAC9B,IAAM,EAAS,CACX,QAAS,KACA,IAAI,CAAC,UAAU,EAAE,CAItB,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC,EAAU,GACjC,EAAO,OAAO,CAAG,EAAQ,KAAK,CAC1B,IAAI,CAAC,QAAQ,EAAI,IAAI,CAAC,QAAQ,CAAC,oBAAoB,EAAI,IAAI,CAAC,UAAU,CAAC,OAAO,IAAI,AAClF,IAAI,CAAC,QAAQ,CAAC,oBAAoB,CAAC,IAAI,EAE/C,CACJ,EAIA,OAHI,MAAM,OAAO,CAAC,IACd,EAAY,IAAI,CAAC,GAEd,AAHyB,EAIpC,EAEG,IAAI,CAAC,MAAM,AACtB,CAKA,KAAK,CAAK,CAAE,CACJ,IAAI,CAAC,UAAU,EAAE,AACjB,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,UAAU,CAAE,EAErD,CACA,SAAU,CACF,IAAI,CAAC,UAAU,EAAE,CACjB,IAAI,CAAC,UAAU,CAAC,OAAO,GACvB,IAAI,CAAC,UAAU,MAAG,EAE1B,CACJ,CACA,EAAQ,OAAO,CAAG,EAClB,EAAQ,KAAK,CAAG,WAAc,oCCrH1B,IALJ,OAAO,cAAc,CAAC,EAAS,aAAc,CAAE,OAAO,CAAK,GAC3D,EAAQ,uBAAuB,CAAG,EAAQ,iBAAiB,CAAG,KAAK,EACnE,IAAM,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,MAGF,EADO,EAgBR,IAAsB,EAAQ,SAhBL,MAgBJ,EAA0B,CAAG,EAAoB,EAAC,CAAC,EAfrD,IAAI,CAAG,OAAO,MAAM,CAAC,CACnC,yBAAyB,EACzB,wBAAyB,EAAS,KAAK,CAAC,IAC5C,AADgD,GAEhD,EAAkB,SAAS,CAAG,OAAO,MAAM,CAAC,CACxC,yBAAyB,EACzB,wBAAyB,EAAS,KAAK,CAAC,IAAI,AAChD,GAOA,EAAkB,EAAE,CANpB,EAMuB,OANd,AAAG,CAAK,EAEb,OAAO,IAAc,IAAc,EAAkB,GAAjC,CAAqC,EAClD,IAAc,EAAkB,SAAS,EACxC,EAAG,OAAO,CAAC,EAAU,uBAAuB,GAAK,CAAC,CAHxC,AAGyC,EAAU,uBAAA,AAAwB,CACjG,EAGJ,IAAM,EAAgB,OAAO,MAAM,CAAC,SAAU,CAAQ,CAAE,CAAO,EAC3D,IAAM,EAAS,CAAC,EAAG,EAAM,OAAA,AAAO,IAAI,KAAK,CAAC,UAAU,CAAC,EAAS,IAAI,CAAC,GAAU,GAC7E,MAAO,CAAE,UAAY,EAAO,OAAO,EAAI,CAAE,CAC7C,EACA,OAAM,EACF,aAAc,CACV,IAAI,CAAC,YAAY,EAAG,CACxB,CACA,QAAS,CACD,CAAC,IAAI,CAAC,YAAY,EAAE,CACpB,IAAI,CAAC,YAAY,EAAG,EAChB,IAAI,CAAC,QAAQ,EAAE,CACf,IAAI,CAAC,QAAQ,CAAC,IAAI,MAAC,GACnB,IAAI,CAAC,OAAO,IAGxB,CACA,IAAI,yBAA0B,CAC1B,OAAO,IAAI,CAAC,YAAY,AAC5B,CACA,IAAI,yBAA0B,QAC1B,AAAI,IAAI,CAAC,YAAY,CACV,CADY,EAGnB,AAAC,IAAI,CAAC,QAAQ,EAAE,CAChB,IAAI,CAAC,QAAQ,CAAG,IAAI,EAAS,OAAO,EAEjC,IAAI,CAAC,QAAQ,CAAC,KAAK,CAC9B,CACA,SAAU,CACF,IAAI,CAAC,QAAQ,EAAE,CACf,IAAI,CAAC,QAAQ,CAAC,OAAO,GACrB,IAAI,CAAC,QAAQ,CAAG,OAExB,CACJ,CAgCA,EAAQ,uBAAuB,CA/B/B,EA+BkC,IA9B9B,AADE,IACE,OAAQ,CAMR,OALI,AAAC,IAAI,CAAC,MAAM,EAAE,CAGd,IAAI,CAAC,MAAM,CAAG,IAAI,CAAA,EAEf,IAAI,CAAC,MAAM,AACtB,CACA,QAAS,CACA,IAAI,CAAC,MAAM,CAOZ,CAPc,GAOV,CAAC,MAAM,CAAC,MAAM,GAHlB,IAAI,CAAC,MAAM,CAAG,EAAkB,SAAS,AAKjD,CACA,SAAU,CACD,IAAI,CAAC,MAAM,CAIP,CAJS,GAIL,CAAC,MAAM,YAAY,GAE5B,IAAI,CAAC,MAFqC,AAE/B,CAAC,OAAO,GAJnB,IAAI,CAAC,MAAM,CAAG,EAAkB,IAAI,AAM5C,CACJ,0FqJvEmC,O4HOG,CrEQC,AzD9BA,AkIDA,ACIA,AFFA,ADCA,ADFA,A7HeJ,EAAA,A4HOgD,U5HPhD,OAAA,E4HO2C,CbpBwB,CiBHhB,AzE+BnB,CAAC,EqERe,mDAoCU,2BAAL,CpHKjC,+DoHsDH,GAAA,EAAA,EAAA,SAAA,GAAA,UAAA,OAAA,EAAA,OAAA,gHAiCS,6FAW9B,CAAA,EAAA,2RAwFiB,UAAA,MAAA,OAAA,CAAA,EAAA,OAAwD,CAAC,CAAC,CZjHrB,CAAC,CwCzCC,+C5BqKY,4BAAL,CAOxF,SAAA,EAAA,CAAA,4LwDF+B,8JAkBZ,mNA0BY,mDAUtB,CAAA,CAAA,sDAE+C,CN/NmB,ArK2D1C,Q2KoKiC,CrC/JmB,CAAA,OqC+JN,ChCnPmB,OgCmPX,CAAA,IAAK,CAAC,AACvF,KAAK,CAAC,EAAE,iBAEgB,CAAA,sBAEQ,CAAC,EAAA,KAAA,CAAA,0IAmBf,QAAA,oBAsU9B,mCACe,MA7TU,CA6TV,UADf,EA5TyB,EAAA,KAAA,EA8TV,EAEX,KAAA,IAAA,cAIA,AAAyB,YAAzB,OAAA,EAAyB,QAAA,GAEA,QAAA,GAElB,OAAA,SAAA,CAAA,QAAyB,CAAA,IAAA,CAAM,CtQnFL,yCsQ9OP,EAAA,CAAA,CAAA,KAChB,EAAA,IAAA,CAAA,QAAA,iDAIkC,GAAA,eAAoB,CAAC,C9FrKjB,AtJcQ,gCoP8K9C,EAAA,IAAA,CAAA,QAAwB,oBAEtB,EAAA,IAAA,EAAA,6BAIY,IAAA,UAEb,mIAgBuB,iDAKV,IAAA,+BAOZ,CAAA,OAAA,CACH,AADG,mCAEmC,CAAA,4CAaxC,CAAA,CAAA,YACQ,EAAA,IAAA,CAAA,OACK,CAAA,8CAKiC,KAAK,CAAC,A3FjMd,Q2FkMlB,SAEL,CvPrGY,AiNhBf,CAAA,IAAA,CAAA,wEsC4H4B,CAAC,ApQ1MlC,C8NyFgB,oBsCyHtB,EAAA,EAAA,IAAA,sCAKoB,EAAA,EAA0B,EAAK,KAAK,C7H/KH,A6H+KI,C7H/KH,A6H+KI,mHAcjD,EAAA,IAAA,gCAIa,CAAA,eAAgB,CAAC,EAAU,EAAY,0BAChC,GAG1B,EAAA,EAAA,EAA+B,KAAK,OAK1C,CAAgC,CEvG9B,AFuG8B,yBAEtB,EAAA,IAAA,mDAKS,IAAI,eAKc,CAAA,KAChC,EAAA,IAAA,CAAA,QAAA,OAEF,EAAA,EAAA,IAAA,uDAOJ,C7HvKH,A6HuKI,OACM,yBAIc,CAAA,QAAS,KACnB,EAAA,IAAA,QACJ,CAAC,EAAA,IAAA,EAAA,2BAIG,EAAA,IAAA,kCAOA,EACP,IAAM,CAAC,MAAQ,IAAI,CAAA,OAAQ,GAAE,CAAE,CAAC,AAChC,AAAC,CV9Pa,sCUiQ0B,IAAI,OAC5B,CW9RH,CAAA,IAAA,oDXoSuB,CAAA,MAAA,CAAA,EAAA,IAAkB,CAAC,OACpC,SACmB,kBACF,CAAC,ALhKJ,QKmKK,C5F3LA,KAAA,c4FyLL,CAAM,CAAC,CrD9RH,CvCkGI,CuClGF,AvCkGG,I4F4LK,ErD9RF,CAAC,C/LyJH,IoPqIY,CAAA,UAK1C,C/FtPT,AoG8aM,CLxLS,QAAA,CAAA,6DAajB,EAAA,EAAA,EAAA,IAAA,CAAA,IAA8B,CAAC,EAAQ,CAAC,CAAgC,CAAC,AAAE,CAAD,ApQ5KvD,GAAA,QoQ8KlB,IAAA,EAAA,IAAA,CAAA,eAC0B,CpEvLmB,CoEuLjB,EAAE,CACjC,AAAC,qBAE2B,6DAGK,C5BjRH,W4BsRV,OAAE,CD0DX,AnEzOU,CAAA,CxBRJ,AwBQI,EoE+KkB,E5K/JJ,I4K+JU,CAAC,EAAA,IAAU,CAAC,CAAC,YAE/B,SAGJ,OAAQ,EAAO,MAAA,kBAFR,CAAA,CAAQ,CAAA,OAAQ,GpQpKL,CAAC,IoQoKY,CAAA,WAKnC,QAAA,CAAU,GzB5SD,CAAC,CAAC,mByBmTlC,IAAqB,CAAA,QAAA,GACG,IAAI,aACb,EAAE,mBAMhB,EAAY,CAAA,CAAA,YACF,EAAA,WAEW,C5FzLf,AsD8EY,A+CnLA,GT8RO,CAAA,OAAQ,EAAE,mBAEX,IAAA,CAAA,MAAW,CAAC,QADE,CDyEX,ACzEY,GAAI,CAAC,UAQzC,IAAA,CAAA,MAAA,EAIR,MAAM,CAAA,CAAA,YACS,EAAA,IACD,CAAA,CAAG,EtQvGU,A2OvEU,GAAA,Q2B8KJ,IAAI,CAAC,C5KhJW,M4KgJJ,EAAE,CAAA,CAAE,CAAC,AAC1C,KAAK,CAAC,AACI,CtQxGX,CsQuGS,EtQvGT,GsQyGS,EAAM,IAAI,CAAA,KAGP,IAHmB,AAGnB,C5FlMM,A4F+Lc,AAGf,CpE9KH,CAAA,A2CjIC,A3OiJV,IAAA,CAAA,EoQ8JyB,KAAK,CAAC,CAAC,oBAMjC,IAAA,EAAA,IAAA,CAAA,KACW,IAAI,E5FnMY,CAAC,A4FmMV,CK2KmB,AjG9WR,A1KqG5B,CsQ8F4B,iBAAqB,CAAC,OAAO,EtQ7FvC,AsQ6FyC,CAAA,CAAE,CAAC,AAClE,KAAK,CAAC,EAAE,KAIA,GAAI,CAAC,GADI,IAAI,CAAC,MAAM,CAAA,EAAO,C5FrML,a4FqMkB,CAAC,CAAC,AAC9B,GLxI6B,CKwIzB,CAAE,CAAC,IACT,EAAA,EAAA,EAAA,EAAuB,KAAA,EAAS,EAAO,IAAD,CAAM,CAAC,MACxC,GAAA,CAAA,GAAA,CAAA,GAEP,KAFuB,OACd,CAAA,GAAI,CAAC,C/FhQT,CG4DC,ACmEI,C2FkIV,SAGF,EAAO,E5KjJJ,A1FqDN,EAAA,CsQ4FgB,qBAME,CAAA,CAAA,mBAE5B,IAAA,KAAA,EAAA,WACuB,GKwKG,ILvKf,GAAG,CAAC,EACpB,CAAC,OACM,IAAA,CAAA,MAAA,CAAA,QACG,EAAA,EAAe,EAAA,GAAS,CAAC,AvD3JA,CrHSO,A4KkJN,AvD3JA,MuD4JzB,CAAC,EtC/GE,AzDlJR,A2B8FQ,AoEmKU,EpQjKJ,CAAA,CoQiKQ,MAGnC,SAiBQ,EAAA,CAAA,UACI,GAAA,AAAmD,YAAnD,OAAA,CAAA,CAAA,OAAA,QAAA,CAAmD,CAOzD,IAAM,CtC1GC,CAAA,IAAA,EAAA,SsC0GgE,EAAA,IAAiB,GAKlF,EAAA,OAAsD,MAAM,CAAC,CAAE,MAAM,EAAM,WAAO,CAAS,CAAE,CAAC,CAAC,CtQzEhE,EAAE,EsQyE0D,AtQzExD,MsQ8EtB,GAAA,CAAiD,CpQ1J/C,AwFcU,I4K6IP,aAAG,CzBlUC,AyBkUA,A/FhQQ,O+FiQL,CAAC,CtQ1ED,AsQ0EE,CAAA,0BAErB,oCAIqB,QAAQ,CAAC,EAAE,CAClC,AAAD,GAAc,EAAS,IAAI,EAAL,AAAO,CAChC,CAAC,G/FhQgB,mB+FkQA,I/FlQA,EAAA,Q+FmQX,IAAI,CKgKC,CL/JR,KAAO,C5K/IiB,A4K+If,MAAO,CAAC,CAAA,EACjB,GACQ,EAAM,KAAK,CAAG,EAAA,MAAiB,CpQjKH,AoQkKrB,CAD0B,QACX,MAAO,C3FxHV,CAAA,A2FwHqB,EAAM,CK8JH,IAAA,GAAA,EL5JpC,C5FjNX,EhFkEI,O4KqJpB,EAAA,MAAA,CAAA,aAGe,WAAa,CAAC,UAAY,GAAG,CAAC,AACrC,AAAC,KAAK,EAAE,EAAE,CAEE,EAAM,QAAA,CAAU,CAChB,C3F3Hb,CjFvBS,E4KkJU,EAAO,EAAA,QAAc,CAAC,E5KlJJ,AxFjBZ,EoQmKoB,GAChC,GAAI,CAAA,EAAA,IAAA,CACA,CvDnKH,CAAC,KAAA,YuDqKY,ELnIF,IKmIK,YAEN,CAAA,cACO,CzB/UF,CAAA,CAAA,KAAA,CAAA,MAAA,CyBgVZ,MAAA,eAA6B,CpP7DT,CyJzDH,EAAA,G2FsHuB,CAAC,EpQ5JU,AoQ4JJ,QAAQ,EAAE,CAAC,CAAE,AAEhE,CAFiE,EAEjE,KAAA,MAAc,EACd,EAAA,QAAc,C/FrQN,CAAA,C+FuQZ,GAAA,EAAA,SAAmB,CAAG,EAAY,G5FpNjB,CAAC,CAAC,C4FoNqB,CpQ5JrB,AoQ4JuB,CAAC,CpQ5JhC,AoQ4JsB,KACV,CAAW,CAAA,EAAO,MLjIE,AjQkEF,GsQ+DS,GAAG,CtQ/DL,AsQ+DM,AAClD,EAAA,GACI,EAAA,QAAA,AADwB,CACP,AADQ,CACE,CAAC,EzBjVH,AnJmMF,CmJnMG,A3NqRN,C2NrRO,AnJmMF,E4K8IS,CAAC,QAAQ,CAAC,EAAE,CAAC,GACG,GpQ3JlC,OoQ2J4C,AAAvC,OAAO,EAAW,MAAM,cAIzD,OAAS,EAAA,QAAc,EAAI,EAAM,KAAK,EAAI,EAAM,SAAS,CAAA,EAAe,MAAM,CAAE,QAEpF,CpPhDP,AlBZA,AsQ4DQ,EAGF,EA0BL,MAAO,EvDzLE,QAAA,euD6LQ,CAAA,CAAA,CAAA,CAAA,CAAA,CACf,KAAA,CACI,KAAO,WACQ,CAAA,MAAA,EpE9KkB,KAAA,EoE8KlB,EAAS,GAAT,CpE9KkB,CoE8KX,MAAE,AAAW,EAAC,AAAE,CAAD,AAAE,CAAC,EAAK,CAAC,CAAF,KAAQ,CAAC,QAAQ,CAAC,EAAE,CAAC,CAAC,AAAE,CAAD,AAAE,EAAS,EAAK,CAAC,CAAF,EAAL,GAAa,CAAC,QAAQ,CAAC,EAAE,CAAC,SAC3F,oBAGQ,cACG,CAAA,GAAI,C5K3JT,AmJ/MM,ClE2PH,A2F+GQ,A5K3JV,AmJ/MM,WyB2WF,GAEZ,EAAM,SAAS,CAAA,MAAO,CAAA,GAAA,KAEnB,EAAA,EADiB,SAAS,CAAC,EAAM,E3F7Gb,O2F6GsB,CAAC,MAAM,CAAG,CAAC,CAAC,CAAC,AACvD,I3F9GiD,A2F8GjD,C3F9GkD,Y2F+G3C,CAIT,CAJW,C5KjJf,iB4KoJoB,IAAI,CAAC,EAAS,CpPtDd,CoPsDmB,KAAK,CAAC,CAAC,MAAM,CAAC,QAAQ,CAAC,EAAE,CAAC,CAAC,AACvD,cAHS,GAAG,EAAE,CAAC,WAWjC,CzB5WR,SAAA,KyB6WS,EAAW,OACN,IAAA,CAAK,OAAA,uBACW,CAAC,EAAS,KAAK,CAAC,cAE1B,KAAA,CAAA,MAAY,EAAG,GAE5B,CAAC,CLxIC,MAAA,QAAA,CAAA,CAAA,IKwIuB,MpQjKR,EoQiKgB,ApQjKd,CAAC,CyQmSe,sPI93BZ,6CTqwBnC,GAAiB,IAAA,CAAA,GAAA,CAAA,CAAA,iBAK6B,G5FzOtB,c4F0OI,CAAC,CAAC,EAAA,IAAS,CAAC,CAAA,EAAM,CAAC,ApQ1JR,CoQ0JS,ApQ1JR,CoQ0JS,CAM7B,C5KnIjB,CAAC,CAAC,OAAA,C4KmID,E5K3IE,OAAA,CAAA,S4K4IS,EAAO,MAAM,CAAC,CAAA,EAAI,CAAC,EAAE,CAAA,CAAE,AKiIA,CLjIK,EAAG,CAAC,CAAC,CAAC,C5KxII,EAAE,EAAE,wB4K+InC,MAAA,CAAO,CAAA,EAAI,IAAM,KAAA,GAAQ,CAAA,EAAA,GAC3C,CAAC,AzBxWA,A3C+LA,QoE8KD,SAAoB,CAAA,SACT,EAAO,MAAM,CAAC,CAAA,EAAA,IAAU,KAAA,GAAA,CAAA,EAAY,CAAC,CAAC,CAAC,CAAC,CpQxJ9B,I6Q/nBb,IAAA,CAAA,GAAA,CAAA,CAAA,4KAmCL,IAAA,EAAA,eA2CD,SAAA,EAAA,CAAA,CAAA,CAAA,yBACoD,CAAA,EAAS,GrLgFxC,MAAA,CAAA,IqLhFsD,CrLiF3E,AqLjF4E,CAAC,E9DE7C,8EcrJyB,CCO3D,ACJ4D,CAAC,KFHQ,CAAA,KAAA,CAAA,SAAA,CAAA,CAAA,CAAqB,OAAO,CAAC,CAAC,K9BMK,CAAC,A+BIlF,EACvB,gCAAgC,EAEnC,MAAM,YAAY,CAAA,0E2CkGZ,EAAA,qGA0EA,EAAoB,+JAuEpB,IAAA,EAAA,6BAwBA,EAAA,gBAYA,EAAA,mCAkCA,EAAA,qDAYA,IAAA,EAAA,gBAYA,EAAA,aAcA,EAAA,aAYA,EAAA,gBAgBA,EAAA,uDAaA,IAAA,EAAA,+CAeA,IAAA,GAAA,gBAYM,GAAA,wBAgBP,SAAA,GAAA,CAAA,SACK,GAAA,UAAA,CAAA,EAAA,IAQJ,IAAA,GAAA,2BAEwB,CAAa,CHzNR,AzPoFJ,AbxHF,2ByQ+P9B,CAAC,AASM,IAAA,GAAA,0BAEmC,mHAiCnC,IAAM,GAAY,YAYZ,GAAA,8BAGF,GAAA,UAAA,CAAA,EAAA,IASJ,IAAA,GAAA,mDAIP,CAAC,AAOM,IAAA,GAAA,eAWA,GAAA,aAYA,GAAA,WAED,SAAA,GAAA,CAAA,sBAC0B,CAAA,EAAA,GAChC,CrDrVC,AqDqVA,AAOM,IAAA,GAAA,0CAsBA,GAAA,mBAED,SAAA,GAAA,CAAA,YACgB,UAAA,CAAA,EAAA,QAQT,GAAA,iBAEP,SAAA,GAAA,CAAA,YACgB,UAAA,CAAA,EAAA,GACtB,CAAC,AAOM,IAAA,GAAmB,aAUnB,GAAiB,C5PtPH,AkP5CI,A/ObN,AiMjCM,SwDuYnB,OAAA,WAAA,2BAGyC,EAAc,GxDpYG,AwDoYK,GAAc,IAAyB,GAAY,AxDpYT,EwDoYyB,GAAgB,EAAW,EAAa,GAAgB,EAA1D,AAA2B,AAA4C,EAAvD,CAAkE,CAA1C,CAAmD,EAAe,EAAlD,AAAa,AAAW,CAAS,AAAwB,EAAF,AAAgB,EAAW,GAAS,CAA3C,CAA0D,EAA1B,AAAS,CAApB,AAAmD,EAAU,EAAe,EAAW,EAAoB,AAAxE,AAAwB,CAAV,CAAsE,EAAe,CAAjD,EAAX,AAAwE,EAAY,CAAzC,EAAmD,EAAxB,AAAoC,CAAhD,CAA+D,AAA1F,CAAmD,AAAU,EAAmD,GAAe,AAAtD,EAAoE,GAArD,AAAuE,EAAM,EAAF,CAAtC,AAAuD,EAAgB,AAAzD,EAA7B,CAAiG,GAAgB,AAAlE,EAAqB,CAA2B,AAA8B,EAAc,CAAvD,EAAgE,CAAC,AAGxlB,CAH8jB,A3C3ShlB,C2C2SokB,A3Q1UnkB,E2Q0UumB,EAAV,W3Q1U7lB,CAAA,C2Q6UmD,CAAiB,CVxVlC,wBU2VvB,gDAMA,wBAGA,0DAOM,IAAI,CAAA,SAAA,CAAW,EIvdW,AJudM,GzPlVL,CAAC,gCyPuVvB,SAAS,CAAA,EAAe,CN1LH,qDMgMX,EAAgB,EVvVE,AjQuBA,e2QmUjC,IAAA,CAAA,SAAA,CAAA,EAAA,IAAwC,GzExXG,AwC7EA,CiCqcC,CAAC,SAAA,CAAA,EAAA,+EAWpD,OAAA,IAAW,CAAC,SAAA,CAAU,C9BheC,CAAA,U8BmevB,OAAA,IAAA,CAAA,SAAA,CAAA,EAAA,IAAkD,IAAI,CAAC,CzE5WC,CAAC,CAAA,MyE4WO,CAAC,EAAc,SAAS,CAAX,AAAY,CAAC,0FAYpD,CAAA,CAAA,EAAA,EAAY,QAAQ,CAAA,CAAE,CAAC,mJAS5D,ClIjUH,AsEpCI,kP4DqXQ,EjLxUF,IAAA,CAAA,EiLwUW,CzQxVe,A2O1Id,C8BkeU,KzPnSE,wBAAA,CyPmS6B,CAAC,AzPnSJ,CyPmSK,AzPnSJ,CAAC,0ByPyS5D,iBAGI,CjG5WD,IiG4WO,cAEF,4EASE,KAAA,WAAkB,C3QtRP,Y2QsRqB,EAAE,CAAE,CACzC,OAGJ,QACM,CzQjVP,A2O3IQ,AHoBA,kBiC0cQ,CL/KjB,mBKgL8B,CAAE,CAC1B,eAIE,CjCzcC,AxNoLF,mByPwRE,CAAE,KAAA,qBAA4B,CAAK,C3QxQhD,A2QwQkD,CACxC,eAIE,qBAGG,KAAM,QACR,CAAE,KAAA,wBAKH,EjG7WJ,kBiGgXK,C3CvRC,W2CuRa,EACd,ChG3SH,AkElLI,K8B6dO,CjG9WL,CxKmCC,CAAC,AoQmKM,aK4KlB,SAEG,C3QlQD,I2QkQO,CzE3UC,AwChIA,CGnBC,CAAC,W8BgeL,MAAQ,sBAAuB,IhGpSrB,SAAA,CAAA,CgGoSwC,CAAE,EhGnS9D,AgExDgE,AgC4VpD,KAAA,eAAsB,C3Q9PzB,Y2Q8PuC,EAAE,CAAE,C3Q7PjD,AiQxCkD,CUsSzC,KAAA,uBAA+B,EAAE,CAAE,iCACD,CzQxUP,CyQwUS,CAAE,CACxC,mBAAsB,YAAY,EAAE,CAAK,CAAE,GAAF,QjLxTK,kBiL0T7B,aAAc,EAAA,QACvB,QAAS,CjLxTL,YAAA,EAAA,QiLyTJ,CjLxTL,2BiLwTmC,EAAE,iBAKzC,0BAGS,eAIf,2BAGe,EACN,CzEvUC,A+DoCA,I/DpCA,MyEuUW,CAAE,I3QjPE,+B2QwPV,oBACc,SzQ7T6B,IyQ6Tf,EAAE,CAAE,eAExC,MAAQ,aAAc,aAAc,EAAE,CAAE,EzPvOF,iCyP8O9B,CACR,CAAE,KAAA,eAAsB,aAAA,CAAA,GACxB,CAAE,CjL9SL,IAAA,WiL8SsB,CAAE,EACnB,KAAA,kBAKV,MAAA,QAEI,WAAA,+BAMG,C3QpOH,gC2QuOmB,CAAE,AzQxThB,CyQyTJ,eAIE,CACH,ChGjRT,IAAA,agGkRqB,CACR,qBAIP,cAES,wCAMT,C3QvND,C+M1GG,A4DkUH,MAAA,CACI,C5DjUC,IAAA,a4DkUW,CACR,CAAE,KAAM,YACR,4BAA+B,cAAc,CAAK,CAAE,EAClD,EjGhXgD,CAAC,CAAC,CiGgXlD,AjGhXmD,eiGiXnD,CLvItB,IAAA,sBKuImD,CjLlSI,EAAE,AiLmSrC,CAAE,CADkC,A5DjUA,CrC7CxC,AxK6DE,AyK6DM,GAAA,WgGqPgB,cAAc,CAAK,CAAE,sBACjB,aAAA,EAAgB,QAChC,gBACR,CzQlTP,AwFmBE,A4K2JU,AKoIH,KAAM,QACR,CjG/WL,AwB6DM,KyEkTO,aAAc,aAAc,EAAE,CAAE,CVnRC,AUoRzC,CAAE,KAAM,cACR,+BAAkC,GACrC,EAD0C,aAKxC,MACG,mCAEqB,CAAE,CAC5B,CAGT,ALvIgB,ApQlKW,CAAC,CAAC,CwFWW,GiL8RxC,6BAIc,KAAM,6BAMN,aACM,CACR,CjGlXL,KiGkXa,CpG5ZH,C+F0RK,EAAE,WKkIW,CAAE,AjGjXvB,CiGkXF,MAAQ,CV1QC,CAAC,UU0QU,CAAE,CACtB,CAAE,C9B7eC,IAAA,W8B8eN,gBAKD,CpG5ZL,A+FyTd,CvDxNqB,G4D2TI,aACM,CACR,CAAE,CjLhRO,IiLgRP,SACL,eAIE,MACG,aACM,EACN,C9BzeW,I8ByeL,cACR,C5DvTC,AbcA,AyEySC,IAAI,CAAE,WAAY,cAAc,CAAK,CAAE,GAAF,2BACP,GAChC,CAAE,CADmC,IACnC,QACF,MAAQ,CzQ1RT,CgBsGK,IyPoLU,CAAE,CACnB,gBAKD,KAAM,0BAEY,GACZ,KAAM,MAAM,C9B1eE,A8B0eA,C9B1eC,CAAC,A8B8e9B,MAAK,SACM,MACG,GACN,CjL9PD,UAAA,uBiLgQK,CzQtRX,AwFyBQ,AiL6PK,IAAI,CAAE,aAAc,C9B3eC,W8B2eW,CAAE,EAAK,CAAE,CAC3C,CADyC,AACvC,CzExSC,IAAA,SyEySD,KAAM,QACX,CAGT,MAAK,GACD,MAAO,oBAES,CACR,CAAE,KAAM,QAAS,aAAc,EAAE,CAAE,EAI/C,MAAK,eAES,IzErSI,WyEuSN,qBACA,CAAE,KAAM,GzEnSG,MyEmSM,CAAE,CzEnSC,AyEoSpB,CzEpSqB,AyEoSnB,CzEpSmB,AxG2C5B,IiLyPe,cAAc,CAAE,CACxB,iBAAmB,CAAE,CACrB,IjL1PgB,EiL0PR,UAAU,CAAE,CACpB,CAAE,KAAM,AjL1PS,QiL2PpB,UAIL,MAAO,CACH,KAAA,qBAEY,eACR,CjLvPH,KiLuPW,GjLvPD,qBiLuP2B,EAAE,CAAE,CACtC,MAAQ,WAAW,CAAE,CACxB,CAGT,MAAK,GACD,MAAA,SAEI,GzE7RG,ChMwBL,AqK3IE,A2BmHG,E3BnHD,KoGgZU,CACR,KzQtQQ,gByQuQR,CAAE,KAAM,SAAS,CAAE,CACnB,iBAAmB,CAAE,CACrB,CAAE,KAAM,UAAU,EAClB,CAAE,KAAM,UAAU,EACrB,OAGJ,EzQrQF,OyQsQQ,oBAES,CACR,MAAQ,aAAa,CAAE,CACvB,CAAE,KAAM,MAAM,EACd,CAAE,IAAI,CAAE,WAAW,GACjB,IAAI,CAAE,OAAO,CAAE,CACpB,AzQ5PiB,CAAC,SyQgQvB,MAAO,CACH,KAAA,GACA,WAAA,CACI,CAAE,KAAM,aAAa,CAAE,CACvB,CAAE,IAAI,CAAE,C9BneC,kB8BmemB,cAAc,CAAK,EAC/C,EAD+C,IACvC,WAAW,CAAE,CACrB,CAAE,KAAM,CjLzPP,SiLyPiB,CjLzPN,AiLyPQ,CACpB,CAAE,KAAM,MAAM,CAAE,CACnB,CAGT,MAAA,GACI,MAAA,CACI,KAAM,GpGhZL,AoGiZD,WAAY,EACN,KAAM,eACR,CAAE,IAAI,CAAA,WAAa,CAAE,WAK7B,MAAO,CzQ/OO,AyQgPV,IAAI,CAAA,GACJ,WAAY,CACR,CAAE,IAAI,CAAE,GjLjPQ,CAAC,SiLiPI,CAAE,CACvB,CAAE,EpGhZN,CAAC,CoGgZS,CAAE,UAAU,CAAE,YAAY,CAAE,EAAE,CAAE,CACtC,CAAE,EjL/ON,EiL+OU,CAAE,KjLhP6B,WiLgPb,CAAE,CAC1B,CAAE,IAAI,CAAE,WAAW,CAAE,CACxB,EjLhPmB,KiLmPvB,EzQvOQ,CyQwOT,MAAO,CACH,KpG/YK,AoG+YC,GACN,CjL9OP,E6E/JkB,ArK8Kd,CyQ8NgB,OACD,CACR,CAAE,KAAM,EzQ/NJ,WyQ+NiB,CAAE,CzQ/NL,AwFfF,AiL+OhB,CAAE,IAAI,CAAE,MjLjP6B,IAGzB,GiL+OZ,CAAE,IAAI,AzQ/NN,CyQ+NQ,OAAO,CAAE,CACpB,CpG7YL,CrK8KC,KyQkOA,GACD,CzQhOD,KyQgOQ,CACH,KAAM,CpG7YP,CAAC,CoG8YA,CzQtNO,UyQsNK,EACN,IAAI,CAAE,GzQlND,CAAC,CAAC,KwFxBG,GiL0OS,CAAE,CACvB,CAAE,IAAI,CAAA,WAAa,CAAE,CACrB,gBAAkB,CAAE,CACvB,MjLzOI,CiL4OR,GACD,MAAO,CACH,KAAM,gBAEA,EjLxOV,AxFgCQ,GyQwMQ,aAAa,CAAE,CACvB,CAAE,KjLzOgB,AiLyOV,GzQxMH,CAAC,GqKlMG,IoG0YU,CAAE,CACrB,CAAE,IAAI,CAAE,OAAO,CAAE,WAKzB,MAAO,CACH,KAAM,GACN,WAAY,CACR,CAAE,GjLzOH,EiLyOG,YAAmB,YAAY,CAAE,EAAE,CAAE,CACvC,CAAE,KAAA,aAAmB,CAAE,CACvB,CzQ3LH,AyQ2LK,KAAA,WAAiB,CAAE,AzQ3LJ,CAAC,CAAC,AyQ4LjB,CpGzYP,IoGyYa,GzQ3LD,CAAC,CAAC,KwF7Ca,KiL4O7B,GACD,MAAA,CACI,KAAM,GACN,WAAY,EACN,IAAI,CAAE,IpGzYR,CAAC,QoGyYoB,CAAE,CACvB,CAAE,IAAI,CAAE,UAAU,CjLrOC,aiLqOe,EAAE,GAClC,KAAM,WAAW,EACtB,CAGT,CjLpOS,KiLoOJ,UAEG,IAAI,CAAE,GACN,KjL9NU,MiL8NE,CACR,CjL7NL,AiL6NO,KAAM,GjL7NH,UiL6NgB,CAAE,CACvB,CAAE,GjL7NL,EAAA,WiL6NuB,YAAY,CAAE,EAAE,CAAE,CACtC,CAAE,EjL9NgC,EiL8N5B,CAAE,OjL7ND,IiL6NY,CAAE,CACxB,CAGT,MAAK,CjL7NP,QiL8Na,CjL7NP,AiL8NI,IAAI,CAAE,GACN,WAAY,CACR,CAFkB,AAEhB,IAAI,CpGzYG,AoGyYD,CpGzYE,CAAC,WoGyYU,CAAE,CACvB,CAAE,IAAI,CjL9NP,AiL8NS,WAAW,CAAE,CjL9NP,AiL+Nd,CjL/Ne,AiL+Nb,IAAI,CAAE,AjL9NX,MiL8NiB,CAAE,CACnB,CAGT,MAAK,GACD,MAAO,MACG,ajL7NC,CiL6Na,AACR,CACR,CAAE,IAAI,CAAE,aAAa,CAAE,CACvB,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,EAAE,CAAE,CACtC,CAAE,IAAI,CAAE,WAAW,CAAE,CACxB,OAGJ,EjL5NJ,CiL6NG,MAAO,CACH,IAAI,CpGvYL,GoGwYC,KpGvYD,KoGuYW,CAAE,CACR,CAAE,EpGvYN,CAAC,CoGuYS,CAAE,aAAa,CAAE,CACvB,CAAE,IAAI,CAAE,WAAW,EACnB,CAAE,CpGvYP,CAAC,EoGuYU,CAAE,UAAU,CAAE,CACvB,OAGJ,GACD,MAAO,CACH,KAAM,GACN,CjLvND,UiLuNa,CjLvND,AiLwNP,CAAE,CjLxNO,A6E9Kd,IoGsYa,aAAa,CAAE,CACvB,CAAE,CjLxNoB,GiLwNhB,CAAE,EjLtNF,SiLsNa,CAAE,CACxB,CAGT,SACI,MAAO,MACG,EACN,WAAY,EAAE,CAG1B,CAAC,AACL,CAAC,CjLrNC,AiLsNL,AAEM,IAAM,GAAa,IAAI,iKMrmCnB,0DAUA,CACX,CtLyGC,AsLzGA,AzLyBA,AyLZK,SAAA,GAAyB,CAAA,CAAA,CAAA,qEAIb,EAAS,KAAK,CAAC,OAEtB,IAAA,EAAA,IAAA,CAAA,6CAIN,EAAA,2DAEiD,CAAC,CAAC,CpGmBnB,A8FsLoB,CAAC,AnGlIf,CyGtE3B,CAAA,EAAA,UAAA,CAAA,KAAA,eAEI,EAAA,mCAGa,KAAA,CAAA,+DAGyB,EAAA,QAEb,gBAAA,UACK,GAAiB,EAAS,C9DsFC,CAAC,EAAE,C8DtFC,CAAC,AT+FG,CAAC,CS/FF,CAAC,yIAqBtE,EAAA,EAAA,GAAA,GAAA,EAAkD,gDAUzC,KAAA,AAAK,CT6FiD,EAAA,CS7F5C,GAAiB,CtC2GoC,CsC3G9B,EAAF,AAAU,KAAK,CAAC,EAAE,CAAC,SAEvD,EAAA,EAAA,IAAA,EAAA,aAHD,MAAA,wDAK+C,CzGyHhD,EAAA,CyGzH4D,aAAa,CAAI,CAAE,CAAC,AACjG,CAD8F,AAAI,AACjG,SAEQ,GAAA,CAAA,CAAA,CAAA,gDAI6B,CjDuJO,CtIpEP,A8KU8B,AGkPtB,KAAA,EAAA,EM/UN,KAAK,CAAC,ClEmG+B,CAAC,SgElKpE,gDAnB2C,CnG0EL,AiE/EpB,GkCK6B,CvGwDD,EAAA,EuGxDS,ErGiDJ,AoCmIuB,AZzHjB,G6E3DG,CAAC,IAAA,EAAQ,CP+F/B,CAAC,A7F/BzB,AoGhE6D,GAAG,CAAC,ClCL7D,A/ByL+E,QiEpLT,EAAI,EAAE,AAAC,KAAK,CAAC,SAAS,CAAC,CAAE,CAAC,0DAErD,EAAE,GAAA,CAAK,IAAI,CvG2D7D,CAAC,EuG3DsE,C5DyFb,I4DzFkB,CAAC,SAAS,EAAI,EAAE,AAAC,GAAG,CAAC,CvG2D7D,QuG3DsE,CAAC,AvG4D1H,CuG5D4H,CAAC,aAC/F,eAEA,E9C4FE,EAAA,CAAA,EAAA,KAAA,C8C5Fc,IAAA,EAAA,EAAe,CtCuEC,IAAA,CsCvEK,IAAI,GAAA,EAAQ,KAAA,CAAM,IAAI,EAAI,EAAM,KAAA,CAAM,SAAS,EAAI,EAAG,KAAK,CAAC,SAAS,CAAC,CAAC,0BACnF,C7QmCI,EAAA,C6QnCA,IAAI,GAAA,EAAA,GAAW,CAAA,IAAK,EAAI,EAAM,GAAA,CAAI,SAAS,EAAA,EAAO,GAAG,CAAC,SAAS,aAEjH,GAAA,MAAA,kBAGJ,sCAS6B,KAAA,CEyElC,SAAA,GAAA,CAAA,SAEK,IAAA,EAAA,IAAA,CAAA,wDAKI,EAAA,QAAA,CAAA,EAAA,IAAA,CAAA,MAAkC,EAAE,CAAC,AjD2JA,wBiD1JG,kBAClB,KAAM,CAAC,UACoB,C/QsE/B,A+QtEgC,2CAGhB,CNkXC,YMlXmB,E/E4EF,Q+E5Ea,IAAI,OAAE,CAAQ,CAAE,CAAE,CAAC,GACxE,MAAM,OAAA,CAAA,GAAgB,6BACW,CjRyIT,AiRzIU,MACvB,EAAM,UAAA,GACd,EAAU,CAAA,CAAM,EAAA,eAEX,CADe,ArByBd,A3CnBA,A8DVE,AnQsEJ,cqQjEuB,WAAa,C7PgFH,CAAC,A6PhFW,C7PgFV,I6PhFQ,KAAa,IAAI,OAAE,EjR2ItC,MiR3IgD,gBAGtE,CAAG,CAAC,AhFsBE,IgFnBxB,QAAA,oCtQ3MT,CCGG,CAAA,UDHY,CAAA,+WqEAnB,IAAA,EAAA,GAAA,KAAA,GAAA,GAAA,KAAA,+CAKA,IAAA,EAAA,GAAA,KAAA,GAAA,GAAA,KAAA,kOA6BA,qBAEA,oEuFPkB,8tBAqE2B,CAAC,SAAS,CAAC,IAAA,CAAA,GAAQ,CAAC,cAG1D,6FAWO,WAAA,sGAOe,MAAA,UAAsB,CAAC,GAAG,CAAC,C0BAK,CAAC,+B1BK7C,CAAA,GAAA,2BAGN,CAAA,IAAA,CAAM,IAAA,mDAGwC,mKAiBtC,wCAGiB,IAAA,CAAA,GAAA,CAAA,kDAKtB,2KAcM,SAGL,CAAA,OAAA,oEAUZ,IAAM,EAAA,IAAA,CAAA,WAA8B,oDAO7B,IAAA,CAAA,GAAA,CAAA,WAIJ,kCAOW,CAAC,GAAA,oDAKL,sBAKR,QAAA,uEAWc,IAAI,CAAA,oBAAA,+CAKd,OAAQ,iBAOR,iBAAA,CAFkB,kBAIR,wDAQP,WAAA,CAAY,SAKE,YAAkB,IAAV,OAAqB,6CAe7B,KAAK,MAArB,CsE1CO,OtE0CC,CAAC,CqFNO,AmB7BA,AxGmCN,wEAQb,GAAA,CAAA,IAAA,CAAA,GAAA,CAAA,iDAQa,4DAKK,CnJ6FO,CmJ7FL,CAAC,C9BmFG,e8BhFrB,IAAA,CAAK,cAAA,aAET,UACQ,CAAA,KAAA,UAIX,KAAA,IAAA,GAAA,IAAA,CAAA,kBAAA,IAAiD,GAC5C,IAAA,CAAA,gBAAA,EAAA,8EAQ4B,EAAA,CAAE,AvKuHI,mFuKxG9B,eAAiB,GAAA,uBAA2B,C0CvCO,sC1C4C/C,C0FsFK,S1FpFV,CAAA,QAAS,oEASnB,IAAA,eACa,CAAC,iBAAiB,+CAM1B,WACI,IAAA,CAAA,oBAAA,EACT,KAAA,QACK,QACA,oBAGH,OAAA,IAAA,CAAA,iBAAA,WAEA,EwG1CU,KxG0CH,IAAA,CAAA,uBAAA,OACJ,mGAKS,+BAA+B,EAC7C,uCACgC,CrJgJG,GqJ5I7B,C7EsGT,CAAC,AmJxJE,iBAAA,OtEqDK,CAAE,E7EsGI,AiFmBO,GAAA,qBJzHiB,OAAO,GAF1B,AGkEyB,CHlEzB,eAAA,GAGpB,CAAC,AwCkGE,qDxC7FmB,QACb,mBAGA,CoG2aO,6BpGtaJ,aAEH,4BAKH,CI+HO,AuBjDI,CxG+BF,AiFkBD,CJ/HL,A7E6GM,AxE6CF,YqJxJJ,C7E8GO,K6E7GJ,C+FiQgC,qB/F1P/B,C7E8GG,IAAA,M6E9GU,MAAA,EAAY,CvKmKG,UuKnKS,CrK6FD,EqK1FxC,0CAKK,CAAA,OAAQ,QACb,yBAGA,MACU,GAAG,C+FiQS,CAAC,CAAC,C/FjQP,kBAGP,C+FiQS,C5KlJL,A4KkJM,A/FjQR,AG2DA,C4FsMQ,gB/F/PpB,MACU,CoGyaS,EAAA,2CpGhajB,CAAE,EyDsJQ,AUzLA,GnEmCF,EsEzDU,UtEyDG,MAAO,CAAU,EAGxC,oCAIF,WAAA,CAAA,gBACe,OAAA,cACmB,8CAKhC,wBADY,CACgB,AGuDnB,CHxDU,CwCyGA,CAAC,ExCzGF,ArKoGJ,KyKuC0B,AJ1IF,EADR,CrKoGH,EqKpGM,EvK8KM,QuK9KI,CAAC,GAAK,EACX,CI0II,AJ1IF,CAAC,CI0IG,yBJpInD,IAAA,CAAA,WAAA,CAAA,KACO,MAAQ,kBAAoB,GAAG,KAAK,0BAK3C,uBADgB,CAAA,KACT,IAAA,CAAA,cAAmB,CAAC,sFAKA,EAC7B,C2B6FG,A3B7FF,AsElEE,4BtEwEQ,KAAA,kBAA0B,CsErEK,ctEoER,GACkB,CAAE,AACtD,CADuD,AACtD,wDAKQ,+BAMA,0BAKH,MAAM,CvK6LK,KAAA,2BuK1LI,kBAAoB,CI2ID,CJ3IG,CAAC,AADhC,IAAA,CAAgB,GsExEa,CAAC,AnE0HL,GHlDF,GACkB,CAAE,ArKoGN,CqKpGO,AAExD,C0FmIG,A1FnIF,qBAGO,EAA0B,EAAA,cAE5B,CAAC,WAAW,CAAA,KACZ,MAAA,IAAA,CAAA,QAAA,CAAA,UACG,C7EqHK,U6ErHM,CAAC,CrJ2MC,IqJ1MlB,EAAA,CAAA,GAGK,IAAA,CAAA,WAAA,IAAoB,OACZ,CvKsMG,C+MvGK,EAAA,CAAA,SxC/FM,MACrB,EAAwB,IAAA,KAAS,sBACM,iBAC3B,CAAC,CG+CC,AxJgKI,QqJ9MhB,CvKuMC,CuKvMI,IAAI,CAAA,SAAU,EAAE,CAAC,AoG+ZQ,CzQnTb,EqK3GA,EAAG,IAAI,KAAK,CG+CC,EH3ClC,GAAI,EAAG,CrKwG2B,CAAC,CqK5GS,CAAC,CAItC,CAAQ,EAAK,C2B0GQ,CxGcF,G6ExHD,EAAE,CIyJW,UJxJxB,2CAEV,C0FoIW,G1FpIP,CAAA,CAAG,KAAM,EAAA,KAAU,CG+CK,GH/CC,EAAG,KAAK,CAAE,CAAC,CAAC,KAG7C,GAAA,EAAA,KAAA,CAAA,KACI,IAAI,CAAC,CoG+ZW,AjG/WN,CHhDH,CAAA,gBACS,CAAA,mDASnB,CAAE,KAAA,iBAAyB,QAAmB,2BAIxC,QAAQ,CoG6ZK,ALnII,C/F1RP,AwC6FI,A4DgUA,EpG3ZzB,IAAA,iBAIK,2CAKS,WACT,YACI,IAAA,CAAA,WAAA,WAEP,C+F2RS,M/F3RF,IAAA,CAAK,CsEhFS,wBtEgFgB,GAE3C,CAAC,CIuLG,oCJpLc,CAAC,ErJoOI,SqJnOR,QAAA,YAKT,OADA,IAAI,CAAA,WAAA,CAAa,KACV,CAAE,C2B8GS,I3B9GH,YAAa,MAAO,EAAE,CAAC,QAAQ,ArK0HH,CAAC,AqK1HG,UAE5C,QACA,QACA,QACA,QACA,WACI,C7E8IC,G6E9IG,CAAC,oBAAoB,EAAE,CAAC,IAChC,wBAGA,yCAE0B,CoG4ZS,CpG5ZP,AGmDI,CHnDH,CrKkIC,OqKhIjC,OAAO,IAAA,CAAK,uBAAuB,EACrC,KAAK,WACI,IAAI,CAAA,gBAAiB,C7EoJD,C6EpJG,CAAC,IAC5B,eACQ,CAAC,qBAAA,OACT,CrJyOK,GqJxOR,OAAA,IAAA,CAAY,+BAA+B,EAAE,CAAC,QAE9C,G7EuJK,IAAA,IAAA,CAAA,kB6EvJyB,YAKlC,IAAA,EAAA,CAAA,MACI,CAAA,WAAA,CAAA,wBACiB,CAAC,CAAC,CAAC,kBAEJ,CAAC,KACjB,IAAA,CAAA,WAAgB,CAAA,KAChB,EAAA,CAAA,QAGK,QAAQ,OAGX,EAAQ,IAAI,CAAC,C7E+JG,CAAC,CmJ/OG,QtEgFI,GAC9B,IAAA,CAAA,WAAA,CAAiB,SAEX,C2BkHK,C3BlH0B,CACnC,KAAA,oBAEA,MAAA,GAOF,OAJI,MACO,C7E+JK,E6E/JC,CAAG,CADL,C7EgKW,E6E/JF,CAAA,QAAA,AAAS,CAAC,C7E+JK,A6E5JhC,CACT,CAAC,E2B8G8C,AhL6HJ,gBqJxOzC,IAAI,EAAS,C2BoHK,G3BpHD,CAAC,OAAO,C2BoHsC,CAAA,AhMsBxC,AqK1II,CAAC,IAIc,KAAK,EAAtB,AAAwB,IAApB,CAAC,C2BmHK,CAAC,CAAA,G3BnHA,GAC5B,MAAA,qCAGD,GAAA,IAAA,CAAA,IAAA,CAAA,QAAiC,CAAC,CAAC,CAAC,CAAC,CAAE,IAClC,IAAI,CAAA,OAAQ,UAGjB,IsEvFQ,KtEuFC,CrKwID,CqKxIS,EAAE,EAGlB,CsExFP,CAAC,CAAC,mBtEwFyB,CAC5B,IAAA,EAAa,C7E4JK,G6E5JD,CAAC,OAAA,GAClB,GAAA,AAAoC,KAApC,GAAA,IAAuB,CAAA,+CAID,IAAA,CAAA,IAAA,CAAU,QAAQ,CAAC,CAAC,A7E2JA,G6E3JI,CAC5C,GAAU,IAAI,CAAC,OAAA,UAGV,SAAS,EAAQ,GAC1B,CAAC,mBAGC,IAAM,E7EuJM,I6EvJS,CAAC,OAAO,EAAE,CAAC,OACxB,OAED,KAEL,IAAA,SAEK,aAEA,SAEL,IAAK,E7EsJQ,E6EpJb,ErK4II,EAAA,IqK1IJ,IAAK,SAEA,GAAG,KAEH,CoGgZO,EpGhZJ,CAAC,YAIJ,IAEL,GsEnFS,CtEmFJ,GAAG,CAAC,AAET,IAAK,QAEA,GAAG,CAAC,AAET,G7EyJO,CAAA,I6EvJL,MAAM,ErKsJM,EyQ0PM,EpGhZN,CoGgZS,IpGhZJ,CAAC,AACpB,CADqB,GrKsJO,CAAC,IqKpJ3B,MAAO,CAAE,KAAM,kBAAoB,EAAE,CAAC,EAAS,CAAE,CAAC,AAExD,CAAC,cACqB,CACpB,GrK+Ja,IqK/JL,IAAI,CAAA,QAAS,CAAC,CAAC,CAAC,EAAE,AACxB,IAAK,CoGgZO,GpG/YZ,CoGgZO,GAAA,IpG/YP,IAAK,GAAG,CAAC,AACT,CoG+YgB,GpG/YX,IACL,IAAK,IACH,CrKwKG,MqKxKI,IAAI,C7EgKO,A6EhKN,KAEZ,G7EgKK,I6EhKE,EACV,CAGO,aAAA,CACR,CrKuKC,AwFPA,CxFOC,AwFPA,I6EhKyB,A7EgKzB,G6EhK4B,G7EgK5B,IAAA,C6EhKU,QAAQ,IAAc,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,oBAIhC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,CAC7C,AAD8C,CAAC,AAC9C,AAES,YAAA,EAAsB,CAAC,CAAA,CoG6YL,ApG5Y1B,OAAA,IAAY,CAAA,QAAS,CAAC,IACpB,IAAK,QACA,ErK8KE,OqK7KF,sBAEA,SACH,OAAO,CACT,E7EkKI,E6EnKU,A7EiKI,K6E/JhB,OAAO,CoG6YS,CpG3YtB,CAAC,gBAGQ,IAAI,CAAC,MAAA,IAAA,IAAgB,CAAC,KoG4YS,MpG5YE,EAAE,CAGlC,AAHmC,QAG7B,E7EkKP,M6EjKC,CAAC,E7EkKA,gBAAA,I6ElKsB,MACtB,E7EiK4B,A6E9JrC,OAAQ,IAAA,CAAK,QAAQ,CAAC,IACpB,IAAK,QACA,aAGL,IAAK,GAAG,CACN,CoG0YS,AzQhMM,MqK1MR,UAEP,MAAO,GAEb,CAAC,cAGC,OAAQ,IAAA,CAAK,QAAQ,CAAC,CAAC,GACrB,IAAA,IACA,IAAK,GAAG,CACN,OAAO,kBAGC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,AACxB,IAAK,GAAG,CAAC,AACT,IAAK,ErK1oBG,AAAmB,CqK0oBnB,ArK1oBoB,CqK2oB1B,OAAO,IAAI,CAAC,YAEL,EAGb,IAAK,GAAG,MrKnpBuE,CqKqpBtD,G7EuKe,A6EvKZ,GAAxB,CACA,GADI,CAAC,I7EuKgB,I6EvKR,CAAC,CAAC,CAAC,C7EuKa,E6EtKP,GAAG,GAAxB,IAAI,CAAC,E7EwKU,M6ExKF,CAAC,CAAC,C7EwKS,A6ExKR,EAAiC,MAArB,E7EyKtB,EAAA,CAAA,QAAA,C6EzKoC,C7E0KtC,A6E1KuC,CAAC,AAAK,C7E0K3C,A6E1K8C,CAAC,iBAK9D,CAAC,AAES,cAAA,KACF,EAAA,IAAA,CAAiB,SAAS,EAAE,AoGsYI,CpGtYH,AACnC,GAAI,CACF,OAAA,KAAiC,IAAjC,IAAW,CAAC,AAA8B,CAAC,E7EyKhC,O6EzKW,EAAC,GACxB,AAAC,CAD2B,KACpB,CAAC,CAAE,QACH,EACR,GADa,CAAC,GACL,CACR,IAAI,CAAA,YAAa,CAAC,GACnB,AACH,CAAC,AAES,oBAAA,CACR,OAAQ,IAAI,CAAA,QAAS,EAAE,EAAE,IAClB,CoGuYO,CjL/NS,mB6ErKrB,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,C7E0KC,G6E1KI,GAAG,CAAC,AACT,IAAK,GAAG,CAAC,IACJ,IACL,IAAA,QACK,GAAG,UAER,IAAK,KACL,IAAK,SACL,IAAA,gBACS,CACT,I7E4KI,K6E3KF,OAAO,GAIH,eAAe,CAAe,CAAA,CACtC,IAAA,EAAgB,CoGsYK,CpGtYH,AoGsYI,CpGrYtB,IAAK,IAAI,CAAC,CAAG,C7E8KG,A6E9KF,CAAE,EAAA,EAAa,CAAC,EAAE,CAAE,OAChB,IAAI,CAAC,CoGsYO,IjLxNE,CAAC,CAAA,O6E7KO,IAAlC,CAAuC,EAAE,AAAzC,IAAoB,CAAC,GACvB,IAD8B,CAAC,CACzB,MAAM,EoGsYU,+BpGpYxB,GAAa,EACd,AAED,E7E6KW,G6EhLW,CAAC,AAGhB,C7E6KmB,A6E7KjB,C7E6KkB,CiLyNZ,CAAC,EpGtYD,WAAW,CAAE,KAAK,CADhB,CACkB,OADV,CACkB,AADjB,EAAW,EAAE,CACI,AADH,CACK,AAC/C,AAF2C,CACK,AAC/C,AAES,EAJ2B,OAIlB,EAAU,CAAA,CAAA,QACpB,IAAI,CAAA,KAAM,CAAC,IAAI,CAAC,GAAA,CAAM,EAAQ,CAAC,AAG9B,IAH4B,GAGrB,EAAA,KACT,EAAW,IAAI,CAAC,QAAA,CAAS,GAE/B,WADI,CAAC,WAAW,MAAC,GACV,E7E+KI,CADgB,Y6E3KiB,CAAA,IACxC,KAAA,IAAA,GAAsB,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,GAAK,EACjD,EADqD,EAAE,EACjD,KAAK,CACT,aAAa,CACX,EACA,iBACA,IAAA,CAAK,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,CACpB,eAAe,CAAA,IACX,CAAC,GAAG,CACX,CAGH,GAAI,IAAI,CAAC,GAAG,EAAI,IAAI,CAAC,KAAK,CAAC,MAAM,CAC/B,CADiC,KAC3B,KAAK,CAAC,yBAAyB,CAEvC,AAFwC,CAAC,IAErC,CAAC,GAAG,EAAE,AACZ,C7EwKC,A6ExKA,AAES,GAAG,CAAC,CAAa,CAAA,CACzB,MAAO,CAAE,MAAO,EAAO,IAAK,IAAA,CAAK,C7EsKC,CAAC,C6EtKC,CACtC,CAAC,A7EsKA,uEmGx9B2B,qzCoBeS,CAAA,iFAOb,2DAMT,UAAA,CAAA,CAAA,kFAOJ,IAAA,CAAA,SAAA,EAAA,OAAA,2DAKG,CAAA,cAAA,CAAA,EAAA,UAEE,EAAA,GAAA,2BACkB,CAAA,sHASiB,CAAA,KAAA,CAAQ,EAAA,GAAA,CAAS,GAAA,wFAMvC,CAAA,EAAA,uCAEuB,KAAK,CAAA,EAAA,GAAA,CAAA,GAAA,2BACtB,uKAiEyB,KAAA,CAAM,CvH8EE,AsIyDD,CfvIC,AeuID,CtIzDG,AuH9ED,aAE1C,CFwGC,MEvGpB,EAAS,UAAA,OAAA,EAAA,IAAA,OAAA,GAAgD,SACxD,GAAA,IAAA,CAAA,GAAkC,EAAA,IAAA,AAJe,CAIf,GAC7C,CAAC,AAEK,SAAA,GAAA,CAAA,SACK,EAAA,OAAa,CAAA,sBAAA,qB4BrHiC,CAAA,CAAA,2FAOhC,oHAiB2D,CAAC,0BAE3C,CAAA,EAAA,IAAA,4EAZkB,IAAA,EAAA,MAAA,AAAoB,CAAC,CAAE,CAAC,IVEE,iCUmElF,CbyHC,AfzHA,E4BAG,CAAA,GAAA,CAAA,SACO,CADa,GAGlB,EAAA,GAAA,EAA2C,EAAA,EAAe,C1B4FC,M0B5FM,CAAE,IACzE,GAAqB,AAArB,GAAwB,CAAxB,EAAA,MAAA,UnEuEE,KAAA,IAAA,kBmEnE2B,GAAA,CAAA,EAAW,EAAA,MAAA,CAAA,8BAOuE,MAC1G,EAAA,yBACwD,ChEkCT,AgElCW,GAAG,A3CmEA,mB2ClEnB,QAChC,0BAG6B,GAAA,oBACZ,GAAA,GAAA,EAAqC,EAAU,EAAS,KAAK,CAAC,CAAC,CAAC,AA8F9F,SAAA,G3OrCiC,A2OqCjC,CAAA,2BAImB,C3C4FA,Aa8BC,CAAA,U8B1HmB,GAAG,CAAC,YAEL,CAAA,UAAA,eACY,CAAC,EAAE,CAAC,ApG8HR,CAAC,CAAC,CkIiWO,CAAC,CAAC,O9B7dnB,CkCQC,AlCRA,iBAKlC,cAGmE,CAAE,CyByStB,AzBzS8E,CyByS7E,gBzBvS9C,EAAG,CAAA,CAAA,CAAA,oBAE0C,IADA,MAID,EAAA,EAAA,AAD1B,EAC0B,OAExC,CAAA,EAAA,qBAIQ,+BAGX,EAAA,KAAA,gBAEe,CADwB,CAAC,EACzB,QAAgD,CAAhD,AAAiD,EAAjD,OAAA,CAAA,A3OmHM,CAC5B,CAAC,S2OpHqB,kCAGK,IAAA,EAAA,EAA+B,IAAI,CAAA,GAAI,CAAC,EAAE,CAAC,OACvD,CnEgHH,AuFyBI,CAAA,EAAA,IpBzIc,CAAC,GAAA,mBACF,C9B6HD,M8B7HU,MAAA,CAAA,EAAA,EAAA,OAAA,AAAY,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,AlE+IzC,AkE/I8C,GAAE,CAAC,GAAR,ElEgJzC,CACT,EkEjJkD,cACb,CzNmJH,A6K1GI,AvGsFF,AmJ/HE,CAI7C,C7O8LC,A6O9LA,CA/BU,EAAA,EAA4C,IAAA,KA4EjD,SAAA,GAAA,CAAA,SACK,AAGX,SAAS,EAAuB,CAAoB,C9BmJf,A8BnJiB,CAA4B,UAC/D,CAAA,UACJ,UAIA,cAAA,GAA0B,UACd,OACX,CAAC,EAAK,IAAI,CAAA,GAAA,EAId,EAAA,EAAA,IAA8B,CAAA,GAAA,GAAS,CAAC,EAAuB,EAAA,IAAS,CAAA,GAAI,CAAE,OAAO,CAAC,EAAE,CAAC,MAGtF,GAAA,GAAA,iBAEA,GAAA,GAAA,GACH,IAD2B,EAC3B,CAAA,SAGD,CAAA,EAAA,UAAA,AACX,CAAC,CAzBU,EAAA,IAAA,IACX,CAAC,AA8DK,SAAA,GAAA,CAAkD,C3C+Jf,mD2C5JrB,QAAA,QACL,EAAA,QAAa,CbuOrB,GAAA,EAAA,UAAA,CAAA,SarOsB,UAAU,CAAA,GAAA,sBAGI,AACpB,CADqB,CACrB,IAAY,CAAC,A7O6PJ,c6O5PmB,EAAW,CAAR,SAAkB,AACjD,CADkD,CnEyHxD,AmExHc,C7OiQS,G6OjQL,EAKnC,CAAC,AAEK,SAAA,GAAA,CAAA,QAgBwB,SAfL,gBACa,EAAK,E3O0KZ,A6MAL,C7MAM,C2O1Ke,CAAC,AAAE,CAAD,MAAC,EAAA,GAAA,EAAA,CAAyB,CAAA,EAAI,EAAK,EAAD,EAAK,CAAC,KAC1D,IAAA,EAAoB,I8BlDxC,GAAA,E9BkDiD,GAAG,CAAC,I8BlDrD,C9BkDkE,E8BlDlE,E9BkDsE,CAAC,EAAE,CAAC,IACtE,EAAA,IAAA,CACJ,GAAI,C7OsQH,CkMvFG,CAAA,GAAA,C2C9KP,C7OsQC,CACF,AiQ1DG,EpB7MI,KAAA,eAWa,eACO,CAAA,IAAK,CAAC,AnE2HR,CmE1HjB,MAAA,CAAA,EAAA,EAAA,IAAA,AAAW,EAAA,KAAA,EAAA,EAAA,GAAA,AAAK,EAAE,AAClB,CADmB,EACP,EAAA,IAAA,CAAA,GAAA,+BAVZ,CnE4HP,CAAA,OmE5HiC,GAC1B,EAAA,IAAA,OAEL,MAAA,mCA0CJ,SAAA,GAAwB,CAAA,MACpB,EAAA,WAGF,C3C6LC,A2C7LA,CAAA,CAAA,UAIE,IAAI,OAFL,QAEoB,CnJ4NH,AmJhNlB,CnJgNmB,CmJhNnB,CAAA,CAAA,CAAkE,CnJqNhC,KmJzKlC,IA4BA,I3NqTR,C2NrTuD,I8B8B7C,A9B5CqC,G8B4CrC,UAAA,C9BrGwB,E8BqGxB,Y9BpGI,AA2CJ,GAAA,CADF,EA1CkC,CnE0HD,CAAC,AqCgDE,CAAC,A8B/HN,AnE+EI,AhF4FA,CqH5CG,A4D6WN,CjLjUK,EmJtNI,AnJsNF,ImJ3KA,CAAC,GAAG,CAAC,AAAC,CAAC,EAAE,AAAC,EAAuB,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAE,aAC3E,EAAa,WAAA,WACf,EAAA,SAAsB,EA7CS,A8ByhBP,kB9BxhBR,E8B8GI,C5P5NC,I8N+GhC,GADqC,IAiDlC,AAhDI,GAgDY,CADG,EA/CM,GA+CkB,AACrB,CtEqFH,CAAC,EsErIY,IAgDF,CAAC,GAAG,CAAA,AAAC,CAAC,CAAC,CAAG,EAAuB,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,EAAE,CAAC,CAAE,OAAf,MACpD,EtEuFF,AsEvFQ,GtEuFD,QsEvFY,WACnB,EAAA,E3O8N4B,CAAC,M2O9Nd,EAlDU,CACjC,IAAI,aAAA,cAmEN,AAlEM,EAAsB,C3O4MP,E2OzIhB,E3C2ME,CAAA,E2C3MG,EAAE,CAAC,KACa,GAAe,EAAM,E3OkOhB,AyQsQE,C9Bxea,CAAK,CAAC,CAAA,CAAA,EAAI,GAAe,EAAM,GAAD,EAAM,CAAC,CAAA,CAAA,CAAG,AAAhB,CAAkB,aACxE,EAAA,WAAA,CACb,UAAW,EAAM,SAAS,WAI3B,GAAgB,GAAe,EAAM,GAAD,CAAK,CAAC,CAAE,eAC5B,WAAW,aACb,SAAS,K3OoOC,CAAC,IApGN,C2O3MnB,GAAI,GAAA,GAAA,KACD,EAAO,EAAA,IAAY,CAAA,GAAI,CAAC,C3O8MP,K2O5MnB,MAAA,AAAU,MAAA,qCAES,EAAuB,E3O8MN,E2O9MU,AnJgOV,AxFlBA,QAAA,E2O9MwB,CAC5D,GnJ+NsD,SmJ/NtD,EAAA,WAAgC,aACb,SAAS,C3O8MX,C2O5MzB,MAAO,G8BoDA,GAAA,UAAqB,CAAC,A9BpDtB,E8BoD4B,Q9BpDK,CAAC,GAiDjB,AAhDb,EAAA,AtEwIW,EsEvFf,GAAgB,CAAA,GAAA,EAAA,EAA6B,EAAO,IAAD,IAAS,CAAC,CAAA,CAAA,EAAI,GAAQ,EAAA,CAAI,CAAE,CAClF,AAD4E,YAC/D,EAAO,WAAW,aACb,SAAA,CACrB,CAAC,AApDS,CAoDR,AAnDI,iBAAA,c3N2WV,E2N1WgC,EAwCtB,G8Bkc2B,A9Blc3B,CAAA,EAAA,GAA2B,EAAA,EAAA,EAA4B,EAAM,GAAD,KAAS,CAAC,CAAA,CAAE,CAAE,eAC1D,WAAW,WACnB,EAAM,SAAA,E8Bgca,K9BzevB,aAAA,MAAA,OACW,EAAA,KAAa,CAAC,E3CkME,S2ClMS,CAAC,GAAG,CAAC,CAAC,AAC3C,EAAA,EAAiB,KAAA,CAAM,CyB0WC,QzB1WQ,CAAA,EAAI,GACpC,EAAa,EAAQ,CtEgFP,CAAC,CAAC,EsEhFU,CAAC,SAAS,CAAC,EAAS,OAAA,SAE1C,CAAC,CAAG,EAAA,QAAmB,CAAC,GAAG,CAAC,CAAC,EAC7B,CAAA,CAAA,EAAe,QAAQ,CAAC,OACxB,CAAC,CAAG,EAAW,E3CmME,M2CnMM,CAAC,MAE3B,GAAgB,EAAA,eACE,WAAW,WACrB,EAAA,SAAA,OACL,O8B4HP,C9B1HI,E8B0HJ,UAAA,C9B1HmB,CnJ+OL,CiLrHd,I9BzHH,CnJ+OD,MmJ/OQ,GAAgB,GAAU,C3CqMC,A2CpM9B,YAAa,EAAQ,M8B4eM,K9B5eK,S8B4eS,a9B3eb,I3O8NN,K2O3NpB,AAAI,MAAM,CAAA,0BAAA,QAA6B,EAAO,KAAA,EAAP,EAAS,CAAF,IAAA,AAAO,CAAA,CAAE,CAAC,CAAjB,AAAkB,EAtD7B,EAAa,A8B6eX,G9BvbgB,OAtDK,CAAE,KAAK,CAAC,CAAC,GAC9C,OAAA,CAAQ,GAAO,E8B6eF,A9B7eA,IAAE,CAAO,CAAC,CAAC,AnJ4NG,CxFlBZ,E2O1MiB,EAAE,CAAG,CAAD,EAAQ,EAAF,CAAC,AAAI,CAAC,CAAC,CAAC,EAAK,EAAE,CAAG,CAAD,EAAO,CAAF,CAAC,EAAK,CAAC,EAAE,CAAC,CAAC,AAEvG,CAAC,AyB2WA,AzBxWD,IAAM,GAAA,SAAoB,CnJ2NH,KAAA,CmJ5HvB,SAAS,GAAe,CAAoB,EACxC,OAAA,GAAA,EAA4B,KAAK,CAAC,CAAC,SAG9B,GAAgB,CAAa,CAAE,CAIvC,iBACwB,KAAK,G3OwOH,E2OxOP,EAAc,EAAQ,SAAA,AAAS,EAAE,CAAC,C3OwOL,iB2OvOrB,M8BmeY,GAAA,A9BneH,EAAA,EAAI,EAAE,AAAN,CAAM,EAAG,EAAK,EAAA,AAAG,CAAH,AAAI,AAAlB,OAAA,KAAA,EAEV,EAAE,AACd,CADe,A8BmeA,A9Blef,EAAG,EAAK,EAAA,CAAA,CAAW,WAAW,CAAA,CAAE,U3SziB/C,SAAS,AAAG,CAAK,CAAE,CAAK,EACtB,OAAO,IAAU,GAAU,GAAU,AAGxB,GAHiC,GAAU,CAC1D,KsHxBA,SAAS,AAAa,CAAK,CAAE,CAAG,EAE9B,IADA,IAAI,EAAS,EAAM,KASN,CATY,CAClB,KACL,GAAI,CADW,EACR,CAAK,CAAC,EAAO,CAAC,EAAE,CAAE,GACvB,GAD6B,IACtB,EAGX,OAAO,CAAC,CACV,ECZA,I6Mo0BA,SS5vBA,enFzEW,GAOA,GAOA,GASA,GAaA,GA8BA,GA2BA,GAwBA,GA4BA,GA8BA,GAyBA,GA2BA,GAmBA,GAyCA,GAwBA,GAwBA,GAqBA,GAYA,GA2CA,GA0BA,GAoCA,GAqBA,GAQA,GA4CA,GAiBA,GAuBA,GAwBA,GAuBA,GAuTA,GAuBA,GAwBA,GAwBA,GA6BA,GAmBA,GAcA,GAgCA,GAwBA,GAYA,GAwBA,GAqBA,GAaA,GAeA,GAaA,GAoBA,GAiBA,GAiBA,GAoBA,GAmBA,GAmBA,GAkCA,GAOA,GAwBA,GAkBA,GA4CA,GA2EA,GAkBA,GA2BA,GAqCA,GA0BA,GAsBA,GAsBA,GAwBA,GAwCA,GAgBA,GAcA,GAoBA,GAqBA,GAsBA,GAuBA,GAeA,GAeA,GAsBA,GAOA,GAOA,GAaA,GAWA,GAOA,GAOA,GAYA,GA6KP,Mbh/DO,GyFtFC,SlDiPN,S1NoIF,GAEA,GAEA,GAEA,GAEA,GAEA,GAEA,wB2G5aoB,QAAQ,C+EGN,MAAM,EAAE,IMOvB,MAsBA,CN7BkC,AMO3B,OAsBC,CAiFR,YAAY,GAiIZ,GAyCA,SAzCY,GAqKZ,OAAO,QAwJP,CApR4B,EA2S5B,OAvBU,GAuBA,KA6aV,gBAAgB,QAwUhB,GAmFA,GA4CA,GA2EA,CA1MU,OAmFI,GA4CA,OAmOd,GAxJqB,MAsPrB,GAoBA,EAlHc,UA8FC,GAoHf,MAsFA,GAtFS,CAhGgB,QAsLb,SnIz8DnB,GAAS,AAHI,MAAM,SAAS,CAGR,MAAM,CmJO9B,SAAS,GAAU,CAAO,EACxB,IAAI,EAAQ,CAAC,EACT,EAAS,AAAW,QAAO,EAAI,EAAQ,MAAM,CAGjD,IADA,IAAI,CAAC,KAAK,GACH,EAAE,EAAQ,GAAQ,CACvB,IAAI,EAAQ,CAAO,CAAC,EAAM,CAC1B,IAAI,CAAC,GAAG,CAAC,CAAK,CAAC,EAAE,CAAE,CAAK,CAAC,EAAE,CAC7B,CACF,CAGA,GAAU,SAAS,CAAC,KAAK,C3QlBzB,E2QkB4B,O3QlBnB,EACP,IAAI,CAAC,QAAQ,CAAG,EAAE,CAClB,IAAI,CAAC,IAAI,CAAG,CACd,E2QgBA,GAAU,SAAS,CAAC,MAAS,CnJT7B,EmJSgC,OnJTvB,AAAgB,CAAG,EAC1B,IAAI,EAAO,IAAI,CAAC,QAAQ,CACpB,EAAQ,GAAa,EAAM,SAE/B,EAAI,GAAQ,GAAG,CAIX,GADY,EAAK,IACR,EADc,CAAG,EAE5B,EAAK,GAAG,CADc,EAGtB,GAAO,IAAI,CAAC,EAAM,EAAO,GAE3B,EAAE,IAAI,CAAC,IAAI,EACJ,EACT,EmJLA,GAAU,SAAS,CAAC,GAAG,ClJhBvB,EkJgB0B,OlJhBjB,AAAa,CAAG,EACvB,IAAI,EAAO,IAAI,CAAC,QAAQ,CACpB,EAAQ,GAAa,EAAM,GAE/B,OAAO,EAAQ,OAAI,EAAY,CAAI,CAAC,EAAM,CAAC,EAAE,AAC/C,EkJYA,GAAU,SAAS,CAAC,GAAG,CjJjBvB,EiJiB0B,OjJjBjB,AAAa,CAAG,EACvB,OAAO,GAAa,IAAI,CAAC,QAAQ,CAAE,GAAO,CAAC,CAC7C,EiJgBA,GAAU,SAAS,CAAC,GAAG,ChJjBvB,EgJiB0B,OhJjBjB,AAAa,CAAG,CAAE,CAAK,EAC9B,IAAI,EAAO,IAAI,CAAC,QAAQ,CACpB,EAAQ,GAAa,EAAM,GAQ/B,OANI,EAAQ,GACV,AADa,EACX,IAAI,CAAC,IAAI,CACX,EAAK,IAAI,CAAC,CAAC,EAAK,EAAM,GAEtB,CAAI,CAAC,EAAM,CAAC,EAAE,CAAG,EAEZ,IAAI,AACb,E/DtBA,IAAI,GAAa,AAAiB,EAAA,CAAA,EAAsB,EAAA,CAAA,CAAO,MAAM,GAAK,QAAA,EAAA,CAAA,CiEEtE,GAA0B,UAAf,GjEFmB,IiEEZ,MAAoB,MAAQ,KAAK,MAAM,GAAK,QAAU,KAGxE,GjEHW,AiEGJ,IAAc,IAAY,SAAS,iBCH1C,GDKW,ACLF,GAAK,MAAM,CCApB,GAAc,OAAO,SAAS,CAG9B,GAAiB,GAAY,cAAc,CAO3C,GAAuB,GAAY,QAAQ,CAG3C,GAAiB,GAAS,GAAO,WAAW,MAAG,SASnD,SAAS,AAAU,CAAK,EACtB,IAAI,EAAQ,GAAe,IAAI,CAAC,EAAO,IACnC,AAkBS,EAlBH,CAAK,CAAC,GAAe,CAE/B,GAAI,CACF,CAAK,CAAC,GAAe,MAAG,EACxB,IAAI,GAAW,CACjB,CAAE,MAAO,EAAG,CAAC,CAEb,IAAI,EAAS,GAAqB,IAAI,CAAC,GAQvC,OAPI,IACE,EACF,CAAK,CAAC,EAFI,CACD,AACY,CAAG,EAExB,OAAO,CAAK,CAAC,GAAe,EAGzB,CACT,E7HnCA,IAAI,GAPc,AAOS,OAPF,SAAS,CAOK,QAAQ,C6MC3C,GjFJW,AiFIM,GAAS,GAAO,WAAW,CAAG,cASnD,SAAS,AAAW,CAAK,SACvB,AAAa,MAAT,AAAe,OAQN,AAPM,IAAV,EAdQ,MAcc,eAAe,AAflC,gBAiBJ,CAhBN,GAgBwB,MAAkB,OAAO,GAC/C,GAAU,G7MLP,GAAqB,G6MMxB,C7MN4B,CAAC,A6MMd,EACrB,K5MAA,SAAkB,AAAT,CAAc,EACrB,IAAI,EAAO,OAAO,EAClB,KAGa,EAHG,MAAT,EAAiB,EAAS,UAAR,GAA4B,YAAR,CAAQ,CAAU,AACjE,KsLFA,SAAS,AAAW,CAAK,EACvB,GAAI,CAAC,GAAS,GACZ,KADoB,EACb,EAIT,CAIa,GAJT,EAAM,GAAW,GACrB,MA5BY,AA4BL,OAAO,cA3BZ,GAAS,AA2Bc,OAAO,uBA1B9B,GAHW,0BA6B6B,AA5BxC,GAEW,IA0BoC,cAAY,CAC/D,EzD/BA,IyD8BsE,AzD9BlE,GAAa,EAAI,CAAC,qBAAqB,CCAvC,GAEK,CADH,GAAM,MADM,GACG,IAAI,CDCV,ACDW,IAAc,GAAW,IAAI,EAAI,GAAW,IAAI,CAAC,QAAQ,EAAI,KACvE,iBAAmB,GAAO,G7HDtC,GAHY,AAGG,SAHM,SAAS,CAGL,QAAQ,QASrC,SAAS,AAAS,CAAI,EACpB,GAAI,AAAQ,QAAM,CAChB,GAAI,CACF,IASS,GATF,GAAa,IAAI,CAAC,EAC3B,CAAE,MAAO,EAAG,CAAC,CACb,GAAI,CACF,OAAQ,EAAO,EACjB,CAAE,MAAO,EAAG,CAAC,CACf,CACA,MAAO,EACT,E6OXA,IAAI,GAAe,8BAIf,GAAc,OAAO,SAAS,CAG9B,GAJY,AAIG,SAJM,SAAS,CAIL,QAAQ,CAGjC,GAAiB,GAAY,cAAc,CAG3C,GAAa,OAAO,IACtB,GAAa,IAAI,CAAC,IAAgB,OAAO,CAjBxB,AAiByB,sBAAc,QACvD,OAAO,CAAC,yDAA0D,SAAW,YAWhF,SAAS,AAAa,CAAK,QACzB,CAAI,CAAC,GAAS,KhHvBP,CAAC,AAAC,GgH8BI,CAPW,EhHvBA,MgHuBS,ChHvBK,CAAA,GgH2B/B,CADO,EAH2B,AhHvBH,CgH0Bb,GAAS,GAAa,EAAA,EAChC,IAAI,CAAC,GAAS,GAC/B,KtDjCA,SAAS,AAAU,CAAM,CAAE,CAAG,EAC5B,IAAI,EtLHG,AAAU,MsLGL,AAAS,MAIR,CtLPW,EAAY,CAAM,CAAC,AsLGd,EtLHkB,CsLI/C,OAAO,GAAa,GAAS,OAAQ,CACvC,ECVA,IAAI,GAAM,MAAgB,O1DDtB,GAAe,GAAU,OAAQ,O0DCjB,GxDKhB,GAHc,AAGG,OAHI,SAAS,CAGD,cAAc,CCH3C,GAAiB,AAHH,OAAO,SAAS,CAGD,cAAc,C8HO/C,SAAS,GAAK,CAAO,EACnB,IAAI,EAAQ,CAAC,EACT,EAAoB,MAAX,EAAkB,EAAI,EAAQ,MAAM,CAGjD,IADA,IAAI,CAAC,KAAK,GACH,EAAE,EAAQ,GAAQ,CACvB,IAAI,EAAQ,CAAO,CAAC,EAAM,CAC1B,IAAI,CAAC,GAAG,CAAC,CAAK,CAAC,EAAE,CAAE,CAAK,CAAC,EAAE,CAC7B,CACF,CAGA,GAAK,SAAS,CAAC,KAAK,ChIhBpB,EgIgBuB,OhIhBd,EACP,IAAI,CAAC,QAAQ,CAAG,GAAe,GAAa,MAAQ,CAAC,EACrD,IAAI,CAAC,IAAI,CAAG,CACd,EgIcA,GAAK,SAAS,CAAC,MAAS,C7PhBxB,E6PgB2B,O7PhBlB,AAAW,CAAG,EACrB,IAAI,EAAS,IAAI,CAAC,GAAG,CAAC,IAAQ,OAAO,IAAI,CAAC,QAAQ,CAAC,EAAI,CAEvD,OADA,IAAI,CAAC,IAAI,IAAI,EACN,CACT,E6PaA,GAAK,C7PfmB,IAAI,I6Ped,CAAC,GAAG,C/HPlB,E+HOqB,O/HPJ,AAAR,CAAW,EAClB,IAAI,EAAO,IAAI,CAAC,QAAQ,CACxB,IAAI,EAAc,CAChB,IAAI,EAAS,CAAI,CAAC,EAAI,CACtB,MArBiB,8BAqBV,EAA4B,OAAY,CACjD,CADoB,AAEpB,OAAO,GAAe,IAAI,CAAC,EAAM,GAAO,CAAI,CAAC,EAAI,MAAG,CACtD,E+HCA,GAAK,SAAS,CAAC,GAAG,C9HXlB,E8HWqB,O9HXZ,AAAQ,CAAG,EAClB,IAAI,EAAO,IAAI,CAAC,QAAQ,CACxB,OAAO,GAAgB,KAAc,KAAV,CAAC,EAAI,CAAkB,GAAe,IAAI,CAAC,EAAM,EAC9E,E8HSA,GAAK,SAAS,CAAC,GAAG,C7HdlB,E6HcqB,O7HdZ,AAAQ,CAAG,CAAE,CAAK,EACzB,IAAI,EAAO,IAAI,CAAC,QAAQ,CAGxB,OAFA,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,GAAG,CAAC,GACtB,CAAI,CAAC,EADwB,AACpB,CAAG,AJbC,GIYoB,MACM,IAAV,EAfV,MAeiC,sBAAiB,EAC9D,IACT,AADa,S/HZb,SAAS,AAAU,CAAK,EACtB,IAAI,EAAO,OAAO,EAClB,KAKa,CALG,UAAR,GAAoB,AAAQ,aAAoB,UAAR,GAA4B,WAAR,EAC/D,AAAU,gBACA,OAAV,CACP,KgIFA,SAAS,AAAW,CAAG,CAAE,CAAG,EAC1B,IAAI,EAAO,EAAI,QAAQ,CACvB,CAKa,MALN,GAAU,GACb,CAAI,CAAe,UAAd,OAAO,EAAkB,SAAW,OAAO,CAChD,EAAK,GACX,AADc,E6HDd,SAAS,GAAS,CAAO,EACvB,IAAI,EAAQ,CAAC,EACT,EAAoB,MAAX,EAAkB,EAAI,EAAQ,MAAM,CAGjD,IADA,IAAI,CAAC,KAAK,GACH,EAAE,EAAQ,GAAQ,CACvB,IAAI,EAAQ,CAAO,CAAC,EAAM,CAC1B,IAAI,CAAC,GAAG,CAAC,CAAK,CAAC,EAAE,CAAE,CAAK,CAAC,EAAE,CAC7B,CACF,CqBRA,SAAS,GAAM,CAAO,EACpB,IAAI,EAAO,IAAI,CAAC,QAAQ,CAAG,IAAI,AdgBlB,GchB4B,GACzC,IAAI,CAAC,IAAI,CAAG,EAAK,IAAI,AACvB,CrBQA,GAAS,SAAS,CAAC,KAAK,C3CdxB,E2Cc2B,O3CdlB,EACP,IAAI,CAAC,IAAI,CAAG,EACZ,IAAI,CAAC,QAAQ,CAAG,CACd,KAAQ,IAAI,GACZ,IAAO,IAAI,AAAC,MAAO,CAAS,CAC5B,OAAU,I0CeC,A1CfG,EAChB,CACF,E2CQA,GAAS,SAAS,A3CXK,C2CWJ,MAAS,C5Hf5B,E4He+B,O5HfP,AAAf,CAAkB,EACzB,IAAI,EAAS,GAAW,IAAI,CAAE,GAAK,CAAD,KAAU,CAAC,GAE7C,OADA,IAAI,CAAC,IAAI,IAAI,EACN,CACT,E4HYA,GAAS,C5Hde,IAAI,I4HcV,CAAC,GAAG,C3HhBtB,E2HgByB,O3HhBJ,AAAZ,CAAe,EACtB,OAAO,GAAW,IAAI,CAAE,GAAK,GAAG,CAAC,EACnC,E2HeA,GAAS,SAAS,CAAC,GAAG,C1HjBtB,E0HiByB,O1HjBJ,AAAZ,CAAe,EACtB,OAAO,GAAW,IAAI,CAAE,GAAK,GAAG,CAAC,EACnC,E0HgBA,GAAS,SAAS,CAAC,GAAG,CzHjBtB,EyHiByB,OzHjBhB,AAAY,CAAG,CAAE,CAAK,EAC7B,IAAI,EAAO,GAAW,IAAI,CAAE,GACxB,EAAO,EAAK,IAAI,CAIpB,OAFA,EAAK,GAAG,CAAC,EAAK,GACd,IAAI,CAAC,IAAI,GAAI,GAAK,IAAI,EAAI,CAAA,EACnB,EAD0B,EACtB,AACb,E8ICA,A9IHuC,G8IGjC,SAAS,CAAC,KAAK,C7JXrB,E6JWwB,O7JXf,EACP,IAAI,CAAC,QAAQ,CAAG,IAAI,GACpB,IAAI,CAAC,IAAI,CAAG,CACd,E6JSA,GAAM,SAAS,CAAC,MAAS,C3RZzB,E2RY4B,O3RZP,AAAZ,CAAe,EACtB,IAAI,EAAO,IAAI,CAAC,QAAQ,CACpB,EAAS,EAAK,EAAD,IAAU,CAAC,GAG5B,OADA,IAAI,CAAC,IAAI,CAAG,EAAK,IAAI,CACd,CACT,E2ROA,GAAM,SAAS,CAAC,GAAG,C1RbnB,E0RasB,O1RbJ,AAAT,CAAY,EACnB,OAAO,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,EAC3B,E0RYA,GAAM,SAAS,CAAC,GAAG,C5RdnB,E4RcsB,O5Rdb,AAAS,CAAG,EACnB,OAAO,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,EAC3B,E4RaA,GAAM,SAAS,CAAC,GAAG,C9DPnB,E8DOsB,O9DPJ,AAAT,CAAY,CAAE,CAAK,EAC1B,IAAI,EAAO,IAAI,CAAC,QAAQ,CACxB,GAAI,gBAAgB,AAAW,CAC7B,IAAI,EAAQ,EAAK,QAAQ,CACzB,GAAI,C/BfO,A+BeN,IAAQ,EAAM,MAAM,CAAG,IAG1B,OAFA,EAAM,IAAI,CAAC,CADkC,AACjC,EAAK,CADgC,CAC1B,EACvB,IAAI,CAAC,IAAI,CAAG,EAAE,EAAK,IAAI,CAChB,IAAI,CAEb,EAAO,IAAI,CAAC,QAAQ,CAAG,IAAI,GAAS,EACtC,CAGA,OAFA,EAAK,GAAG,CAAC,EAAK,GACd,IAAI,CAAC,IAAI,CAAG,EAAK,IAAI,CACd,IAAI,AACb,SnNtBA,SAAS,AAAU,CAAK,CAAE,CAAQ,EAIhC,IAHA,IAAI,EAAQ,CAAC,EACT,EAAkB,GAUT,GAVA,EAAgB,EAAI,EAAM,MAAM,CAEtC,EAAE,EAAQ,IAC8B,GADtB,CACnB,EAAS,CAAK,AAAkC,CAAjC,EAAM,CAAE,EAAO,KAIpC,OAAO,CACT,EoIjBA,IAAI,GAAkB,WACpB,GAAI,CACF,IAAI,EAAO,GAAU,OAAQ,kBAE7B,OADA,EAAK,CAAC,EAAG,GAAI,CAAC,GACP,CACT,CAAE,MAAO,EAAG,CAAC,CACf,WCGA,SAAS,AAAgB,CAAM,CAAE,CAAG,CAAE,CAAK,EACrC,AAAO,eAAe,CDFb,ACcA,GAXX,GAAe,EAAQ,EAAK,CAC1B,aAAgB,GAChB,MAHsC,MAGxB,EACd,MAAS,EACT,UAAY,CACd,GAEA,CAAM,CAAC,EAAI,CAAG,CAElB,EoDfA,IAAI,GAHc,AAGG,OAHI,SAAS,CAGD,cAAc,QAY/C,SAAS,AAAY,CAAM,CAAE,CAAG,CAAE,CAAK,EACrC,IAAI,EAAW,CAAM,CAAC,EAClB,AADsB,CACpB,AAAD,GAAgB,EAMR,EANY,CAAC,EAAQ,IAAQ,GAAG,EAAU,KAClD,AAAU,CAD8C,WAC/B,CAAF,CAAC,GAAQ,CAAM,GACzC,AAD6C,GAC7B,EAAQ,EAAK,EAEjC,KCZA,SAAS,AAAW,CAAM,CAAE,CAAK,CAAE,CAAM,CAAE,CAAU,EACnD,IAAI,EAAQ,CAAC,CACb,KAAW,CAwBE,CAxBO,EAAC,CAAX,AAAY,CAKtB,IAHA,IAAI,EAAQ,CAAC,EACT,EAAS,EAAM,MAAM,CAElB,EAAE,EAAQ,GAAQ,CACvB,IAAI,EAAM,CAAK,CAAC,EAAM,CAElB,EAAW,EACX,EAAW,CAAM,CAAC,EAAI,CAAE,CAAM,CAAC,EAAI,CAAE,EAAK,EAAQ,QAClD,CAEA,MAAa,QACf,EAAW,CADe,AACT,CAAC,EAAA,AAAI,EAEpB,EACF,GAAgB,EADP,AACe,EAAK,GAE7B,GAAY,EAAQ,EAAK,EAE7B,CACA,OAAO,CACT,KzL5BA,SAAS,AAAU,CAAC,CAAE,CAAQ,EAI5B,IAHA,IAAI,EAAQ,CAAC,EACT,EAAS,GAQA,GARM,GAEZ,EAAE,EAAQ,EAAG,CAClB,CAAM,CAAC,EAAM,CAAG,EAAS,GAE3B,OAAO,CACT,KCOA,SAAS,AAAa,CAAK,EACzB,OAAgB,MAAT,GAAiB,AAAgB,IAG3B,aAHkB,CACjC,KyLbA,SAAyB,AAAhB,CAAqB,EAC5B,OAAO,GAAa,IAVR,MAaC,gBAHiB,GAAW,EAC3C,ECXA,IAAI,EDUiD,CCVnC,OAAO,SAAS,CAG9B,GAAiB,GAAY,cAAc,CAG3C,GAAuB,GAAY,oBAAoB,CAoBvD,GAAc,GAAgB,WAAa,OAAO,SAAW,KAAO,GAAkB,SAAS,CAAK,EACtG,OAAO,GAAa,IAAU,GAAe,IAAI,CAAC,EAAO,WACvD,CAAC,GAAqB,IAAI,CAAC,EAAO,SACtC,EzLVI,GAAU,MAAM,OAAO,QCV3B,SAAS,EACP,OAAO,CACT,ECXA,IAAI,GAAW,IwLiCA,sBxLvBf,SAAiB,AAAR,CAAa,CAAE,CAAM,EAC5B,IAAI,EAAO,OAAO,EAGlB,GAMa,GANN,CAAC,CAAC,CAFT,EAAmB,MAAV,CAGP,AAHwB,CAfL,iBAewB,CAAA,IAGlC,UAAR,GACU,UAAR,GAAoB,GAAS,IAAI,CAAC,EAAA,CAAO,EACvC,EAAQ,CAAC,GAAK,EAAQ,GAAK,GAAK,EAAQ,CACjD,KCOA,SAAS,AAAS,CAAK,EACrB,MAAuB,UAAhB,IAIM,GAJC,GACZ,EAAQ,CAAC,GAAK,EAAQ,GAAK,GAAK,GA9Bb,MA8BsB,UAC7C,EiNAA,IAAI,GAAiB,CAAC,EACtB,EAAc,CAAC,AAZE,wBAYS,CAXtB,AAWyB,EAAc,CAX1B,AAW2B,wBAAW,CAVnD,AAWJ,EAAc,CAXA,AAWC,qBAAQ,CAVnB,AAUsB,EAAc,CAVzB,AAU0B,sBAAS,CAT9C,AAUJ,EAAc,CAVC,AAUA,sBAAS,CATpB,AASuB,EAAc,CAAC,AAT3B,sBASoC,CACnD,AATI,EASU,CAAC,AATO,6BASS,CAAG,AAR9B,EAQ4C,CAAC,AARjC,uBAQ2C,CAC3D,AARI,EAQU,CAAC,AARC,uBAQS,EAAG,EAC5B,EAAc,CAAC,AAjCD,qBAiCS,CAAG,AAhCtB,EAgCoC,CAhCzB,AAgC0B,iBAAS,CA/B9C,AAgCJ,EAAc,CApBO,AAoBN,uBAAe,CAnB1B,AAmB6B,EAAc,CAhCjC,AAgCkC,mBAAQ,CA/BpD,AAgCJ,EAAc,CApBI,AAoBH,oBAAY,CAnBvB,AAmB0B,EAAc,CAhC9B,AAgC+B,gBAAQ,CA/BjD,AAgCJ,EAAc,CAAC,AAhCA,iBAgCS,CA/BpB,AA+BuB,EAAc,CA/B3B,AA+B4B,oBAAQ,CA9B9C,AA+BJ,EAAc,CA/BD,AA+BE,eAAO,CA9BlB,AA8BqB,EAAc,CA9BvB,AA8BwB,kBAAU,CA7B9C,AA8BJ,EAAc,CA9BE,AA8BD,kBAAU,CA7BrB,AA6BwB,EAAc,CA7B1B,AA6B2B,kBAAU,CA5BjD,AA6BJ,EAAc,CA7BD,AA6BE,eAAO,CA5BlB,AA4BqB,EAAc,CA5BvB,AA4BwB,kBAAU,CA3B9C,AA4BJ,EAAc,CA5BG,AA4BF,mBAAW,CAAG,UhNtC7B,SAAS,AAAU,CAAI,EACrB,OAAO,SAAS,CAAK,EACnB,CAIW,MAJJ,EAAK,EACd,CACF,E+HLA,IASI,AATA,GASY,WATC,AAUf,GAAI,CASF,OAAO,AAtBO,CAuBhB,CAAE,GApB4B,GAoBrB,EAAG,CAAC,CACf,GAF0B,CqFpBtB,GAAmB,IAAY,GAAS,CrFoBN,OAAO,IqFpBW,ArFoBP,CqFD7C,GAAe,GAAmB,GAAU,CrFrBZ,CAsByB,EiF6B7D,EjFhDiD,GAmBmB,CAAC,GiF6B5D,AAAiB,AjFnDsB,CiFmDjB,EAC7B,EjFjD2D,EqFkBO,GJ+B3D,CjFpDkD,CAAC,CiFoDtC,EjFjDiD,CAAC,CiFkDpE,GAAS,AjFrDuD,EiFqDjD,CjFlD4D,KiFkDtD,AjFrDmD,GAGW,AiFkDzD,CAAC,AjFrDiD,CiFqDhD,EAAc,AjFlD6C,CiFkD5C,GAAW,GAC1D,AADiE,EyD7C7D,GAHc,AAGG,OAHI,SAAS,CAGD,cAAc,QAU/C,SAAS,AAAc,CAAK,CAAE,CAAS,EACrC,IAAI,EAAQ,GAAQ,GAChB,EAAQ,CAAC,GAyBA,AAzBS,GAAY,GAC9B,EAAS,CAAC,GAAS,CAAC,GAAS,GAAS,GACtC,EAAS,CAAC,GAAS,CAAC,GAAS,CAAC,GAAU,ArDC/B,GqDD4C,GACrD,EAAc,GAAS,GAAS,GAAU,EAC1C,EAAS,EAAc,GAAU,EAAM,MAAM,CAAE,QAAU,EAAE,CAC3D,EAAS,EAAO,MAAM,CAE1B,IAAK,IAAI,KAAO,EACV,CAAC,GADgB,AACH,GAAe,IAAI,CAAC,EAAO,EAAA,CAAI,EAC7C,CAAC,CAAC,GAEC,CAAO,WAFO,CACd,CAGC,IAAkB,MAAR,IAAC,GAA0B,UAAP,CAAO,CAAQ,EAE7C,IAAkB,MAAR,IAAC,GAA0B,YALuB,EAK9B,GAA8B,cAAP,CAAO,CAAY,EAEzE,GADA,AACQ,EAAK,EAAA,CAChB,CAAC,EACH,CADM,CACC,IAAI,CAAC,GAGhB,OAAO,AAN2B,CAOpC,ExQ7CA,IAAI,GAAc,OAAO,SAAS,QASlC,SAAqB,AAAZ,CAAiB,EACxB,IAAI,EAAO,GAAS,EAAM,SAMb,EANwB,CAGrC,CAFI,MAEG,KAFqB,KAEX,OAFL,OAAQ,GAAsB,EAAK,SAAS,EAAK,EAAA,CAG/D,KCPA,SAAS,AAAQ,CAAI,CAAE,CAAS,EAC9B,OAAO,SAAS,CAAG,CAKN,CAJX,OAAO,EAAK,EAAU,GACxB,CACF,EyETA,IAAI,GAAa,GAAQ,OAAO,IAAI,CAAE,Q0EIlC,GAHc,AAGG,OAHI,SAAS,CAGD,cAAc,QAS/C,SAAkB,AAAT,CAAe,EACtB,GAAI,CAAC,GAAY,GACf,MADwB,C1EZb,A0EaJ,GAWI,AAXO,GAEpB,IAAI,EAAS,EAAE,CACf,IAAK,IAAI,KAAO,OAAO,GACjB,GAAe,EADW,EACP,CAAC,EAAQ,IAAe,eAAP,AAAsB,GAC5D,EAAO,IAAI,CAAC,GAGhB,OAAO,CACT,KICA,SAAS,AAAY,CAAK,EACxB,OAAgB,MAAT,GAAiB,GAAS,CAGpB,CAH0B,MAAM,GAAK,CAAC,GAAW,EAChE,KsDEA,SAAS,AAAK,CAAM,EAClB,OAAO,GAAY,GAAU,GAAc,GAAU,CAGxC,EAHiD,EAChE,K5MzBA,SAAS,AAAa,CAAM,EAC1B,IAAI,EAAS,EAAE,CACf,GAAc,MAAV,AAAgB,EAQP,AAPX,IAAK,IAAI,KAAO,OAAO,GACrB,EAAO,GADuB,CACnB,CAAC,GAGhB,OAAO,CACT,E+LTA,IAAI,GAHc,AAGG,OAHI,SAAS,CAGD,cAAc,QAS/C,SAAS,AAAW,CAAM,EACxB,GAAI,CAAC,GAAS,GACZ,MADqB,CACd,GAAa,AAaT,GAXb,IAAI,EAAU,GAAY,GACtB,EAAS,EAAE,CAEf,IAAK,IAAI,KAAO,EACV,AAAS,CAAR,IADiB,UAChB,EAAwB,EAAC,GAAW,CAAC,GAAe,IAAI,CAAC,EAAQ,EAAA,CAAI,CAAC,CAC1E,EAD6E,AACtE,IAAI,CAAC,GAGhB,OAAO,CACT,KCHA,SAAgB,AAAP,CAAa,EACpB,OAAO,GAAY,GAAU,GAAc,GAAQ,CAGtC,EAH8C,GAAW,EACxE,KpGNA,SAAS,AAAY,CAAM,CAAE,CAAM,EACjC,GAAI,EACF,MADU,CACH,EAAO,IASH,CATQ,GAErB,IAAI,EAAS,EAAO,MAAM,CACtB,EAA6C,IAAI,EAAO,CAA/C,UAA0D,CAAC,GAGxE,OADA,EAAO,IAAI,CAAC,GACL,CACT,K3FxBA,C2FoB6B,Q3FpBpB,AAAU,CAAM,CAAE,CAAK,EAC9B,IAAI,EAAQ,CAAC,EACT,EAAS,EAAO,KASP,CATa,CAG1B,IADA,IAAU,EAAQ,GAAT,GAAe,EAAA,CAAO,CACxB,EAAE,EAAQ,GACf,CAAK,CAAC,EAAM,AADW,CACR,CAAM,CAAC,EAAM,CAE9B,OAAO,CACT,KCRA,SAAS,AAAY,CAAK,CAAE,CAAS,EAMnC,IALA,IAAI,EAAQ,CAAC,EACT,EAAkB,GAaT,GAbA,EAAgB,EAAI,EAAM,MAAM,CACzC,EAAW,EACX,EAAS,EAAE,CAER,EAAE,EAAQ,GAAQ,CACvB,IAAI,EAAQ,CAAK,CAAC,EAAM,CACpB,EAAU,EAAO,EAAO,KAC1B,CAAM,CAAC,CAD2B,GAChB,CAAG,CAAA,CAEzB,CACA,OAAO,CACT,KCJA,SAAS,EACP,MAAO,EAAE,AACX,EqKbA,IAAI,GAHc,AAGS,IrKeZ,GqKlBU,SAAS,CAGK,oBAAoB,CAGvD,GAAmB,OAAO,qBAAqB,CAS/C,GAAa,AAAC,GAA+B,SAAS,CAAM,SAC9D,AAAc,MAAV,AAAgB,EACX,EAAE,CAGJ,GAAY,GADnB,EAAS,OAAO,IAC6B,CAAT,QAAkB,CAAM,EAC1D,OAAO,GAAqB,IAAI,CAAC,EAAQ,EAC3C,EACF,EARqC,UpKXrC,SAAS,AAAU,CAAK,CAAE,CAAM,EAK9B,IAJA,IAAI,EAAQ,CAAC,EACT,EAAS,EAAO,CASP,KATa,CACtB,EAAS,EAAM,MAAM,CAElB,EAAE,EAAQ,GACf,CAAK,CAAC,EADiB,AACR,EAAM,CAAG,CAAM,CAAC,EAAM,CAEvC,OAAO,CACT,E0FdA,IAAI,GAAe,GAAQ,OAAO,cAAc,CAAE,QwIY9C,GATmB,AASJ,CAAC,MATU,qBAAqB,CASA,SAAS,CAAM,EAEhE,IADA,IAAI,EAAS,EAAE,CACR,GACL,GAAU,CADG,CACK,GAAW,IAC7B,ExIdW,AwIcF,GAAa,GAExB,OAAO,CACT,EAPuC,U1FDvC,SAAS,AAAe,CAAM,CAAE,CAAQ,CAAE,CAAW,EACnD,IAAI,EAAS,EAAS,GACtB,KAGa,EAHN,GAAQ,GAAU,EAAS,GAAU,EAAQ,EAAY,GAClE,KgDNA,SAAS,AAAW,CAAM,EACxB,OAAO,GAAe,EAAQ,MAChC,EAEe,GMHf,SAAsB,AAAb,CAAmB,EAC1B,OAAO,GAAe,CNDc,CMCN,GoCWjB,GpCVf,EAEe,ArDZf,IAAI,GAAW,MAAgB,YCA3B,CoDSoC,EpDT1B,MAAgB,MDAL,KEArB,GAAM,MAAgB,ODAF,AEApB,GAAU,MAAgB,WDAV,AkIKhB,GAAS,ajILW,EiIOpB,CADA,EACa,mBACb,GAAS,eACT,GAAa,mBAEb,GAAc,oBAGd,GAAqB,GpIZV,IoIaX,GAAgB,OAChB,GAAoB,GnIdT,ImIeX,GAAgB,GAHc,IAI9B,GAAoB,GAHK,AjIbd,IiIyBX,GAAS,GAXoB,AAc7B,KAAa,GAAO,EAbK,EAaD,GAAS,IAAI,CAZR,WAYoB,MAAQ,IACxD,IAAO,GAAO,IAAI,KAAQ,IAC1B,IAAW,GAAO,GAAQ,OAAO,KAAO,IACxC,IAAO,GAAO,IAAI,KAAQ,IAC1B,IAAW,GAAO,IAAI,KAAY,EAAA,GAAa,CAClD,GAAS,SAAS,CAAK,EACrB,IAAI,EAAS,GAAW,GACpB,EA/BQ,AA+BD,UAAU,WAAY,EAAM,WAAW,MAAG,EACjD,EAAa,EAAO,GAAS,GAAQ,GAEzC,GAAI,EACF,OAAQ,GADM,AAEZ,KAAK,GAAoB,OAAO,EAChC,MAAK,GAAe,OAAO,EAC3B,MAAK,GAAmB,OAAO,EAC/B,MAAK,GAAe,OAAO,EAC3B,MAAK,GAAmB,OAAO,EACjC,CAEF,OAAO,EACT,SAGa,G5QrDf,IAAI,GAHc,AAGG,OAHI,SAAS,CAGD,cAAc,QAS/C,SAAS,AAAe,CAAK,EAC3B,IAAI,EAAS,EAAM,MAAM,CACrB,EAAS,GAUA,CAVI,EAAM,WAAW,CAAC,GAOnC,OAJI,GAA6B,UAAnB,OAAO,CAAK,CAAC,EAAE,EAAgB,GAAe,IAAI,CAAC,EAAO,UAAU,CAChF,EAAO,KAAK,CAAG,EAAM,KAAK,CAC1B,EAAO,KAAK,CAAG,EAAM,KAAK,EAErB,CACT,E8DpBA,IAAI,GAAa,GAAK,UAAU,Q6BMhC,SAAS,AAAiB,CAAW,EACnC,IAAI,EAAS,IAAI,EAAY,QAKhB,GAL2B,CAAC,EAAY,UAAU,EAE/D,OADA,IAAI,GAAW,GAAQ,GAAG,CAAC,IAAI,GAAW,IACnC,CACT,KCHA,SAAS,AAAc,CAAQ,CAAE,CAAM,EACrC,IAAI,EAAS,EAAS,GAAiB,EAAS,KAInC,CAJyC,EAAI,EAAS,MAAM,CACzE,OAAO,IAAI,EAAS,WAAW,CAAC,EAAQ,EAAS,UAAU,CAAE,EAAS,UAAU,CAClF,E3FZA,IAAI,GAAU,cASd,SAAS,AAAY,CAAM,EACzB,IAAI,EAAS,IAAI,EAAO,QAKX,GALsB,CAAC,EAAO,MAAM,CAAE,GAAQ,IAAI,CAAC,IAEhE,OADA,EAAO,SAAS,CAAG,EAAO,SAAS,CAC5B,CACT,E4FXA,IAAI,GAAc,GAAS,GAAO,SAAS,MAAG,EAC1C,GAAgB,GAAc,GAAY,OAAO,MAAG,SCMxD,SAAS,AAAgB,CAAU,CAAE,CAAM,EACzC,IAAI,EAAS,EAAS,GAAiB,EAAW,KAIrC,CAJ2C,EAAI,EAAW,MAAM,CAC7E,OAAO,IAAI,EAAW,WAAW,CAAC,EAAQ,EAAW,UAAU,CAAE,EAAW,MAAM,CACpF,KuJ2BA,SAAS,AAAe,CAAM,CAAE,CAAG,CAAE,CAAM,EACzC,IAAI,EAAO,EAAO,QAmCL,GAnCgB,CAC7B,OAAQ,GACN,IA3BiB,CA2BZ,sBACH,CA3BF,MA2BS,GAAiB,EAE1B,KAvCU,AAuCL,mBACL,CAvCA,GAAU,CAuCL,eACH,CAvCF,MAuCS,IAAI,EAAK,CAAC,EAEnB,KAjCc,AAiCT,oBACH,CAjCF,MAiCS,GAAc,EAAQ,EAE/B,KAnCa,AAmCR,wBAAY,CAlCjB,GAAa,CAkCS,uBACtB,CAlCA,GAAU,CAkCL,oBAAS,CAjCd,GAAW,CAiCQ,qBAAU,CAhC7B,GAAW,CAgCuB,qBAClC,CAhCA,GAAW,CAgCN,qBAAU,CA/Bf,GAAkB,CA+BE,4BAAiB,CA9BrC,GAAY,CA8B8B,sBAAW,CA7BrD,GAAY,CA6B8C,sBACxD,OAAO,GAAgB,EAAQ,EAEjC,KAjDS,AAiDJ,eAUL,CA1DA,GAES,CAwDJ,cATH,CA9CF,MA8CS,IAAI,CAEb,KAnDY,AAmDP,kBACL,CAnDA,GAEY,CAiDP,iBACH,CAjDF,MAiDS,IAAI,EAAK,EAElB,KAAK,AAtDO,kBAuDV,CAtDF,MAsDS,GAAY,EAKrB,KAzDY,AAyDP,kBACH,OxJ1DG,AwJ0DI,GxJ1DY,OAAO,GAAc,IAAI,CwJ0DzB,AxJ1D0B,IAAW,CAAC,CwJ2D7D,CACF,E3JvEA,IAAI,GAAe,OAAO,MAAM,CAU5B,GAAc,WAChB,SAAS,IAAU,CACnB,OAAO,SAAS,CAAK,EACnB,GAAI,CAAC,GAAS,GACZ,KADoB,CACb,CAAC,EAEV,GAAI,GACF,OAAO,GAAa,CADJ,EAGlB,EAAO,SAAS,CAAG,EACnB,IAAI,EAAS,IAAI,EAEjB,OADA,EAAO,SAAS,CAAG,OACZ,CACT,CACF,I2FtBI,GAAY,A9DwBD,I8DxBa,GAAS,KAAK,CAmBtC,GAAQ,GAAY,GAAU,I7BXlC,SAAS,AAAU,A6BW4B,C7BXvB,EACtB,OAAO,GAAa,IAVT,gBAUmB,GAAO,EACvC,EiCVI,GAAY,GjCSiC,CiCTrB,GAAS,KAAK,CAmBtC,GAAQ,GAAY,GAAU,IhCXlC,SAAS,AAAU,AgCW4B,ChCXvB,EACtB,OAAO,GAAa,IAVT,AAUmB,mBAAO,EACvC,EyJcI,GAAU,GzJfmC,kByJoB7C,CAJA,EAIU,oBAIV,CAHA,EAGY,kBAoBZ,CAnBA,EAmBgB,CAAC,EACrB,EAAa,CAAC,GAAQ,CAAG,EAAa,CAAC,AA7BxB,iBA6BiC,CA5B5C,AA6BJ,EAAa,CAAC,AAfO,uBAeQ,CAAG,AAd5B,EAcyC,CAAC,AAd5B,oBAcwC,CAC1D,AAdI,EAcS,CAAC,AA9BA,mBA8BQ,CA7BlB,AA6BqB,EAAa,CA7BxB,AA6ByB,gBAAQ,CA5B3C,AA6BJ,EAAa,CAAC,AAfG,wBAeQ,CAAG,AAdxB,EAcqC,CAAC,AAdzB,wBAcoC,CACrD,AAdI,EAcS,CAAC,AAdA,qBAcQ,CAAG,AAbrB,EAakC,CAAC,AAbxB,sBAaiC,CAChD,AAbI,EAaS,CAAC,AAbC,sBAaQ,CAAG,AAZtB,EAYmC,CA5B1B,AA4B2B,eAAO,CA3B3C,AA4BJ,EAAa,CA5BG,AA4BF,kBAAU,CAAG,EAAa,CAAC,GAAU,CACnD,EAAa,CA3BG,AA2BF,kBAAU,CA1BpB,AA0BuB,EAAa,CA1B3B,AA0B4B,eAAO,CAzB5C,AA0BJ,EAAa,CA1BG,AA0BF,kBAAU,CAzBpB,AAyBuB,EAAa,CAzBxB,AAyByB,kBAAU,CAxB/C,AAyBJ,EAAa,CAhBE,AAgBD,sBAAS,CAfnB,AAesB,EAAa,CAfjB,AAekB,6BAAgB,CAdpD,AAeJ,EAAa,CAfG,AAeF,uBAAU,CAdpB,AAcuB,EAAa,CAAC,AAdzB,uBAcmC,EAAG,EACtD,EAAa,CArCE,AAqCD,iBAAS,CAAG,EAAa,CAAC,GAAQ,CAChD,EAAa,CA5BI,AA4BH,mBAAW,EAAG,SAkB5B,SAAS,EAAU,CAAK,CAAE,CAAO,CAAE,CAAU,CAAE,CAAG,CAAE,CAAM,CAAE,CAAK,EAC/D,IAAI,EACA,EAnEgB,CA6IP,CA1EA,CAlEX,CAmEE,EAnEgB,EAmEP,CAlEX,CAmEE,EAnEmB,AAiEA,EAEV,EAKb,EANuB,CAGnB,IACF,CAHqB,CAGZ,EAAS,EAAW,EADf,AACsB,EAAK,EAAQ,GAAS,EAAW,EAAA,OAExD,IAAX,EACF,KADwB,EACjB,EAET,GAAI,CAAC,GAAS,GACZ,KADoB,EACb,EAET,IAAI,EAAQ,GAAQ,GACpB,GAAI,GAEF,GADA,CADS,CACA,GAAe,GACpB,CAAC,EACH,MADW,CACJ,GAAU,EAAO,EAC1B,KACK,CACL,Y3IpGyB,E2IoGrB,EAAM,E3IpGqB,C2IoGd,GACb,EAAS,GAAO,IA7EX,8BA6EsB,AA5E/B,EA8EA,GAAI,EAFkC,CAEzB,GACX,KADmB,EACZ,GAAY,EAAO,GAE5B,GAAI,GAAO,IAAa,GAAO,IAAY,GAAU,CAAC,GAEpD,GADA,EAD6D,AACnD,GAAU,G9H1Ga,M8H0GH,CAAC,IAAI,C9H1GhC,EAA4C,IAApC,CADQ,E8H2GgC,G9H1GjC,CADO,UACI,EAAmB,GAAY,GAE5D,CAAC,E1FeQ,A0FhBT,GAAW,GAAa,I8H0GpB,CAAC,EACH,MADW,CACJ,G5K7GgB,EcEtB,CADa,E8J6GwB,CAAlC,A5K9GyB,GcCT,AACT,EADW,C8J6GwB,E9J5GhB,GADF,GACkB,E8J6G1C,C5K9GH,KAAmB,G4K6GF,G5K7GwB,I4K6GjB,G/J5GxB,CADW,ACCU,E8J6GY,G9J7GG,CDDnB,AACP,EADS,GACU,G+J6GY,A5K9G9B,AaAc,GACkB,EbDX,CiCAhC,KJiBM,AIjBa,G2I8GJ,G3I9GwB,G2I+G1C,CADyB,I/J7GD,A+J+GnB,CACL,GAAI,C/JhHiC,A+JgHhC,EAAa,CAAC,EAAI,CACrB,CADuB,E3IjHX,I2IkHL,C3IlHwB,C2IkHf,EAAQ,CAAC,EAE3B,EAAS,GAAe,EAAO,EAAK,EACtC,CACF,CAEA,IAAU,EAAQ,GAAT,CAAa,EAAA,CAAK,CAC3B,IAAI,EAAU,EAAM,GAAG,CAAC,GACxB,GAAI,EACF,OADW,AACJ,EAET,EAAM,GAAG,CAAC,EAAO,GzH/GJ,AyHiHT,GAAM,GACR,EAAM,GADU,IACH,CAAC,SAAS,CAAQ,EAC7B,EAAO,GAAG,CAAC,EAAU,EAAU,EAAS,EAAY,EAAU,EAAO,GACvE,G7HpHW,A6HqHF,GAAM,IACf,EAAM,EADiB,KACV,CAAC,SAAS,CAAQ,CAAE,CAAG,EAClC,EAAO,GAAG,CAAC,EAAK,EAAU,EAAU,EAAS,EAAY,EAAK,EAAO,GACvE,GAGF,IAAI,EAAW,EACV,EAAS,GAAe,GACxB,EAAS,GAAS,GAEnB,EAAQ,OAAQ,EAAY,EAAS,GASzC,OARA,GAAU,GAAS,EAAO,SAAS,CAAQ,CAAE,CAAG,EAC1C,IAEF,EAAW,CAFF,AAEO,CADhB,AACiB,EADX,EACW,AAAI,EAGvB,GAAY,EAAQ,EAAK,EAAU,EAAU,EAAS,EAAY,EAAK,EAAO,GAChF,GACO,CACT,KnPpIA,SAAS,AAAM,CAAK,EAClB,OAAO,GAAU,EA7BM,EA8BzB,GAD0B,E7DxBjB,E6D2BM,O7D3BG,CAAM,CAAE,CAAQ,CAAE,CAAQ,EAMxC,IALA,IAAI,EAAQ,CAAC,EACT,EAAW,E8DKJ,K9DLW,GAClB,EAAQ,EAAS,GACjB,EAAS,EAAM,MAAM,CAElB,KAAU,CACf,IAAI,EAAM,CAAK,CAAC,AAAqB,EAAE,EAAM,CAC7C,GAA+C,IADnB,CACxB,EAAS,AAAyC,CAAjC,CAAC,EAAI,CAAE,EAAK,GAC/B,KAEJ,CACA,OAAO,CACT,EyJVF,IAAI,I1FDoB,GyFCxB,ICAe,C1FDiB,EAAE,EyFCzB,AAAW,CAAM,CAAE,CAAQ,EAClC,EzFFyC,KyFElC,GAAU,GAAQ,EAAQ,EAAU,GAC7C,EzFFS,E0FAqB,O1FAZ,CAAU,CAAE,CAAQ,EAClC,GAAkB,MAAd,AAAoB,EACtB,OAAO,EAET,GAAI,CAAC,GAAY,GACf,OAAO,GADqB,AACZ,EAAY,GAM9B,IAJA,EAIQ,EAJJ,EAAS,EAAW,MAAM,AAIV,CAHhB,EAA6B,CAAC,EAC9B,EAAW,CADH,MACU,GAEQ,EAAE,CAHR,CAGgB,IACa,GADJ,CAC3C,EAAS,CAAQ,AAAqC,CAApC,EAAM,CAAE,EAAO,KAIvC,OAAO,CACT,U9DZF,SAAS,AAAS,CAAK,EACrB,OAAO,CACT,K+NiBA,Q/Nfe,C+NeN,AAAQ,CAAU,CAAE,CAAQ,EAEnC,MAAO,CADI,GAAQ,GAAc,GvEvBpB,EuEuBgC,CAIhC,CAHD,EhK3BL,AAAgB,OAAT,GgK2BU,GhK3BY,QgK2BC,EhK3BO,GgK4B9C,AAF+C,E9NhC/C,IAAI,GAAiB,AAHH,OAAO,SAAS,CAGD,cAAc,QAU/C,SAAS,AAAQ,CAAM,CAAE,CAAG,EAC1B,OAAiB,MAAV,GAAkB,GAGZ,AAH2B,IAAI,CAAC,EAAQ,EACvD,K4JOA,SAAS,AAAS,CAAK,EACrB,MAAuB,UAAhB,KAIM,EAJC,GACX,GAAa,IArBF,mBAqBY,GAAW,EACvC,ECtBA,IAAI,EDqB6C,CCrB9B,mDACf,GAAgB,eAUpB,SAAS,AAAM,CAAK,CAAE,CAAM,EAC1B,GAAI,GAAQ,GACV,KADkB,CACX,GAET,CASa,GATT,EAAO,OAAO,QAClB,GAAY,UAAR,GAA4B,UAAR,GAA4B,WAAR,GAC/B,MAAT,GAAiB,GAAS,EAAA,GAAQ,AAG/B,GAAc,IAAI,CAAC,IAAU,CAAC,GAAa,IAAI,CAAC,IACpD,AAAU,SAAQ,KAAS,OAAO,EACvC,E7FuBA,SAAS,GAAQ,CAAI,CAAE,CAAQ,EAC7B,GAAmB,YAAf,OAAO,GAAmC,MAAZ,GAAuC,YAAnB,AAAgC,OAAzB,EAC3D,MAAM,AAAI,UAAU,AAhDF,uBAkDpB,IAAI,EAAW,WACb,IAAI,EAAO,UACP,EAAM,EAAW,EAAS,KAAK,CAAC,IAAI,CAAE,GAAQ,CAAI,CAAC,EAAE,CACrD,EAAQ,EAAS,KAAK,CAE1B,GAAI,EAAM,GAAG,CAAC,GACZ,GADkB,IACX,EAAM,GAAG,CAAC,GAEnB,IAAI,EAAS,EAAK,KAAK,CAAC,IAAI,CAAE,GAE9B,OADA,EAAS,KAAK,CAAG,EAAM,GAAG,CAAC,EAAK,IAAW,EACpC,CACT,EAEA,OADA,EAAS,KAAK,CAAG,IAAI,AAAC,GAAQ,KAAK,IAAI,CAAQ,CACxC,CACT,CAGA,GAAQ,KAAK,CyKvCE,EzKuCC,CEnEhB,IAAI,GAAa,mGAGb,GAAe,WASf,IDME,GAAQ,CAPR,GD0DS,AC1DA,GCCkB,CAAd,QAAuB,CAAM,EAC9C,IAAI,EAAS,EAAE,CAOf,OAN6B,GDHR,ACGW,EAA5B,EAAO,CAA0B,KAAI,IAApB,CAAC,IACpB,EAAO,IAAI,CAAC,IAEd,EAAO,OAAO,CAAC,GAAY,SAAS,CAAK,CAAE,CAAM,CAAE,CAAK,CAAE,CAAS,EACjE,EAAO,IAAI,CAAC,EAAQ,EAAU,OAAO,CAAC,GAAc,MAAS,GAAU,EACzE,GACO,CACT,EDV6B,SAAS,CAAG,EAIrC,OAfmB,MAYf,GAAM,IAAI,EACZ,GAAM,AADW,KACN,GAEN,CACT,IAEmB,KANoB,AAMf,CACjB,WhEbT,SAAS,AAAS,CAAK,CAAE,CAAQ,EAK/B,IAJA,IAAI,EAAQ,CAAC,EACT,EAAkB,IAST,EATA,EAAgB,EAAI,EAAM,MAAM,CACzC,EAAS,MAAM,GAEZ,EAAE,EAAQ,GACf,CAAM,CAAC,EADgB,AACV,CAAG,EAAS,CAAK,CAAC,EAAM,CAAE,EAAO,GAEhD,OAAO,CACT,EoNZA,IAAI,GAAW,EAAI,EAGf,GAAc,GAAS,GAAO,SAAS,MAAG,EAC1C,GAAiB,GAAc,GAAY,QAAQ,CAAG,cAU1D,SAAS,EAAa,CAAK,EAEzB,GAAoB,UAAU,AAA1B,MAcS,CAdF,EACT,OAAO,EAET,GAAI,GAAQ,GAEV,KAFkB,EAEX,GAAS,EAAO,GAAgB,GAEzC,GAAI,GAAS,GACX,KADmB,EACZ,GAAiB,GAAe,IAAI,CAAC,GAAS,GAEvD,IAAI,EAAU,EAAQ,GACtB,MAAkB,KAAX,GAAmB,EAAI,GAAU,CAAC,GAAY,KAAO,CAC9D,KDrBA,SAAS,AAAS,CAAK,CAAE,CAAM,SAC7B,AAAI,GAAQ,GACH,EAEF,GAHa,AAGP,CAGA,CAHO,GAAU,CAAC,EAAM,CAAG,AlJS3B,GCFN,AAAS,QAAO,GAAK,GiJPkC,GAChE,EhJfA,IAAI,GAAW,EAAI,GgJcoC,MhJLvD,QDY2C,CCZlC,AAAM,CAAK,EAClB,GAAoB,UAAhB,OAAO,CAOE,EAPmB,GAAS,GACvC,KAD+C,EACxC,EAET,IAAI,EAAU,EAAQ,GACtB,MAAkB,KAAV,GAAkB,EAAI,GAAU,CAAC,GAAY,KAAO,CAC9D,KuLFA,SAAS,AAAQ,CAAM,CAAE,CAAI,CAAE,CAAO,EACpC,EAAO,GAAS,EAAM,GAMtB,IAJA,GAmBa,CAnBT,EAAQ,CAAC,EACT,EAAS,EAAK,MAAM,CACpB,GAAS,EAEN,EAAE,EAAQ,GAAQ,CACvB,IAAI,EAAM,GAAM,CAAI,CAAC,EAAM,EAC3B,GAAI,CAAC,AAAC,GAAS,AAAU,SAAQ,EAAQ,EAAQ,EAAA,CAAI,CACnD,EADsD,IAGxD,EAAS,CAAM,CAAC,EAAI,AACtB,QACA,AAAI,GAAU,EAAE,GAAS,EAChB,EAGF,CAAC,CADR,AACS,EAJwB,CAGd,MAAV,EAAiB,EAAI,EAAO,MAAA,AAAM,GACxB,GAAS,IAAW,GAAQ,EAAK,KACjD,GAAQ,GAAT,CAAoB,GAAY,EAAA,CAAO,AAC3C,KzFNA,SAAS,AAAI,CAAM,CAAE,CAAI,EACvB,OAAiB,MAAV,GAAkB,GAAQ,AAGpB,EAH4B,EAAM,GACjD,EgHfA,IAAI,GAHc,AAGG,OAHI,SAAS,CAGD,cAAc,QAmC/C,SAAS,AAAQ,CAAK,EACpB,GAAa,MAAT,AAAe,EACjB,OAAO,EAET,CAoBa,EApBT,GAAY,IACX,IAAQ,EAAT,EAAmC,UAAhB,OAAO,GAA4C,YAAvB,OAAO,EAAM,MAAM,EAChE,GAAS,IAAU,GAAa,IAAU,GAAY,EAAA,CAAM,CAChE,EADmE,IAC5D,CAAC,EAAM,MAAM,CAEtB,IAAI,EAAM,GAAO,GACjB,GApDW,gBAoDP,AAnDF,GAAS,IAmDA,YAAU,EACnB,KAD0B,CACnB,CAAC,EAAM,IAAI,CADgB,AAGpC,GAAI,GAAY,GACd,KADsB,CACf,CAAC,GAAS,GAAO,MAAM,CAEhC,IAAK,IAAI,KAAO,EACd,GAAI,CADiB,EACF,IAAI,CAAC,EAAO,GAC7B,GADmC,IAC5B,EAGX,OAAO,CACT,ErF9DA,SAAS,GAAS,CAAM,EACtB,IAAI,EAAQ,CAAC,EACT,EAAmB,MAAV,EAAiB,EAAI,EAAO,MAAM,CAG/C,IADA,IAAI,CAAC,QAAQ,CAAG,IAAI,GACb,EAAE,EAAQ,GACf,IADuB,AACnB,CAAC,GAAG,CAAC,CAAM,CAAC,EAAM,CAE1B,CAGA,GAAS,SAAS,CAAC,GAAG,CAAG,GAAS,SAAS,CAAC,IAAI,C3LVhD,E2LUmD,O3LV1C,AAAY,CAAK,EAExB,OADA,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,EAbC,KAaM,wBAClB,IAAI,AACb,E2LQA,GAAS,SAAS,CAAC,GAAG,C1LftB,E0LeyB,O1LfhB,AAAY,CAAK,EACxB,OAAO,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,EAC3B,SCDA,SAAS,AAAU,CAAK,CAAE,CAAS,EAIjC,IAHA,IAAI,EAAQ,CAAC,EACT,EAAkB,IAUT,EAVA,EAAgB,EAAI,EAAM,MAAM,CAEtC,EAAE,EAAQ,GACf,GAAI,CADmB,CACT,CAAK,CAAC,EAAM,CAAE,EAAO,GACjC,KADyC,EAClC,EAGX,OAAO,CACT,KCZA,SAAS,AAAS,CAAK,CAAE,CAAG,EAC1B,OAAO,EAAM,GAAG,CAAC,EACnB,IAEe,C0LSf,SAAqB,AAAZ,CAAiB,CAAE,CAAK,CAAE,CAAO,CAAE,CAAU,CAAE,CAAS,CAAE,CAAK,EACtE,IAAI,EAjBqB,EAiBT,CAhBd,CAiBE,CA4DS,CA5DG,EAAM,IADI,EACE,CACxB,EAAY,EAAM,MAAM,CAE5B,GAAI,GAAa,GAAa,CAAC,CAAC,GAAa,EAAY,CAAA,CAAS,CAChE,EADmE,KAC5D,EAGT,IAAI,EAAa,EAAM,GAAG,CAAC,GACvB,EAAa,EAAM,GAAG,CAAC,GAC3B,GAAI,GAAc,EAChB,OAAO,GADqB,AACP,GAAS,GAAc,EAE9C,IAAI,EAAQ,CAAC,EACT,GAAS,EACT,EA/BuB,EA+Bf,EAAoC,IAAI,IAA9B,IAAyC,EAM/D,IAJA,EAAM,GAAG,CAAC,EAAO,GACjB,EAAM,GAAG,CAAC,EAAO,GAGV,EAAE,EAAQ,GAAW,CAC1B,IAAI,EAAW,CAAK,CAAC,EAAM,CACvB,EAAW,CAAK,CAAC,EAAM,CAE3B,GAAI,EACF,IAAI,EAAW,EACX,EAFU,AAEC,EAAU,EAAU,EAAO,EAAO,EAAO,GACpD,EAAW,EAAU,EAAU,EAAO,EAAO,EAAO,GAE1D,QAAiB,IAAb,EAAwB,CAC1B,GAAI,EACF,QADY,CAGd,GAAS,EACT,KACF,CAEA,GAAI,GACF,GADQ,AACJ,CAAC,GAAU,EAAO,SAAS,CAAQ,CAAE,CAAQ,EAC3C,GAAI,CAAC,GAAS,EAAM,KACf,IAAa,GAAY,CAA1B,CAAoC,EAAU,EAAU,EAAS,EAAY,EAAA,CAAM,CACrF,EADwF,KACjF,EAAK,IAAI,CAAC,EAErB,GAAI,CACN,GAAS,EACT,MACF,MACK,GAAI,CAAC,CACN,IAAa,GACX,EAAU,EAAU,EAAU,EAAS,EAAY,EAAA,CACvD,CAAG,CACL,GAAS,EACT,KACF,CACF,CAGA,OAFA,EAAM,GAAD,GAAU,CAAC,GAChB,EAAM,GAAD,GAAU,CAAC,GACT,CACT,KzL1EA,SAAS,AAAW,CAAG,EACrB,IAAI,EAAQ,CAAC,EACT,EAAS,MAAM,EAAI,EAQV,EARc,EAK3B,OAHA,EAAI,OAAO,CAAC,SAAS,CAAK,CAAE,CAAG,EAC7B,CAAM,CAAC,EAAE,EAAM,CAAG,CAAC,EAAK,EAC1B,AADgC,GAEzB,CACT,KCRA,SAAS,AAAW,CAAG,EACrB,IAAI,EAAQ,CAAC,EACT,EAAS,MAAM,EAAI,EAQV,EARc,EAK3B,OAHA,EAAI,OAAO,CAAC,SAAS,CAAK,EACxB,CAAM,CAAC,EAAE,EAAM,CAAG,CACpB,GACO,CACT,E0PWA,IAAI,GAAc,GAAS,GAAO,SAAS,CAAG,OAC1C,GAAgB,GAAc,GAAY,OAAO,MAAG,SAmBxD,SAAS,AAAW,CAAM,CAAE,CAAK,CAAE,CAAG,CAAE,CAAO,CAAE,CAAU,CAAE,CAAS,CAAE,CAAK,EAC3E,OAAQ,EAgEK,CA/DX,IAzBc,CAyBT,mBACH,GAAK,EAAO,UAAU,EAAI,EAAM,UAAU,EACrC,EAAO,UAAU,EAAI,EAAM,UAAU,CACxC,CAD2C,KAG7C,CAFS,CAEA,EAAO,MAAM,CACtB,EAAQ,EAAM,MAAM,AAEtB,KAlCiB,AAkCZ,uBACH,CAlCF,EAkCO,EAAO,UAAU,EAAI,EAAM,UAAU,EACtC,CAAC,EAAU,IAAI,GAAW,GAAS,IvMrD9B,AuMqDkC,GAAW,IACpD,KAD6D,CAG/D,CAFS,MAEF,CAET,KAAK,AAnDK,mBAoDV,CAnDA,GAAU,CAmDL,eACL,CAnDA,GAEY,CAiDP,iBAGH,CAnDF,MAmDS,GAAG,CAAC,EAAQ,CAAC,EAEtB,KAxDW,AAwDN,iBACH,CAxDF,MAwDS,EAAO,IAAI,EAAI,EAAM,IAAI,EAAI,EAAO,OAAO,EAAI,EAAM,OAAO,AAErE,KAAK,AAxDO,kBAyDZ,CAxDA,GACY,CAuDP,iBAIH,CA1DF,MA0DS,GAAW,EAAQ,EAE5B,KAAK,AAjEI,eAkEP,CAjEF,GAiEM,EAAU,EAEhB,KAAK,AAjEI,eAkEP,CAjEF,GAiEM,EA5EiB,EA4EL,CA3ElB,CA8EE,GAFA,IAAY,CADc,CACJ,EAAA,CAAU,CAE5B,CAFO,CAEA,IAAI,EAAI,EAAM,IAAI,EAAI,CAAC,EAChC,MAGF,CAHS,EADoC,CAIzC,EAAU,EAAM,GAAG,CAAC,GACxB,GAAI,EACF,OADW,AACJ,GAAW,EAEpB,GAtFuB,EAyFvB,EAAM,GAAG,CAHE,AAGD,EAAQ,GAClB,IAAI,EAAS,GAAY,EAAQ,GAAS,EAAQ,GAAQ,EAAS,EAAY,EAAW,GAE1F,OADA,EAAM,GAAD,GAAU,CAAC,GACT,CAET,KAnFY,AAmFP,kBACH,GAAI,GACF,OAAO,GAAc,GADJ,CACQ,CAAC,IAAW,GAAc,IAAI,CAAC,EAE9D,CACA,OAAO,CACT,E5LpGA,IAAI,GAHc,AAGG,OAHI,SAAS,CAGD,cAAc,QAe/C,SAAS,AAAa,CAAM,CAAE,CAAK,CAAE,CAAO,CAAE,CAAU,CAAE,CAAS,CAAE,CAAK,EACxE,IAAI,EAtBqB,EAsBT,EACZ,CA+DS,CA/DE,GAAW,GADA,AAEtB,EAAY,EAAS,MAAM,CAI/B,CAHI,EAGA,GAHW,AACC,GADU,GACD,IAER,CAFb,CAA2B,EAED,CAAC,EAC7B,OAAO,EADiC,AAI1C,IADA,IAAI,EAAQ,EACL,KAAS,CACd,IAAI,EAAM,CAAQ,CAAC,EAAM,CACzB,GAAI,CAAC,CAAC,EAAY,KAAO,EAAQ,GAAe,IAAI,CAAC,EAAO,EAAA,CAAI,CAC9D,EADiE,KAC1D,CAEX,CAEA,IAAI,EAAa,EAAM,GAAG,CAAC,GACvB,EAAa,EAAM,GAAG,CAAC,GAC3B,GAAI,GAAc,EAChB,OAAO,GADqB,AACP,GAAS,GAAc,EAE9C,IAAI,GAAS,EACb,EAAM,GAAG,CAAC,EAAQ,GAClB,EAAM,GAAG,CAAC,EAAO,GAGjB,IADA,IAAI,EAAW,EACR,EAAE,EAAQ,GAAW,CAE1B,IAAI,EAAW,CAAM,CADrB,AACsB,EADhB,CAAQ,CAAC,EAAM,CACK,CACtB,EAAW,CAAK,CAAC,EAAI,CAEzB,GAAI,EACF,IAAI,EAAW,EACX,EAFU,AAEC,EAAU,EAAU,EAAK,EAAO,EAAQ,GACnD,EAAW,EAAU,EAAU,EAAK,EAAQ,EAAO,GAGzD,GAAI,CAAC,MAAc,IAAb,EACG,IAAa,GAAY,EAAU,EAAU,EAAU,EAAS,EAAY,GAC7E,CAAA,CACJ,CAAG,CACL,GAAS,EACT,KACF,CACA,IAAa,EAAW,AAAO,MAAnB,UAAmB,CAAa,AAC9C,CACA,GAAI,GAAU,CAAC,EAAU,CACvB,IAAI,EAAU,EAAO,WAAW,CAC5B,EAAU,EAAM,WAAW,CAG3B,GAAW,GACV,gBAAiB,GAAU,gBAAiB,GAC7C,CAAC,AAAC,CAAkB,mBAAX,GAAyB,aAAmB,GACjC,YAAlB,OAAO,GAAyB,aAAmB,CAAA,CAAO,GAAG,AACjE,GAAS,CAAA,CAEb,CAGA,OAFA,EAAM,GAAD,GAAU,CAAC,GAChB,EAAM,GAAD,GAAU,CAAC,GACT,CACT,E8M1EA,IAAI,GAAU,qBACV,GAAW,iBACX,GAAY,kBAMZ,GAHc,AAGG,OAHI,SAAS,CAGD,cAAc,QAgB/C,SAAS,AAAgB,CAAM,CAAE,CAAK,CAAE,CAAO,CAAE,CAAU,CAAE,CAAS,CAAE,CAAK,EAC3E,IAAI,EAAW,GAAQ,EA4CV,CA3CT,EAAW,GAAQ,GACnB,EAAS,EAAW,GAAW,GAAO,GACtC,EAAS,EAAW,GAAW,GAAO,GAE1C,EAAS,GAAU,GAAU,GAAY,EACzC,EAAS,GAAU,GAAU,GAAY,EAEzC,IAAI,EAAW,GAAU,GACrB,EAAW,GAAU,GACrB,EAAY,GAAU,EAE1B,GAAI,GAAa,GAAS,GAAS,CACjC,GAAI,CAAC,GAAS,GACZ,KADoB,EACb,EAET,GAAW,EACX,GAAW,CACb,CACA,GAAI,GAAa,CAAC,EAEhB,OADA,CAD0B,EAChB,GAAQ,GAAT,CAAa,ArBhCX,EqBgCW,CAAK,CACnB,GAAY,GAAa,GAC7B,GAAY,EAAQ,EAAO,EAAS,EAAY,EAAW,GAC3D,GAAW,EAAQ,EAAO,EAAQ,EAAS,EAAY,EAAW,GAExE,GAAI,CAAC,CArDoB,EAqDnB,CAAU,CAAoB,CAAG,CACrC,IAAI,EADU,AACK,GAAY,GAAe,IAAI,CAAC,EAAQ,eACvD,EAAe,GAAY,GAAe,IAAI,CAAC,EAAO,eAE1D,GAAI,GAAgB,EAAc,CAChC,IAAI,EAAe,EAAe,EAAO,KAAK,GAAK,EAC/C,EAAe,EAAe,EAAM,KAAK,GAAK,EAGlD,OADA,IAAU,EAAQ,GAAT,CAAa,EAAA,CAAK,CACpB,EAAU,EAAc,EAAc,EAAS,EAAY,EACpE,CACF,OACA,CAAI,CAAC,IAGL,IAAU,EAAQ,CAHF,EAGP,CAAa,EAAA,CAAK,CACpB,GAAa,EAAQ,EAAO,EAAS,EAAY,EAAW,GACrE,K/G/DA,SAAS,EAAY,CAAK,CAAE,CAAK,CAAE,CAAO,CAAE,CAAU,CAAE,CAAK,SAC3D,AAAI,IAAU,AASD,IANA,GAHQ,GAGjB,GAA0B,MAAT,IAAkB,AAAC,GAAa,IAAW,GAAa,EAAA,CAAd,CAGxD,CAH+E,EAG/D,EAAO,EAAO,EAAS,EAAY,EAAa,GAF9D,GAAU,GAAS,GAAU,EAGxC,KCRA,SAAS,AAAY,CAAM,CAAE,CAAM,CAAE,CAAS,CAAE,CAAU,EACxD,IAAI,EAAQ,EAAU,MAAM,CA2Cf,AA1CT,EAAS,EACT,EAAe,CAAC,EAEpB,GAAc,MAAV,AAAgB,EAClB,MAAO,CAAC,EAGV,IADA,EAAS,OAAO,GACT,KAAS,CACd,IAAI,EAAO,CAAS,CAAC,EAAM,CAC3B,GAAK,GAAgB,CAAI,CAAC,EAAE,CACpB,CAAI,CAAC,EAAE,GAAK,CAAM,CAAC,CAAI,CAAC,EAAE,CAAC,CAC3B,CAAC,CAAC,CAAI,CAAC,EAAE,GAAI,CAAA,CAAM,CAEzB,EADI,KACG,CAEX,CACA,KAAO,EAAE,EAAQ,GAAQ,CAEvB,IAAI,EAAM,CADV,EAAO,CAAS,CAAC,EAAA,AAAM,CACT,CAAC,EAAE,CACb,EAAW,CAAM,CAAC,EAAI,CACtB,EAAW,CAAI,CAAC,EAAE,CAEtB,GAAI,GAAgB,CAAI,CAAC,EAAE,EAAE,AAC3B,QAAiB,IAAb,GAA0B,CAAC,CAAC,KAAO,CAAA,CAAM,CAC3C,EAD8C,KACvC,CACT,KACK,CACL,IAAI,EAAQ,IAAI,GAChB,GAAI,EACF,IAAI,EAAS,EAAW,EADV,AACoB,EAAU,EAAK,EAAQ,EAAQ,GAEnE,GAAI,CAAC,MAAY,IAAX,EACE,GAAY,EAAU,EAAU,EAA+C,EAAY,GAC3F,CAAA,CACJ,CACF,EADK,KACE,CAEX,CACF,CACA,IAPmE,GAO5D,CACT,K/FjDA,SAAS,AAAmB,CAAK,EAC/B,OAAO,GAAU,GAAS,CAAC,GAAS,EACtC,EAEe,GqGJf,SAAsB,AAAb,CAAmB,EAI1B,IAHA,IAAI,EAAS,GAAK,GACd,EAAS,EAAO,CAWP,KAXa,CAEnB,KAAU,CACf,IAAI,EAAM,CAAM,CAAC,EAAO,CACpB,EAAQ,CAAM,CAAC,EAAI,CAEvB,CAAM,CAAC,EAAO,CAAG,CAAC,EAAK,EAAO,GAAmB,GAAO,AAC1D,CACA,OAAO,CACT,KnKZA,SAAS,AAAwB,CAAG,CAAE,CAAQ,EAC5C,OAAO,SAAS,CAAM,EAST,OARX,AAAc,MAAV,AAAgB,GAGb,CAAM,CAAC,EAAI,GAAK,SACP,GAAd,CAAC,GAA2B,KAAO,OAAO,EAAA,CAAQ,AACtD,CACF,K6LNA,SAAS,AAAY,CAAM,EACzB,IAAI,EAAY,GAAa,UAC7B,AAAwB,EAQX,CART,EAAU,MAAM,EAAS,CAAS,CAAC,EAAE,CAAC,EAAE,CACnC,CADqC,EACb,CAAS,CAAC,EAAE,CAAC,EAAE,CAAE,CAAS,CAAC,EAAE,CAAC,EAAE,EAE1D,SAAS,CAAM,EACpB,OAAO,IAAW,GAAU,GAAY,EAAQ,EAAQ,EAC1D,CACF,KzBRA,SAAS,AAAQ,CAAM,CAAE,CAAI,EAC3B,EAAO,GAAS,EAAM,GAKtB,IAHA,IAAI,CASS,CATD,EACR,EAAS,EAAK,MAAM,CAEP,MAAV,GAAkB,EAAQ,GAC/B,EAAS,CAAM,CADwB,AACvB,GAAM,CAAI,CAAC,IAAQ,EAAE,CAEvC,OAAQ,GAAS,GAAS,EAAU,OAAS,CAC/C,KrGMA,SAAS,AAAI,CAAM,CAAE,CAAI,CAAE,CAAY,EACrC,IAAI,EAAmB,AAAV,WAIA,EAJiB,EAAY,GAAQ,EAAQ,GAC1D,YAAkB,IAAX,EAAuB,EAAe,CAC/C,K9DtBA,SAAS,AAAU,CAAM,CAAE,CAAG,EAC5B,OAAiB,AAAV,SAAkB,GAGZ,EAHmB,OAAO,EACzC,KkNiBA,SAAS,AAAS,CAAI,QACpB,OAAO,GAAM,IjNrBO,CiNwBP,CAHqB,CjNrBX,CiNqBF,CAAmB,GjNpBjC,MiNoB0C,GjNpBjC,CAAM,EACpB,OAAO,AAAU,aAAO,EAAY,CAAM,CAAC,EAAI,AACjD,G8DAO,SAAS,CAAM,EACpB,OAAO,GAAQ,EmJiBiD,EnJhBlE,CmJiBF,GnJlB2B,E+JE3B,SAAS,AAAa,CAAK,EAGzB,GAAoB,YAAhB,AAA4B,MAcnB,CAdF,EACT,OAAO,EAET,GAAa,MAAT,AAAe,EACjB,OAAO,GAET,GAAoB,UAAU,AAA1B,OAAO,OkCFgB,EAAM,EAAF,AlCG7B,MkCHuC,ClCGhC,GAAQ,MACS,CAAK,CAAC,CAA1B,CAA4B,GAAE,CAAK,CAAC,EAAE,CkCHxC,AAAJ,GAAU,IAAS,GAAmB,GAC7B,GAAwB,GAAM,EADU,CACH,GAEvC,SAAS,CAAM,EACpB,IAAI,EAAW,GAAI,EAAQ,GAC3B,YAAqB,IAAd,GAA2B,IAAa,E9GI1C,AAAU,S8GHX,A9GGmB,G8GHb,EAAQ,E9GG2B,I8GFzC,GAAY,EAAU,EAAU,EACtC,GlCJM,GAAY,EAAA,CAElB,K5EGiC,E4EH1B,GAAS,EAClB,CkCA+D,A9GEpB,I3BnB3C,SAAS,AAAQ,CAAU,CAAE,CAAQ,EACnC,IAAI,EAAQ,CAAC,EACT,EAAS,GAAY,GAAc,EAQ1B,IARgC,EAAW,MAAM,EAAI,EAAE,CAKpE,OAHA,GAAS,EAAY,SAAS,CAAK,CAAE,CAAG,CAAE,CAAU,EAClD,CAAM,CAAC,EAAE,EAAM,CAAG,EAAS,EAAO,EAAK,EACzC,GACO,CACT,K4F4BA,SAAS,AAAI,CAAU,CAAE,CAAQ,EAE/B,MADW,AACJ,IADY,GAAc,GAAW,EAAA,CAI/B,CAHD,EAAY,GAAa,EAAU,GACjD,K3FrBA,SAAS,AAAO,CAAM,EACpB,OAAiB,MAAV,EAAiB,EAAE,CxDjBnB,EwDiBsB,CAGhB,AAHmC,GAAK,GxDjB9B,SAAS,CAAG,EACjC,OAAO,AwDgB+B,CxDhBzB,CAAC,EAAI,AACpB,EAFgB,AwDkBlB,0G0ItB6B,EAAE,2CzOTO,MAC9B,EAAA,IAAA,OAAA,OAAA,qBsFEG,IAAA,OAAA,OAAA,8H7GMX,SAAS,AAAU,CAAK,CAAE,CAAK,CAAE,CAAG,EAClC,IAAI,EAAQ,CAAC,EACT,EAAS,EAAM,IAmBN,EAnBY,AAErB,GAAQ,GAAG,AACb,GAAQ,CAAC,EAAQ,EAAS,EAAK,EAAS,CAAA,EAGtC,CADJ,EAAM,EAAM,EAAS,EAAS,CAAA,EACpB,GAAG,CACX,GAAO,CAAA,EAET,EAAS,EAAQ,EAAM,EAAM,EAAM,IAAW,EAC9C,KAAW,EAGX,IADA,IAAI,EAAS,MAAM,GACZ,EAAE,EAAQ,GACf,CAAM,CAAC,EADgB,AACV,CAAG,CAAK,CAAC,EAAQ,EAAM,CAEtC,OAAO,CACT,EC3BA,IAAI,GAAe,YAUnB,SAAS,AAAgB,CAAM,EAG7B,IAFA,IAAI,EAAQ,EAAO,MAAM,CAElB,EAIM,GAJK,GAAa,IAAI,CAAC,EAAO,MAAM,CAAC,MAClD,EAD2D,CAAC,IACrD,CACT,E8DbA,IAAI,GAAc,O8GEd,GAAM,EAAI,EAGV,GAAa,qBAGb,GAAa,aAGb,GAAY,cAGZ,GAAe,gBAyBnB,SAAS,AAAS,CAAK,EACrB,GAAoB,UAAU,AAA1B,OAAO,CAoBE,CAnBX,OAAO,EAET,GAAI,GAAS,GACX,KADmB,EACZ,GAET,GAAI,GAAS,GAAQ,CACnB,MAAI,EAAgC,YAAxB,OAAO,EAAM,OAAO,CAAiB,EAAM,OAAO,GAAK,EACnE,EAAQ,GAAS,GAAU,EAAQ,GAAM,CAC3C,CACA,GAAoB,UAAhB,AAA0B,OAAnB,EACT,OAAiB,IAAV,EAAc,EAAQ,CAAC,EAEhC,E9G3CO,CADS,E8G4CC,G9G1Cb,A8G0CI,C9G5Cc,CAEX,KAAK,CAAC,EAAG,GAAgB,GAAU,GAAG,OAAO,CAAC,GAAa,IAClE,E8G0CJ,IAAI,EAAW,GAAW,IAAI,CAAC,GAC/B,OAAO,GAAa,GAAU,IAAI,CAAC,GAC/B,GAAa,EAAM,KAAK,CAAC,GAAI,EAAW,EAAI,GAC3C,GAAW,IAAI,CAAC,GAAS,GAAM,CAAC,CACvC,E7G1DA,IAAI,GAAW,EAAI,GACf,MCwBJ,SAAS,AAAU,CAAK,EACtB,MAAI,EDCJ,CADgB,ECAM,CDClB,CAAC,CAID,AALiB,CAIrB,ACJa,EDIL,GAHI,AAGK,CCEJ,CDFI,IACH,IAAY,IAAU,CAAC,GAE5B,CADK,EAAQ,EAAI,CAAC,CACX,CAF+B,CAChB,EA/Bf,sBAkCT,GAAU,EAAQ,EAAQ,EAPd,IAAV,EAAc,EAAQ,ECD3B,EAAY,EAAS,EAEzB,OAAO,GAAW,EAAU,EAAY,EAAS,EAAY,EAAU,CACzE,K4DLA,SAAS,AAAK,CAAK,CAAE,CAAC,CAAE,CAAK,EAC3B,IAAI,EAAkB,MAAT,EAAgB,EAAI,CAQpB,CAR0B,MAAM,QACxC,AAAL,EAIO,EAJH,CAIa,EAAO,CAJX,AAGb,EAAK,QAAe,IAAN,EAAmB,EAAI,GAAU,EAAA,EACnB,EAAI,EAAI,EAAG,GAH9B,EAAE,AAIb,K3HzBA,SAAS,AAAM,CAAI,CAAE,CAAO,CAAE,CAAI,EAChC,OAAQ,EAAK,MAAM,EACjB,AAQW,KARN,EAAG,OAAO,EAAK,IAAI,CAAC,EACzB,MAAK,EAAG,OAAO,EAAK,IAAI,CAAC,EAAS,CAAI,CAAC,EAAE,CACzC,MAAK,EAAG,OAAO,EAAK,IAAI,CAAC,EAAS,CAAI,CAAC,EAAE,CAAE,CAAI,CAAC,EAAE,CAClD,MAAK,EAAG,OAAO,EAAK,IAAI,CAAC,EAAS,CAAI,CAAC,EAAE,CAAE,CAAI,CAAC,EAAE,CAAE,CAAI,CAAC,EAAE,CAC7D,CACA,OAAO,EAAK,KAAK,CAAC,EAAS,EAC7B,EgEfA,IAAI,GAAY,KAAK,GAAG,C9DEpB,GAAY,KAAK,GAAG,C2HMpB,I3HKc,GwLJI,CAAC,AxLID,EwLJ6B,I7DDjC,K6DC0C,CAAI,CAAE,CAAM,EACtE,OAAO,GAAe,EAAM,WAAY,C7DFf,A6DGvB,cAAgB,EAChB,YAAc,EACd,MzLIK,GyLJI,QzLKT,OyLLkB,AzLKX,CACT,EyLLE,UAAY,CACd,EACF,EAPwC,GxLKlC,GAAQ,EACR,GAAa,EAEV,WACL,IAAI,EAAQ,KACR,EApBO,AAoBK,IAAY,EAAQ,EAAA,CAAU,CAG9C,CAH2B,EAE3B,GAAa,EACT,EAAY,GAAG,AACjB,GAAI,EAAE,IAzBI,IA0BR,CAzBJ,AAwBiB,MACN,KADiB,IACR,CAAC,EAAE,AACrB,MAEA,GAAQ,EAEV,OAAO,GAAK,KAAK,MAAC,EAAW,UAC/B,U2KrBF,SAAS,AAAS,CAAI,CAAE,CAAK,M7GEL,E6GDtB,G7GC2B,EAAE,E6GDtB,AhDAM,I7DEb,EAAQ,A6GCK,C7GFyB,EACpB,KAAU,O6GFM,G7GEO,A6GFb,E7GEkB,MAAM,CAAG,C6GFpC,C7GEyC,EAAO,GAC5D,WAML,IALA,IAAI,EAAO,UACP,EAAQ,CAAC,EACT,EAAS,GAAU,EAAK,MAAM,CAAG,EAAO,GACxC,EAAQ,MAAM,GAEX,EAAE,EAAQ,GACf,CAAK,CAAC,EADiB,AACX,CAAG,CAAI,CAAC,EAAQ,EAAM,CAEpC,EAAQ,CAAC,EAET,IADA,IAAI,EAAY,MAAM,EAAQ,GACvB,EAAE,EAAQ,GACf,CAAS,CAAC,CADY,CACN,CAAG,CAAI,CAAC,EAAM,CAGhC,OADA,CAAS,CAAC,EAAM,CAAG,A6GjBoB,G7GiBV,GACtB,KAAY,IAAI,CAAE,EAC3B,G6GnBoD,EAAO,GAC7D,KqCCA,SAAS,AAAe,AlJgBP,CkJhBY,CAAE,CAAK,CAAE,CAAM,EAC1C,GAAI,CAAC,GAAS,GACZ,MADqB,CACd,AAYI,EAVb,IAAI,EAAO,OAAO,QAClB,CAAY,UAAR,KACK,GAAY,IAAW,GAAQ,EAAO,EAAO,OAAM,EAC3C,UAAR,GAAoB,KAAS,CAAA,GAChC,AACG,GAAG,CAAM,CAAC,EAAM,CAAE,EAG7B,EiChBA,IAAI,GAHc,AAGG,OAHI,SAAS,CAGD,cAAc,CAkC3C,OAAwB,EAAf,OAAwB,CAAM,CAAE,CAAM,EACjD,GAAI,GAAY,IAAW,GAAY,GAAS,YAC9C,GAAW,EAAQ,GAAK,GAAS,GAGnC,IAAK,IAAI,KAAO,EACV,GAAe,EADG,EACC,CAAC,EAAQ,IAC9B,EADoC,CACxB,EAAQ,EAAK,CAAM,CAAC,EAAI,CAG1C,ErH5CS,GAAS,SAAS,CAAM,CAAE,CAAO,EACtC,IAAI,EAAQ,CAAC,EACT,EAAS,EAAQ,MAAM,CACvB,EAAa,EAAS,EAAI,CAAO,CAAC,EAAS,EAAE,MAAG,EAChD,EAAQ,EAAS,EAAI,CAAO,CAAC,EAAE,MAAG,EAWtC,IATA,EAAc,GAAS,MAAM,CAAG,GAA0B,YAArB,CACjC,MADwC,GACvC,IAAU,CAAA,CAAU,CACrB,OAEA,GAAS,GAAe,CAAO,CAAC,EAAE,CAAE,CAAO,CAAC,EAAE,CAAE,KAClD,EAAa,CAD6C,CACpC,OAAI,EAAY,EACtC,EAAS,GAEX,EAAS,OAAO,GACT,EAAE,EAAQ,GAAQ,CACvB,IAAI,EAAS,CAAO,CAAC,EAAM,CACvB,GACF,GAAS,EAAQ,AADP,EACe,EAAO,EAEpC,CACA,OAAO,CACT,I8D5BE,GAAe,IAAY,GAAS,QAAQ,CAmB5C,GAAW,GAAe,GAAU,I7DXxC,SAAS,AAAa,CAAK,E6DW6B,A7DVtD,OAAO,GAAa,IAVN,mBAUgB,GAAW,EAC3C,QADqD,C8DUrD,SAAS,AAAS,CAAK,EACrB,MAAuB,UAAhB,KAIM,EAJC,GACX,CAAC,GAAQ,IAAU,GAAa,IArBrB,mBAqB+B,GAAW,EAC1D,KkCXA,GlCUoE,MkCV3D,AAAQ,CAAM,CAAE,CAAI,CAAE,CAAK,CAAE,CAAU,EAC9C,GAAI,CAAC,GAAS,GACZ,KAgCW,CAjCU,CACd,EAET,EAAO,GAAS,EAAM,GAOtB,IALA,IAAI,EAAQ,CAAC,EACT,EAAS,EAAK,MAAM,CACpB,EAAY,EAAS,EACrB,EAAS,EAEI,MAAV,GAAkB,EAAE,EAAQ,GAAQ,CACzC,IAAI,EAAM,GAAM,CAAI,CAAC,EAAM,EACvB,EAAW,EAEf,GAAY,cAAR,GAA+B,gBAAR,GAAiC,aAAa,CAArB,EAClD,MAGF,CAHS,EAGL,GAAS,EAAW,CACtB,IAAI,EAAW,CAAM,CAAC,EAAI,AAEtB,AAAa,WADjB,AAC4B,EADjB,EAAa,EAAW,EAAU,EAAK,QAAU,CAAA,IAE1D,EAAW,GAAS,GAChB,EACC,GAAQ,CAAI,CAAC,EAAQ,EAAE,EAAI,EAAE,CAAG,EAAC,CAE1C,CACA,GAAY,EAAQ,EAAK,GACzB,EAAS,CAAM,CAAC,EAAI,AACtB,CACA,OAAO,CACT,K1DnCA,SAAS,AAAW,CAAM,CAAE,CAAK,CAAE,CAAS,EAK1C,IAJA,IAAI,EAAQ,CAAC,EACT,EAAS,EAcA,AAdM,MAAM,CACrB,EAAS,CAAC,EAEP,EAAE,EAAQ,GAAQ,CACvB,IAAI,EAAO,CAAK,CAAC,EAAM,CACnB,EAAQ,GAAQ,EAAQ,GAExB,EAAU,EAAO,IACnB,GAD0B,AAClB,EAAQ,GAAS,EAAM,GAAS,EAE5C,CACA,OAAO,CACT,KgCJA,SAAS,AAAO,CAAM,CAAE,CAAS,EAC/B,GAAc,MAAV,AAAgB,EAClB,MAAO,CAAC,CAWG,CATb,IAAI,EAAQ,GAAS,GAAa,GAAS,SAAS,CAAI,EACtD,MAAO,CAAC,EAAK,AACf,GAEA,OADA,EAAY,GAAa,GAClB,GAAW,EAAQ,EAAO,SAAS,CAAK,CAAE,CAAI,EACnD,OAAO,EAAU,EAAO,CAAI,CAAC,EAAE,CACjC,EACF,yT/JsC2B,KAAA,uBAAA,KACV,CAAA,cAAA,CAAA,UAAA,6BAWX,MAAA,WAAA,sD6M3BS,8B7M4CT,MAAA,WAAA,+NA8CH,CAAA,uCAGO,CACJ,GAAA,EAAA,GAAA,KAAA,IAAA,8CAkBI,EAAA,UAAA,6BmLZmC,KAAA,InLehB,CAAC,AmLfe,4InLsDpC,CAAA,EAAA,UAAA,wBAGI,EAAA,GAAA,KAAA,IAAA,sBAMH,sGAsBA,EAAA,UAAA,qEAGJ,GAAA,EAAA,AAAiB,GAAA,KAAA,IAAA,KAKjB,MAAA,eAKQ,CkQ1HG,AJqCA,AZ4FA,A/O/BR,AyJpBA,A5JgDN,CAAA,yBAGoB,GAAA,KAAA,IAAA,0BAKD,kBZ5PP,CAAA,CAAA,QACL,oDAAA,wCAAA,mCAAA,gDAAA,4DAW+C,CAX/C,oDAAA,uCAAA,wCAAA,qCAAA,iCAAA,mSvBNV,SAAS,AAAW,CAAK,CAAE,CAAS,EAIlC,IAHA,IAAI,EAAQ,CAAC,EACT,EAAkB,IAUT,EAVA,EAAgB,EAAI,EAAM,MAAM,CAEtC,EAAE,EAAQ,GACf,GAAI,CADmB,AAClB,EAAU,CAAK,CAAC,EAAM,CAAE,EAAO,GAClC,KAD0C,EACnC,EAGX,OAAO,CACT,K8DTA,SAAS,AAAU,CAAU,CAAE,CAAS,EACtC,IAAI,GAAS,EAKb,OAJA,GAOa,AAPJ,EAAY,SAAS,CAAK,CAAE,CAAK,CAAE,CAAU,EAEpD,OADA,AACO,EADE,CAAC,CAAC,EAAU,EAAO,EAAO,EAErC,GACO,CACT,K+J6BA,SAAS,AAAM,CAAU,CAAE,CAAS,CAAE,CAAK,EACzC,IAAI,EAAO,GAAQ,GAAc,GAAa,EAOjC,CAHb,OAHI,GAAS,GAAe,EAAY,EAAW,KACjD,GADyD,IAC7C,CAAA,EAEP,EAAK,EAAY,GAAa,EAAW,GAClD,K5N1CA,SAAS,AAAc,CAAK,CAAE,CAAS,CAAE,CAAS,CAAE,CAAS,EAI3D,IAHA,IAAI,EAAS,EAAM,GAWN,GAXY,CACrB,EAAQ,GAAa,EAAY,EAAI,EAAC,CAAC,CAEnC,CAFgB,CAEJ,IAAU,EAAE,EAAQ,GACtC,GAAI,CAD2C,CACjC,CAAK,CAAC,EAAM,CAAE,EAAO,GACjC,KADyC,EAClC,EAGX,OAAO,CAAC,CACV,KCdA,SAAS,AAAU,CAAK,EACtB,OAAO,GAAU,CACnB,KCCA,KDCe,ICDN,AAAc,CAAK,CAAE,CAAK,CAAE,CAAS,EAI5C,IAHA,IAAI,EAAQ,EAAY,EACpB,EAAS,CAUA,CAVM,MAAM,CAElB,EAAE,EAAQ,GACf,GAAI,CADmB,AACd,CAAC,EAAM,GAAK,EACnB,KAD0B,EACnB,EAGX,OAAO,CAAC,CACV,K8KPA,SAAS,AAAY,CAAK,CAAE,CAAK,CAAE,CAAS,EAC1C,OAAO,GAAU,EACb,GAAc,EAAO,AAIZ,EAJmB,GAC5B,GAAc,EAAO,GAAW,EACtC,E6CVA,IAAI,GAAY,KAAK,GAAG,QAgCxB,SAAS,AAAS,CAAU,CAAE,CAAK,CAAE,CAAS,CAAE,CAAK,EACnD,EAAa,GAAY,GAAc,EAAa,GAAO,EAY9C,CAXb,EAAa,GAAa,CAAC,EAAS,GAAU,GAAa,EAE3D,IAAI,EAAS,EAAW,MAAM,CAI9B,OAHI,EAAY,GAAG,CACjB,EAAY,GAAU,EAAS,EAAW,EAAA,EAErC,GAAS,GACX,GAAa,GAAU,EAAW,OAAO,CAAC,EAAO,GAAa,CAAC,EAC/D,CAAC,CAAC,GAAU,GAAY,EAAY,EAAO,GAAa,CAAC,CAChE,K/JvCA,SAAS,AAAS,CAAU,CAAE,CAAS,EACrC,IAAI,EAMJ,OAJA,GAAS,EAAY,CAOR,QAPiB,CAAK,CAAE,CAAK,CAAE,CAAU,EAEpD,MAAO,CAAC,CADR,EAAS,EAAU,EAAO,EAAO,EAAA,CAEnC,GACO,CAAC,CAAC,CACX,KgKuBA,SAAS,AAAK,CAAU,CAAE,CAAS,CAAE,CAAK,EACxC,IAAI,EAAO,GAAQ,GAAc,GAAY,EAOhC,CAHb,OAHI,GAAS,GAAe,EAAY,EAAW,IACjD,IADyD,IAC7C,CAAA,EAEP,EAAK,EAAY,GAAa,EAAW,GAClD,qJxLGqE,EAAA,mEAUtD,GAAA,EAAA,oNA0BF,aAAA,mKEpED,EAAA,UAAA,CAAA,CAAA,EAAwC,2BACP,EAAA,oHAMT,uHAKW,WAC9B,aAAA,sCAEJ,GAAA,aAAA,yBAAgD,EFiBM,A6OWA,qF3OvB5B,CR0BS,A8NsFA,mBtN9G5B,0BAKlB,C2PuBC,A7PHA,AgMiFE,AkCpEA,YAAA,ChOhCiB,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,2CAiBC,EAAA,MAAA,CAAgB,+FAoB7B,EAAA,qGAeJ,wHAoBqB,CAAA,YAKrB,EAAA,+FAkBkD,GAAK,qBAM7D,CsPkJC,A3QjFA,QAAA,GAAA,CqBhEoC,CACnC,CAAuB,CACvB,CAAuB,K4P3CA,wD5PgDgC,qCAIW,GyI3JpE,IAAI,GAAmB,GAAS,GAAO,kBAAkB,MAAG,SAS5D,SAAS,AAAc,CAAK,EAC1B,OAAO,GAAQ,IzBoBF,AyBpBY,GAAY,IAIxB,AAHX,CAAC,CAAC,CAAC,IAAoB,GAAS,CAAK,CAAC,GAAA,AAAiB,CAC3D,KpDHA,SAAS,EAAY,CAAK,CAAE,CAAK,CAAE,CAAS,CAAE,CAAQ,CAAE,CAAM,EAC5D,IAAI,EAAQ,CAAC,EACT,EAqBS,AArBA,EAAM,MAAM,CAKzB,IAHA,IAAc,EAAY,EAAA,CAAa,CACvC,GADa,CACF,EAAS,EAAE,AAAF,EAAV,AAEH,EAAE,EAAQ,GAAQ,CACvB,IAAI,EAAQ,CAAK,CAAC,EAAM,CACpB,EAAQ,GAAK,EAAU,GACrB,EAAQ,EAEV,CAH+B,AAClB,CAED,EAAO,EAAQ,EAAG,EAAW,EAAU,GAEnD,GAAU,EAAQ,GAEX,AAAC,IACV,CAAM,CAAC,EAAO,EADM,IACA,CAAC,CAAG,CAAA,CAE5B,CACA,OAAO,CACT,K9DnBA,SAAS,AAAQ,CAAK,EAEpB,MAAO,CADe,MAAT,EAAgB,EAAI,EAAM,EAI1B,IAJgC,AAAN,EACvB,GAAY,EAAO,GAAK,EAAE,AAC5C,KCRA,SAAS,AAAc,CAAK,CAAE,CAAK,EAEjC,MAAO,CAAC,CAAC,CADa,MAAT,EAAgB,EAAI,AAIpB,EAJ0B,MAAA,AAAM,GAC1B,GAAY,EAAO,EAAO,GAAK,CAAC,CACrD,K7DLA,SAAS,AAAkB,CAAK,CAAE,CAAK,CAAE,CAAU,EAIjD,IAHA,IAAI,EAAQ,CAAC,EACT,EAAkB,EAUT,IAVA,EAAgB,EAAI,EAAM,MAAM,CAEtC,EAAE,EAAQ,GACf,GAAI,CADmB,CACR,EAAO,CAAK,CAAC,EAAM,EAChC,CADmC,MAC5B,EAGX,OAAO,CACT,KCPA,SAAS,EAET,EiLAA,IAAI,GAAY,AAAE,CAAD,GAAS,EAAI,GAAW,IhER1B,AjHUA,AiLF8B,GAAI,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,EAT5C,EAAI,AAS6C,EAAmB,OAAX,EAAoB,CAAM,EAChG,OAAO,IAAI,GAAI,EACjB,EAF4E,UyDK5E,SAAS,AAAS,CAAK,CAAE,CAAQ,CAAE,CAAU,EAC3C,IAAI,EAAQ,CAAC,EACT,EAAW,GACX,EAAS,CAiDA,CAjDM,MAAM,CACrB,EAAW,GACX,EAAS,EAAE,CACX,EAAO,EAEX,GAAI,EACF,GAAW,EACX,EAAW,GAFG,KAIX,GAAI,GAvBY,IAuBgB,CACnC,EADiB,EACb,EAAM,EAAW,KAAO,AzDdjB,GyDc2B,GACtC,GAAI,EACF,GADO,IACA,GAAW,GAEpB,EAAW,GACX,EAAW,GACX,EAAO,IlEZI,AkEYA,EACb,MAEE,CADG,CACI,EAAW,EAAE,CAAG,EAEzB,EACA,KAAO,EAAE,EAAQ,GAAQ,CACvB,IAAI,EAAQ,CAAK,CAAC,EAAM,CACpB,EAAW,EAAW,EAAS,GAAS,EAG5C,GADA,EAAQ,GAAyB,AAAV,MAAe,EAAQ,EAC1C,GAAY,GAAa,EAAU,CAErC,IADA,IAAI,EAAY,EAAK,MAAM,CACpB,KACL,GAAI,CAAI,CAAC,EADS,AACC,GAAK,EACtB,QADgC,CACvB,EAGT,GACF,EAAK,IAAI,CADG,AACF,GAEZ,EAAO,IAAI,CAAC,EACd,MACU,CAAL,CAAc,EAAM,CAAhB,CAA0B,KAC7B,IAAS,GACX,CAF4C,CAEvC,GADc,CACV,CAAC,GAEZ,EAAO,IAAI,CAAC,GAEhB,CACA,OAAO,CACT,K7KjDA,SAAS,AAAK,CAAK,EACjB,OAAQ,GAAS,EAAM,MAAM,CAAI,EAGpB,CAH6B,GAAS,EAAE,AACvD,6G3BFI,aAAA,IAAA,aAAA,IAAA,aAAA,IAAA,aAAA,IAAA,aAAA,IAAA,aAAA,IAAA,aAAA,IAAA,aAAA,mLHsCI,GAAA,EAAA,UAAA,CAAA,AAEH,iRoEzBuD,EAAQ,GAAG,CAAC,YAAA,IAAA,CAAA,OAAA,CAAA,IAAA,cAGnC,qDlGrBrC,SAAqB,AAAZ,CAAiB,EACxB,YAAiB,IAAV,CACT,IAEe,CCNf,SAAS,AAAQ,CAAK,EAMpB,IALA,IAAI,EAAQ,CAAC,EACT,EAAkB,MAaT,AAbA,EAAgB,EAAI,EAAM,MAAM,CACzC,EAAW,EACX,EAAS,EAAE,CAER,EAAE,EAAQ,GAAQ,CACvB,IAAI,EAAQ,CAAK,CAAC,EAAM,CACpB,IACF,CAAM,CAAC,CADE,GACS,CAAG,CAAA,CAEzB,CACA,OAAO,CACT,EgMtBA,IAAI,GAAc,OAAO,SAAS,CAG9B,GAAiB,GAAY,cAAc,CAuB3C,GAAW,GAAS,SAAS,CAAM,CAAE,CAAO,EAC9C,EAAS,OAAO,GAEhB,IAAI,EAAQ,CAAC,EACT,EAAS,EAAQ,MAAM,CACvB,EAAQ,EAAS,EAAI,CAAO,CAAC,EAAE,MAAG,EAMtC,IAJI,GAAS,GAAe,CAAO,CAAC,EAAE,CAAE,CAAO,CAAC,EAAE,CAAE,KAClD,GAD0D,AACjD,EAGJ,EAAE,EAAQ,GAMf,IANuB,AACvB,IAAI,EAAS,CAAO,CAAC,EAAM,CACvB,EAAQ,GAAO,GACf,EAAa,CAAC,EACd,EAAc,EAAM,MAAM,CAEvB,EAAE,EAAa,GAAa,CACjC,IAAI,EAAM,CAAK,CAAC,EAAW,CACvB,EAAQ,CAAM,CAAC,EAAI,OAET,IAAV,GACC,GAAG,EAAO,EAAW,CAAC,EAAI,GAAK,CAAC,GAAe,IAAI,CAAC,EAAQ,EAAA,GAAO,CACtE,CAAM,CAAC,EAAI,CAAG,CAAM,CAAC,EAAA,AAAI,CAE7B,CAGF,OAAO,CACT,UqCxCA,SAAS,AAAe,CAAK,CAAE,CAAM,CAAE,CAAQ,CAAE,CAAU,EACzD,IAAI,EAAQ,CAAC,EACT,EAAW,GACX,CA0CS,CA1CE,GACX,EAAS,EAAM,MAAM,CACrB,EAAS,EAAE,CACX,EAAe,EAAO,MAAM,CAEhC,GAAI,CAAC,EACH,MADW,CACJ,EAEL,IACF,EAAS,GAAS,CADN,CACc,GAAU,GAAA,EAElC,GACF,EAAW,GACX,GAAW,CAFG,EAIP,EAAO,MAAM,EA/BD,EA+BK,IACxB,EAAW,GACX,GAAW,EACX,EAAS,GAHiC,CAG7B,GAAS,IAExB,EACA,KAAO,EAAE,EAAQ,GAAQ,CACvB,IAAI,EAAQ,CAAK,CAAC,EAAM,CACpB,EAAuB,MAAZ,EAAmB,EAAQ,EAAS,GAGnD,GADA,EAAS,GAAwB,IAAV,EAAe,EAAQ,EAC1C,GAAY,GAAa,EAAU,CAErC,IADA,IAAI,EAAc,EACX,KACL,GAAI,CAAM,CAAC,EAAY,EADH,CACQ,EAC1B,QADoC,CAC3B,EAGb,EAAO,IAAI,CAAC,EACd,MACS,AAAC,CAAL,CAAc,EAAQ,EAAU,IACnC,EAAO,IAAI,CAAC,EADoC,AAGpD,CACA,OAAO,CACT,K3GpCA,SAAS,AAAkB,CAAK,EAC9B,OAAO,GAAa,IAAU,GAAY,EAC5C,EAEe,AuENf,IAAI,GAAa,GAAS,SAAS,CAAK,CAAE,CAAM,EAC9C,OAAO,GAAkB,GACrB,GAAe,EAAO,GAAY,EAAQ,EAAG,IAAmB,IAChE,EAAE,AACR,UpIpBA,SAAS,AAAW,CAAU,CAAE,CAAS,EACvC,IAAI,EAAS,EAAE,CAMf,OALA,GAAS,AAQI,EARQ,SAAS,CAAK,CAAE,CAAK,CAAE,CAAU,EAChD,EAAU,EAAO,EAAO,IAC1B,EAAO,IAAI,CAAC,EAD2B,AAG3C,GACO,CACT,KqI4BA,SAAS,AAAO,CAAU,CAAE,CAAS,EAEnC,MAAO,CADI,GAAQ,GAAc,GAAc,EAAA,CAIlC,CAHD,EAAY,GAAa,EAAW,GAClD,E7B5CA,IAAI,GAAY,KAAK,GAAG,C1CkCpB,IyC5BgB,GzC4BT,A0CGX,SAAS,AAAU,CAAK,AD/BS,CC+BP,CAAS,CAAE,CAAS,EAC5C,IAAI,EAAkB,MAAT,EAAgB,EAAI,E1CJb,A0CImB,MAAM,CAC7C,GAAI,CAAC,EACH,MADW,CACJ,CAAC,EAEV,IAAI,EAAqB,MAAb,EAAoB,EAAI,GAAU,GAI9C,OAHI,EAAQ,GAAG,AACb,GAAQ,GAAU,EAAS,EAAO,EAAA,EAE7B,GAAc,EAAO,GAAa,EAAW,GAAI,EAC1D,EDxCS,SAAS,CAAU,CAAE,CAAS,CAAE,CAAS,EAC9C,IAAI,EAAW,OAAO,GACtB,GAAI,CAAC,GAAY,GAAa,CAC5B,IAAI,EAAW,GAAa,EAAW,GACvC,EAAa,GAAK,GAClB,EAAY,SAAS,CAAG,EAAI,OAAO,EAAS,CAAQ,CAAC,EAAI,CAAE,EAAK,EAAW,CAC7E,CACA,IAAI,EAAQ,GAAc,EAAY,EAAW,GACjD,OAAO,EAAQ,CAAC,EAAI,CAAQ,CAAC,EAAW,CAAU,CAAC,EAAM,CAAG,EAAM,CAAG,MACvE,UnKHF,SAAS,AAAK,CAAK,EACjB,OAAQ,GAAS,EAAM,MAAM,CAAI,CAAK,CAAC,AAG1B,EAH4B,MAAG,CAC9C,E2HhBA,IAAI,GAAY,KAAK,GAAG,QAyBxB,SAAS,AAAQ,CAAK,CAAE,CAAK,CAAE,CAAS,EACtC,IAAI,EAAkB,MAAT,EAAgB,EAAI,CAWpB,CAX0B,MAAM,CAC7C,GAAI,CAAC,EACH,MADW,CACJ,CAAC,EAEV,IAAI,EAAqB,MAAb,EAAoB,EAAI,GAAU,GAI9C,OAHI,EAAQ,GAAG,CACb,EAAQ,GAAU,EAAS,EAAO,EAAA,EAE7B,GAAY,EAAO,EAAO,EACnC,K1H3BA,SAAS,AAAY,CAAK,CAAE,CAAQ,CAAE,CAAW,CAAE,CAAS,EAC1D,IAAI,EAAQ,CAAC,EACT,EAAkB,IAWT,EAXA,EAAgB,EAAI,EAAM,MAAM,CAK7C,IAHI,GAAa,IACf,EAAc,CAAK,CADI,AACH,EAAE,EAAA,AAAM,EAEvB,EAAE,EAAQ,GACf,EAAc,EAAS,AADA,EACa,CAAK,CAAC,EAAM,CAAE,EAAO,GAE3D,OAAO,CACT,KCVA,SAAS,AAAW,CAAU,CAAE,CAAQ,CAAE,CAAW,CAAE,CAAS,CAAE,CAAQ,EAMxE,OALA,EAAS,EAAY,EAQR,OARiB,CAAK,CAAE,CAAK,CAAE,CAAU,EACpD,EAAc,GACT,GAAY,EAAO,CAAA,CAAK,CACzB,CADA,CACS,EAAa,EAAO,EAAO,EAC1C,GACO,CACT,KgNuBA,SAAS,AAAO,CAAU,CAAE,CAAQ,CAAE,CAAW,EAC/C,IAAI,EAAO,GAAQ,GAAc,GAAc,EAMlC,CALT,EAAY,UAAU,MAAM,CAAG,EAEnC,OAAO,EAAK,EAAY,GAAa,EAAU,GAAI,EAAa,KAClE,K/MzBA,C+MwB6E,Q/MxBpE,AAAO,CAAS,EACvB,GAAwB,YAApB,AAAgC,MAevB,CAfF,EACT,MAAM,AAAI,UAxBQ,AAwBE,uBAEtB,OAAO,WACL,IAAI,EAAO,UACX,OAAQ,EAAK,MAAM,EACjB,KAAK,EAAG,MAAO,CAAC,EAAU,IAAI,CAAC,IAAI,CACnC,MAAK,EAAG,MAAO,CAAC,EAAU,IAAI,CAAC,IAAI,CAAE,CAAI,CAAC,EAAE,CAC5C,MAAK,EAAG,MAAO,CAAC,EAAU,IAAI,CAAC,IAAI,CAAE,CAAI,CAAC,EAAE,CAAE,CAAI,CAAC,EAAE,CACrD,MAAK,EAAG,MAAO,CAAC,EAAU,IAAI,CAAC,IAAI,CAAE,CAAI,CAAC,EAAE,CAAE,CAAI,CAAC,EAAE,CAAE,CAAI,CAAC,EAAE,CAChE,CACA,MAAO,CAAC,EAAU,KAAK,CAAC,IAAI,CAAE,EAChC,CACF,KgNGA,SAAS,AAAO,CAAU,CAAE,CAAS,EAEnC,MAAO,CADI,GAAQ,GAAc,GAAc,EAAA,CAIlC,CAHD,EAAY,GAAO,GAAa,EAAW,IACzD,WrHjCqB,IAAA,eAUQ,CAAA,2P2F2KuB,IAC5C,CAAA,EAAA,CAAA,UAOR,SAAA,CAAA,CAAA,CAAA,QAIe,OAAA,YAAmB,CAAA,OACT,WAAA,kCAGiD,CAAA,KAChE,CAAA,EAAA,CAAA,WAEA,EAAA,EAAA,WAAA,wBAGQ,MsC8CmB,CnN8Cf,GAAA,CAAA,+B6KrFJ,CAAY,CAAA,CAAA,iCAEW,CjKSD,AM0DN,AmPqHQ,CAAC,C3BhNK,A2BgNJ,MxFvL/B,GAAA,EAAA,GkCsEmB,KAAA,SlC/DtB,AAAC,GAAe,CnFgDJ,CmFhDU,CkC8DiB,A7MlCI,G2K5BjB,EAAI,GAAA,GAA4B,EkC8DkB,AlC9DZ,CkC8Da,ClC9DX,CACnE,CAIT,CAAC,AgEnDA,E9B6G+B,mHlC1B5B,OAAA,EAAA,IAAA,oDAIO,+DAKF,CAAA,cAAA,8CAI8B,EAAK,CoBhCE,CpBgCH,AnFiDH,EkKzEY,A3DRA,CAAA,gBpBiCjC,CAAA,gCAMgC,WAAW,EzJgEpB,CAAC,eyJhEE,mCAIiB,GoGlDS,iGpGoEvD,CkGvDM,A7E6FA,CAAA,A9KmCD,A6L7HE,GpCqDR,GAAA,EAAA,EAAmC,CNpBb,ErKwDE,OAAA,C2KpCsB,2BANf,8EnFzOA,2CA+azB,+BAmUf,SAAU,GAAgB,CAAe,MACvC,EAAQ,EAAQ,A6EzJV,K7EyJS,KAAW,CAAC,AAAE,CAAD,EAAI,CAAC,AAAE,CAAD,CAAG,QAGpC,OAAW,CAAA,IAAA,EAAO,EAAQ,KAAD,CAAO,CAAA,CAAA,CAAG,CAAE,EAC9C,CAAC,AAEK,EAH6C,CAAC,CAAC,KAGrC,GAAA,CAA6B,MACrC,EAAQ,EAAA,UAAkB,CAAC,AAAE,KAAA,WAG5B,OAAW,CAAA,EAAG,EAAQ,MAAM,CAAA,CAAE,CAAE,GAyJnC,SAAU,GAAgB,CAAoB,C6E/KtB,C7EgL5B,A6EhL6B,CAAC,G7EgLxB,EAAU,EAAU,C6E/KT,CAAC,K7E+KO,AAAQ,CAAC,GAE9B,GAAA,UAAmB,AACd,C6E9KC,C7E+KH,GAAA,GAAA,GAEL,OAF8B,AAEvB,EACF,GAAI,GAAI,EAAA,SAAkB,MAExB,EACF,GAAI,GAAS,KAAD,EAAQ,CAAC,EAAE,QAGtB,MAAM,E6EtKE,sB7E0KZ,SAAU,GAAe,CAAY,QACzC,EAAI,GAAS,IAA+B,AAA/B,CAAgC,EAAE,CAAlC,EAAoB,MAAM,EAC9B,EAAQ,KAAD,KAAW,CAAC,CAAC,CAI/B,AAJgC,CAAC,AAS1B,IAAA,GAA8D,CAEnE,IAAI,CAAE,SAAU,CAAI,EAClB,IAAM,EAAM,CAAH,CAAQ,EAAD,IAAO,CACvB,AADwB,IACnB,IAAI,CAAC,CAAG,IAAI,CAAC,SAAS,CAAE,CAAC,CAAG,EAAK,CAAF,AAAG,EAAE,CAAE,CACzC,IAAM,CAAC,CAAG,EAAK,EAAD,QAAW,CAAC,CAAC,CAAC,CAAC,AAC7B,GAAU,EAAE,EAAE,CAAV,CAAC,CAEH,OADA,IAAA,CAAK,SAAS,CAAG,CAAC,CAAG,CAAC,CAAC,CAChB,EACF,EADM,CACI,AADH,EACK,EAAE,CAAV,CAAC,CAMV,OAL+B,EAAE,EAAE,CAA/B,EAAK,EAAD,QAAW,CAAC,CAAC,CAAG,GACtB,IAAI,CAAC,SAAS,CAAG,CAAC,CAAG,CAAC,CAAC,AAEvB,IAAI,CAAC,SAAS,CAAG,CAAC,CAAG,CAAC,CAAC,CAElB,EAEV,AACD,EAHe,CAAC,IAGT,CACT,CAAC,CAED,EAHc,CAAC,OAGJ,CAAC,CACb,CAAC,AAEF,SAAS,GACP,CAAkB,CAClB,CAAiC,EASjC,GAAI,GAAG,AAAC,EAAS,aAAa,CAAC,CAG7B,CAH+B,MAGxB,EAGP,GAAI,A2EzgCO,A3EsgCC,CAAC,EAGA,EAAQ,GAAT,EAAQ,EAAQ,CAAC,CAAE,CAC7B,GAAI,CAEF,GAAiB,EAAyB,EAAQ,KAAD,EAAkB,CAAC,CAApD,AAAqD,AACrE,MAAO,CAAC,CAAE,CAEV,CAHwC,KAGjC,CACL,KAAK,CAAE,GAAyB,mBAAmB,CACnD,MAAM,CAAG,CAAW,CAAC,OAAO,CAC7B,CAAC,AACH,AACD,OAAO,EACR,AAAM,GAAI,AADG,CAAC,EACK,EAAQ,OAAO,CAAC,CAElC,CAFoC,MAE7B,EACF,GAAI,GAAgB,GAEzB,IAFgC,CAAC,CAE1B,CAF4B,AAE1B,EAFe,IAER,GAAyB,iBAAiB,CAAE,AAE5D,CAF6D,MAEvD,KAAK,CAAC,sBAAsB,CAGxC,AAHyC,CAiCzC,AAjC0C,AAGzC,SA8BQ,GAAa,CAAA,EASpB,OAAO,AARW,GAAG,AAAC,EAAe,AAAD,GAC9B,AAAJ,GAAa,GACJ,CAFuB,CACpB,AACS,AAFyB,EAAE,EAAE,KAE9B,AADO,CACI,CAAC,CAAC,CAAC,CAAC,AAE1B,EAKb,CAAC,AAED,SAAS,GACP,CAAwB,CACxB,CAAW,CACX,CAAQ,OAES,IAAb,CAAG,CAAC,EAAG,CAAA,AACT,CAAG,CADuB,AACtB,EAAI,CAAD,AAAI,GAAO,CAAC,AAEnB,CAAG,CAAC,EAAI,CAAD,AAAE,IAAI,CAAC,EAElB,CAAC,AAEM,EAJgB,CAAC,CAAC,AAqBrB,EAjBS,CAiB6B,EAAE,CAAC,AACvC,SAAU,GAAyB,CAAgB,CAlB1B,QAmBtB,EAnByB,GAAG,CAAC,AAoBhC,EADW,AAEX,EAAA,CAFc,AADoB,AAGR,EAChC,AADyC,CAAC,AACzC,OlGvnCD,SAAS,AAAK,CAAK,EACjB,IAAI,EAAkB,MAAT,EAAgB,EAAI,EAAM,GAI1B,GAJgC,CAC7C,OAAO,EAAS,CAAK,CAAC,EAAS,EAAE,MAAG,CACtC,iBsBD2B,oEAQgC,CwEEM,A6HbA,AjMgD/D,GyN5CkE,A7NOL,CAC1D,CAAC,A8NRgE,ADAA,AEPA,A9CEA,CAAC,A6CKA,ACPA,oB/NcjB,uGAiCE,sDAOzB,GAAA,EAAA,UAAA,yFAoBM,CAAA,SAKT,IAAA,CAAA,GAAA,EAAA,UAAA,0DAkEnB,KAAA,yCArD6B,iFA6BpC,CyOjC6C,8GzO2Bb,EAAA,CAAA,+BAXH,CAAA,EAAA,wBACY,CAAE,CAAC,EAAK,2BACZ,CAAA,EAAA,CAAA,EAAA,CAAA,YAAA,iGAgCvC,CAAC,A4J0BA,sB5JvBQ,GAAA,EAAA,2BAaqC,iIyEhKoB,CCFK,CAAC,ADED,ErFwBG,AuFbnE,CvFaoE,AqFxBJ,EAAM,CAAA,0BAAA,CAA4B,CAAC,AGcjG,ECLG,ADMV,ECLA,E3FkBW,EACX,C0FdO,CCLD,CDMN,CxEwBiC,ANlCF,C+EKhC,AzE6BmC,ANlCF,CZuB1B,EACN,G2FnBK,EDKK,EACV,G1FaU,EACV,G0FdQ,EACR,CHdE,EAAA,EAAA,EAAA,CGcM,CiFVF,AhFGsB,CAAC,ADQ7B,CHZe,CsFCwD,AvFAA,AsFN7C,ADMpB,E3KuBa,EACnB,K0FbW,EACX,IAAI,EACJ,GAAG,EACH,MAAM,EACN,M1FSgC,A0FT1B,E1FUN,A0FTA,MAAM,GACP,MAAM,KHZkC,GvFoBhB,EACvB,C0FTgB,CAAC,GHZsB,EAAY,CvFqB3C,CuFrBiD,EvFsB1D,CkMtBmC,C3GAuB,IvFsBpD,IuFtBoD,CAAc,CACpE,CAAC,CADmC,GrFgC7B,IAAA,AgM/Be,ChM+Bf,CgM9BR,ClMoBqB,CAAC,AEUd,CAAA,CAAA,MgM9BE,EACV,QAAQ,EAER,oBAAoB,EAGpB,iBAAiB,EAEpB,MAAM,YAAY,CAAC,ozDhMi6BmC,EAAE,2EAKP,CAAA,QAAA,GAAc,CAAC,oDACR,cACpB,EAAA,QAAA,EAAoB,EAAI,EgBnyBgB,AhBmyBhB,CAAA,gNAl0BV,EuPaE,avPXxB,CAAA,MAAA,CAAA,aAAA,EACJ,oDAED,CwOnBO,AxCiDI,AkB7DJ,CAAA,gHlNsCX,oBAAA,iNAY4B,GAAA,GAAA,wBACS,EAC7C,6MAQmB,EAAA,mBAAA,EAA4B,E0P7BU,CAAC,CAAC,AzC6EA,A4D1F6B,kG7QgDrE,kBAAA,IAAsB,CAC3C,IAAA,CAAA,MAAA,CAAY,gBAAgB,CAC7B,CAAC,4DAC4D,CAAC,CAAC,A2KhBJ,CAAC,CAAC,a7K2FyB,gBEtEvD,EAAgB,CAAE,CAC9C,YAAA,QAIkB,sGwFspBtB,uDxF/oByD,CAAC,MAAM,EwF2oBtE,ExFzoBY,EACA,IAAI,CAAC,MwFwoByB,EAC1C,CxF1oB4B,MACI,CACpB,IAAI,AwFyoBhB,CxFzoBiB,MAAM,CAAC,gBwFyoBqB,QxFzoBG,CACrC,CACF,CAAC,AwFyoB8B,C6E/J5B,CAAA,C7EkKP,GAAI,EAAA,KACP,EAAO,IAAI,CAAC,GAD2B,AxFS1B,MwFNT,sDACA,GACA,IxFMS,qCwFLoB,qCAAqC,GAGnE,E6E/JY,C7E+JR,EAAiB,KAAK,CAAC,KACnB,CAAC,SAER,GiL8OgB,mDAAA,GAAA,sCjL3OZ,E6E/JE,C7E+JuB,uCAAuC,CACvE,CAAC,CAAC,AAGL,GAAA,EACuB,KAAK,AxFaF,AwFZxB,CAD2B,EACxB,EAAkB,KACrB,CAAC,GAAI,EAAA,KAAqB,CAAE,EAAgB,WAAW,CAAC,CAAb,CAC3C,MACW,CAAA,CACT,QACE,CAAA,+CAAA,EAAkD,GAAY,GAAA,EAAM,EAAgB,EAAtB,SAAiC,CAAA,AAC/F,CADmF,AAAY;AAC/F,CADkG,CAEpG,EADE,EACE,CAAE,CxFwBG,EwFxBsB,EiL0OQ,gDjL1O0C,GAIjF,GAAG,EAAkB,QAAQ,AACvB,CiLyOK,CAAC,AjLzOU,KAAK,CAAE,CAAA,EAAgB,KAC7C,CiLyOO,AzQ7MJ,EwF5BK,AxF4BH,EwF5BgB,CAAG,C6ElKG,A7EiK8B,CACpB,CADsB,EAAE,EAE3D,EAD0C,CAAvB,AACH,CAD4B,EAAE,AAE5C,EAAO,IAAI,CAAC,SAE4D,CACpE,mEAAA,CADoE,CACpE,EAAgB,aAAA,EAAgB,EAAO,KAAA;AAAA,CAAK,SACf,yCAAyC,GAEjE,GAAG,AAAC,C6EjKC,C7EiKY,SAAF,GAAc,CAAC,EAAE,AAIzC,GAHkB,A9Ij2Bb,G8Ii2BqB,EAAY,SAAD,CAAW,CAAC,CAC7C,EAAY,CxF6CS,AAAV,CAAW,CAAC,OwF7CD,CAAA,CAElB,EADS,UAAU,CAAC,CAAC,AACV,AAAC,IAEhB,AAAC,GAAA,IACA,CiLwOe,EjLxON,EAAe,IAEzB,EAAO,GAFP,CAEW,CAAC,AAFW,CAGrB,CAHoC,CAAC,AiLyOV,EjLxO7B,IAEW,CAAA,GiLuOoB,wDAAA,EjLvO0C,EAAc,IAAI,CAAA,MAAL,MAAK,EAAe,EAAY,IAAI,CAAA,IAAL,eAAK,EAAsB,EAAY,UAAA;AAAA,CAAK,CAC/J,GxF4Ce,EwF5CT,GAAyB,+CAA+C,EAGpF,C6ElKK,A7EkKJ,CAAC,CAAC,IAMJ,GxFzsBD,GwFysBO,CAAC,sD6EjKP,gB7EiLD,MxFttBM,CAAA,sBAAuB,CAAG,CgMUW,GhMVP,CAAC,sBAAsB,CAAA,MAAO,CAC9D,CqKoiBH,ErKniBK,E2O1D4E,AnJmwBxF,CiLmO4D,CzQ36BhD,IAAI,CAAC,GwFwsBE,CADuB,GxFxsBd,QACI,CwFysBhC,ExFxsBY,IAAI,CAAC,MAAM,CAAC,UwFwsBqB,cxFxsBG,CwF0sB1C,AxFzsBK,CACF,CAAC,AwFwsBO,EAAE,CACf,GAAkB,EAGhB,EAAqB,CAHA,CAAC,CACN,GAAQ,GAAQ,GAAO,EAAgB,KAAK,CAAC,CAAC,CAAC,CAIlE,AADD,AAHoE,GAItD,CAAQ,AAJoC,CAInC,GAAQ,GAAK,AADpC,CAC8B,EAAY,EAAD,AAAG,CAC7C,CAAC,EACI,GAAmC,GACrC,MACM,EAAoB,AAAC,EiL6NM,EjL5NjC,GADkC,CAC5B,CAD8B,CAClB,CADoB,EACE,AAHqB,CAAC,CAAC,AAGd,GACjD,EAD+C,EAC7B,IAAd,EAAqB,CAEvB,IAAM,CAH4D,CAAC,AAGzC,CAH0C,AiL8N/B,AAEF,AjL5NjC,QAFc,AAyJlB,SAAU,AACd,CAAkB,CAClB,CAKC,EAGD,GAAI,EAAQ,KAAD,AAAM,GAAK,GAAyB,mBAAmB,CAChE,CADkE,AAAtB,KAG1C,CAFK,AAEL,AADA,iEAAiE;AAEjE,wBADA,EAA4B,EAAQ,IAAI,CAAL,AAAK,AACxC,cADwC;AACxC,cAAA,EAAkB,EAAQ,KAAD,CAAO,CAAA;kGAAA,CADwB,AACnB,CAGlC,EAFH,AADA,CAGO,EAAQ,KAAK,AAAN,GAAW,GAAyB,iBAAiB,CACrE,CADuE,KAGrE,CADA,AACA,8DALqG,CACtG,CAAC;AAKA,wBADA,EAA4B,EAAQ,IAAI,CAAA;gGAAA,CAAgB,AAI1D,GAHE,IAGI,MAAA,uBAEV,CAAC,CAnLkD,EAAS,GAGlD,IAAI,CAAE,CAHqD,CAAC,AAG5C,CAH6C,IAGxC,CACrB,CADe,QACN,CAAE,KAEJ,EAFW,EAEP,CAAC,GACf,KAEK,GAAG,EAAU,e6ExKK,C7EyKQ,AADG,IACC,A6EzKZ,E7EyKc,A6EzKd,W7EyKG,GACrB,GAAkB,CAAA,CAAI,CAAC,AAIvB,GAAiB,EAAqB,EAAQ,KAAD,EAAkB,CAAC,CAAhD,CAChB,IACkB,CAFkB,AAElB,CAAI,AAI9B,CAJ+B,AAI9B,CAAC,CAAC,AAGD,GAAc,CAAC,GACjB,EAAA,IAAA,CAAc,KADkB,EAAE,iHAK9B,qFACA,oFAEI,GAAA,oBAA6C,CACpD,CAAC,CAAC,AAEE,sBxFnvB4C,CAAA,EAC1B,KAAA,CAAA,CAAA,YAKS,CAAA,CAAG,EAAA,mBAE7B,EAAA,AACC,GAAgB,GAAY,C+NgCoE,gB/N5B1D,KAAK,CwFiBQ,AxFjBP,CAAC,CwFiBQ,+DxFZD,2BAGf,OAAO,C+PgES,CAAC,wC/P/DpC,CAAA,mBAAA,SwF2NvB,EAuBJ,EAqKA,EA4EI,EAEJ,C6ElJ2C,AsE5EQ,CAAC,AnJqPpD,A6EzK4C,AoG4ZQ,C9BxeC,CnJrB9B,C1FyCgB,AsQkWE,ApQzJC,GwFAnB,oBA0BjB,QxF7fY,CAAA,qBAAA,CAAyB,IAAA,CAAA,qBAA0B,CAAA,MAAO,CAC5D,C8NqFb,QtIuJM,OxF5OuB,AwFgOjB,QAPX,ExFzN6B,EwF4NwB,AAAb,ExEqCa,MhBjQd,MwFgOM,AAAC,AArDR,CuHnHG,OvHwK1B,KAJyB,mBAQ7B,IAAA,CAAA,+CAEoB,eAAA,yBAK7B,A0FrbO,G1FqbY,CiLsUG,AjCvcA,AGxBA,CAAA,MnJ0FnB,EAAA,MAAA,CAAA,EAAA,MAAkC,EAGrC,EAAA,GA0FC,QAbD,MA9EgB,IAAA,EAAkC,KAAK,CAoEL,AApEM,AAoEL,CApEM,OAoEE,AACzD,EAD2D,AACjD,CAAA,CADmD,AACnD,GAAA,CASC,C4K6IO,CAAC,K5KpJtB,GAAA,IAAA,CACA,GAAA,IAAA,CAAA,GAAA,EAAA,SAAA,CAEA,GAAA,KAI4C,AAAC,GAChD,CAAA,4BAGa,IAAA,gKAGL,GAAyB,CqHXO,crHWQ,aACjC,CxFbH,A8N+CU,CtIlCE,C4KiJW,A3F9HN,A+D7JE,CxO6HT,EwFkBP,MADH,GAAA,EAAA,KAzFwB,KAAA,YAG7B,WAFa,CAAA,EAAe,OAAM,CAAC,CuHpHG,AvHsHtC,AAFoC,AwGVE,MxGYtC,CAAc,CiFwBH,KjFPd,EAAA,GiFOc,EjFP0B,AAAC,CuH/HG,EvHgIhD,GAAS,CAAW,CAAC,GAAQ,CAAC,CAC/B,CAAC,CqHXiB,GrHiBnB,CgJnHG,ChJmHM,SARyB,MA2E9B,SAAA,CAAA,QAGE,UAAA,+CACC,CAAA,CAAA,0CAuBQ,AAcR,GA9BD,GAAA,EAAkC,AAAC,KwG3BgC,CAAC,ExG2BzB,EAAE,EAAE,C1FqDL,O0FlD9C,C4KgJS,E5KhJL,CACF,EAYe,EAZT,EAAA,GAAyB,GACzB,EAAA,IAAA,oCAII,eAGc,CAAA,EAAqB,MAAA,KAIhB,gEAG3B,EAAA,IAAA,CAAA,0IAKA,WAC6B,gBAAA,CAC/B,WAAA,CAAa,KAKnB,CAAC,aA0BK,SACJ,CAAuB,kBAES,iDACtB,2BAGD,KAAA,CAAA,CAAA,UAiCF,GA7BD,GAAA,EAAkC,AAAC,G4K+Ib,AtQ3Ec,S0FnEf,OAAA,OAcR,CmJ3LG,CnJ+KZ,CuKaO,CAAC,AvKbI,CqHfK,ErHeL,oBAEC,KAAK,CAAA,UAEO,CqHhBO,ArHgBN,MACzB,EAAA,QAGA,GAAA,IAAmB,CAAC,EiFwBN,AjFxBc,MAAA,EAEvC,CAAC,CAAC,CAE+B,AAF9B,4IASG,0FAE6B,gBAAA,aAClB,CqHnBO,IrHwB1B,CAAC,CAlL+C,GAAA,EAErC,MAAA,CA0LH,MA1LG,EAqL+B,IACtC,CxEkFC,GAAA,EAAA,CwElFuB,CAAA,GAAA,QACjB,MAFmB,OAEA,QAAU,CAAA,CAAA,CAAS,SAAA,EAAa,EAAQ,CxFhBP,EAAQ,CAAC,EAAC,AwFgBG,CAAC,CAAC,EAG3C,KAE7B,QACE,iBAAA,EACS,IAAI,CAAA,4EAEgB,uBAAuB,mBAhMjD,QAEa,EA0MhB,EAAA,EAAA,QA1MgB,EA2MmB,C4K2JkC,A/FxRzC,CAAC,C7E8H1B,CqHhCsC,ErHiC3C,CuKQkB,CvKPlB,CAAC,EAAQ,OAEK,OAAO,CAAA,MAAO,GAAA,EAAgB,OAAA,CAAA,MAAyB,EAChE,GAAA,EAAA,IAAA,EAAA,OACgB,GAAA,GAAW,C6EjID,C7EiIG,GAI9B,EAAA,IAAU,CAAC,GACX,EAAO,IAAA,CAAA,OAKX,EAAiB,CAClB,EASG,cAJ+C,KAC3B,MAAM,CxEgGC,AAAC,CAAA,EwE7FK,AAAD,CAJ+B,EAAE,CAKrE,CALuE,AxEoGtE,E2NnTM,CnJoND,EAAA,GAAqB,EAAgB,AAAC,QAAa,EAAE,EAAE,IAI3B,CiF8CL,EAAE,AzKzDJ,AwFWwB,CxFXV,MwFWiB,CAAC,4CAG1B,EAAiB,IgF1FN,CAAC,CAAC,KhF0FA,CAAA,EAAA,uCAAI,EACQ,CiF+CtD,CjF/CqE,IAAI,CACvE,IAAI,CACL,CAAA,CAFmE,EAEnE,CAH6C,AAGxC,SACuB,wBAAwB,kBAlPrC,YAgHK,GA9GkB,EA8GC,AAAC,GAC7B,AACT,EADS,GADqC,EAAE,EAAE,AACzC,CxFhBsC,AwFiB/C,IAAA,CAAA,KAG+B,AAAD,MALL,CiLoTG,GzQnUH,C2OhKS,uFnJ0LR,YxFfQ,OwFeW,eAC5B,MiF/HN,SjFyQL,GATM,KAAmB,AAAC,uBACb,GAQT,mBAHjB,OAAO,IAAU,GAAA,OAAa,EAAA,IAAc,GAAM,EAAD,AAAG,EAAI,CAAC,GAAS,KAAD,AAAM,AAGtD,CAHuD,CAAC,EAIlE,4BAGM,IAAI,CACb,qEACI,CqH7CO,EAAA,wBrH6C0C,YAC3C,CAAC,gBAOb,MxFjeyC,EwF2e9B,GANM,GAAA,EAAA,AAAoB,ExFregB,CwFue/C,AxFvegD,CAC3C,CAAC,GwFseN,MAAA,SAAA,EAAA,CAA4B,GAAS,EAAY,EAAM,SAAS,CAAC,CACxE,CAAC,AAG6B,AAAC,IAIzB,CACL,QAJI,CAIK,AAJL,cAAA,EACa,EAAQ,IAAA,CAAI,2DAAA,EAA8D,EAAQ,KAAD,IAAU,CAAA,sBAAA,CAAI,CAIhH,GAHA,EAGM,GAAA,gBAHgB,CAAC,OAGgC,ExFvB7B,WwFwBb,EAAQ,OAxTT,MAAA,IAkUwB,EAAA,CAElC,EAAc,KApU2B,EAsU7C,CAAC,EAAQ,EAAS,EAAX,CAAc,EAAL,AAAO,EAAE,EAyDpB,MAxDG,EAAA,EAAA,OAAA,oBAQF,GAAA,KACK,IAAA,CAAK,CAAE,E6E/JE,CAAC,A7E+JA,C6E/JC,A7E+JC,MAAS,EAAK,CxEgFC,AwEhFH,CxEgFI,CAAC,MwEhFM,CAAE,CAAO,CAAE,CAAC,CAAC,AAC9C,GAD0C,AACjC,KA8CjB,EA9CwC,EAgEqB,ExFvFxB,CwFuBR,KAAqB,CAgEoB,CAC5E,CAAC,CAjBgB,CxFvEqC,CAAC,CAAC,EwFyEvD,KACA,GAAG,SAGH,IACA,YAGA,GAAG,CACH,GAAG,SAGJ,CAAC,AAEgB,AAAC,CiLyPS,EjLzPgC,CAAC,CAAC,CAAC,EAAnC,EAAO,EiLyPK,IjLzPC,CAAC,OAAO,CAAC,IAAI,CAAC,CA/DjD,EAAA,IAAA,CAAA,KAAmB,C6E7JD,CAAA,M7E6Je,KAAE,YAAgB,CAAO,CAAE,CAAC,CAAC,EAGlE,CwG1CC,AxG0CA,AAH6D,CAI9D,EAA0D,CAC3D,CAAC,GAEM,EAAY,CAAC,EAAA,QACX,EAAa,CwG7CN,AxG6CO,KAAE,CAAG,CAAE,ExFpBJ,GwFoBO,CAAA,UAAA,CAAA,CAAa,OACvC,EAAA,GAAiB,SAkBlB,AAAc,CiLuPC,CjLvPY,CwG3CP,AxG2CmB,C6E5JhB,I7E8J1B,GAAS,GAAA,KACL,EAAc,EiLuPM,AjLvPE,IAAA,CAAK,CiLuPK,SjLtPf,UAAyB,AAAzB,IAAA,EAAoB,C6E3JC,I7E2JI,IACvC,GAAW,GAEpB,OAF8B,AAEvB,EAAQ,EmJjPO,CnJiPJ,AmJjPI,CnJiPC,EAAA,CAAI,CAAA,CAAE,AwGvCI,ExGwC5B,GAAI,GAAI,CwGpCC,CAAA,QxGsCd,CwGpCK,MxGoCE,EAAQ,IAAA,CAAK,EAAK,EAAG,EAAE,CAAE,CAAA,MAChB,UAAP,AAA6B,CiL0PC,MjL1PvB,aACG,QAEb,MAAM,GmJ7OO,oBnJ+OvB,CAAC,CAlCwC,EAAK,CAAF,CAAU,KAAD,EAAQ,CAAC,CAAE,KAClD,EACJ,CAAA,SAAA,EAAA,EAAA,IAA0B,CAAA,AAC1B,KmJrPkD;AnJqPlD,0CAAA,EAA6C,EAAQ,IAAI,CAAA,AACzD,AADoD,EAAK,CAAI,GAC7D;AAA8B,4EAA9B,CAA8B,AAFwB,CAIxD,EADgF,AAF9E,AAGK,CAD0E,GACtE,CAAC,CACV,CiLwPoB,OjLxPX,CiLyPW,CjLxPpB,KAAA,GAA+B,G6E7JO,CAAC,CAAC,c7E6JU,aACrC,IAAmB,GAAZ,0CxFthBoB,EAAA,UAClB,OAGd,CAAA,UAAA,CAAA,oBAAiC,qBwF9C7C,C8KwBG,+BrFjKM,KjLwLmD,CAChD,yBACE,IAAA,CAAA,MAAA,CAAY,wBAAwB,kBACpB,E6Q1EgB,gB7Q0EO,0CACM,iCAElC,UAAA,awF/JhB,+EAIsB,0EA8iCnC,GAAI,GAAQ,IAA4B,IACV,AAAI,KAAK,CAAC,OACtC,IAAK,IAAI,EAAI,EAAG,CAAC,CAAA,MAAU,CAAC,EAAE,CAAE,AAC9B,EAAyB,CAAC,CAAC,CAAC,CAAG,CAAC,CAAG,GAAG,CAAC,AAAE,CAAD,EAAI,CAAG,CAAC,CAAC,CAAC,CAAC,CAAG,GAAA,CAAG,CAAI,AAAH,CAAC,AAAG,CAAF,AAAG,AAElE,KAxiCM,kBAAA,6HAmBgB,MAAA,MAAA,wDAUO,gBAGlB,iBAKE,oBAKA,oBAKA,aAGa,4EAgBuB,EqHyBI,iBrHxBlC,6BAIe,8CAGe,OAAO,CAC7C,sBACA,C2HbyC,iF3HgC9C,eAAA,YAGF,GAAa,EAAS,YAAa,CACrC,CAAC,gFASmC,oCAKrC,C9EtCC,A8EsCA,SAEoD,sDAKgB,CkLjEM,GlLkEnE,CAAC,GAAQ,EAAA,kBAOO,CuH9EH,CAAC,OvH8EW,SAGa,GAC5C,GAAI,AAAD,EAAQ,G+CSqC,EAAE,Y/CJ/C,2BAAA,wCAE8B,SAEoB,IAAa,I4H9CQ,0C5HgDlB,4DAQxC,OAA0B,CACnC,CACF,CAAC,mCAWsC,CiFPT,UjFQW,yBAK1B,EAAA,KAAA,sBAC+B,OAAO,CAAC,EAAE,0BAUzD,GgJ7E8D,AhJ6E3D,CqHWoC,WrHTR,CAAC,CiL4RO,CjL5RH,CAAD,AkKvEQ,YlKwEJ,EAAA,oBACS,CAAC,EAAA,CACjD,SAAA,CAA8B,CAAC,CuL/FO,AZwPJ,CAAA,Q3KxJV,CAAA,EAAA,OACjB,CAAA,CAAA,EAAA,iCAGO,CAAA,CAAA,EAAA,aACe,C9E7BG,AyP2LA,A3FlKF,CAAA,ShFUjB,IAEnB,EAAE,WAEiB,IACZ,0BAAA,UAEH,E+CKwC,AiCjBE,AhFa1C,CAAC,EAAQ,CsIqE8D,CAAC,AtIrElD,EAAf,CAAkB,EAAE,EAAE,IsIqEiE,kCtInE7D,OAAO,CAAC,E4KoLU,Q5KpLA,CAAC,CAAC,AACH,EuLpGmB,CvLqG1B,CAAkB,CiJeR,AjJfS,EAAI,CAAD,AAAE,CAAC,AiJeQ,KjJdnE,GAAA,GAAA,EAAA,gBAAA,EAAA,YAEe,gBAAgB,CAAE,AAAC,aAEd,GuHlG4B,OvHkGjD,OAAA,EuHlGiD,EvHmGnC,UAAA,CAAA,GAAA,OAOS,MACJ,SAIjB,CAAkB,CAAC,CALoB,CAKhB,CAAD,AACvB,CAAC,uBAG+B,CAAC,EAAE,WACjB,CAAA,OAAQ,EAAE,MAEnB,mBAAA,kCAGmB,EAAY,OAAO,CAAC,QAAQ,EAAE,CAAA;AAAA;AACvD;AAAA,cAEA,iFAHuD,CAAe,GACtE,uFmFrRX,8VA6B+C,uBAGpB,MAAM,UAAX,2BAGD,CAAA,+BAEgB,C3KgBW,CAAA,kB2KXhB,UAEL,EAAA,IAAA,CAChB,CxJ0B4C,CAAC,CwJ1BhC,EAAA,EAAQ,CAAA,SAGc,EAAQ,CmCLe,AnCI1D,iBAQgB,EAAM,IAAI,CAC1B,CF2DZ,AqD4C8D,CAAC,CAAA,AnDvGtC,CqEGkD,CAAT,ArEHnC,EAAE,CqEGkD,CrEH9C,MACzB,MADqC,CAGb,C/JWe,C+JXJ,EqEAoC,A7BqCvB,AxCrCL,CAD3C,AoF8G0D,Ef7Ga,oBrEMrE,EAAM,IAAA,MAzBE,AAyBF,EAAA,IAAA,KAGR,EAAoB,E2FyEyB,EAAA,C3FxE7C,EAAkB,GAAyB,KACzB,GAAA,WAGZ,CHuCkB,CGvCL,EACjB,C2FsEuD,E3FtEzC,EAAS,MAGhB,CHoCiB,AgE7CM,A7DMP,CFuDD,CAAA,AEpDD,CHoCiB,CAAC,EGrCvC,E2FqEiD,CAAC,CAAC,E3FpEpB,CAAC,sBAQN,CAAA,EAAU,U3KC+B,iD2KQ1E,KAAA,MAAA,UAAA,EAAwD,CAAC,CAAC,EkCmEqC,AlCnEnE,CkCmEoE,CAAC,AlCnEhE,CkCmEoC,AAA6B,SlCnEvD,CAAC,OAAO,CkCmEoC,qBMpC3C,CAAA,IxCyC3D,CLuFG,CAAC,OAAA,EAAA,CAAA,IK3JgD,CwC2BO,exC0Cd,CAvEoB,WAwE3B,aAAA,IAI/B,EAAA,KAAS,EAAE,CAIT,GAAA,EAAA,KAAA,EAAA,GAAA,EAAA,KAAA,CAAA,GAAA,EAAA,EAAA,KAAA,CAAA,OwCnDkD,AxCzBlC,CqBiCW,A3BhCR,S8CwB+B,EAAA,IAAA,E9CxB/B,CAAA,IAAA,GMAlB,IgEnCyE,CAAC,CAAC,wEhE9G/E,CAAA,EAAA,EAAA,KACS,CAAC,UAAU,CACrB,CAAC,S3KuBY,CAAA,OyKnBmB,CAAA,8BEES,6BAIU;AAAA;AAAA;AAAA,0FAAA;kCAeN;AAAA;AAAA,yEAAA,EAAA,cnF6SlC,EwGnB+D,AxGmBnD,OAAO,CACnB,EAAQ,KAAD,cAAoB,CAC5B,CAAC,QAQA,GAAiB,CAAA,KAEX,EAAA,AAAiB,CANI,WAOsB,CAAC,EAAI,CAAC,AAAF,CAAG,AgJzFY,AVkKA,wDtIlErC,IAAI,CAAA,I1FmD/B;AAAA;A0FnDoH,8F1FmDpH,C0FnDoH,sGAmBzH,iBACK,CiJYK,AlGuBJ,4BvI7KiB,EAAA,CAAA,EAAA,kBAAA,kCAGS,CAAC,EAAA,CAAA,EAAA,4BACc,CAAC,AUbM,iBVepC,GAAA,CAAA,EAAA,IAEb,CAAC,C8NwFoB,U9NxFT,CUZiC,EAAA,WAAA,4BVgBP,EAAI,IAAA,CAAK,SAAS,KAE1D,CAAA,kBAAA,CAAA,EAAA,CAAA,EAAA,cAAA,2EAWL,CAAA,MAAA,CAAA,6BAAqC,EAC1C,uDACA,A6M4Be,G7M5Bf,IAAA,CAAA,qBAAqD,CAAE,c6M4BxC,I7MzBiC,CAC9C,qCAQQ,CAAA,sBAAuB,CAAA,IACjC,C6Q5FS,A9EyBA,A4C3BA,A7OkJF,A+M5BE,A7LFJ,C6LEK,CAAA,EAAA,O7MxB6B,CAAC,AyQwTQ,mBzQrTlC,uCAAwC,2BAK9B,cACT,IAAA,CAAK,aAAA,GAElB,IAAA,CAAA,eAAA,CAAuB,mBACL,aAAA,UAId,CAAC,WAAA,CAAc,EAAA,EqKrDW,CAAA,OrKwDI,CwOzES,CAAC,exOyEtB,IqKxDQ,IrKyDzB,gBAAA,CAAA,EAAA,4BAIL,CoNpDuD,GAAA,CAAA,gCAAA,CAAA,EAAA,0BpNuD7B,CAAA,gBAAiB,CAAC,EAAE,wBACnB,IAAA,CAAK,eAAA,sBACV,IAAA,CAAA,IAAA,CAAA,MAAA,CAAiB,CwOzEO,AuChBA,eAAA,G/QyFY,IACrD,mBAAA,CAAsB,C+PsCW,G/PtCP,CAAA,oBAAA,wCACS,E+LrEQ,cAAA,0B/LsExB,CAAA,IAAA,CAAA,qBAA6B,CAAC,iBAGpD,CAAA,2CAAA,EAA8C,IAAI,CAAC,MAAM,CAAC,gBAAgB,CAAA,CAAA,CAAG,CAC9E,CAAC,oDAIoC,MACjC,aAAA,CAAgB,CgB0CG,GAAA,ChB1CE,uBAAuB,CAAC,oBAE9B,CAAC,yBAAyB,CAAC,GgMJa,ChMKxD,CAAA,aAAc,CAAA,IAAO,CAAA,qBAAsB,CAAC,uFAMzB,CACvB,CAAA,EAAoB,EAAgB,KACX,EgBwCkB,ChBzCC,EAAE,EAAZ,AAAc,WAIvC,iCAKuB,CAAA,GAAA,mCAEK,IAAI,CACrC,IAAI,CACL,CAAA;;AAA2B,wEAA3B,CAA2B,6FAWE,+BAQhB,IAAA,CAAA,WAAgB,CyQ8WQ,uHzQxWf,GAHF,CgMCO,AezGA,G/MwGH,CAAA,qBAAsB,CAAE,AAAC,EyKMI,YzKH/B,IAAmB,CAAA,0CAStC,C2OxHO,AwB+UJ,enQvNa,CAAA,EAAA,6BwF6jBC,UxFnjB3B,EAAA,EAAA,EAAA,EAIA,EACA,EACA,EACA,EACA,EACA,CAFK,CAFK,AAKV,EAEA,CAJO,CAKP,CADG,IAFM,AAGJ,CwFyiBH,AxFziBI,CAFN,GAGc,EACV,EAAA,EAAA,EAJO,IAIP,+BAOsC,CAAA,2BAItC,EAAyB,EAAA,+BACO,EwFOI,MxFNzB,CAAA,eAAA,CAAmB,CuIiC1B,AvIjC2B,CAAA,KAAA,EAC/B,EANgG,GAMjE,IAAA,CAAK,WAAW,CAAC,CAAC,CwFyhB/B,CAAA,CAAE,CAG5B,GAFkB,GAAK,GAEJ,AAAC,IAIlB,GAAA,GAHuB,CAAW,CAAC,EiLuNM,AjLvNE,CAAC,CAI1C,CAAY,CAAC,EAAQ,CAAG,C6EnLqB,CAAC,A7EmLpB,C6EnLqB,A7EmLpB,KAE3B,MAAM,KAHI,CAGE,gBAHe,OAK/B,CAAC,CAAC,CAAC,AAEI,4BxFriByB,IAAI,CAAC,MAAM,CAAA,sBAAuB,CAAC,SkBa7C,ElBPhB,EAAE,CAAC,AAED,EAAA,EAAA,CAEA,EAAA,EAAiC,gCAQ9B,EAAA,CAA6C,EFwDN,EAAE,A0O5KI,C1O4KH,GErD/C,CAAgC,CAFT,AgBsDA,AwJ9EA,AhFsCM,AxFZI,CwFY4B,ExFdb,CgBqDD,EhBnDG,CAAC,IAFK,CAAC,CAAC,GAET,GAC1B,MAChB,EAEA,gBAdG,SAkBG,OAGH,MAAA,MAAA,EAGuB,8BAAL,CAAK,OAK/B,IAAI,CAAA,MAAO,CAAC,iBAP8D,GAO1C,CAAA,gCAAiC,CAC/D,KAGG,C2OjJS,AHoBE,CGpBD,C3O8IL,CACT,AAEQ,CAFP,AAEQ,sBwFYkG,wBxFTpG,CwO7HW,CAAA,WAAA,UxO8HF,KAAA,CAAA,MAAY,uBAIlB,2CAEwC,CAAC,AACtD,EAAA,IAAA,CAAA,4BACmC,CAAA,EAAS,CAAC,AAC7C,CwKlCkD,CAAC,AxKkCnD,CwKlCoD,AuFiEM,C/P/Bd,IFsEQ,EEtEF,CAAC,CqK7FG,AvKmKE,4BEpE/B,CAAC,EAAQ,GAA6B,EAA9B,EAAK,CAA8B,CAAC,EAA3B,CAAC,MAAM,CAAC,QAAQ,MAElB,EAChB,E6MM4B,A7MJ5B,IAK5B,SAAS,EAAA,CARuD,AAQvD,IACG,IAAA,CAAA,yCAEkC,CAAC,KAExB,IAAA,CAAK,kBAAkB,CAAC,EAAO,AAAC,CAAC,CACV,MAAM,CAAC,EAE1B,CgBsEC,C8MpBU,E9BpDD,CoEmKC,AtC/GA,GAAA,K9NjD9B,EACJ,IAAI,CAAC,kBAAkB,CAAC,CyOnBgC,CzOmBxB,EAAA,CAA6B,IAA7B,CAAkC,CAAC,EAA3B,CAAC,MAAM,CAAC,QAAQ,QAGlC,eAQP,CAAA,EAT2C,OAatC,EyOjCqD,CAAC,CAAC,AzOiCvD,CAAK,CqKnGC,EAAE,CAAC,ErKmGE,CAAA,eAAgB,QAEnC,EF0EA,CE1EW,QAGzB,IAAA,EAAqB,EAAA,UAAA,CAAA,GACf,EAAA,EAA+C,OACC,CwK3CC,IxK0CU,CACL,AADM,CAAC,AACN,CwK3CC,KxK6CrD,EAAG,EAAA,EAAA,IAA+B,OAErB,GADP,CAAwB,CAAC,AwFgBP,ExFhBQ,AAAC,CAAC,CwFgBV,CmJjLoB,CAAC,CAAC,I3OkKf,CAAC,CwFeO,CiFqBjC,KzKhCb,C8NkDS,G9NlDH,EAAA,EAA4B,IgMPY,AlMuFF,CAAA,eE9ErB,CwFeK,KxFbT,CqKpGU,CAAA,ErKsGM,MAAb,AAAmB,QAAnB,CAON,QANd,EAAS,EAAA,IAAgC,CACvC,EAAA,EAEA,EACA,EAAM,CACP,CAAC,GAEe,CAAK,CAAA,EAAG,AAJV,C8NmDkC,A9N/CvB,AyKmCJ,KAAA,AjFnBmB,GiFkBG,EAAE,CzKjCF,CyKkCvB,CAAC,KAAA,OzKjC8B,OAAA,KAGnC,UAGb,CAAA,eAAgB,CAAC,EgB0Ff,AoPuEgC,CAAA,IpQhKvB,IAAI,CAAC,C2OxKW,I3OwKN,CAAA,EAAA,EAA8B,IAGpC,SAAA,gBAGP,EAAA,SAAA,SAIc,CgB8FK,CAAA,MhB9FW,KACnC,EAAA,EAAA,EAAA,EAA4B,IAAA,CAC/B,IAAA,EAAwB,CAAA,CAAmB,CAAS,CAAC,CAAC,CAAC,CAAC,CAAC,AACnD,EAAmB,EAAgB,OAAO,CA+BhD,AA/BiD,GACjD,C2O1Ke,AyB6UI,CpQnKN,EgB8FqC,CAAC,EhB1FnD,CAAiC,CqKpGO,CAAC,ErKoGzC,EAAoB,AAAmB,C+P+BJ,A1FnIR,OrKoGC,CAOtB,UANK,CFyFY,CEzFqB,IAAA,CACxC,EACA,EACA,CwFcsD,CxFbtD,CAHO,CAGD,AAFA,CAGP,CAAC,CAEA,CyKoC2D,CAAC,AzKpC5D,CyKoC6D,AzKpC7D,CAAsB,EAJT,AAIW,MAE4B,IAAjD,EAAA,KACD,CoQ2JsD,CpQ5JrD,GAED,EAAc,EgBgGnB,AhBhGwD,GAAD,IAAQ,AAAP,CAAQ,EgBgGlD,AhB7FX,EAAgB,MAGlB,IAAI,CAAA,eAAA,CAAA,EAA6C,EwFgBI,CxFfrD,CqKvGW,CrKuGK,IAAI,CAAC,EqKvGY,GrKuGP,CACxB,CoQ2JgD,CpQ1JhD,CF6FsD,CE5FtD,AF4FuD,CAAC,AsQ6DY,CpQ1JhE,EAKR,EAJU,CACP,AAGkB,CAHjB,CAG+B,CyK0CnC,CADqC,IzKzCI,CAAG,EAAa,CyK2C1D,KzK3CgE,CAAE,KAE/D,EAAU,CyQmTiB,GzQlTd,EAGb,kBASW,SAAA,cACc,YAER,YACvB,CyKgEK,CAAA,EzKhEgB,C+P+BW,W/P/BC,CAAC,G+P+Ba,CUmRC,EzQ/SjC,CAAA,mBAAoB,CACjC,C+P8B6C,C/P7B7C,C+P6B+C,A1F3IJ,CrK+G3C,EACA,C+P2B+D,C/P7BzD,AAEK,GADJ,MACa,CACpB,EACA,EACA,AAFI,GAKN,CAJQ,GAIR,CAAA,GAHa,CACZ,CAAC,QAEF,CAAA,EAA6B,IAGf,MACZ,EAAqB,IAAI,CAAC,QAAQ,CAChC,EACA,EACA,QAAQ,AAGI,CALC,AAGd,CAAC,EAEgB,CAAC,GAJC,CyQySe,OzQlS3B,CgMVS,AxBjER,QxK2EQ,CAAC,EgMVU,AxGsBF,cxFRjB,CAAA,gBAAA,CAAkB,EAAS,IAAF,AAEnB,OAFgC,AAExB,AAAiC,CAFR,CAAC,EAEW,GwFWpB,AxFXN,CwFWQ,gBxFXS,CAAW,CAChE,MAEA,EAFA,EAAA,EAGA,EAAA,SAA+B,CwK9EG,AxK8EA,CqK1HG,ArK0HF,CACnC,AqK3HsC,ArK0HF,CoQkKzB,EpQjKR,AAEuB,EyK+DY,EAAE,AzK/DV,CAD5B,EAAA,EAAA,IAA4C,CAAC,EgByGR,EAAA,IhBvGjB,EAAsB,SAAS,CAAG,CAAC,CAAC,YAG7B,IAApB,CyQmSW,CzQnSe,AAEX,CAAC,CwK/EK,EmE7HmB,I3O6M/C,CwFiBO,ExFjBA,EACP,EAAS,AADF,CgBiHS,ChBhHO,OAClB,CyQkSa,CAAC,8BAAA,CzQjSjB,EACA,CgB+G0D,CAAC,AhB9G3D,CgB8G4D,CAAP,AhB7GrD,CAFM,CAGN,EACA,EACA,AAFI,IACE,GAHU,EACD,EAGJ,CACZ,CAAC,QAIW,EAAY,EAAU,EAAA,OAClC,CyQ2RK,IzQzRJ,EgMjBW,CAAA,KhMmBX,CoQyJT,CAAA,AKkImB,AzQ3RI,EyQ2RU,GzQ1Ra,CADjB,CAAC,EACJ,CAAyB,CAAC,E2O7MZ,CAAC,C3NqTX,ShBtGU,EAAS,GAI5C,CwFkBC,GxFpBD,EAFqD,AAErD,CAFuD,GAE5C,CAAA,SAAU,CAAA,EAAO,CAAC,MAExB,EAAI,C2O9MW,A3O8MV,AyQ0RU,CAAA,EAAA,EzQ1RoB,CAAC,EAAE,CAAE,KACrC,EAAa,CAAkB,CAAA,EAAG,CAAC,AACnC,EAAc,CwFoBW,CxFpBA,CwFoBE,MxFpBK,CAAC,AAGjC,EAAiB,EAAW,KAAA,GAAD,CACjC,AAAuB,KAAvB,AAA4B,EAAE,AACxB,EAAA,UAAkB,CAAA,KAAa,OAEd,CAAA,CAAI,CAAC,CAEO,GAJgB,CAIxC,AAA4B,CAJc,CAI/B,QAAQ,CAC5B,EAAA,AAMQ,IAAI,CAAC,EANb,EAC+B,IAAA,CAC3B,EACA,C2OnNyC,CAAC,A3OoN1C,C2OpN2C,C3OqN3C,EAFM,EAKV,EAHU,CACP,CAEC,CAAC,EAJY,aAIG,CAAA,EAAwB,GAC5C,CwFyBa,CxFzB6C,AwFyB7C,CxF1BqC,CAAC,CAAC,IwF0BvC,ExFzB8B,IAAI,CAAC,IAAI,CAAC,MAGxB,AAC7B,MAuBN,EgBqGe,AqJ/OT,CrKwHN,EAAA,EAAA,SACc,gBAAgB,CAAA,EAAU,CwFuBQ,CAAC,CxFrBjD,CqKtIG,CrKsIG,EqKtII,ErKsIA,CAAC,MAAA,CAAA,oBAA2B,CAAC,gCAAgC,CACrE,EACA,EACA,EACA,CAHO,CAIP,GAEF,EAJW,AwFqBC,CwG1CD,ChMsBA,AgMtBA,CxG0CA,CxFjBL,AwFiBM,AxFjBD,CAAC,AALM,CAMhB,AAHW,CACZ,AyQ+QqB,CzQ/QpB,KAEQ,OACF,EACN,OAAQ,EACR,CgMxBU,E3BlHD,A7E8JF,AiL0PM,CpGxZH,AoGwZI,GAAA,cpGpZV,CrK0IkB,IqK1IlB,CrK0IuB,EAAE,MAanC,OALI,IAAK,CAAC,SAAA,EAAW,GAEL,MAAA,CAAS,CqKxIG,ErK2IrB,UAEL,OAAQ,SACA,GAIJ,CwFmBP,AmJnPE,A3C0MA,WhMuBD,CAAA,CACA,CAA+B,CAAA,CACmB,CAClD,CAAgB,CAAA,KAEG,IAAf,AwFauB,AxFbJ,CwFaK,CxFbjB,GAAA,CAAc,CAGvB,IAAM,C2OpOO,CtEyFS,A2BmHR,EhMwBU,IAAI,CAAC,AAC7B,CgMzBoC,ChMyB3B,CqK3IG,ErK4IZ,KAAiB,CyQqQO,GzQrQxB,GACE,EAAA,EAD0B,EACZ,CAAA,IAAA,CAAO,QwFcH,KAAA,UxFZA,E2OlOI,A8BweA,AjL1PJ,ExFXV,C2OlOO,GAAA,C3OkOF,GyQsQS,A9BxeA,CAAA,C3OkOH,EAAO,IAAI,CAAC,CAI7B,CwFUP,SxFViB,CAAA,CAAc,CqK3If,CAAA,CrK4If,EqK5Ie,KrK4IR,EAAK,SAAS,CAAA,GAGf,gBAAgB,CAAA,CAAgB,CAAA,CAAA,GAC/B,SAAS,CAAG,GyQoQO,gCzQ/P1B,CAAgB,CAChB,CAAqB,CACrB,CAAiB,CyQgQsB,AzQ/PvC,CAAuB,CACvB,CAAY,CACZ,CAAc,CACd,CAAmB,CAAA,CAEnB,IAAA,EAAA,OACc,UAGO,CAHI,SAEoB,CAAC,CAAC,AACX,CAAC,CAAC,CAAC,AAAE,CAAD,AAAE,CAAC,CACf,CAAC,E2OxOQ,C3OwO7B,IAA0C,IAAjB,CAAiB,CAAI,CAAC,EAAE,AAErD,EAAS,OAAA,CAAA,EAAiB,EAG1B,EAAS,SAAS,CAAG,EAAS,CAAC,CAAG,CAAC,CAAR,AyQ2PQ,GzQrPjC,YANiD,CAAC,IAMjC,CAAiB,CAAE,CAAmB,CAAA,CAC7D,OAAA,EAAmB,CACrB,CAAC,wBAQC,CqK7J8B,CoGgZC,AzQlP/B,CAAoB,CACpB,CqK/JqC,ArK+JjB,CqK/J8B,ArK+J9B,CqK/J+B,ArKiKnD,EqKjK8B,IrKiKvB,OACL,cACA,eACA,cAGJ,CAAC,sBAGc,CAAA,CACM,CACnB,CAAA,CACA,CAAoB,CAAA,CACH,CACjB,CAAmB,CAAA,CAEnB,MAAO,8DAKL,eAKI,gBACN,CyQsOoB,CzQrOpB,CwFVsB,CiL+OF,AzQpOpB,CAAoB,CACpB,CAAoB,CACpB,CAAiB,CACjB,CAAmB,CACnB,CAAmB,CAAA,4BAIjB,EACA,UAAW,EAAA,EAA4B,CAAC,+CAI7B,EqK9KE,ArK8KY,CqK9KX,C7EiKG,AxFasB,CAAC,4BAI5C,CAAC,AAUO,kBACN,CAAqB,CACrB,CAAa,CACb,CAAkB,CAAA,CAGlB,CyQgN0B,AjLxOzB,C6ElKa,A7EkKZ,CAAC,IxFuBH,EAAY,IAAA,CAAK,GACV,4BAIP,CAAqB,CACrB,CAAa,CwF1Be,AxF2B5B,CwF3B6B,AxF2BX,CAAA,SAEP,CAAC,EAAM,CAAG,EwF5BE,AxF4BN,EAEV,CACT,CAAC,AAKO,sBAAA,CAAmC,CqKjMjB,CrKiM+B,CAAA,CAAS,CAE1D,AAF2D,wBAE3D,CAAqC,CAAE,CAAY,CAAA,CACzD,OAAA,IACE,EAAM,OAAO,CAAG,CyQwMQ,CAAA,ezQ5L1B,CAAe,CACf,CqK5MgB,ArK4MJ,CACZ,CAAc,CAAA,AwF5CO,IAAU,GxF+C/B,CAAc,IADA,EACM,AADE,AwF7Cd,C6EhKS,A7EgKR,GxF6CiB,CAAC,EwF7CN,CxF+CZ,EwF9Ca,AxF8CR,GwF7CD,MxF6CU,CAAC,EwF7CD,CAAA,CxF6CiB,GwF7CD,EAAE,EAAE,EAAA,ExF+CpC,KAGD,cAAA,CAA6B,CAAE,CAAY,CAAA,CyQ2LvB,AzQ1L1B,IAAM,EAAc,EyQ2LM,IzQ3LM,CAAC,EyQ2LM,CzQ1LvC,OAAO,OAAA,EAAuB,CAAW,CAAC,CAAC,CAAC,CAAC,AAAE,CAAD,GAAK,AACrD,CADsD,AACrD,4FAx1Ba,GAAA,OAAO,CAAA,oFAEnB,yGAEY,GAAA,EAAA,CAAA,+LsFrDU,IAAA,4WAqCO,CAAA,GAAA,kIAqBd,CAAA,CACA,CACjB,CCmB8D,ADnB/C,CCmBgD,ADlB/D,CiKUc,AjKVK,CAAA,CACF,QAEV,qMgFrFuC,CAAA,CAAA,SAAA,CAAA,CAAA,sDAInB,EAAA,IAAa,CAAA,IAAA,CAAA,wCAEiB,EAAO,ClFEK,IAAA,CAAA,KAAA,CkFFO,C8CRK,A9CQJ,C8CRK,8G9CcX,KAAA,mEAM7D,C6ESuE,A/JIjF,sBkFZE,CAAqB,CACrB,UAAQ,CACT,qEAOU,EAAA,EAAA,0BAI4B,MAAA,CAAO,GACxC,EAAmB,CACpB,CAAC,IqFE+C,GrFEzC,C2CuEgC,CAAC,CAAA,E3CvEnB,AAAC,CyBU0C,EzBVxB,GAAW,IAAgB,IAAI,CAClE,IAAI,CACL,CAAA,CAAA,CAAG,CACP,CAAC,EtKMyC,CAAA,IsKHzC,CAAC,EAAA,IAAiB,CAAA,EAAA,EAAK,EAAM,EAAA,EAAA,EAAM,EAAA,CAAS,CAC7C,CAAC,G6EJ0E,CAAC;E7EKJ,C7EGH,AqHtCU,CxCmCgB,IAAI,CAClG,GmGmC4G,CnGnCxG,CACL,CAAA,CAAA,+FAUH,CAAQ,CAAA,+CAI0B,KAAA,CACgB,sCAQ5C,CAAA,EAAI,GAAA,EAAc,AAAC,CyEyBhB,EzEzBkC,G6CmBiC,A7CnBtB,G7EG1B,C6EH0C,IAAI,CAClE,GAAG,CACJ,CAAA,CAAA,CAAG,CACP,CAAC,UAEgG,QyEsBpE,CAC/B,CAAC;GzEvBkG,EAAA,EAAA,IAChE,CAAA,MAAA,CAAA,CADgE,+BAWtG,gHAOmC,iCAAA,EAAA,IAAA,CAAA,MAS9B,GAAA,sFAsBgD,C6FoDD,iF7FhD9C,EAAA,CAAgB,G2C8BmD,C4DzFgB,aAAA,EvG2D/C,EAAa,EAAA,CAAI,CAAC,AAAE,CAAD,EACzD;wFAGgD,EAAY;;uDAMlD,OAAA,CAAA,SAAA,uCAK0B;0EAGyC,EAAK,IAAI,CAAA,A2CuBnD,K3CvByD,E2CuBzD;AAAA;AAAA;sDAAA,C3CrBwE,sCAMxE,CgG+BC,2BhGxBlC,GAAW,IACX,IAAI,CAAC,QAEuB,sBAAA,GAAS,C/BjBgB,AkG+CI,ClG/CH,AkG+CI,AnE9Bb,CgGuBuB,UhGvBZ,CAAC,GAAG,sDAEP,IAAA,CACnD,EIEiE,CAAC,CAAC,AJF/D,AGK+D,CHJpE,CAAoC;AAAA,MAAA,EAAA,EAAA,UAAA,EAAA,EACG,CnJ9BkB,WAAA,CmJ8BL,IAAA,CAAe,AAAX,UAAW;AAAA,CAAA,EAAA,EtKxCC,yDsKyCG,EgGoBM,AtQ7DV,CAAC;AAAA;oBAAA,CsKuChC,AAGgD,6DAarF,GAAW,IACX,GADkB,CACd,AADe,CACd,IAAI,CAAC,CAAC,EAEiB,CAAC,qBAAA,GAAA,EAAgB,WAAA,CAAY,CuCUoB,EAAA,wCvCRxC,EAAA,gBAAA,CAAyB,CtJcS,GAAA,CAAA,MAAA,QAAA,EsJZ3D,E/B5B4C,Q+B4BlC,CAAA,C/B5BkC,A+B4BlC,E/B5BkC,E+B6BpC,YAAY,CAAC,IAAA,CAAA;AAAA,CAAA,EAAA,EAAA;AAAA,CADR,AAE+C,C/B9BhB,A+B8BiB,OAMpE,QtKvDmE,CACrE,CAAC;CsKoD0F,CAAA,mFAUjE,CAAC,mBAAN,MACb,EAAA,UAAA,CAAA,GAAA,0CAIyC,YAAY,CAAC,C0BjC9B,G1BiCkC,CAAA;AAAA,oCAAA,CAAmC,yBAanG,gBAZiC,2BAqBtC,CAAA,GAFH,2BAEG,EAAA,EAAA,cAAA,CAA0D,CAAC,CAAA,AAAG,CAAH,OAAG,EAAA,EAAA,WAAA,CAChC,E8CrEM,AHkDE,C3CmBL,CAAA,UAAA,EAAA,EAAA,YAAA,CAAkC,EmECM,EnEDF,CAAA;AAAA,sDAAA,CAAW,AADpB,mCAYJ,wBAVF,CAAC,EGzBC,CDVA,CAAC,ACUC,EAAE,C2C5CM,AHkDA,CGlDC;A9CiFnE,GAFwD,EAAA,EAAA,WAAA,CAChC,GAAA,CAAA,UAAA,EACxB,EAAA,YAAoB,CAAC,IACvB,CAAA;AAAA,KAAA,EACE,EAAQ,WAAW,CAAC,UAAU,CAAC,MAAM,CAAG,CAC1C,CAAA,cAAA,CAL0D,AAK1C,CAAC,+CASkB,CAAA,IAAK,C9EzCD,A8EyCE,wBAEhB,CoGjHuB,GpGkHlC,CyGzHkD,A/QgEvB,CsKyDlB,IAAI,CAC5B,CAAC,EyG1HgF,YzG2HrC,EAAA,MAAA,CAAA,4BAIP;AAAA,OAAA,EAAA,EwD4BT,6BxD3BgD,CEhD3E,CsD2E2B;AAAA;AxD1BoE,CwD0BpE,ExD1B+C,kBAAiB,EAAA,CAAI;AAAA;AAAA,4DAAA,CAF3D,oHAwBF,MAAM,iBAG7B,EAAA,YAAA,CAGE,CAAA,8BAAA,EAAiC,EAAQ,wCAAA,EAA2C,EAAQ,WAAW,CAAA,EAAA,CAAI,CAAC,AoF5GjF,uUnF1KY,CAAA,IAChD,CAAC,YAAY,CACjB,CDQqB,A/ELrB,E+EKuB,CCRnB,mCAI4B,sBAAA,gFrDpBxC,SAAS,AAAU,CAAK,CAAE,CAAC,CAAE,CAAK,EAChC,IAAI,EAAkB,MAAT,EAAgB,EAAI,CASpB,CAT0B,MAAM,QAC7C,AAAK,EAKE,EALH,CAKa,EAAO,CALX,CAKc,CAD3B,EAAI,GADJ,EAAK,GAAe,SAAN,EAAmB,EAAI,GAAU,EAAA,CAClC,EACkB,EAAI,EAAI,GAJ9B,EAKX,AALa,KCPb,SAAS,AAAQ,CAAU,CAAE,CAAQ,EACnC,OAAO,GAAY,GAAI,EAAY,GAAW,CAGjC,CAFf,K5HhBA,SAAS,AAAgB,CAAK,CAAE,CAAM,CAAE,CAAQ,CAAE,CAAW,EAI3D,IAHA,IAAI,EAAQ,CAAC,EACT,EASS,AATS,MAAT,EAAgB,EAAI,EAAM,MAAM,CAEtC,EAAE,EAAQ,GAAQ,CACvB,IAAI,EAAQ,CAAK,CAAC,EAAM,CACxB,EAAO,EAAa,EAAO,EAAS,GAAQ,EAC9C,CACA,OAAO,CACT,K8DNA,SAAS,AAAe,CAAU,CAAE,CAAM,CAAE,CAAQ,CAAE,CAAW,EAI/D,OAHA,GAAS,EAAY,GAMR,MANiB,CAAK,CAAE,CAAG,CAAE,CAAU,EAClD,EAAO,EAAa,EAAO,EAAS,GAAQ,EAC9C,GACO,CACT,E+DXA,IAAI,GAHc,AAGG,OAHI,SAAS,CAGD,cAAc,CAyB3C,OAA2B,GAAjB,MAA0B,CAAM,CAAE,CAAK,CAAE,CAAG,EACpD,GAAe,IAAI,CAAC,EAAQ,GAC9B,CAAM,CAAC,CAD6B,CACzB,CAAC,IAAI,CAAC,GAEjB,GAAgB,EAAQ,EAAK,CAAC,EAAM,CAExC,EgExBS,SAAS,CAAU,CAAE,CAAQ,EAIlC,MAAO,CAHI,GAAQ,GAAc,GAAkB,EAAA,EAGvC,CAFR,CAEoB,GAAQ,GAAa,EAAU,GAFP,CAEW,AAFV,CAA/B,CAGpB,aAHkC,+IZuBA,CAAA,gOAmBU,EAAA,OAAA,iEACyB,IAG9D,SAAA,CAAA,GAAA,gBAH+F,QAI/E,GAAA,+GAcR,EAAA,yKAgBO,cAAA,CAAA,6JAaa,SAAA,CAAU,GAAG,sDACS,GAAG,kDAa3C,mEANa,CAAA,oJAkBjB,YAAA,CAAA,IAAA,GAAsB,IAAA,CAAA,gBAAA,EAAA,EACtB,GAAA,GAAA,IAAA,CAAA,sBAAA,EAAA,CAAA,IAAA,CAAA,KAAA,CAAA,0BAGH,CACyC,CADzC,MAAA,CAAA,iDAoBN,MAAA,WAAyD,CyC8BxC,wMzCV0B,iBAItB,CAAA,gBAEE,CAAA,UAAA,CAAA,YACgB,MAAM,CAAA,iCACA,+EAGrB,CiG6KS,EAAA,GjG7KY,YAGxC,CAAA,SAAA,EAAA,EAAA,qBAKyC,gBAEZ,CAAA,CAAA,CAAA,CAAA,CAAA,sCAKD,EAAS,EqC6BQ,IrC7BF,CAAA,2BACzB,CAAA,KAAA,IAAA,wCAEiB,YAAY,0BACP,GAAA,6BAGJ,0CAQpB,CAAA,CAAA,CAAA,iBAGS,C2FoHC,SAAA,CAAA,kB3FnHoB,CAAC,iCACD,4CAER,EuC1EU,CyBmBC,AzBnBA,CvH8EP,AuH9EQ,AyBmBA,ChJ2DP,AuH9EQ,AyBmBA,OhEuDD,aACzC,UAAA,CAAA,EAAkC,GAAG,CAAC,E4ChCoE,A1CiD3G,CuCFoE,CAAC,AvCEnE,2BFdgC,qBAMK,sBAEH,CAAA,CAAA,CAEnD,ChFS4C,AgFTrB,ChFUd,4BgFRsC,CtJhBD,A6OwEM,WvFtDvC,CsD4EA,KtD5EM,CAAC,oDAG+B,G1KqDK,O0KrDK,OAC7C,KAAA,CAAA,EAA0C,C9JnCW,W8JmCC,CAAC,WACxD,CAAC,UAAA,CAAA,EAA+C,GAAG,QAE3D,uBACmB,EAAmB,EAAA,sBAavB,EAAE,mCAa+B,WAEnC,QANC,CAAC,GAAK,EAAA,EAAe,CAAC,CAAC,AhFMtC,CgFNuC,AG1C5B,CHiDf,EACA,2BAYG,EAAA,MAAA,CAAA,GAAA,EAAmC,EAAU,MAAM,EAAA,KAClD,EAAA,CAAA,CAAiB,EAAA,2BAId,EAAA,EAA4B,UAAA,qEAIE,UAAU,4CACD,YAMhB,oEAUvB,sBAPyB,EAF2B,AAE3B,ChFWsB,SgFXP,CAAE,CAAC,AuFyCQ,4CvFvCP,CgEtEW,QhEsEF,CAAE,CAAC,CAAC,CAAC,ChFcC,CAAC,CAAC,GgFdG,CAC5D,EAAK,EAAD,QAAW,CACrB,UAIA,GAAA,aAAA,yBAA6C,OhFaD,GgFXhC,aACA,IAAA,GAAA,CAAe,aAAc,EAAK,SAAS,CAAE,CAAC,A1K0D3C,Q0K1DmD,CAC5D,EAAI,EAAA,QAAW,CACrB,GAEJ,C1KwDyB,AkMnElB,AxBWN,4BAQO,OAN4B,ChFeP,agFdO,CAAA,gCAEN,CwBHW,oDxBQhB,CqC4BO,IrCxBK,IAAhC,GAAuC,AAAvC,EAAgB,UAAA,UACsB,GtJyCW,AlBrCJ,CkBqCK,ClBrCH,AkBqCI,MsJzCH,CAAC,C8FkGW,A9FlGV,EAGjD,UACE,aAAgB,SACZ,CAAA,EAAA,YAAA,wDAOV,IAAA,CAAA,mCAKA,EAUH,SAAA,GAAA,CAAA,CAAA,CAEiB,CACrB,CAAwB,CuG5FkD,CvG6FtD,ExJuDF,CACf,CAAC,IuHpB0C,CAAC,CAC5C,CAAC,oBiCjC0B,CAAC,EAAkB,GACnB,CxJ6DN,AyPsTI,wCjG/WwC,CAAC,CAAC,CmE7GG,mBnEkHvD,CAAC,YAEZ,+BAEY,CuBxEK,CAAA,GvB2EjB,CAAA,GAAA,IAAyB,YACI,EAAG,CAAC,AhFcC,6BgFLrB,GAAA,kBAFd,aAQwB,CAAC,AhFoBE,EgFnBT,EAAA,SAAA,uCAQtB,IAAA,EAAa,CAAA,CAAQ,EAAA,eAGb,EAAW,oDAIY,MAEf,IAAA,CAAA,WACL,C4FuLG,YAAA,U5FvLuB,kBAI3B,CAAyB,CAAA,EAAS,CHhEK,AGgEJ,AACZ,C2FkQE,C3FlQE,EAAjB,AAAiB,UAAa,CAAC,CAAE,OAC9B,iBAGf,UAAW,CgE3Fa,iBhE4FP,UAEA,SAGhB,CsD+EK,EAAA,IAAA,EtD/E+B,CAAC,EAAE,CAErC,IAAI,CAAA,CACT,cAAA,EAAA,YAAgC,uBACN,EsDgFY,CAAA,6BtD9ErB,cAInB,MAAA,MAAA,gCAEO,aAAA,GAA6B,CxKkCJ,AyOfO,CAAC,AzOeP,GwKjC7B,EAAe,GAAM,UACT,EAAA,eAAA,gBAGC,IAAA,CAAK,EAAA,GAAA,aAGjB,QACK,UAAU,CAAA,MAAO,CAAC,EAAuB,GxKkCC,AwKlCI,CxKkCH,AwKlCE,aAC5C,C4FmMa,C5FlMxB,CwBuBa,C2CzIH,cnEkHO,qBAGV,aAAgB,GAAQ,CgE5FI,iBhEgG9B,GAAA,mDAMY,gCAIG,CAAC,MAAM,CAAA,GAAM,IACjC,GADwC,OACxC,oCAIG,GAAI,aAAA,GAAqC,EsD4F0B,YtD1FjC,cACpB,EsD6FU,AhOuBN,QAAA,sC0KjHQ,CAAC,CHzDG,KGyDG,CAAC,CAAC,EAAgB,CAAE,GAAK,IAI7D,GxKuCmD,AwK3CiB,CAAC,CAAC,CAAC,IAI5D,kBACM,C1K2HO,Q0KzHR,CAAA,WACT,aAAgB,GAAkC,cAKpB,CxK8C1B,WwK7CC,KAJY,GAAA,CACxB,CxK8CC,AwFgBM,CAAC,CiFqBD,AuB3CI,UAAA,EAAA,SxBxCiB,GAGI,CAAC,GxJmIE,CAAC,EwJnIG,CAAC,EAAK,EAAD,OwByCa,CxBzCF,CAAC,IwByCO,CAAC,AxBxC3D,EAAA,GAAA,MAIL,IAAA,EACA,CiG+WS,GjGlXL,CAGC,CAHD,A4F+MU,U5F/Me,CAAA,MAAO,CAAA,CAAE,CCoFG,CDpFa,CAAE,GxJwIK,AwJxID,CxJwIE,AwJxIF,GAI5D,UAAW,EACX,gBAAA,SAEgB,CAAC,WACV,EmEvHI,WAAA,GnEuHqC,YAG3C,wCAGY,2BASb,EAAgB,C4FoNW,G5FpNP,GAAW,OhFmEA,agFtEF,cACnB,EAAA,SAAc,EhFkEQ,CgF/DJ,CAAA,MAAO,CAAC,EAAK,AmE1HE,CAAC,CnE0HJ,QAAW,CAAC,OmE1HY,anE+H/D,MAFS,CAGT,CiG4WiB,A9B1eE,UnE2HK,CAAC,MAAA,CAAO,CAAC,EAAc,CAAE,GAAI,CAAA,aAI/C,kBACM,qBAGV,aAAgB,GAAA,YAGlB,GxJ2JS,AlBJJ,M0KtJA,+BAEO,KAEL,IAAA,CAAA,GAEd,CiGgXO,CjGhXO,CqC+CO,GAAA,CAAA,OrC5Cf,CqC8CO,ApCoEF,AsF7BE,A/O+EF,CAAA,IAAA,GAAA,cwJnKQ,UAAA,CACjB,IAAA,EAAU,GAAG,CiG+WS,AzEpTA,AabA,CbaA,cxBzDR,CqC8CO,CAAA,UAAA,CAAA,MrC9Ce,CAAC,OAAsB,CiG+WO,oCjGxWtD,IAAA,CAAK,mCAGV,CwB8DO,AxB9DN,CAAG,CqCgDO,ApC8EN,CoC9EM,UrChDQ,CAAA,MAAA,CAAU,CAAC,CAAE,GAAK,CAAC,CAAA,IAAO,OAEhC,CAClB,IAAK,C4F6Oe,AvD7LJ,KrClDG,EAAK,UAAA,CAAW,EAAE,CAAC,AAGzB,MC6HO,AgGmPS,EhGhPN,CAAC,CDhID,CAAC,MAAM,CAAC,GAAK,CAAD,MAAQ,CAAC,CAAC,4BAIjC,IAAI,CAAC,KACL,C4F4Oa,GAAA,CAAA,2B5FzO7B,EAAA,IAAA,CAAmB,GADmB,EAE/B,CxJsLC,iBwJrLc,CAAC,MAAM,CAAC,GAAK,cACtB,kBACM,YAEV,aAAA,MAAsB,aAY5B,CAAA,CAEP,CAAA,CAAA,CACuB,CACvB,CxJ2LyD,AwJ3L5B,CxJ2L6B,CAAC,MwJzLtC,CqCgDG,ErChDG,UACT,EAAQ,CwB8DG,GAAA,ExB5D7B,IAAM,EAAyB,EhF4FT,CxE4FO,CAAA,WwJtLN,IAAI,CAAC,CAAC,CAAC,CAAC,AAExB,KACA,MACA,EAAQ,UAAU,CACvB,UAAA,kBACiB,IA1BM,EAAM,EAAS,AAAX,EAA0B,GAAjB,QAAe,QAAqB,CAAC,CACtE,CAAC,8BAKC,uFC5iBkC,mIAQvB,IAAA,qCAAA,8KASgD,kIAalB,CAAA,CAAA,mDAO5C,CqCrBuD,CAAA,EAAA,mBrCqG3D,CAAA,CACA,CAA6B,CoCyB0B,CAAC,CAAC,qBpCtBb,sCAWnC,SAAA,CAAA,kBASkB,IAAI,kCAKnB,EAAA,EAAA,MAAA,gBAGgB,OAAA,CAA0C,IAA1C,EAAA,CAAiD,GAAlB,CAAA,CEzDP,GFyDY,GzJeY,CAAC,CAAC,WyJX9C,EAAA,EAAoB,CAAC,EAAE,CAAA,SACtB,EAAA,GACF,CzK7CD,AyQkMY,AzEpKA,AwDvEC,AuBSD,CAAA,MAAA,atG8ElB,EAAI,C7J7CS,C6J6CO,IAAK,IAEM,OAAO,4EAuDjD,EAAA,EAAA,EAAA,EAAsB,CAAC,A2C5CM,G3C4CF,SACb,EAAA,CACf,EAAA,EAAA,MAA+B,CAAC,AoGrFQ,AdoIA,MtF9C/B,IAAI,EAAI,CAAC,CAAA,EAAM,EAAgB,IAAK,KAC3C,EAAA,CAAA,CAAmB,EAAA,CACzB,EAAA,EAAgC,MAAM,CAAC,AzKXJ,IyKY9B,IAAI,EAAI,EAAA,EAAA,EAAA,QAEkC,KwCGxB,AxCH6B,EAAE,GAD9B,CAAC,EAAE,CAAC,EAAA,GACE,CgE6Ba,AxB1BpB,AxCHe,CgE6BM,AhE7BN,EAAA,kDAtC1C,CAAC,EAAQ,EAAS,WADlB,UAGiC,YAAa,CAAC,AuBpBK,CAAC,CvBoBJ,GACpC,EAAA,YAAA,CAAA,CAA6B,CAAA,KAE9B,EAAA,eAAA,CAAA,6BAC+B,oCAcpB,EAAE,CAAC,eACe,CAAC,CAAC,gBAsC/C,CvJKW,CAAA,CuJJkB,aAEc,AAAC,GAC1B,MAAA,MAAA,EAGZ,EAAa,EAAA,MAAA,QAIY,uBAAA,4BAkCJ,EAAA,WACiB,wBAGS,iBADf,CAAC,AiF/DU,CAAC,AjF+DV,CACJ,CsC3FW,AtC2FH,CAAC,AsC3FG,C/LmIH,A+OLI,CtFnCJ,6BAWlC,CoG9FO,AlCRE,AtE2CV,CIUqB,iBAIE,CAAC,aAAA,GAAA,CACC,CAAC,EAAG,CAAA,eAAgB,CAAC,AzJ2BL,CAAA,QyJzBJ,CAAC,CAAC,CAAC,CAAC,KoCwBW,CAAC,CAAC,KpCvBQ,CAAC,AsBvED,OtByE7D,oDAID,EAAA,GAAA,EAAA,CAAA,EAEK,EAAa,GAAG,EAAE,EAAE,wBAEP,eAAA,CAAA,MACX,EAAkB,EAAG,C5JkFG,M4J9EnC,EAAe,0BAK2B,CAAA,6BAAD,CAAC,SAGzC,4SAuBT,OAAM,WAAA,2CAIM,8HAee,C0F0MoB,AxB1TI,ClEiHxB,CsGnGF,ApCdoC,qClEoHrB,EAAA,IAAA,CAAA,cAAA,GAAA,gBAGtB,CAAG,EAAA,MAAA,CAAA,IACR,kBAST,CAAuB,CAAA,yBAEuB,K2F+Ka,C3F/KP,C2F+KS,A3F/KP,AlCkCC,EkClCS,CzKND,EAAE,MyKO1D,CAAA,CADoE,UACpE,EAAwB,CoCEO,CpCFG,oBAMzC,CjFH4B,AwGJK,CAAA,CAAA,CAAA,oBvBY7B,EAAA,GAAA,oBAC8B,CAC9B,EACA,MADQ,EACA,CACT,EACD,YACiC,EAAA,0BAOZ,CAAA,MAGf,aAAa,CAAA,EAAA,GAEP,mCAAmC,CAC7C,EAAA,WAGF,UACiB,EAAA,EAA6B,QAAQ,CAAC,CAAC,GAKtC,CsFVF,AtFWlB,CAAA,CACA,CAAuB,CAAA,MAGf,aAAA,CAAc,EAAA,GAAA,UAAA,CAAA,EAAA,UAEd,CjFxBK,AiFuBX,UjFvBW,EAAA,EAAA,kBiF8BU,CsChJW,A8DAA,ApGiJlC,CAAuB,CAAA,CjFvBqB,AiFyB5C,AACG,IAAI,CAAC,aAAA,CAAA,EAAA,GAEM,yBAAyB,CACnC,EACA,QAAQ,CACT,EACD,YAC8B,CkEpKO,ClEoKG,CgE7BO,GhEqCrD,MAAA,WAA4C,CzK7BH,A+PEI,ctF+BjC,CAAA,CAAA,CAAA,CAEA,ClCAF,AkCAiB,CgEpCyB,AhEoCzB,sEAAf,gBALuB,CAAC,qEAgBX,GAAK,CjFjBN,EAAA,CiFkBb,AjFlBa,KiFkBb,IjFlBa,IiFkBb,CAAA,SAAA,EAA4B,IAAA,IAAa,CAAA,SAAA,AAAU,CAAC,EACzD,C0FqM8D,CAAC,I1FpM1D,MAAM,CAAA,EAAA,UAAA,cAII,CAAA,CAAY,EoCtBT,A2B7HA,CxNyKL,CwNzKO,qE/DwJG,CzK/BH,EyK+Ba,UAAU,CAAC,CAAC,0BAGQ,CAAA,6CACA,CAAC,AAC1D,CAD2D,AAC1D,AuBrCE,C+DMC,OjQsDgB,8B2KpBlB,C+DvJuC,A/DuJD,CgE5CK,yBhE8CR,mCAAmC,CAAC,CAAC,iFAIZ,CqDgBK,ArDhBJ,CqDgBI,ArDhBH,kBAGvB,CAAA,yBACJ,EoC5BM,SpC4BK,CAAC,CAAC,CAEnD,AAED,SAAA,GAAiC,CAAA,iCAEL,qBAW5B,SAAS,GAAA,CAAgC,SAC3B,YACH,EAAI,CAAC,AzJoCJ,CAAA,EAAA,EAAA,MAAA,CAAA,IAAA,QyJnCY,CAAA,EAAG,CACjB,EAAA,EAAe,KAChB,CzJqCD,A8MvBM,GAAA,EAAA,EAAA,ErDdU,EAAI,EqDcI,ArDdJ,IAAA,CAAS,IAAK,CACpC,EuB5CiB,EvB4CjB,EAAA,CAAA,CAA4B,CAAC,CAAA,OACd,CDpEoC,ACoEpC,EAAA,IAAA,EAAA,YAA4C,CAAC,CAAC,QACpD,CAAC,AJ9HE,AmEhCI,CAAA,EAAA,E/D8JI,EAAQ,KAAD,AzKjCJ,UyKiCqB,CAAC,MAAM,CAAE,CAAC,AzKjCL,CAAC,CyKiCM,CAAE,OAC5B,GAAG,CAAG,CjFfa,CAAC,AiFeN,KAAD,UAAiB,CAAC,CAAC,CAAC,CAAC,MAC/C,CAAC,EkEnLU,AnJoKN,AiFea,CkEnLS,CAAC,CFmIC,AEnIA,CFmIC,IhEqDnD,OAAO,CACT,CuBrCC,AvBqCA,AA+BK,SAAA,GAAA,CACmB,CACvB,CAAS,C2FyHoE,CAAC,E3BtLf,EhE+DzD,EAAA,GAAA,EAA4B,AAAC,EkErMI,CAAA,GlEsMnB,CAAC,EAAQ,CAAE,CAAC,CAAC,CAChC,CAAC,AAD0B,AAEtB,EAAA,GAAA,EAAkD,CJ1ID,KI0IO,CJ1ID,AI0IE,CAAC,AAC1D,EAAa,CqDaG,EAAA,ErDbc,QAC5B,CqDaK,CrDb8B,CAAA,cAClB,OACf,GAAA,EAA2B,WAAA,EACnB,IACZ,CAAI,CAAC,EAAA,CAAA,CAAA,UkErMR,ElE0MW,MAGT,IAAA,EAAA,EAAA,GAAkC,EAAA,IAAiB,OAClC,CJxIC,CAAC,AoGmaI,C3C9QC,YrDZyB,CAAC,AzJoDA,CyJpDC,YAGjC,EAAS,EAAY,EzJoDE,CAAC,CAAC,EyJpDE,CAAE,IAAU,EAAJ,EAAE,CAClD,EAAA,CAAA,CAAsC,EAAO,CAAC,IqDsBvC,YrDlB2B,MAAM,CAC5C,IACA,OADW,CAEmC,CAFjC,AAEkC,EAAY,CAAC,QAAF,GAAa,CAAC,IAC9B,EAAY,CAAC,C2FwHzC,EAAE,EAAE,G3FxHmC,CAAW,CAAC,EAC9C,GAAe,MAC5B,AA/Dd,SAAA,CAC8C,CAC5C,CjFjB4C,AiJlCE,AzOoBN,AwFcM,CgJlJC,AhJkJD,CAAA,AiFkBnC,IzKhCmD,EyKmC5D,IAAA,EAAA,EAAA,EACa,CgEvD0B,CAAA,MAAA,ChEwDvC,IACA,QAEmB,CgE3DoE,CAAC,CAAC,MzN4FvD,CAC/B,CAAC,IyJ/BE,EAAA,CAAA,CAA2C,EAAA,WAC5B,CAAC,AgGkSI,CAAA,EAAA,EAAA,MhGlS+B,CAAE,OgEvDb,CAAA,ChEuDsB,EAAE,CAAE,EAE3C,AAAqB,CzKrClB,CyKoCG,EAAA,CACI,CgEzDO,mBhEuGN,EAAY,ED1FF,AC0Fc,CzKzCX,AoQiKwB,K3FxHP,CAAC,AAE3C,CAF4C,AgGwRnC,AzQ9TR,GyKwCa,CoCvCS,CAAC,ApCuCK,CoCvCJ,KpCuCU,GAAK,CAAC,CAAE,OAC3C,CjFxBU,CmJ1LI,AlEkNF,CkElNG,CnJ0LP,AiFwBW,CAAC,AjFxBX,CAAC,CmJ1LmB,ClEoNlC,CAAA,CkEpN0C,CAAC,ElEoNxD,GAAa,EAAA,GAA0C,OACvC,CAAA,OAEb,IAAA,EAAQ,EAAA,EAAO,ED1FQ,AC0FG,CsFTI,AvFjFN,CuFiFO,AvFjFN,CuFiFO,GtFSA,CAAE,CAAC,EAAE,CAAE,CAC1C,IAAA,EAAgB,C3KkDW,AE1FR,AyKwCO,CAAC,AjFxBD,CiFwBE,CAAC,CAC7B,CAAU,CAAC,EAAA,CAAA,EAAgB,EAAG,QAK/B,CACH,IAAA,EAAA,GACE,EoC1Cc,ApC2Cd,EAAa,CAAC,AoC3CuB,CAAA,EpC8CvC,EAAA,CAAA,EAAe,CAAG,CzK3CP,AyK2Cc,CAAC,EAAO,CAAC,EzK3Ca,CyK2Cf,GAAQ,CAAA,MAGhC,EAA4B,OAC5B,GAAA,EAAiC,WAAW,CAAC,CAAC,AAC/B,CzJ0Df,GyJzDJ,CgGiRe,ApGhaJ,AI+ID,CJ/IE,AI+ID,CD9FO,CC8FA,CAAC,C2FsHc,CAAC,A3FtHX,CAAN,AAAK,CAAI,CAC5B,GADgC,CAAC,WAQpC,CACT,CAAC,AAEK,SAAA,GACJ,CAAkB,CjFzB4B,AiF0B9C,CAAiB,CAAA,CACR,CACT,CAAoB,MAEd,EAAA,IAAA,GAAA,EAEJ,GAAU,CzJ0De,UyJ1DJ,CzJ0De,mByJvDnB,EzJwDF,CyJvDV,GAAA,EAAA,MAAgD,CAAE,CAAC,CAAC,CAAC,YAI5D,CAAkB,CAClB,CAAiB,CACjB,CAAmB,CACnB,CAAS,MAEH,EAAmB,IAAA,GzKpDyD,AyKqDhF,EAAA,mBAII,EAAA,EAAA,MAAmC,CAAC,AAOpC,EALiB,AAKjB,IALqB,CDnHL,ECoHpB,EACA,EACA,GAE8B,YAAA,UAKzB,GAAkC,CAHtB,IAAA,GAAA,CAAsB,OoC1ES,CAAC,CAAC,CpC0ED,CAAE,CAAS,CAAE,CAAC,CAAC,AAC5D,IAAA,CADwD,EACxD,WjF9CgF,CiF8ClC,IAEY,CAAE,CAAC,CAAC,CAAC,AAGjE,SAAA,GACJ,CAAA,CAAA,CAAA,YAG2B,EAAI,CAAC,CAAA,EAAM,EAAY,MAAM,CAAA,IAAO,QAChC,CAAC,CAAC,CAAA,uBACW,EAAE,IAGvC,IAAA,EAAA,EAAA,EAAA,EAAA,MAAA,CAAiC,IAAK,KACnC,EAAY,CAAA,CAAW,EAAE,CAAC,IACL,EAAA,QAErB,CAAA,IAAA,GAAA,KAEsD,IAFtD,EAEK,kBAAmB,CAAC,EAAA,YAAuB,CAAC,AAAK,oBAKvD,UAGF,CACT,CAAC,AAkBK,SAAA,GACJ,CAAmC,EzJ2CH,OyJzCzB,GAAA,EAAA,GACL,GAAM,EAAgB,AAAC,GACrB,CADmC,EAC7B,EAAD,AAAa,AAAC,EADY,CACF,CAAD,AADK,CACT,CAAa,CAAX,CAAV,AAA2B,EAAP,CAAM,YAAiB,CAAC,CAAC,CAC9D,CACF,AACH,CADI,AACH,6H3KxjB4B,4RAuBrB,CAAA,cAAe,CAAA,IAAA,CAAA,gEAMC,IAAA,CAAA,gHAWD,CAAA,CAAA,wJA0JtB,sIA4F4B,C6OvLK,4B7O0L+B,CAAA,qBACzC,IAAA,CAAA,yCAIpB,CAA+C,CAAA,oBAE5B,CAAC,IAAI,CAAA,0CAIJ,IAAA,CAAA,qmBgR5YL,sDASa,CAAA,mJvI0U1B,SAAU,GAAA,CAAA,CAAA,CAAA,CAAA,CAIc,CAAA,CACR,CAAA,CAAA,CAEpB,CAAgE,CAChE,CAAkB,QAEN,IAAA,CAAK,2BAAA,CAA4B,E6H6IQ,ApEpLJ,AzDuCU,CrHZb,A8K3BI,4BzDwCA,CkGvBG,AlGuBF,6CAEJ,SAGvC,eAAe,UAFsB,EAAA,CAAG,EAAa,CAAC,AAEvC,EiGnI6C,CjGoIvC,YAAY,2BACb,CAAA,QAGE,CwHpBG,CxHoBe,AwHpBd,EUwVE,GlIpUY,eACH,gBACI,CAAC,AAKrB,EkCjBmB,AjFnBI,CAAC,iB+CoCnC,MAAA,EAAW,GAAA,KAAA,IAAA,EAG3B,wCAOqE,kCAK/B,CAAA,EAEpC,EACA,QAAQ,CACT,uBAK2B,CAC1B,EAAA,EAEA,EACA,C/C5B6D,CAAC,ExEuCnD,uE+NjcX,CzEL2D,CAAA,YyEKtC,AzELsC,EyEKtC,EAAI,GAAsB,YAAY,CAAC,KAAd,iBAQhB,CAAC,uBAAA,CAAA,EAAA,KAAA,yDAGyB,EAAQ,CtGnBD,IsGmBM,kDACI,CACvE,EAAA,KAAA,CACA,IAAI,CAAA,YAAa,CAClB,CAAC,0CAEA,EAAA,KAAA,CAAA,IACI,CAAA,YAAa,CAClB,CAAC,2DjPgON,CAAA,CAAA,CAAA,CAEA,CsN7F0E,CpByBC,AoBzBA,AtN6F5D,EAAE,wBAsCkB,CAAA,sEAQG,aACA,CiRtIK,AjD2JA,ArD5Ed,A3KuDU,AEjER,sBFmER,IAAA,aAAA,IAAA,aAAA,IAAA,aAAA,IAAA,aAAA,IAAA,aAKA,CiRvIO,AvCkBM,e1OwHI,EAAU,UAAA,+CAKtB,CAAA,GACtB,CiR3I4D,CjR2IrB,EAAY,KiR3I6C,KjR2InC,CAAC,CAC/D,AiR5IwG,4CjRiJ/F,C+QhJK,gC/QmJoB,0EArEgB,CgODvC,ApD9CgC,C5KyHzC,QA1E0D,CAAC,CgOAnD,AhOAoD,gCAKtC,GAAA,EAAA,sBAGC,CiNlIS,AoDwMJ,sBAAA,CrQtEmB,CAC9C,aAAA,gCAG8B,C2QgMS,CAAC,AV9LA,YAAA,uBjQKxC,GAAA,EAA8C,EAAK,MAAA,CAAO,CAAC,EAAQ,CAAC,EACtC,QAC5B,EAAA,CAD4B,EAC5B,0BAKJ,EACA,2BiPjPA,EACA,EACA,C9BiEgG,MAAiB,CAAC,CAAC,CAAC,uDnN8OpH,EAAA,IAAA,kBAEA,EAAA,YAAA,IAMK,kBADuC,EACvC,CAAqB,EAAA,UAExB,CAAC,E+M/BuD,AlC9DN,AHmCJ,C1K2D9C,C+MhCyE,C/MgCvE,CACF,GACA,CAAC,CACF,CAAC,WiPpTF,CjP8DY,wBAuPqB,IAGuB,CAAA,yDAKlB,mBAAmB,YAC5B,IAAA,iBACD,eACI,CAAC,AsN9GU,sD2B3M3B,CAAA,qBjP2UhB,CoB1BC,UpB0Ba,IAAA,e0K/Df,G1KqEC,GAJF,EAAA,YAAA,CAIE,GAAgD,AAAxB,CAAwB,MAAxB,iBAAwB,E0KrEjD,A1KuEwB,gCAGrB,EAAA,uBACJ,CwQ6B+C,CxQ/BH,E0FjDJ,AuJ/RtC,EjPqVF,MAsHJ,CkM/EuC,CyE6VD,A3QjYlC,EALA,AAyHJ,EAnHI,EAoHJ,EkBJgB,ElBhHN,AAkHiB,AAG3B,EiP7cM,AjPyVF,AAFY,CAoHQ,C0F5KqD,A1FmD7D,CA6HV,CA5HF,CAG0B,AAyHW,C0KrMV,AtJ8CE,CAAC,A6OJE,AjQ2JK,AiNzRL,CjN+T9B,AoB7L6B,EFiJjB,ClBOW,AkBN1B,ClBjHa,CsQsND,CAAA,AtQrNX,EsQqNW,CtQ7FZ,EAAQ,E2QwQ8C,A3QxQrC,CA/HE,EsQ4NmC,GtQ3FQ,MAAM,GiPpd7B,CACrC,CACF,CAAC,OjPkdsC,CAAC,iBAAiB,6BAMjB,OuKnKK,UvKsKX,KAEmC,IAAI,EAClE,WADuB,EAAgB,CAAC,iBAAiB,EAEzD,EAAA,IAAA,CAA2B,C2KtCG,a3K2CD,C6O3NO,A7O2NN,EAAA,CAAA,EAR4B,CAS9C,A0KhH+C,CAAC,C1KgH3B,A0KhH4B,Q1KgHpB,CAAC,EAC5C,AACwB,CAAA,8BApBnB,GA6BX,EAAA,EAGI,AAAwC,CkBF5B,kBlBIQ,CAAA,GACN,EAAa,CAAC,CAC/B,CAAC,KAD0B,CAUrB,CACL,QARkB,EAAA,8BAA6C,CAAC,8DAIlC,C0OhNO,G1OgNH,O2Q2Pa,kB3QtPD,CAC9C,SAAA,EAAA,IAAA,YACY,EAAA,GAAe,EgOvBQ,chOwBH,IAAA,CAEpC,CAAC,MAMD,C0F5DgD,C1FtH5C,CiQxCwE,CAAC,AjQ2N7E,CiQ3N8E,ApBzIA,C7OkL1E,EAmLJ,EiPnhBM,CrOfuE,CZ+WnE,AAoLV,AAH2B,AAEjB,EAlLN,CkB5BkC,AlB6Md,MiPlhBP,EjPuhBX,EAAA,CAH+C,EAInD,AAtLE,E0FsHkB,A1FiEpB,CkBnNoB,AlBmNnB,E0K7HuC,A1K6H/B,EAAS,EAAX,CAAc,EAAL,AAAO,EAAE,OACK,EAAS,AAAC,GEhFH,AFyF7B,CARG,CAAE,IAAA,mBAEJ,EAAA,MAAA,CAAA,IAET,EAAA,EAIQ,QAGoC,IAFlB,E0KlIJ,A1KoI4B,IEnFpC,MwKjDQ,CAAA,E1KkI0C,GAAG,CAAC,CAAC,kBAGjE,MAAO,EAAA,OAES,EAAA,GAAA,GACC,EAAA,IAAA,QAkBU,AAsBtB,GAtCkC,GkBKI,CAAF,CAAC,AlBH1C,AAAC,CAF4C,AkBKF,OyJmEjD,MAAmB,EAhHwB,AAiH3C,A3KvEuB,C2K1CoB,C3K0ClB,EAAE,GAIL,GAWhB,OAX0B,CAAA,EAAkB,GAAA,CAAA,CAAA,iBAAsB,C2K9C7B,CAAA,EAAA,G3KgDb,CsQ2Eb,MtQxEc,CgOrBK,ChOqBY,IAAI,Y2KiE5B,MAAM,EsFnCU,GAAA,EAAA,CAAA,EAAA,WjQ9Bc,E2KmEvB,CkEpQC,A8B8eM,ChG1OH,CAAC,AzKzDJ,C2O3MK,I7OiM2B,CAAC,CACxD,CAAC,G2KoEQ,GAAA,C3KvEkD,C2KwEjD,kBAAmB,CAAC,EAAQ,YAAA,CAAc,M3K/DvD,AAAC,UACqB,CAAC,C0K3IL,C1K2IuB,GAAA,CAAM,AAD7B,CAC8B,CADiB,AACf,EAAY,C+MxFP,A/MwFQ,CAAC,CAAC,AACzD,EAAiC,AAApB,MAAA,GAAA,CAAwB,EAAE,CAAG,AAAF,CAAC,CAAa,GAAG,CAAC,A2KjDlB,CAAW,AAAV,I3KiDY,gDAEQ,CAAC,cACpD,EACd,YAAA,8CAMM,GAAA,qBAA+C,UAC3C,EAAK,IAAA,+BAQvB,CAAC,CAAC,CACH,WA/O4B,MAAA,CAAA,gEAiE7B,C2K1BC,EsEhYG,EjP0ZmB,AAAC,mBAEV,CuKlJa,AwCmGR,KAAA,CAAA,M/MgDX,EAAA,cAAoD,CAAC,UAExC,C0KjFA,E1KiFY,GkBF5B,ElBG0B,C+M/CO,C2B7HC,A3B6HA,A/M+CC,C0O5KA,C2B6VE,CAAC,SrQjLS,EiPhahD,EjPgaoD,SAQtB,GARkC,AACzC,CAD0C,A0KhF/C,A4F2L0B,CtQ1GZ,GAAG,CAGjC,EACA,EACA,EAEiC,CAAC,CAAC,CAAC,CAH5B,AAG6B,CAJ1B,CAKgC,G0KtFH,IuEnV1C,GjPsaoB,AAGA,CAFnB,CAJC,AAIA,uBAGuD,CAAC,GiQrDW,CAAC,CAAC,0CjQ0D1D,UACuB,sBAAsB,CiQ1CW,SjQ2CvD,EAAA,IAAA,QAMX,4C2K9bP,EACA,MAGM,C2CMwD,CAAC,G3CVzC,SACO,EAC7B,aAAuB,KsEoBX,IAAI,CrOrCqD,A6OdD,EAAA,ERoDxD,QtExBQ,C0C8BK,G4BND,GACpB,EAAQ,aAAA,GAAA,EACA,GzE1B2C,iBAAA,CGWjD,EAAA,KANA,GAAA,EAEJ,CqErB2D,CrJyD3C,AqJzD4C,ArEsB5D,IAGI,EqCtCyE,CrHuEzD,AgFjChB,CqCtC2E,EiCsD7E,OtETF,CkE7CqD,AzNsDV,CAAA,4CuJa7C,QAAmB,EACnB,C0CW6D,O1CbhC,QAMX,mCsEJM,GACpB,EAAA,oBAA4B,GAC5B,GAAY,EAAQ,KAAD,GAAS,CAAC,iBtEQ/B,OAKE,GsEZA,ItEeY,CAAA,EAAA,CAAA,EAEd,6BsEjByC,CACxC,CAAC,mCtJ+DG,IAAA,CAAA,UAAA,CAAA,uBASQ,EAAA,8HAQK,gEAIS,EAAA,2FAOZ,CAAA,MAAA,CAAQ,IAAA,CAAA,uCAInB,CAAA,UAAA,CAAA,uBAAA,CAAoC,IAAI,CAAA,6BAGiB,CAAA,oFAKd,CAAA,yLwIpOmB,QAGlB,+DAKH,SAAA,cAMR,EAAA,SAAyB,EAAA,CAAA,KAAW,2HAsBf,gDAEJ,4CAEJ,CAAC,CnNFC,CAAC,G2JyBK,A2CiBE,sBalCQ,iGlJtD/D,cAAA,CAAA,SAAA,oMwKsBD,IAAA,CAAA,EAAA,IAAA,CAAA,CAAA,EAAA,QAAA,CAAA,SAqFI,IAAA,CAAA,GAAA,CAAA,CAAA,omBrOwQZ,SAAS,GAAA,CAAA,CAAA,CAES,CAChB,CAAkB,CAAA,GACG,CAAK,QAG1B,CiP6JC,GAAA,EjP7JqB,GAAA,IAAS,CAAA,kBAAA,YAC+B,EAAY,CoPyDG,EpPzDA,CAAC,AAExE,EAAA,IAAA,EAAA,cAA8C,CyJ1ES,AzJ0EP,CyJ1ES,EzJ0EN,CAAE,CsN9GG,CAAC,CAAC,6BtNgH3B,CAAC,uCAGhB,CAAA,EAAA,aAAA,AAA4B,CAAC,AFMJ,AwE5BF,CxE4BG,uBEHzB,CAAA,IAAK,CAAA,SACV,CAAA,IAAA,uDAKpB,CAAC,2BAIO,EAAA,GAAA,IAAA,CAA0B,kBAAkB,CAAC,AiPiLP,CjP/KtC,EAAA,CAAA,IAAA,GAAA,MAEW,MAAA,EAAsB,EAAY,GAAG,CAAC,SAErB,2CAGoC,CqHYG,AvIxCJ,CuIwCK,CAAC,CrHZxC,AuJtBuC,AvJsBA,CuJtBC,CvJsBxC,kBAA8B,iCAE1B,+BACa,C6LpIK,A7LoIJ,iBAG/C,EACoB,CADC,EAAA,GAAA,GAAA,EAAA,IAA+C,CAAC,CAAC,CAAC,aAGzD,IAAA,CAAA,yBAGkB,cAAgB,2FAGmB,CAAC,CAAC,iCAI1C,CAAA,CAAA,CAAA,MAE3B,CAAA,eAN+H,GAM/H,CAAA,IAAA,CAAA,oDAIC,EACT,CAAC,sBAGQ,IAAA,EAAA,GAAA,CAAA,EAAA,EAAA,CAAA,AACT,CAAC,AAED,SAAA,GAAA,CAA2C,OAC/B,CAAC,EAAA,MAAU,AAAgB,+CAGC,CuNdG,CvNcO;AAAA,sDAAA,EAExC,IACF,CAH0C,AAGxC,CACL,CAAC,UAFqB,CACnB,qBAGE,+BwJxZR,IACA,IACA,+NAmB2E,gGAKjE,IAAA,CAAA,GAAA,CAAA,CAAA,mhCAoFD,UAAA,CAAA,cAAA,6GAW6B,CAAE,UAIxB,EAAA,OADuC,CACvC,qBAAA,CAEN,IAAA,CAAA,UAAA,CAAA,CAAA,EAAA,EAAA,KAAA,CAAsC,CAAE,YACd,CqFuDe,CNhED,ArC5BE,A2C4FA,CAAC,erFvDC,CACxC,EACA,qBAAqB,CACtB,CAAC,4CAKe,uEvF/JvB,MAAA,wCuFsKyC,CJPS,AIOR,EvFtK1C,gBACY,gFoFRwC,C5JMhC,C6JY6C,C7JZ3C,A8JVjB,uCCmLwB,gBAAgB,CAAC,MAAM,CAAA,oBAGvC,CAAA,sBAAA,eAGsC,CAAA,QAAhB,CAAC,C0DxES,A2CHA,crG2EM,CAAA,YvF9J1D,KrF2oBC,EACA,EACA,KAFiB,CAIX,EAEA,AALiB,MAC8B,iB4K9eJ,mCACA,gCAEvC,eAAA,iEvF1JA,cAAc,CwKIqB,A7PiC7C,E6PjC6C,ExKHnC,WAAW,uBrFyCjB,YAAA,IAA2C,YA+BM,cAelC,GAJb,GsH1FO,wBtH0FP,gBAIa,+LAzCjB,IACA,IAulBuC,EAAA,GAEnC,GAAiB,EAAA,GAA2B,EAAU,CiQlEG,GAAA,ejQqEvD,EAAA,EAAA,IAAA,YACkC,OACvB,EAAA,2BAA0C,CAAC,mBAG/C,OACH,GAA0B,+BAA+B,+DAlOjD,CsQ4GO,ApEvLJ,GAAA,IlMyE8B,gBAI7B,YAAA,IAGtB,EAAW,UAAA,CAAA,MAAA,CAAoB,KAAK,SAGrB,C2Q+RW,A1DvdA,CjNwLI,6BAA6B,CAAC,C0FxDpD,A1FyDA,aAAA,kBAGF,CuK9IK,IAAA,GAAA,aAAA,UvK+IK,CoB9CY,AsNxHD,CAAA,I1OsKM,YACf,EAAA,GAAA,GAIT,EAAA,4BAtRX,CmNzBuF,CnN0BvF,CAAA,MAEM,EAAA,EAAA,IACc,GAClB,EAAA,CAAA,EAAA,0BAOA,UAGM,EAAA,EAAA,2BAAmD,CAAA,0DAMvB,mBAAA,gCAvIhC,EACA,EACA,CmNKwG,anNL1F,CACf,CACF,CAKC,AALA,IEhDuC,A8MrC4C,C9MqC5C,CqQHN,+C3FmJgB,uDAElB,CAAA,SAAA,uI5KpIzB,GAA0B,WsFnCd,GACrB,MAAM,OtFkCwD,EACxD,YAAY,EACf,CAAC,CAAC,GsFpC+B,CAAC,UsFyKA,CAAC,CqBpDW,erBoDK,CAAA,MAAO,CAClD,EACA,EFhBiF,uBEgBxD,CAC1B,CAAC,2BAOoB,kBACN,yBAAA,6BAED,CAAC,oBAAoB,CAAC,CAClC,CAAC,wCxF7K0D,2BwF8K1C,CAAA,+FAKE,EAAC,GDFpB,OAAA,GAAA,EAAA,IAAA,CAAA,ECEiC,mCACK,qCAER,CAAA,GAAQ,IAAA,CAAA,oBAAyB,CAAC,CAAC,CAAC,AoD+C5C,CAAC,CAC/B,CAAA,uBfvI6E,arC4FlC,EAAA,CAAA,GAAA,IAAA,CAAA,gBACV,kCAGP,ClFZsB,GAAA,EAAA,OkFab,CAC/B,CAAC;KAEsD,IAAI,CACxD,uCAAA,CACC,CACJ,CAAC,CyCnC6E,4EzC8C9E,gBAAA,CAAA,uDAGA,oBAAA,CAAqB,EAAiB,wIAO3B,uBACR,AAAI,MAAA,0XAtIyB,CA+I2D,AA/I3D,CAAA,oNnCrEH,CAAA,EAAA,gDAWhC,IACA,IACA,6JAkBF,C4GpBuD,A5GoB3B,CwFgD4B,AxFhD5B,CAAA,CAAA,wEASG,IAAA,CAAA,EAAO,CAAC,kBAGV,2JAazB,EyDFsB,EzDElB,CAAC,EAAE,CAAA,4EASY,CAAA,EAAA,GAAA,uFASO,CAAA,EAAA,MACN,mHAiBxB,CAA6B,CAAA,kCASR,CAAA,IAAA,CAAA,EAAQ,CAAC,GAAA,2DAgB1B,IAAA,CAAA,2BAAgC,CAAA,EAA0B,UAAU,CAAC,CACtE,EACD,sBAWkB,CAAA,KAEd,EAAA,IAAA,CAAmB,qBAAqB,CAAC,EAAS,wCACV,CAAC,wBAO3B,CAAA,4CAEwB,CyDXK,CAAA,UzDWsB,GoC5C5B,EpC6ChB,gBAAgB,CAAC,gDAIiB,G6EvCO,A1C+CpD,iDnCLP,2DAST,CAAA,CAAA,gDAG0C,EAAe,IAAA,IAAA,CAAA,iCAAA,CAAA,uCAO/B,CAC1B,CAAA,CAAA,UAEU,gCAAA,CAAA,2CAUJ,AAKC,S3BrNI,A2BgNL,GAAA,EAAA,uBAEsC,2GAcO,CAAA,IAAA,CAC5C,EAAE,CAAA,GAAA,yCAUa,CAAC,gBAAA,kBACW,yBAAyB,CAAC,kCAK1B,IAAI,CAAA,gBAAiB,EAAE,CAAC,oCAKL,AAAC,uJAiBK,4CACA,EAAE,A0EnBI,Q1EoBlC,gCAAgC,EAAE,CAAC,AwDhFI,4CxDmF9B,CAAA,0DAED,wCAKT,CAAA,UAAA,6BAC4B,CAAC,C0ErBK,c1EuBvB,mDAKC,CAAC,oBACrB,CAAA,CAAwB,CvHWC,CuHXG,sCACQ,CAAC,EAAM,CAAH,AAAI,AkCb1C,ClCa2C,8BASvD,kCAHwC,GAAI,AAAC,CiCnBL,gCjCoBb,CAAC,kDAU/B,sBAIc,EAAA,gBAAA,CAA6B,EAAE,CAAG,ErHM1C,AqHNoD,CrHO5D,KqHPkE,CAAC,+DAYjE,CAAC,YAAY,CAAA,EAAA,WACH,CAAC,4BAON,IAAA,CAAA,EAAA,CAAA,eACwC,mHAYtD,CwExH6C,AyBeE,AjGyGnB,CAAA,CACR,CACpB,CAAsB,CACtB,CAAgE,CAChE,CAAkB,CAAA,yBAQA,CAAA,CACE,CkGXwB,OlGenB,YACZ,GAHuB,CAAA,yBAA0B,EAAE,CAAC,GvIpCvB,auIqCJ,CAGnB,EAHyB,IAAA,CAAA,qBAA0B,2EAWvD,CAAA,UAAA,CAAA,GAAA,IACT,CAAC,uBAAuB,CAAC,2B9CjXlB,CAAA,CAAA,uNAMiF,OAIzF,EAAA,iBAAA,2BAC6C,YAAA,oBAD6D,GyKlBf,CAAC,CAAC,gHzK2BxF,CAAA,YAAA,CAAA,CAAA,WAAA,CAAA,CAAA,OAAA,CAAA,CAAA,oBAAA,CAAA,kCAKJ,CAAA,yBACA,CAAuB,CACxB,GAAG,CAAe,GsK2EY,KtK3EJ,CAAC,CAAC,CsK4EL,CJrF6C,6BlKgN7B,CAAC,2BApMjC,EAAA,IAAA,EAAA,GAAA,CAAA,GAAA,EAAA,GAAA,4BAC8C,EAAA,CAAS,CAAA,oEACO,CAAC,IsJJ5D,sDtJOkC,IAAI,CAAC,C+CEW,AuGDrC,WAAA,qFtJKlB,IAAI,CAAA,mBAAoB,CAAC,EAAS,IAAI,CAAC,EACvC,EoGhCuF,CpGiCvF,EAAS,GAAG,2EASF,CqHtC6C,CrHuCzD,GACA,aAAA,EACS,YAAY,CAAA,GACA,C0HgB4D,CAAC,CAAC,K1HhBtD,C6EH8B,A7EG7B,CAC/B,A6EJ6D,C7EI5D,A6EJ6D,qC7EUjD,EACZ,GACA,SACA,EsJ4BC,AwBxDc,ATKW,ArKuBjB,YAAY,CAAA,GACA,wCAKE,CAAA,EAAA,EAEd,GAAG,CqHtD6C,CrHuDzD,IACA,sBACA,EAAS,CiFjCQ,CAAA,IjFiCT,MAAa,CACrB,GAAqB,QAAQ,CAAC,CAC/B,CAAC,MADoB,0BAOpB,EAAA,GAAA,MAAA,mCAGA,EAAS,YAAY,CACrB,GAAqB,WAIQ,8BAE7B,EAAA,EAAA,GAAA,EAEA,GgFrCG,ChFsCH,GgFrCI,CACb,CAAC,oBhFoCiC,CACzB,EAAS,MAAD,MAAa,CACrB,GAAqB,QAAQ,CAAC,CAC/B,CAAC,MADoB,uBAaQ,CACpC,CAAA,CAAA,wBAGwC,CzELZ,AyEKa,KAAA,GAAA,EAAA,CAAwB,CAC/D,kCACwC,yBAAA,CAAA,yGAIW,EsHzFQ,ctH+FvD,EADA,EADA,A2KoK0E,I3KpK1E,CAAK,mBAAA,CAAA,EAAyB,CqK3D2C,GAAA,CrK2DtC,C2KoKyB,wD3KxJ9C,CACpB,CAAA,CAAA,QAME,EADA,A8J1DsE,CAAC,CAAC,kJ9JqE7C,EAAA,sN/E9I8F,sBAU/E,qZAYgB,C6N2CK,ADxER,kD5N+Bd,gCACD,gIAKP,CAAA,mLAMJ,oBAAoB,GAAG,+GAIvB,CAAA,sEAGyB,E8NNqB,CAAA,mB9NMM,CAAA,CAAA,CAAA,uLAQvE,CAAA,oFAUZ,CAAA,CAAA,6BAOmB,CAAA,EAAA,CAAA,GAAA,WAAkB,iEAMlB,aACJ,0RA0BiD,CAAA,yIAWlD,CAAA,GAAA,uCAMR,EAAA,EAAA,QAAA,gBAIiB,EAAA,WAAA,EAAA,CAAA,MAAgC,CsL2BK,+FtLnB7C,CAAA,+FAYkB,WAAA,GAAgB,cAC/B,EAAA,SAAmB,4DAaP,CAAA,IAAK,CAAA,SAAA,CAAA,MAAA,CAAoB,CMqEH,ANrEI,CAAC,sCuN1I1B,uHvNqJO,CAAC,SAAS,CAAA,MAAA,CAAA,EAAY,CAAC,oBACxC,GAAA,WAAA,IAAA,KuNxIhB,QAAA,CvNwIgB,EuNxIhB,CAAA,IAAA,CvNwIgB,qDAEqD,CAAC,CAAC,oFASpE,KACJ,IAAA,CAAK,SAAS,GACd,GAAK,IAAI,CAAC,oBAAoB,kB6OnMS,oJAoFC,kBAAA,EA3Da,MA2Db,GAgBxC,MAb2D,MAUD,CjFaN,MiFhBvC,EjFa+C,CAAC,CAAC,GiFP9D,CvOkCgE,EAAE,CuO/B7D,4CAEa,WAAW,CAAA,IAAA,CAAA,aAAA,CACb,qEA7EiB,GAAG,CACnC,CAAC,G7EUe,CAAA,2C6ERoB,IAAA,CAAA,WAAgB,CAAA,IAAK,CAAA;AAAA,CAAA,EAAA,EAAA,IAAA,CAAA,QACxB,OAAO,CAAA,MAAA,OAAA,CADiB,+BAUhE,EAAA,WAAA,CAAA,0D7O+JkB,CAAA,yBAA0B,CAAC,2FAQe,CAAC,CAAA,K6OlKzD,EAAA,eAAA,E7OoKE,IAAI,CAAC,SAAS,C6OpKhB,E7OqKE,GAAK,CAAD,G6OnKS,A7OmKJ,CAAC,AiO7L8D,oBjO6L1C,CAAC,C6OlKrC,E7OmKM,IAAI,CAAC,Q6OnKc,oB7OmKc,EAAE,CACpC,CAAC,4LACwC,CoNoGZ,0GpN5FC,mBACG,EAAA,qEAKT,MAAA,CAAA,EAAA,yFAKqB,EAAA,8NsPrPsC,imDhP2H5E,KACJ,CAAA,CAAA,EAAA,IAAA,CAAA,CAAA,2OAkBqC,SAAA,GAAA,GAAA,EAAA,KAAA,GAAA,GAAA,MAIzC,GAAQ,EAAiB,EAAlB,aAAiC,CAAC,CAC1C,CAAC,oBAGE,GAAA,kGAiBiB,EAAQ;AAAA,4FAAA,CAAgF,8BAKxG,EAAA,aAAgC,oDAJ+D,CACjG,CAAC,KAG4F,MAGvD,qBACA,CAAC,uBAKnB,EAAK,C+LnGqB,0F/LuGf,CAAA,SAuC+B,MAAA,CAC/D,gCA/BK,CAAA,uCAGyC,EAAA,IAAA,CAAA,UAAA,sCAEhB,CAAA,IAAA,CAAA,SAAe,CAAC,MAAA,CAAA,EAAA,mEAId,EAAA,EAAA,mGAWE,CAAA,EAAA,EAAsB,IAAI,CAAA,UAAW,CAAC,CAAC,A8MmB5C,A9BzDsD,C8ByDrD,oD9MhBE,EAAA,EAAkB,2CASlD,UAAE,E+LxGgE,A/LwGtD,C+LxGuD,qB/LwGvD,CAA2B,sBASb,CAAA,CACD,CAAA,OAEsB,0BAAA,YAMlB,cAAA,IAAA,IAAwB,CAAA,eAAgB,CAAC,MAE7C,GAAA,WAGjB,EAAA,IAAA,CAAA,mBAAwC,iEAEX,CNrEO,OAAA,CAAA,QMsEhC,CAAC,SAAS,QAMT,EAAA,EANS,YAEV,CAAC,SAAS,CAAA,IAAK,CAAC,SAAS,CAAC,MAAM,CAAG,CuHdhC,AACf,AvHagD,CAAC,CAAC,sBACd,CyPkOa,AV/MC,CAAA,E/OlBrC,sBAMP,IAAA,EAAA,IACM,CAAC,SAAA,CAAA,IAAc,CAAA,SAAU,CAAA,MAAA,CAAU,EAAE,wEAOlB,kBAKtB,EAAA,qEAiBiC,CAAC,IAAA,eACjC,mBAAmB,CAAC,EAAA,EAAA,0BAMd,ClB0B4B,CkBzBnC,CAAA,cAEc,kBAAA,CAAA,MAEQ,qBAAA,KACJ,C0O3FO,EAAA,a1O4FM,gCAKnB,IAAI,CAAA,IAAA,GAAA,EAA+B,IAAI,CAAA,IAAK,SAG5D,MAIW,CAAA,MAAA,IAAA,CAAA,IAAA,gBACG,CqJjFG,GAAA,wBrJyFyC,CAAA,6CAI/D,2CAKA,8BAO+D,CACjE,CAAW,C+KhHoD,iC/KkHnB,CyJxCH,C3KwDH,C2KxDK,AzJwCI,CAAC,0BAGrC,EAAkB,GAAG,CAAC,QACK,IAAA,IAEhC,KAAA,MAAyB,SAE3B,EAAA,UACuB,CAAA,IAAA,GAAU,EAAqB,IAAI,CAAC,IAAI,CAAC,CAAC,ayJ/BxC,CAAA,MzJsCC,IAAA,CAAK,C8M+CP,ArDrFC,GAAA,EzJsCsB,ChBxCf,UgByCf,CAAA,kBAAA,CAAA,4BAGJ,iFAOH,oBAAoB,CACF,EAAmB,EhBtCkC,CAC9E,CAAC,GgBqCkD,CACvD,CAAC,KAQC,CAT6C,0BAS7C,CAAA,IAAA,CAAA,kBACoB,CACvB,CAAC,C+Od6D,C/Oc7C,EAAkB,CAC9B,A+Of2E,GjQwCpE,IkBvBZ,ClByBY,CkBxBZ,MAFA,MACc,CwEtC+F,CACpG,CAAC,A1F+DI,CACf,CAAC,KkB5BgB,UAQI,CANa,AAMb,CAAA,AALrB,CAKqB,AALpB,OAQY,IAAA,CAAA,2BAAA,MAAA,0CAIuC,EAAS,KAAK,CAAC,CAAC,gCAOrE,CAAW,CAAA,OAEI,EAAA,GAAA,YAMgC,EgLvDM,CAAC,CAAA,AhLuDH,CwNlJK,uBxN+IG,CAAC,OAGxB,CAAA,IAAK,CAAC,CAAW,cAKnD,IAAA,EAAA,IACS,EE3BM,AuP+UI,A5DrWA,EAAA,CAAA,YAAA,CAAA,I7LiDY,CAAA,EAAA,CAAA,GAAQ,QAIT,CAAA,2BAAA,EAAA,CAAA,GAAA,IAG5B,IAAA,CAAA,OAAA,CAAA,cAEsC,CAAC,iCAIT,CAAA,IAC1B,CAAA,2BAA4B,CAChC,oBASA,ChB5CkD,CAAC,AgB6CnD,eAGI,IAAA,CAAK,uBAAA,CAAA,EAAA,GAEC,kBuHXW,CACxB,CAAC,evHU+C,CAC7C,EAAQ,KAAD,EAAQ,CAChB,AAEL,CAFM,A8MiBH,A9MfF,AAED,EwEnCI,WxEqCF,CAAA,CAAA,CAAA,CAAA,WAGkB,CAAA,2BAA4B,CAAC,IAAU,C6L1DK,S7L2DvD,IAAA,CAAK,iBAAA,CAAkB,EAAgB,EAAmB,eAAF,QAM/D,CAA0D,CAC1D,CAAW,CAAA,KAGP,IADoB,IAAI,CAAC,C+LxLK,iB/LwLa,CAAC,MAEf,mBAAtB,EAAsB,GACtB,EAAkB,GAAA,OACT,EAAA,IAAsB,CAAC,cAEZ,KACrB,CwJ9EG,CAAA,IxJ+EW,IAClB,EAAA,IAAqB,CAAA,IAAK,GAAK,EAAqB,IAAI,CAAC,IAAI,CAAC,CAAC,QAI1D,SAGI,EACf,KwJ9EiC,CAAA,IxJ8E1B,EAAA,IAAA,CAAA,IAA2B,CAAC,ElBQJ,CkBR8B,CwJ9E5B,GxJ8Ee,AAAiB,CAAE,IACtD,C6L3CO,E7L0CoC,CACvC,CAAA,kBAAmB,CAAA,mCAIJ,CAC9B,IAAA,CAAK,EgL9DuC,UhL8D3B,CAAA,CAChB,EAAgB,EAAkB,CAC9B,MAEL,EACA,CAJe,KAAmB,GACZ,EACtB,CACc,OADN,QAEmB,CAYP,CAAA,CAAA,CAAA,uCAGwB,CAC5C,KAAA,8BAf6E,GAkBjD,CAAC,C+OnCK,C/OmCW,EAAS,KAAF,AAAO,CAAC,CAAC,GAAlB,qBAM7C,CAAA,CACA,CAAA,CAAA,KAEM,EAAA,EAAiB,C6L9DK,A7MPR,CqK9FC,AwCqGQ,CAAA,G7L+DX,CyNpFK,A5BsBA,CAAA,GAAA,K7LkEiB,IAHlC,IAAA,CAAA,kBAAA,CAA+C,cAGb,yCAIZ,CAAA,IAAA,CAAM,EAAE,CAAC,CAAC,EAAA,QAGgB,IAAI,CAAE,iBAAlC,CAAA,IAAK,CAAC,EAAE,CAAC,GAAI,IAGnC,IAAA,CAAK,OAAA,CAAA,KAEE,IAAI,CAAA,IAAK,kCAIc,CAC9B,G8MnBoD,CAAA,C9MmB/C,OhBvEoC,oBAAA,CgBwEzC,oBAQA,EAAA,eAAA,mBASkB,CACtB,CAAoB,CwJnH0B,AiG6WQ,AzPzPtD,CAAqC,CACrC,CAA0B,CAC1B,CAAyE,CAAA,MAElE,UAGA,OAAA,CAAA,KACE,IAAI,CAAA,IAAA,kCASmB,CAC9B,IAAI,CAAA,2BAA4B,CAChC,KAGE,MAGD,CACD,OAEA,CoP2EiF,A3FvHnC,CzJ6C9C,eAFA,OAMoC,CAAA,CAAA,OACd,IAAA,CAAK,gBAAgB,CqJxLC,CrJwLC,CAAC,AAMhD,SALO,IAAA,CAAA,IAAS,EACO,AAIhB,IAJgB,CAAK,gBAAgB,GAIrC,cAK0C,CAAA,CAC/B,CAAA,KAEZ,EAAQ,IAAA,CAAA,2BAAA,CAAiC,IAAQ,IwJxIE,CxJyI5C,GAAA,GAAsB,CyPuOK,CAAA,EzPvOmB,GAAG,ClBJ3C,AkBI4C,EAEhD,AACM,IADN,CAAA,kBAAuB,CAAC,EyJpDE,CzJqDb,CoPmEK,GpPnED,CAAC,C8MhCP,G9MgCW,CAAE,E8MhCN,C9MiCjC,GAAA,KAAqB,CwEzED,GxEyEpB,OAAgC,EACC,ChBzFN,AgByFU,CAAA,EAAc,CACxB,CgL1FO,EhL0FJ,CAAC,IAAI,CAAA,IAAK,MAEpC,CAAC,mBAAA,CAAA,EAAA,EAEmC,OAAO,mCAK1C,UAAU,CAAA,GAAI,OACf,CAAC,qBAAqB,CAAA,GAAA,6BAGA,GAEK,CAAC,kBAAb,CAAA,MAAO,GAAoC,IAA1B,CAA+B,EhB9FlC,CgB8FO,CAAA,cAAe,EAAE,CAAY,CACnE,C6L7FO,ArCnDN,GxJgJK,CgL3FO,ChL2Fa,IAAI,CAAC,EAAE,CAAA,GAC3B,CoPkEO,CpPlEE,IAAA,CAAA,oBAAyB,CAAC,CyJtDL,4BzJsDkC,CAAC,+BAEvD,CAAC,mBAAA,KAEjB,IAAA,CAAA,UAAe,CAAA,IACT,GAA2B,EAAQ,ChB/FO,qBgBsGT,CACzC,CAAA,CACA,CAAA,CAAA,sBAI2B,EyPwNQ,EzPxNpB,EAAwB,EAAQ,IAAI,CAAC,CAAC,IAAC,CwJvJC,CxJgKrD,yBAPA,EAAa,EAAW,CwJvJV,AwBoDQ,AoEgKa,IpP7DN,CAAA,IAAA,CAAO,GoP6Da,CpP7DT,uBAEtC,EACY,C6LzGmB,Q7LyG/B,EhBhGsB,AyKqCQ,EAAE,IzJ2DW,IAAlB,EAAQ,GAAmB,EAAd,AAAN,CAAoB,EAAA,KACnC,CACb,EAAA,QAAA,EAEN,QACO,EAAA,OACD,IAAI,CAAC,oBAAA,CAAA,EAAwB,EAAS,EAAW,QAAQ,CAAC,CAAC,AAErE,CAAC,C2NpRG,qB3NwRI,CAAA,CAAA,CAEN,CAAgB,AyPiNkB,CL5JO,ApPrDzB,CAYhB,MAVI,E2N3RM,CAAA,S3N2R8C,IAAvB,CAAC,CAAC,GwEvFK,EAAE,A4K2IM,ApPpDmB,WAAhB,GACjD,IAAA,CAAK,kBAAkB,CACrB,CAAC,CAAC,gBAAgB,MACN,IAAZ,MhBrGwC,EgBqGG,IAAlB,EAAQ,ChBrG6B,EgBqGV,EAAd,CyJzDpC,AzJ0DE,CyJzDT,CAAC,AzJyDgB,KAAK,CAAA,8BAMf,CAAC,iBAKP,CAAkB,CAAA,CACP,CAAA,CAAA,CAAA,KAGP,UAEI,C6L3HO,CAAA,I7L2HS,CAAA,EAAG,CAAC,EACoB,IAAI,EAAE,KAA3C,YAAY,CAAC,EAAW,EqJzNF,ErJ0N7B,IAAA,CAAK,EqJzNA,UAAA,YrJ4ND,CAAC,oBAAA,CAAA,EAAA,EAAyC,WAEvB,CACzB,EAAgB,CqJvNG,AsE9EI,GAAA,CAAA,G8B4ee,oBzPvMM,CAC1C,EACA,EACA,CADG,G2NvS0D,M3N4SjE,IAAI,CAAC,EgL/GM,ahL+GS,CAAA,KAAA,IAAA,QACyB,IAAlB,EhBvGe,AgBuGP,ChBvGQ,CwKvEW,CxJ8KA,EAAd,CAClC,EAAQ,EoP+DU,GpP/DL,CACb,EAAA,IAAY,CAChB,4BAQF,CAAiB,CwJpLa,AxJqL9B,CAAsC,CAAA,EwEhGK,CAAC,CAAC,GxEmGvC,EAAgB,IAAI,CAAC,EAAE,CAAA,WAC7B,KAAgB,CoPsDS,GpPtDzB,GAA6B,EAAA,OAAe,EAAE,CAC9B,OAAO,KAEX,CAAC,CyP2LO,mBzP3La,CAAC,yBAAyB,CAAC,CACxD,SAAU,CqJlOC,A7EqII,mBxE+FL,WACA,IAAI,CAAC,mBAAmB,E6LjIU,A7LiIR,OAG9B,CAAA,UAAW,CACnB,IAAI,GAAyB,EhBzGgB,CgByGb,ChBzGa,AgByGA,MhBzGkB,CAAC,CAAC,qBgB+GjD,CAClB,CAAW,CACX,ChB/GyB,AgB+GF,CAAA,OhB/G0B,CgBoH3C,CAAC,eAAA,EAEY,+BAAA,IAAA,EAAA,CAAA,IACZ,CAAC,cAAc,GACpB,KACM,EAAA,IAAA,CAAA,wBAJwF,GAI9C,CAAA,EAAe,GAC/D,GAAA,QACS,CyPiLS,GzPjLL,CAAA,iBAAA,CAAA,EAAiC,YAE5C,GAAI,EAAoB,IAAI,GAAK,WwJxLiB,CAAC,CAAC,IxJ6L5C,GgLtHa,AhL0HvB,MAT6D,AASvD,EATyD,qBAe3D,EAAA,IAAA,CAAmB,MAAM,CACzB,A2NvTgC,A3NsTN,EACT,GAAM,CoPkDK,GpPlDD,CAAC,UAAU,CoPkDK,ApPlDJ,OACtC,CwElFD,OxEmFI,iBACQ,CAAA,gBAAiB,EAAE,wBAExB,IAAI,CAAC,SAAS,oBAI+B,CAAA,MACrD,MAAA,CAAS,CoPgDb,CpPhDsB,MAAM,CAAC,AqJzOJ,CoG2ZS,EjL/PzB,CxE8EN,CAAC,gBAAA,CAAiB,EAAA,UAAA,OACjB,UAAU,CAAG,EAAS,UAAU,AACvC,CAEA,AAHwC,A2NzTI,A8B2eA,AzPjL3C,0BAIC,CqJ5OmB,CrJ6OnB,CAAgB,CAChB,ChBxG4B,AgBwGJ,ChBxGa,AgBwGb,MAEnB,qBAAA,CAAsB,E2N/TM,C8B2eC,CAAA,CAAA,QzP3K7B,UAAA,CAAA,IAAe,CAAC,G2N/TO,6B3NiUC,CAAC,EAChC,CAAC,gBAEa,ChBzGF,AgB0GV,OAA2C,IAApC,IAAI,CAAC,CqJ/OD,kBAAA,CrJ+OqB,CgL5HK,KhL4HC,AACxC,CAAC,0BAGO,EAAA,IAAA,CAAA,4BAA6C,EAAE,CAAC,AACtD,C2NlUK,M3NkUE,IAAI,CAAC,mBAAmB,CAAC,CgL7HK,AxG6CF,CwG7CE,AhL8HvC,C2NlUG,A3NkUF,wBAE4C,CwEjFxB,CAAA,QxEkFZ,IAAI,CAAC,mBAAmB,CAAA,EAAA,6BAIpB,CAAA,YAAa,CAAC,G2NpUO,CAAA,C3NoUF,EAAE,CAAC,CAAC,EAAG,YAIrC,ChBtGC,GAAA,CgBsGI,GgL5HO,C2CzMC,W3NqUO,EyPuKM,AzEnSA,AhL4HJ,C2NrUK,A3NqUJ,IACnB,CAAC,GgL5HO,OhL4HG,CAAA,2BACY,EAAE,CAAC,AgL5HI,AyEmSA,WzPtKvB,CAAA,EAAK,CAAC,AACjB,IAAA,CAAA,UAAe,CAAA,EAAK,CAAC,AAErB,ChBrGC,E2OjO2B,C3OiO3B,CgBqGI,SAAS,CgL5HK,EhL4HA,CAAC,CyPuKK,CAAC,EzPtKtB,CAAC,qBAAqB,CAAG,EAAE,CAAC,iFmPpzBJ,EAAA,EAAA,8NAyCQ,8HAwBxB,eAAe,CAAA,EAAU,EAAA,+GAqBnB,CAClB,CAA2B,CAAA,iIAkBU,CAAC,CAAA,6HAwB3B,CAAA,eAAA,CAAA,EAAA,EAAA,qPAwCgC,kGAgBA,4CAQhB,CAAA,EAAA,EAAA,6FAgB7B,6HAoB6B,EAAA,2CAOmB,CAAC,0CAOD,kGAmBY,CAAA,mDASnD,IAAA,CAAA,cAAA,CAAA,EAAA,MAKP,CAAA,CAAA,CAEA,OAAA,IAAA,CAAA,UAAA,CAAA,EAAA,sBAOY,UAAU,CAAC,EAAA,mCAOY,CAAC,+BAOd,CAAA,EAAa,CAAC,ApDlMI,CAAC,AoDkMJ,AtD1FI,CExGC,AoDkMJ,cAO/B,IAAA,CAAA,UAAA,CAAA,EAAA,oEAcgB,EAAA,mCAOY,C3B9LK,A2B8LJ,CGhHK,AHgHJ,ApErLM,CoEqLL,AMyHI,2GN/F1C,CAAA,CAAA,kBAEiB,CAAC,EAAA,SAKlB,CAA0D,CAAA,qBAErC,SAKrB,CAAA,CAAA,sCASK,CrQjGC,WAAA,CAAA,EAAA,SqQsGN,CAAA,CAAA,mDASkB,EAAA,yCAYlB,CAAA,CAAA,8FAa0B,EAAA,aAGQ,CAAA,CAAA,8KAgBA,CAAA,CAAA,MAC7B,oBAAA,CAAA,EAAA,4CAIwB,0CAIH,CAAC,CAAE,yDAOK,CAAA,CAAA,yGAevB,CAAA,kBAAA,CAAA,EAAA,gEAYsD,CAAA,4CAOjE,CAAA,CAAA,sEASuB,CAAC,CAAC,ApExQI,A4C7BE,CAAA,+DwBiT/B,CAAA,CAAA,wBAEuB,CAAA,EAAA,wHAqBlB,0BAAA,CAA2B,CAAC,ArQpJA,AiMjII,CoEqRF,oHAcA,qBAKnC,CAAA,CAAA,KAEI,CAAA,0BAAA,CAAA,EAAA,oHAc+B,EjP9LS,CuJhB1B,CvJgB4B,iBiPmM9C,CAAA,CAAA,gCAE+B,CAAC,EAAG,CpDvUK,EoD0U1C,kBAAA,CAAA,CAAA,MAIO,0BAA0B,CAAA,EAAA,0DAOI,sBAKE,CAAA,MAEhC,0BAAA,CAAA,EAAA,QAKL,CAAA,CAAA,CAAA,CAAA,EAAA,EAE4C,CAAA,YAE1B,iBAAA,CAAA,GAAA,KAOV,EAAA,SALJ,GAAqC,QtDzO5B,mBAAA,CAAA,0GsDmPU,CAAC,IAAA,CAAA,yBAGF,CAAA,IAAA,CAAA,wBAEoB,CAAA,EAAO,EAAgB,CtDpOK,iBsDqOhD,mBAMV,CAAA,CAAA,CAAA,EAAA,EAEgC,CnPzKO,oBlBzPrD,EqQsaI,IAAI,CAAA,GAFuC,cAErB,CrQra1B,EqQsaI,IAAI,CAAC,ErQtaQ,OqQsaC,CACf,ArQraG,CqQqaF,AA3XG,CzFvFmB,AyFuFnB,EAAA,kCrQvCqC,2DAE+C,EAAS,oDAAA,CAAI,CAEtG,EAAA,IAAA,CAAA,wCAEuD,EgOJ9C,KhOC6C,CAAC,EqQ4ZrD,CnEzOgC,4BmE6Ob,CAAG,CnQrOwC,GmQqOxC,CAAK,gBAAgB,CAAC,MAAM,CAAC,C9F9TH,wB8FgUP,EAAM,EAAI,EAAA,gBAC/B,CrQ5KoB,cqQkLR,CAAA,CAAA,CAAA,2CAKR,CAAC,IAAA,CAAA,OACnB,EAAA,IAAA,CAAA,cAAA,MACF,iCAIK,EAAA,iBAEE,GrCnLa,CrDhBH,C0FmML,kBAKT,gBAAgB,CAAC,M3FhQI,AsDgFU,0DqCwLjC,IAAA,CAAK,oBAAoB,CAAC,sCAI1B,GAAA,GAAA,IAA4B,CAAA,oBAAA,EtP5YjC,SAAA,EAAA,CAAA,8BAGJ,2BAGwD,6EAO9B,KAAK,CuPyFO,ADxEH,C3BnLI,A4B2PA,ADxEJ,CtPjBI,C2EvGH,IAAA,A3EuGQ,CAAC,A8J9II,mB9JkJtB,sDAGsB,kCAIvC,4CAEuC,CAAC,Af/CE,EeiD7C,GAAA,aAAA,eAEG,8GAImD,0CAK/B,E2N7JkB,CAAA,C3N6JP,CmLnGW,CzD2BC,AyD3BD,WnLmGG,EAAI,E0HxEU,A1HwEV,AyP7EgB,OzP6EhB,mBAEpB,UAAA,WAE5B,C6PrKC,A5CqJA,YAAA,6CjNmBH,EAAA,GAAA,qBAEgC,aAAc,EyPzEkB,AzPyEb,EK9Gc,CAAC,CAAC,KL8GP,CAAE,CAAC,CAAC,CACpE,EyP1EuF,CAAC,CAAC,SzP2E5D,CwJ7IP,ArJyEM,C+P3GW,A/P2GV,UHoEe,8HAUvC,oBACI,GAAA,CACV,WAAA,EAAA,EAAA,UAAA,gCApXG,gEAAA,EA0Xe,EAAA,YAAiB,CAAC,A2EvEF,gF3E4EM,CuP4GO,IAAA,UvPzG5B,CgQ/KK,WAAA,CAAA,OhQ+Ke,8BACZ,aACE,EbrFF,CAAA,GAAA,EAAA,MAAA,CAAA,CAAA,kCa4FD,kBAEpB,EAAA,IAAA,uFAQZ,CAAC,E8NnLE,CwBkeF,wC5KnrBkB,EAAE,4aAmCC,CAClB,CAAmB,CAAA,CAAA,CAAA,uCAMjB,CiDcqE,WjDbrE,aAHyC,CxEjBH,AyNsBQ,CAAA,CjJLF,EAAA,CAI5C,EACA,CwJ6BoC,CrE5BjB,AqE6BpB,CAAC,AResG,A7D5CnF,CnFDf,CAAC,YAAY,CAClB,AACmD,CADlD,AACkD,EAAG,0PAaO,IAAI,CAAA,EAAG,CAAC,kGAUf,MAKhD,YAAY,CAClB,CAAC,+QAiBsC,EAAE,CAAC,GAAA,6FqGnGmB,CCfK,ACCA,AzGUhE,AuGI4D,AGZI,GHc/D,GAAA,gBAA4B,8DAM9B,EAAA,IAAA,CAAA,YACiB,CACjB,IAAI,CAAC,C5LoBM,AwOpCgF,CQFC,AhPsCjF,AwOpCiF,CSLC,ADGA,SpDkB5E,qFAcjB,WACA,CqEzBwE,ErE0BxE,GsEhByF,SAAA,6QhPiFnD,EAAA,EAAS,oCAEY,C+L0CJ,uC/LzCR,iSAcF,CAAA,CAAA,SAAA,CAAA,gCACX,CAAC,CAAA,kFAGM,CAAA,EAAA,wCAMhC,IAAI,CAAA,qBAAA,CAAA,EAAA,EAAkC,QAE3C,CAAA,OAAA,CAAA,SAAA,CAAA,CAAA,CAAA,CAAA,CAAuC,CqONY,A5E5BnB,A8DyFc,YvNtDrC,CAAA,qBAAA,CAAA,EAAA,EAAkC,wFAKnB,CAAI,kEAIzB,kBAAA,CAAA,EAAA,+DAGwB,CAAA,EAAA,kDAId,IAAA,CAAA,gBAAA,aACH,CAAA,SAAA,EAElB,C4MwEG,AzD3FF,AnJmBA,AwOzCE,uCxO4CmB,CAAA,CAAA,MAKhB,CAAC,UAAA,CAAA,6BAAyC,eAG/B,EAAA,EAAA,GAAA,IAAA,yJAOA,CAAA,CAAA,QAAA,EAAA,EAAA,CAAA,CAAA,QACJ,IAAA,CAAA,CAAA,YAAA,EAAA,EAAA,CAAA,CAAA,oCAC8B,oBAGjB,YACX,AAfW,CAeX,OAAA,YACA,CAAA,MAAS,EAAA,qDAGK,C+LsCO,A/LtCN,AyPbM,uDzPkBlC,CkMjBK,ArBTA,A7K0BJ,CAAC,eAMkC,CAAA,CAAA,oFAqBpC,CkPgNK,AhDpOU,A7EmDZ,A4E9BE,EAAA,cjMA8B,eAAkB,EkMpBM,ElMoBF,CAAA,CAAM,CAAE,CAAC,CAAC,4CAErC,CAAC,4DAKc,2BAAL,uLAM3B,EAAA,QAKL,wBAOR,CAAA,CAAA,CAAA,CAAA,eAGsB,CAAA,IAAK,CAAE,GAAA,EAA2B,8BAMxD,CAAiE,ClBepB,SkBb7B,IAAA,CAAA,GAA2B,CpBuEC,CoBvEkB,qCAK5C,CAAA,CACmB,CAAA,CAErC,GAAA,IAAA,CAAA,IAAA,CAAA,GAGE,EACA,KADO,KACG,EACV,cAMgB,CAAA,CAAA,CAAA,cAGI,GAAY,EAAmB,CpB0Dd,EAAE,EAAE,sCoBjDzC,IAAA,CAAA,GAEA,EAAA,sCAWkB,IAAI,CAAA,IAAK,CAAA,EAAc,6CAUQ,I+LnBQ,AG7CpD,ClMgEY,GAAA,EAAgB,YkMhE5B,yGlMmEsD,C6KnFO,Q7KmFE,CAAA,GAE5D,WAAA;AAAA,yBAAA,EAEK,IAAA,CAAA,kBAAuB,CAAC,CAAC,CAAE,CAAC,IACrC,CAAA,CAAA,CAAG,CACN,CAAC,+CAK2B,CAAA,kBAAA,WAES,EsN5FM,qBtN2F7B,EAAA,QAAA,sBAIR,CsETiD,CxEgBD,KEPlC,CFO8C,+FEMrE,CAAkB,C6K5FY,AgBnBA,C7LgHZ,CAAA,CACS,C6K9FwB,O7KgG5B,qCAGK,GAAkC,SAAvB,uDAAuB,EAAA,KAAA,SACI,CAAA,GqHLA,MrHO3D,EAAG,CFKR,EuHZgE;AAAA,yBAAA,EAAA,IAAA,CAAA,kBrHS5B,CAAC,CkMjF4B,AlMiF3B,CAAA,CAAA,IAClC,CAAA,CAAA,CAAG,AANqD,CAO3D,CAAC,EFKG,CACN,CAAC,8DEFgD,CAAC,8CAI1C,KAAA,EAAA,EAAS,KAAK,IAAd,QAEA,UAAA,CAAA,IAAA,CAAA,OAIZ,yDoNrWqC,CCFK,A5NiBF,A6NhBE,AlEUN,AyDTM,sBOErC,EAAA,AAAmD,UAAnD,OAA6B,6HAS2B,2IAWL,IAAA,CAAA,yBAC3B,CAAA,IAAA,CAAA,iBAAyB,EAAE,4EAKJ,CzNoBR,CACxC,AyJmBoD,MgExCI,GAAA,mDACN,+D5D2PtD,CAAC,CAAC,uDjCpS2B,CAAA,GAAA,OAAA,CAAA,mHAepB,GAAA,SAAqB,CAAA,EAAA,iCAKuC,C2GoBS,A3GpBR,qCiC+RnC,CAAA,EAAA,EACqB,CAAA,YAE3B,CDTD,CqDgFO,AvFjEJ,C6EnEK,4EUnOoD,0UAkUhF,GACL,CAAA,CAAA,CAAA,CAAA,CAAA,kDAKwB,CAAE,AqC0Ec,ArC1Ed,GAAA,UAjIrB,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,UA4VY,UA1OG,CAAA,CAAc,QA8GoB,EAtM1D,EAAA,EAsM2E,AAtM3E,EfmB+C,A0DqdA,C1DrdC,AgECxB,GjDFpB,CjB1B+B,ApCpBN,CqDgEzB,EAAA,EAAA,MAoBU,EAAA,+CA5E4C,CAAA,mBACrB,uBAoVjC,IACA,IAGM,EAAO,CAHI,AUtLH,IVsLG,CAGQ,cAAA,CACnB,EAAQ,EAAI,CUzLC,eAAA,CAAA,GAAA,CAAA,GV0Lb,CUzLC,CAAA,GAAA,EVyL0C,EAAA,EAAA,eAO3C,IAAA,GAA0B,EAAA,EAJ1B,EAAA,EAIuC,CAJA,EAAA,EAAA,AAIK,CAAC,CAAA,AAJyB,6BA3VrE,GAAA,aAAA,aAAuC,QAgGhC,ChO5BL,cgO4B4D,CACjE,MAHoB,CqC0DY,AxF/KA,6BmD2HP,UAAA,CAAY,AAAC,CVvHC,AUuHA,ApN/GJ,EoN+GS,EAAK,EAAK,EAAM,A9NvFd,CyOwCW,CAAC,AX+CA,A9NvFV,E8NwF9C,GAAA,EAAA,EAAA,EAAA,KAAA,2BAnGmC,aAwGnC,AAvGK,EAuGL,KAvGY,EAsGE,EAtGF,IAAA,E5MCO,K4MsG+B,C5MtG/B,8B4M0GoC,EvFvDH,EuFuDO,CtIrEH,A+CcJ,GuFwDnD,IAAA,IAAoB,OAyGb,CtD/FH,AqGrFI,E/C2EY,G+C3EZ,IAAA,wC/CyLsC,EW7DE,CAAA,EX6DG,CUvKC,AVuKE,CUvKD,C1O6JD,AgOWpD,CA3NW,AhOgN0C,CAAC,4BgO/MhB,OAcvC,C/BxFC,CAAA,G+BuFX,EAZ0B,EAY1B,EAZ0B,EAY1B,EAZ0B,E/B3Ef,O+ByFG,QAEe,YAIrB,EAAA,EAAA,GAEM,E9MnB8C,A8MmBzC,CAAF,CAAQ,IAEd,GAAA,EAAA,EAAA,EAA4B,EAxBb,8BAgChB,eAAY,eAAA,+BASd,CxDxBwC,EwDwBlC,EAAK,EAAI,EV7FsD,AU6FtD,EAEb,EAAA,GAAe,EAAA,EAAA,EAAA,SAAA,CAAiC,CtIzDH,EsI0D5C,GAAA,EAAA,EAAA,EAAA,EAAA,kCAYD,WArDgD,OA6CtD,IAAA,IAIuE,MAFxC,Cf1IgB,aegJzC,GAAA,EAAA,EAAA,EAAA,EAAA,GAKI,CtDvEiD,CsDuE9C,CAAA,CAAQ,EChDwD,kEDqEvE,sBAdI,sCAYA,CbjEuD,AzCXrD,CsD4EG,CiCrBuD,CAAC,AjCqBlD,CnD/GmD,CAAC,ImDiHnE,GAAA,EAAA,EAAA,EAAA,SAAA,CAAgD,GAC/C,GAAK,EAAA,EAAA,EAAA,EAAA,MAgC0B,C5MvGgB,AkPwN8B,CAAC,AtCjH1C,EAAM,IAC7C,AAAC,CAAC,E9NxFuB,KAAA,I8NwFlB,CAAC,I9NxFiB,oB8N2FV,EAAA,CACZ,IAAA,EAAA,MAAA,iBA0JF,CAAkB,CAAA,CAAA,UACC,MAAM,KACzB,IAAA,EAAA,EAAW,EAAA,EAAiB,EAAA,IAAA,KA6HhB,EAAA,KAAyB,CjB/Dd,IiB7DT,CAAI,CAAA,EAAA,CAEoB,CAAC,EAAE,M2C8RM,E3C9RhC,WAAW,CAAC,CzD7IP,CAAC,ArKyFY,G+POD,CAAA,KjC8ChB,EAAA,IAAW,CAAC,WAAW,CAAC,EAAE,AAAD,C9MAF,A8MAG,oBAEI,OAEzC,Ca9LC,CAAA,CAAA,CAAA,Eb8Le,CAAC,CAAC,CAAC,IAAI,CAAA,AU1KC,CAAC,UV4Kf,IAAI,MAChB,EAAA,KAAY,CAAC,IAAA,EsC8GR,GtC9GiB,CsC8GjB,CtC7GU,IsC6GV,ItC5GH,GAAA,EAAA,WAA8C,GAAK,EAAO,CiC5BC,GAAF,AjC4BA,CAAM,CAAC,CAAA,EACnD,MAAA,GAAA,EAAkB,CqCgLP,CAAC,GAAA,ArChLW,CAAC,EACzC,kBAEwB,CU7KC,AGpBA,CyB+SK,ApQ9Jd,a8N4JL,SAvGoB,CAAC,AAwGtC,CsCgGC,AzB1UA,AbkIqC,CAwGlC,AAxGmC,CAwGpC,KAAC,CAAA,MAAa,CAAA,EAAA,MAAW,CAAC,ChO0BH,KgOlI0C,CAwGhC,CAAC,GAAQ,CAAC,CAAC,CAAA,mBAjGzC,EAAQ,CAAI,CAAA,EAAG,CACf,EAAA,CAAA,CAAA,EAAyB,EAAA,kCAKnC,MA1LA,CAAC,aAGW,CjBxDM,CAAA,CAAA,CAAA,CAAA,CAAA,CiB4Dd,CAAA,wBAG2B,CAErB,EAAO,GAAA,EAAA,EAAA,EAAA,8BAI2B,EAAA,EAAA,+BAIxC,EAAA,QAAA,CAAA,uBACwC,mCAAqC,QtIrErD,csIqE4E,EAAK,EAAD,CAAI,CAAC,CAAC,CAAG,EACjH,CajLC,CbgLoH,A2CoPnH,CAAA,A3CpPoH,EACtG,iCAQZ,CUzJC,AjGwFJ,AsI1GI,AxGkCJ,E9BwEA,EuFiEiB,UAEI,GAFQ,CAER,iBAIf,iFAiBG,gBAGJ,EAAA,GAAA,EAAA,EAA4C,EAAA,OACxC,aAE0C,EAAM,2BAG5C,CAAA,4BAIC,QACF,kBAFmC,CqCsGF,GTzPO,E/EuBF,CAAC,CAAC,QmD8HP,OAGR,mFAQoD,C9BrFC,A8BqFA,CAAA,CAAI,EACxF,A2CkS0F,CAAC,CAAC,C3CnSC,CAAC,2BAiBlE,CAAA,4CAErB,CAAA,EAAA,cAAA,CAAA,MAA4B,CAAA,EACnC,EAAA,QAAA,AACX,CAAC,AAED,SAAA,GAAA,CAAA,CAAA,CAAA,CAAA,CAG0B,CAAA,CAAA,CAAA,GAAA,CAEY,GiC7DoB,QjC+DlB,EAAK,EAAA,EAAkB,0BAKhD,OADL,CtDxFH,EAAA,CAAA,EsDyFQ,kBAGK,EAAA,EAAA,IAAe,CjB5EC,AiB4EA,A9BnFA,W8BoFP,CAAE,CWhEC,AD5GA,AuCRA,kBjD+LrB,mBAGX,SAAS,AAAY,C5MtDD,+B4MuDuB,CtDpFH,AiEkBI,SXoEjC,CtIxDH,EAAA,asIwD6B,QAAQ,sCAEI,mCAGlC,gBAD+C,aAE/C,aAAA,uCAEA,aAAsB,kCAAkC,mEAfrB,GAAa,E+C7LR,A/C6LmB,GAAG,CAAC,CAAC,CAAG,KAAK,CAAA,UAFxE,GA+Df,CalMC,QbkMQ,C9NhDH,E8NiDF,CAAA,CAAA,CACU,CAAA,CACU,CtDrFa,AsDsFjC,CAAqC,MAE/B,EAAA,GAAA,EAAiC,EAAM,C2CuRX,C3CvRuB,ChOqBjB,AgOpBpC,ChOoBqC,QgOlBnC,EAAA,GAA6B,EAAK,CtDvFnB,C1K4GC,A0K5GA,AsDuFwB,EAAA,OACpC,aAEI,EAAM,IAAI,GAAA,EAAA,oBAK5B,CAAC,YAqCgB,CAAe,CAAA,CAAiB,cACJ,GAE7C,CAAC,AAED,SAAA,GAAA,CAAA,CAEI,CAAU,CAAA,CAAA,CAAA,CAES,MAEb,EAAA,OAAA,MAAA,CAAA,KACF,uCAEwB,SAExB,KrDtBgD,OAAA,EqDsBjC,CACf,mBAAmB,CAAE,EAAE,CACvB,WAAW,CAAE,EAAI,CAAD,KAAO,CAAC,MAAM,EAC3B,OAAO,CACG,CAAA,kBAEV,CACX,CAAC,AAED,SAAA,GAAA,CAA0C,CAAA,CAAA,EAGjB,GAAe,EtI/CJ,CsI+CtB,WAAW,CAAA,MAAA,uCACkC,EtI/CL,CsI+CO,CAEzD,AAFyD,AtI/CL,CAAC,CsIiD/C,IrDzBkD,OqDyBlD,CAAY,IAAI,CAAC,EAC3B,CAAC,mSyChkB4B,GAAA,EAAA,GAAA,wFAapB,CAAA,EAAA,EAAA,CAAA,CAAA,EAAA,EAAA,GAAA,CAAA,CAAA,CAAA,GAAA,CAAA,EAAA,EAAA,KAAA,CACQ,WAAA,CAAA,CAAA,EAAA,EAAA,KAAA,CACE,GAAG,CAAA,GAAQ,C7FGV,A6FHW,CAAC,C9K4BZ,U8K5BuB,CAAC,QAAQ,EAAE,CAAC,CAAC,IAAI,CAAC,KAAA,CAAM,CAAA,A9K6BnC,kBjGzGhC,GAAA,EAAA,CAAA,CAAA,OCAA,GAAA,EAAA,CAAA,CAAA,OACA,GAAA,EAAA,CAAA,CAAA,4LuMuFuB,CAAA,EAAA,CAAU,kGAOwB,cAYzD,ClLtCC,GAAA,GAAA,IAAA,EkL4CK,OAAA,WAAA,qEAQiB,EAAS,OAAO,AAAP,CzDGzB,CAAA,EyDHqC,AAAC,GAAY,CAAD,GAAJ,EAAE,CAAU,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,CAAC,2I8BuF9B,C2BrDJ,A5OJf,CAAA,MiN0DpB,EAAA,EAAA,MAAA,mCAGY,GAAA,EAAA,EAAA,KAAA,EAAA,0BAG6C,0CAIlC,EAAA,8BAGjC,Cf3HC,Ae2HA,A3M5EA,AoN6BA,AsBIA,6E/B8ZD,SAAS,CAAA,CAA0B,C9NnDZ,C8NmDwB,CAAgB,CrDb3B,sBqDcE,CAAC,GAAG,CAAC,GACxB,CAD4B,AhO6B/B,AuKlLY,CyDqJqB,AACxB,IAAI,MACnB,EAAO,EAAA,eAAmB,CAAA,GAAA,CAAA,cACX,EAMzB,CAAC,EsC4GE,atC1fQ,+B9B2GF,CAAA,2DAG+B,SACb,qIAAe,EAAA,cAAkB,CAAC,CAAC,CAAC,CAAA,UAEpD,CACX,CAAC,yMA/K0E,CAAG,CwCzCD,A1BnBA,0DdgE3C,CAAA,GAAA,CAAA,WAAA,CAAA,EAAA,+GASK,GAAA,CAAA,CAAA,EAAA,mIAU4B,AAAD,SACN,sDAWjB,EAAA,CAAA,GACsC,GrB1CrC,CAAC,CqEAqB,CAAC,EsByEE,ItE/BwB,CAAA,qBAC9B,CsE+BI,GtE/BnB,EsE+BmB,oBtE9BZ,EAAA,KAAA,EAAA,EAAE,IAAI,CAAA,eACX,AAAe,CAAA,MAAf,AAA2B,IAAlB,CAAA,IAAK,CDtCC,ACsCA,yGAevB,CyE4MC,CVxIC,I/DpEU,EAAA,EAAA,MAAA,2CAErB,CAAA,CAAA,EAAU,CAAE,IAAI,cACF,OAAA,EAAA,IAAA,CAAuB,IAAI,CAAC,CAAC,CAAA,cAExB,C+DmEC,GAAA,CAAA,E/DnEW,EAAA,EAA2B,C8B0DtF,M9B1D6F,CAAC,CAAC,OrBjCH,sBqBqC9E,6BACqC,CAAA,EAAQ,EAAe,GAAkB,OAAO,CAAC,CAAC,0BAC7C,+BAWxD,2BAC2B,CAAA,CAAA,SAAA,CAAA,CAAA,qBAAA,CAAoC,CAAA,CAAA,oBAExC,CAAA,OAAA,aAGd,EAAA,wBAAA,QAAA,iGASyB,yBAImC,C+D2DD,CAAC,C/OpBT,A+OoBU,AvK9CN,gCwGR1B,CAAC,AmE6IF,aAAA,CAAA,EAAA,GAAA,OAAA,AnE5IrB,EAAC,CAAiB,CAAA,EAAA,CAAA,eAAA,EACzB,CoEkMsD,CAAC,OpEjMX,EAAA,aACiB,CAAA,OAEtD,6BACa,YAAY,C8BkFK,E9BlFA,2BAKnC,CAAA,EAAA,oBAEW,CADsB,CoEuMO,A1FhLV,AsBtBnB,YAAA,CAAA,EAA6B,IAAI,CAAA,MhLkCF,CAAC,uBgLjCF,QACV,EAAG,qCAUa,aADtB,CAAA,eACgB,CAAA,yBAKvC,EAAA,GAAyB,IAAA,CAAA,IAAA,CAAA,EAAiB,EAAe,C0DrDC,E1DqDiB,K0DrDK,e1DsDhD,SAAmB,CAAC,AxGkBR,GwGlBJ,EyEoTA,CAAC,GzEpTK,OAMvD,GAAA,CAAA,CAAA,GAAmE,CAAI,sCAIzD,IAAA,iBACO,EAAK,kEAUM,EADS,A3B7Cf,A7EoEA,mDwGpBC,mBAIR,GAAA,CAAA,SACG,aAiB/B,SAAA,GAAA,CAAA,CAAA,CAAA,CAAA,CAI8B,CAAA,CACF,GxGoBoB,AiFXY,CsFmCW,E/D1C7D,EAAM,CAAA,CAAA,EAAA,CAAoB,qBAElB,MAAA,gBAsST,AAAkB,CAAA,MACjB,EAAA,IAAc,CxGiBD,EwGfb,EAAA,EAA+B,WAAA,CAAY,CxGkB3B,EAAE,AiLgS4B,GzElTG,CAAA,GyEkTI,CzEjTtD,IAAA,EAAA,EAAA,EAAA,EAAoC,CAAC,AyEkTA,MzEhTZ,OADpB,EAAA,WAAA,CAAA,EAAA,CAAA,MAAuC,CAAA,AAGzC,IAAA,QACO,EAAA,aAMnB,CAAC,gBApTsE,CAAC,Aa6BZ,gCiBqEjD,GAAA,K9B7F2B,CAAC,IAAA,CAAA,GAAY,EAAO,CwCnEJ,CxCmEkB,EAAQ,CAAC,CxGkBf,AwGlBe,MxGmBtD,OwGbf,CACR,CAAA,CACA,CAAA,CACA,C9KoCiD,A8KpCzB,CxBLqB,uCwBatC,CAAM,KAkJR,EAEL,SAFK,MAjJyC,CAAC,CAAC,CAAA,OAqJ7B,ClM8EP,C0OzMkB,AhE6FjB,AwB8BY,C8ByDa,W9BzDD,CAAC,CAAA,4BAnJG,IAAA,CAAM,CAAC,EAAK,QAA+B,EyEwXE,AjCrcA,AVkKA,iB9BoC1F,SAAA,CAAA,CAEI,CAAA,CAAA,CACe,MxMxcF,ICED,EAAO,GAAF,CDFM,ICEI,qCuM6cvB,YAJgB,CAAA,QAAA,CxM3cK,EwM2cL,GACT,CAAC,CAAC,CxM5coB,CQyd6B,GgMb5C,CAAC,WAAW,CxM3czB,AwM4cJ,CxM5cI,AwM4cJ,ExM5cI,GAAA,OAAA,AAAW,EAAC,CAAA,EAAA,GAAA,OAAA,AAAG,EAAC,EAAY,GAAW,IwM+cnC,MAAM,CAAA,GAA6B,aAAa,IAChD,GAAA,CAAA,GAAA,EAAA,SAAA,IAAA,GAAA,EACI,YAAA,CvM/cP,GAAS,EAAM,MAAM,CAAI,CAAA,EAAA,GAAA,OAAA,AAAQ,EAAC,EAAO,CAAA,EAAA,GAAA,OAAY,AAAZ,EAAa,EAAU,IAAM,EAAE,cuMsdlF,CAAC,CAzI4C,EAAM,CmE6MH,CAAC,AnE7Ma,sFAarD,GAAA,CAEG,CAAA,CACW,CAAA,CACN,CAAA,CAAA,CAAA,CAEa,CAC1B,CAAwB,QA8H5B,SAAS,CAAA,CAAA,CAEQ,CoEqKuB,ApEpKpC,CAAA,QAEM,ClMyED,CkMzEgB,IAAI,GACnB,EAAA,EAAmC,CAAA,AyE2UZ,uBzEzUG,CAAE,IACL,CAAA,MAAR,CAAqB,CAAnB,AlM2EkB,A0K/GJ,CwBoCb,AxBpCc,EwBoCZ,GAAG,uCAIE,gBAGrB,EAAmB,CAAC,A2CvJE,A3N2OR,C2N3OQ,KAAA,CAAA,W3CuJgB,CAAA,MAAA,KACvC,IAAA,EAAQ,EAAA,EAAA,EAAA,IAAA,OAEM,AAiC3B,EhM5ByB,OgM4BzB,CAAA,CAAA,CAEiB,OAnC6B,kBAuCzB,EAAA,EAAA,SAA2B,CAAC,AoEgKA,gBpE3JjD,CAAC,CA7C8B,EAAA,KAAA,CAAQ,WAAW,CAAA,EAAG,CACP,EAC9B,MAAA,IAAA,GACA,EAAa,EADS,CACT,CAAA,CACT,MAAA,WACU,kBAa1B,GAJiC,CAAC,KAAZ,MAAA,EAAsC,CAAC,EAAE,CAAzB,ClMuFD,CAAA,IkMvFkB,GoEmKG,KpE/J1D,KAAc,IAAd,qBACgB,KACiB,QAAQ,EACjC,CyEuUC,EzEvUO,EAAG,C+DqCC,C1FlIS,M2BiGP,MAAA,CAAA,GAAc,CAAC,CxBzCF,QwB8L9B,CAA8C,UACxC,KAAK,ChLsHL,CAAA,QgLtHqB,CAAE,cACnB,CAAA,IAAK,QACL,C2ClMC,AtEgFN,C2BqHV,AoEqKiB,MpErKjB,CAAA,GxBpMmC,AwBgMK,QAvJ8B,QAClD,IACN,GAAA,CAAI,WAKtB,CAAC,GA9K2C,OAAA,CAAS,EAAO,CyE4WC,CAAC,IzE3WvC,qBACJ,EAAA,EAAA,EAAA,IACJ,SAGI,GAAY,KAuL/B,SAAS,CAAA,CAEL,CAAA,EAEA,IAAA,UACW,KAAA,EAAa,QAAA,KACW,CxBrDP,E1K2IQ,AEzFR,GgMGa,EAAlB,CAAA,EAAA,GAAM,sBACE,EACR,AvBoCF,SuBnCF,EaDA,EAAA,EbCU,GAAA,EAAK,MACf,OAIZ,CACX,CAAC,iFA/LU,GAAA,AAiUX,SAA0C,CAAqB,CxG0CjB,IwGnD9C,SAAS,AAA2B,CAAqB,CyEwSb,C9B3eC,Q3CoM9B,KAAK,EAAQ,QAAQ,CAAE,SACxB,KAAK,CAAC,E3BnHN,EAAA,K2BmHe,C2CnMC,A8B2eA,EzEvSX,YADyB,AAQT,UAAU,EhLoHO,CAAC,CAAC,agL3G7C,AACL,CyEoS4B,AzEpSC,MAEvB,EAAA,IAAmB,IACzB,IAAA,IAAA,KAAA,EAAyB,KACf,EAAM,ExG0CN,CwG1CsB,CAAC,CAAE,MACpB,EAAA,GAAgB,CAAC,QACf,E3BnHJ,Q2BoHE,CAAA,EACP,EAAa,GAAG,CAAA,EAAA,QAEb,GAAA,CAAI,EAAG,YAjBoB,EAAA,QAAgB,CAAC,CAAA,OAGhD,AADH,IhMwBQ,CwFoBO,IwGvBnB,CAA6C,CyEiSX,SzE/RvB,GhMqBH,EgMrBY,MAAM,IAAI,CAAC,EAAQ,C3BnHT,CAAC,G2BmHO,CAAO,IAAK,cAC/B,CAAA,GAAQ,MAAA,CAAS,EAC5B,CAD+B,KACxB,UAGR,CACX,EA7B6B,IAAY,CAAC,AA+B1C,CxGaqD,CwG5CjB,OA+B3B,CAAA,MAGA,IAAM,KAAS,EhMwBJ,C2OpOO,A3C0K2C,GAkCxC,IAAI,CAAC,EAAQ,MAAM,EAAE,CAAC,CAAE,GACZ,CAAC,EAAE,YAAtB,CAAA,GAAQ,CxGoCC,CAAC,IAAA,QwGnCd,SAGR,CACX,CAAC,CAxCsE,EAEvE,CAAC,CAzUU,GAAA,AAuUmE,CAAC,CAAA,GAtUjE,EAAA,CAAA,EAAA,GAAA,OAAA,AAAgB,EAAA,EAAO,IAAA,iCAEV,CAAG,IACb,OAAA,CAAQ,SAAS,CAAA,iBACY,EAAK,IAAiB,IAAA,YAGrD,GAAA,EAAgB,EAAA,EAAkB,EAEjD,CAAC,AAED,SAAS,GAAA,CAAA,CAAA,CAGY,CAAA,CACS,CyCYqC,AzCX/D,CAAwB,MAkBC,CoE6KK,A5BhRJ,WxCmFpB,EAAA,EAA4B,CAAA,A2C7HZ,2B3C+HH,CAAA,IAAA,CAAA,EAAA,CAAA,GAAA,SAAA,MAEb,EAAA,EAAA,aAAA,MAGA,cAFN,EAAA,IAAkC,uFAiBI,CAAA,GAAA,GACvB,IACb,IAAI,CAAC,IAAI,CyCCqB,AzCDpB,CACN,EAAA,AaAuC,IbAvC,EAAA,UACgB,CAAA,GAAI,CAAS,GaDU,AbCL,EAAQ,UAAU,CAAC,GAAG,2CAEb,gBAAgB,CAAC,IAAI,CAC9D,IAAI,CACP,CAAA,MAAA,EAAS,SAWY,CwChHC,AxCgH8B,CoEoK5C,A5KlJkB,SwG7BG,qBAYD,8BAEE,aAExB,aAAgB,CyCHD,A3OsEV,akMjET,GAAA,aAAA,iDAGI,yBADkD,EAElD,aAAgB,yBAAyB,4BAEb,uDAK7B,MAAA,uBAEd,CAAC,CA/BsC,EAAQ,KAAD,KAAW,CAAC,CAAA,EAAG,EAAa,QAAH,CAAA,CAAA,AAAG,EAAA,EAAA,YAAA,CACjC,IAAA,CAAe,UAAA;AAAA,CAAA,EAAA,EAAA;AAAA,CACwB,AAFN,CAEM;CAIsB,CAAA,yBA0ItG,SAAS,GAAA,CAAA,QACE,CACH,QAAA,yDASJ,CAAA,CAAA,CAAA,CAAA,CAAA,WAIK,GAAA,EAAA,UACK,CAAA,EAAO,YAAY,CAAC,CxGWE,C4K+II,A5K/IJ,CwGVzB,eAGkB,CAAE,CAAe,E2CtLjB,kB3CuLA,KAKnB,EAAA,EAAA,OAAA,CAAA,GAAA,GACW,EAAI,C3B1GT,K2B0Ge,CAAA,EAAA,wBAIrB,OAAO,CAAA,QAAA,KACT,MAAM,CAAC,EAAA,CAAU,EACd,GAoBX,SAAS,GAAQ,CAAA,CAAA,CAAA,MACP,EAAI,EAAA,KAAA,cAEA,CAAoB,CxBjET,AuFiGU,C/PtBX,AwFWU,AuKWE,E/D/BxB,EAAA,KAAY,CAAC,EhLqHF,IAAA,CAAA,EAAA,kBgLpHsB,KAED,SADH,GAAA,sBAMP,aAIX,CAAA,UAKd,EAAE,sBAAsB,EACzB,AAD2B,EAC3B,GAAW,CAAA,OAGT,EAAA,EAAA,WAAA,CAAiC,MAAA,KAClC,IAAI,EAAA,EAAA,EAAA,EAA6B,CAAC,EAAE,CAAA,CAErC,IAAM,CAAC,CAAG,SASd,CAAiB,CAAA,CAAA,2BAIN,SACe,CxBhEH,AwB8DsB,KxB9DtB,CwBiEf,IAAK,CxG4BD,AmJ3NE,CAAA,GAAA,c3CgMa,EAEpB,GAAI,aAAsB,GAAgB,E2C9LA,K3C+L/B,C2C9LC,A3C8LA,GAAG,EAAA,KAAY,GAAa,WAAA,EAC3C,MAAO,OACI,EAAW,MAAM,KACnB,EAAO,CaZC,EAAA,Obab,KAvBM,EADJ,EAAA,WAAA,CAAA,EAAA,OAGI,IAAN,CAAC,AhL4HN,MgL5HsB,CyE6SC,AjG3WF,AwB+DL,GAGvB,CAAC,ANzpBG,CACD,KAAgB,GAAc,EAAC,CAAC,EADnB,EAAE,AACA,CAJd,EAGiB,OAHR,AAAG,CAAK,EACb,MAAwB,UAAjB,OAAO,CAClB,EAQA,CACD,KAAQ,EAAD,CAAO,EAAC,CAAC,EADX,EAAE,CAHN,EAGS,OAHG,AAAH,CAAQ,EACb,MAAwB,UAAjB,OAAO,CAClB,EAKA,IAMD,KAAY,GAAU,EAAC,CAAZ,AAAa,EANf,SAAS,CAAG,CAAC,WACrB,GAAQ,SAAS,CAAG,WAIpB,GAAQ,EAAE,CAHV,EAGa,OAHJ,AAAG,CAAK,EACb,MAAwB,UAAjB,OAAO,GAAsB,GAAQ,SAAS,EAAI,GAAS,GAAS,GAAQ,SACvF,AADgG,EAMhG,CADO,GAOR,KAPgB,AAOH,GAAW,EAAC,CAAC,CAAd,CANF,SAAS,CAAG,EACrB,GAAS,SAAS,CAAG,WAIrB,GAAS,EAAE,CAHX,EAGc,OAHL,AAAG,CAAK,EACb,MAAwB,UAAjB,OAAO,GAAsB,GAAS,SAAS,EAAI,GAAS,GAAS,GAAS,SACzF,AADkG,EAwBlG,IASD,KAAa,GAAW,CAAC,CAAC,EAAd,CATF,MAAM,CATf,EASkB,OATT,AAAO,CAAI,CAAE,CAAS,EAO3B,OANI,IAAS,OAAO,SAAS,EAAE,CAC3B,EAAO,GAAS,SAAA,AAAS,EAEzB,IAAc,OAAO,SAAS,EAAE,CAChC,EAAY,GAAS,SAAA,AAAS,EAE3B,MAAE,YAAM,CAAU,CAC7B,EASA,GAAS,EAAE,CAJX,EAIc,OAJL,AAAG,CAAK,EAEb,OAAO,GAAG,aAAa,CAAC,IAAc,GAAG,QAAQ,CAAC,EAAU,IAAI,GAAK,GAAG,QAAQ,CADhE,AACiE,EAAU,SAAS,CACxG,EAoBA,CAZO,GAqBR,EArBa,GAqBH,GAAQ,CAAT,AAAU,CAAC,GATb,MAAM,CAXZ,EAWe,OAXC,AAAP,CAAU,CAAE,CAAG,CAAE,CAAK,CAAE,CAAI,EACjC,GAAI,GAAG,QAAQ,CAAC,IAAQ,GAAG,QAAQ,CAAC,IAAQ,GAAG,QAAQ,CAAC,IAAU,GAAG,QAAQ,CAAC,GAC1E,IADiF,EAC1E,CAAE,MAAO,GAAS,MAAM,CAAC,EAAK,GAAM,IAAK,GAAS,MAAM,CAAC,EAAO,EAAM,EAE5E,GAAI,GAAS,EAAE,CAAC,IAAQ,GAAS,EAAE,CAAC,GACrC,GAD2C,GACpC,CAAE,MAAO,EAAK,IAAK,CAAI,CAG9B,OAAU,AAAJ,MAAU,CAAC,2CAA2C,EAAE,EAAI,EAAE,EAAE,EAAI,EAAE,EAAE,EAAM,EAAE,EAAE,EAAK,CAAC,CAAC,CAEvG,EASA,GAAM,EAAE,CAJR,EAIW,OAJF,AAAG,CAAK,EAEb,OAAO,GAAG,aAAa,CAAC,IAAc,GAAS,EAAE,CAAC,EAAU,KAAK,GAAK,GAAS,EAAE,CAAC,AADlE,EAC4E,GAAG,CACnG,EAiBA,CATO,GAkBR,KAlBgB,AAkBH,GAAW,EAAC,CAAC,CAAd,CATF,MAAM,CAHf,EAGkB,OAHF,AAAP,CAAU,CAAE,CAAK,EACtB,MAAO,KAAE,QAAK,CAAM,CACxB,EASA,GAAS,EAAE,CAJX,EAIc,OAJF,AAAH,CAAQ,EAEb,OAAO,GAAG,aAAa,CAAC,IAAc,GAAM,EAAE,CAAC,EAAU,KAAK,IAAM,CAAD,EAAI,MAAM,CAAC,AAD9D,EACwE,GAAG,GAAK,GAAG,SAAS,CAAC,EAAU,IAAG,CAC9H,AAD+H,EAoB/H,IAWD,KAAiB,GAAe,EAAC,CAAC,EAXpB,GAWE,GAXI,CAHnB,EAGsB,OAHb,AAAO,CAAS,CAAE,CAAW,CAAE,CAAoB,CAAE,CAAoB,EAC9E,MAAO,WAAE,cAAW,uBAAa,uBAAsB,CAAqB,CAChF,EAWA,GAAa,EAAE,CANf,EAMkB,OANT,AAAG,CAAK,EAEb,OAAO,GAAG,aAAa,CAAC,IAAc,GAAM,EAAE,CAAC,EAAU,WAAW,GAAK,GAAG,MAAM,CAAC,EAAU,SAAS,GAC/F,GAAM,EAAE,CAAC,EAAU,oBAAoB,IACtC,CAAD,EAAO,EAAE,CAAC,EAAU,oBAAoB,GAAK,GAAG,SAAS,CAAC,AAHjD,EAG2D,qBAAoB,CACnG,AADoG,EAqBpG,CAZO,GAwBR,EAxBa,GAwBH,GAAQ,CAAT,AAAU,CAAC,GAZb,MAAM,CARZ,EAQe,OARN,AAAO,CAAG,CAAE,CAAK,CAAE,CAAI,CAAE,CAAK,EACnC,MAAO,KACH,QACA,EACA,aACA,CACJ,CACJ,EAYA,GAAM,EAAE,CAPR,EAOW,OAPF,AAAG,CAAK,EAEb,OAAO,GAAG,aAAa,CAAC,IAAc,GAAG,WAAW,CAAC,EAAU,GAAG,CAAE,EAAG,IAChE,GAAG,WAAW,CAAC,EAAU,KAAK,CAAE,EAAG,IACnC,GAAG,WAAW,CAAC,AAHJ,EAGc,IAAI,CAAE,EAAG,IAClC,GAAG,WAAW,CAAC,EAAU,KAAK,CAAE,EAAG,EAC9C,EAkBA,CAVO,GAmBR,IAAqB,IAAmB,EAAC,CAAC,EAnBlB,AAUN,MAAM,CANvB,AAemB,EATO,OANjB,AAAO,CAAK,CAAE,CAAK,EACxB,MAAO,OACH,QACA,CACJ,CACJ,EASA,GAAiB,EAAE,CAJnB,EAIsB,OAJb,AAAG,CAAK,EAEb,OAAO,GAAG,aAAa,CAAC,IAAc,GAAM,EAAE,CAAC,EAAU,KAAK,GAAK,GAAM,EAAE,CAAC,AAD1D,EACoE,KAAK,CAC/F,EAmBA,CAXO,GAsBR,KAAsB,GAAoB,EAAC,CAAC,EAXzB,CAXM,KAWA,CAPxB,CAkBoB,CAXO,OAPX,AAAP,CAAY,CAAE,CAAQ,CAAE,CAAmB,EAChD,MAAO,OACH,WACA,sBACA,CACJ,CACJ,EAWA,GAAkB,EAAE,CANpB,EAMuB,OANd,AAAG,CAAK,EAEb,OAAO,GAAG,aAAa,CAAC,IAAc,GAAG,MAAM,CAAC,EAAU,KAAK,IACvD,CAAD,EAAI,SAAS,CAAC,EAAU,QAAQ,GAAK,GAAS,EAAE,CAAC,EAAA,CAAU,GAC1D,EAAD,CAAI,SAAS,CAHF,AAGG,EAAU,mBAAmB,GAAK,GAAG,UAAU,CAAC,EAAU,mBAAmB,CAAE,GAAS,GAAE,CAAC,AACpH,EAWA,CAJO,GAaR,KAAqB,GAAmB,EAAC,CAAC,EATxB,AAJM,OAaJ,AATK,CAAG,UAI3B,GAAiB,OAAO,CAAG,UAI3B,GAAiB,MAAM,CAAG,SA8B1B,IAYD,KAAiB,GAAe,EAAC,CAAC,EAZpB,GAYE,GAZI,CAnBnB,EAmBsB,OAnBb,AAAO,CAAS,CAAE,CAAO,CAAE,CAAc,CAAE,CAAY,CAAE,CAAI,CAAE,CAAa,EACjF,IAAM,EAAS,WACX,UACA,CACJ,EAaA,OAZI,GAAG,OAAO,CAAC,IACX,GAAO,UADqB,IACP,CAAG,CAAA,EAExB,GAAG,OAAO,CAAC,KACX,EAAO,QADmB,IACP,CAAG,CAAA,EAEtB,GAAG,OAAO,CAAC,KACX,EADkB,AACX,IAAI,CAAG,CAAA,EAEd,GAAG,OAAO,CAAC,KACX,EAAO,SADoB,IACP,CAAG,CAAA,EAEpB,CACX,EAYA,GAAa,EAAE,CAPf,EAOkB,OAPT,AAAG,CAAK,EAEb,OAAO,GAAG,aAAa,CAAC,IAAc,GAAG,QAAQ,CAAC,EAAU,SAAS,GAAK,GAAG,QAAQ,CAAC,EAAU,SAAS,IACjG,CAAD,EAAI,SAAS,CAAC,EAAU,cAAc,GAAK,GAAG,QAAQ,CAAC,EAAU,eAAc,CAAC,GAC/E,EAAD,CAAI,SAAS,CAAC,EAAU,YAAY,GAAK,GAAG,QAAQ,CAAC,EAAU,aAAY,CAAC,GAC3E,EAAD,CAAI,SAAS,CAAC,EAAU,IAAI,GAAK,GAAG,MAAM,CAJ/B,AAIgC,EAAU,KAAI,CACpE,AADqE,EAmBrE,IASD,KAAiC,GAA+B,EAAC,CAAC,EATpC,MAAM,CANnC,EAMsC,OANtB,AAAP,CAAe,CAAE,CAAO,AAeF,EAd3B,MAAO,UACH,UACA,CACJ,CACJ,EASA,GAA6B,EAAE,CAJ/B,EAIkC,OAJzB,AAAG,CAAK,EAEb,OAAO,GAAG,OAAO,CAAC,IAAc,GAAS,EAAE,CAAC,EAAU,QAAQ,GAAK,GAAG,MAAM,CAD5D,AAC6D,EAAU,OAAO,CAClG,EAWA,CAJO,GAiBR,KAAuB,GAAqB,EAAC,CAAC,EAb1B,EAJM,GAID,CAAG,EAI3B,CASqB,EATF,OAAO,CAAG,EAI7B,GAAmB,WAAW,CAAG,EAIjC,GAAmB,IAAI,CAAG,EAe1B,CAPO,GAcR,KAAkB,GAAgB,EAdb,AAcc,CAAC,EAPrB,IAOE,OAPS,CAAG,EAM5B,GAAc,UAAU,CAAG,EAa3B,CACD,KAAoB,GAAkB,EAAC,CAAC,EADvB,EAAE,CAJlB,EAIqB,CACH,MALN,AAAH,CAAQ,EAEb,OAAO,GAAG,aAAa,CAAC,IAAc,GAAG,MAAM,CAD7B,AAC8B,EAAU,IAAI,CAClE,EA4BA,CApBO,GAqCR,KAAe,EArCG,CAqCU,CAAC,CAAC,GAjBlB,CAiBE,KAjBI,CAhBjB,EAgBoB,OAhBX,AAAO,CAAK,CAAE,CAAO,CAAE,CAAQ,CAAE,CAAI,CAAE,CAAM,CAAE,CAAkB,EACtE,IAAI,EAAS,CAAE,gBAAO,CAAQ,EAa9B,OAZI,GAAG,OAAO,CAAC,KACX,EAAO,IADe,IACP,CAAG,CAAA,EAElB,GAAG,OAAO,CAAC,KACX,EADkB,AACX,IAAI,CAAG,CAAA,EAEd,GAAG,OAAO,CAAC,KACX,EAAO,EADa,IACP,CAAG,CAAA,EAEhB,GAAG,OAAO,CAAC,KACX,EAAO,cADyB,IACP,CAAG,CAAA,EAEzB,CACX,EAiBA,GAAW,EAAE,CAZb,EAYgB,OAZP,AAAG,CAAK,EACb,IAAI,EAEJ,OAAO,GAAG,OAAO,CAAC,IACX,GAAM,EAAE,CAAC,EAAU,KAAK,GACxB,GAAG,MAAM,CAAC,EAAU,OAAO,IAC1B,CAAD,EAAI,MAAM,CAJD,AAIE,EAAU,QAAQ,GAAK,GAAG,SAAS,CAAC,EAAU,SAAQ,CAAC,GACjE,EAAD,CAAI,OAAO,CAAC,EAAU,IAAI,GAAK,GAAG,MAAM,CAAC,EAAU,IAAI,GAAK,GAAG,SAAS,CAAC,EAAU,KAAI,CAAC,GACvF,EAAD,CAAI,SAAS,CAAC,EAAU,eAAe,GAAM,GAAG,MAAM,CAAC,OAAC,EAAK,EAAU,eAAe,AAAf,EAA6C,IAAxB,CAA6B,EAAI,EAAG,GAA5B,EAAgC,CAAE,EACrI,EAD0G,CAC3G,CAAI,GAD4G,GACtG,CAAC,EAAU,MAAM,GAAK,GAAG,SAAS,CAAC,EAAU,OAAM,CAAC,GAC7D,EAAD,CAAI,SAAS,CAAC,EAAU,kBAAkB,GAAK,GAAG,UAAU,CAAC,EAAU,kBAAkB,CAAE,GAA6B,GAAE,CACrI,AADsI,EAoBtI,IASD,IAAY,IAAU,EAAC,CAAZ,AAAa,EATf,MAAM,CAPd,EAOiB,OAPR,AAAO,CAAK,CAAE,CAAO,CAAE,GAAG,CAAI,EACnC,IAAI,EAAS,OAAE,UAAO,CAAQ,EAI9B,OAHI,GAAG,OAAO,CAAC,IAAS,EAAK,MAAM,CAAG,GAAG,CACrC,EAAO,SAAS,CAAG,CAAA,EAEhB,CACX,EASA,GAAQ,EAAE,CAJV,EAIa,OAJD,AAAH,CAAQ,EAEb,OAAO,GAAG,OAAO,CAAC,IAAc,GAAG,MAAM,CAAC,EAAU,KAAK,GAAK,GAAG,MAAM,CADvD,AACwD,EAAU,OAAO,CAC7F,EAiBA,CATO,GAkCR,KAAa,AAlCG,GAkCQ,EAAC,CAAC,CAAd,CAzBF,OAAO,CAHhB,EAGmB,OAHV,AAAQ,CAAK,CAAE,CAAO,EAC3B,MAAO,OAAE,UAAO,CAAQ,CAC5B,EAUA,GAAS,MAAM,CAHf,EAGkB,OAHT,AAAO,CAAQ,CAAE,CAAO,EAC7B,MAAO,CAAE,MAAO,CAAE,MAAO,EAAU,IAAK,CAAS,UAAG,CAAQ,CAChE,EASA,GAAS,GAAG,CAHZ,EAGe,OAHN,AAAI,CAAK,EACd,MAAO,OAAE,EAAO,QAAS,EAAG,CAChC,EAQA,GAAS,EAAE,CANX,EAMc,OANL,AAAG,CAAK,EAEb,OAAO,GAAG,aAAa,CAAC,IACjB,GAAG,MAAM,CAFE,AAED,EAAU,OAAO,GAC3B,GAAM,EAAE,CAAC,EAAU,KAAK,CACnC,EAeA,CAXO,GAmBR,IAAqB,IAAmB,EAAC,CAAC,EAnBlB,AAWN,MAAM,CAQJ,AAlBnB,EAU0B,OAVjB,AAAO,CAAK,CAAE,CAAiB,CAAE,CAAW,EACjD,IAAM,EAAS,OAAE,CAAM,EAOvB,YAN0B,IAAtB,IACA,EAAO,CAD0B,gBACT,CAAG,CAAA,OAEX,IAAhB,IACA,EAAO,CADoB,UACT,CAAG,CAAA,EAElB,CACX,EAQA,GAAiB,EAAE,CANnB,EAMsB,OANb,AAAG,CAAK,EAEb,OAAO,GAAG,aAAa,CAAC,IAAc,GAAG,MAAM,CAAC,EAAU,KAAK,GAC1D,EAAD,EAAI,OAAO,CAAC,AAFE,EAEQ,iBAAiB,GAAK,KAAgC,MAAtB,iBAAiB,AAAK,CAAS,GACpF,EAAD,CAAI,MAAM,CAAC,EAAU,WAAW,QAA+B,IAA1B,EAAU,WAAW,AAAK,CAAS,AAChF,EASA,AACD,MAA+B,GAA6B,EAAC,CAAC,EADlC,EAAE,CAJ7B,EAIgC,OAJvB,AAAG,CAAK,EAEb,CAGyB,MAHlB,GAAG,MAAM,CAAC,AADC,EAEtB,EAeA,CAXO,GAsCR,KAAsB,GAAoB,EAAC,CAAC,EA3BzB,CAXM,MAWC,CA2BL,AA9BpB,EAG4B,OAHnB,AAAQ,CAAK,CAAE,CAAO,CAAE,CAAU,EACvC,MAAO,OAAE,UAAO,EAAS,aAAc,CAAW,CACtD,EAYA,GAAkB,MAAM,CAHxB,EAG2B,OAHlB,AAAO,CAAQ,CAAE,CAAO,CAAE,CAAU,EACzC,MAAO,CAAE,MAAO,CAAE,MAAO,EAAU,IAAK,CAAS,UAAG,EAAS,aAAc,CAAW,CAC1F,EAWA,GAAkB,GAAG,CAHrB,EAGwB,OAHf,AAAI,CAAK,CAAE,CAAU,EAC1B,MAAO,OAAE,EAAO,QAAS,GAAI,aAAc,CAAW,CAC1D,EAMA,GAAkB,EAAE,CAJpB,EAIuB,OAJd,AAAG,CAAK,EAEb,OAAO,GAAS,EAAE,CAAC,IAAe,IAAiB,EAAE,CADnC,AACoC,EAAU,CAA/B,WAA2C,GAAK,GAA2B,EAAE,CAAC,EAAU,aAAY,CAAC,AAC1I,EAeA,CAPO,GAeR,KAAqB,GAAmB,EAAC,CAAC,EAflB,AAON,MAAM,CAQJ,AAXnB,EAG0B,OAHjB,AAAO,CAAY,CAAE,CAAK,EAC/B,MAAO,cAAE,QAAc,CAAM,CACjC,EAQA,GAAiB,EAAE,CANnB,EAMsB,OANb,AAAG,CAAK,EAEb,OAAO,GAAG,OAAO,CAAC,IACX,GAAwC,EAAE,CAAC,EAAU,YAAY,GACjE,MAAM,OAAO,CAHJ,AAGK,EAAU,KAAK,CACxC,EAkBA,IAOD,KAAe,GAAa,CAAC,CAAC,GAPlB,CAOE,KAPI,CAbjB,EAaoB,OAbX,AAAO,CAAG,CAAE,CAAO,CAAE,CAAU,EACpC,IAAI,EAAS,CACT,KAAM,aACN,CACJ,EAOA,YANgB,IAAZ,SAAgD,AAAvB,IAAC,EAAQ,SAAS,OAA6C,IAA3B,EAAQ,cAAc,AAAK,CAAS,GAAG,AACpG,EAAO,OAAO,CAAG,CAAA,OAEF,IAAf,IACA,EAAO,CADmB,WACP,CAAG,CAAA,EAEnB,CACX,EAOA,GAAW,EAAE,CALb,EAKgB,OALJ,AAAH,CAAQ,EAEb,OAAO,GAAgC,WAAnB,EAAU,IAAI,EAAiB,GAAG,MAAM,CAAC,EAAU,GAAG,KAAK,IAAuB,IAAtB,EAAU,OAAO,EAC5F,MAAiC,IAAhC,EAAU,OAAO,CAAC,SAAS,EAAkB,GAAG,OAAO,CAF7C,AAE8C,EAAU,OAAO,CAAC,UAAS,CAAC,KAAK,GAAsC,IAArC,EAAU,OAAO,CAAC,cAAc,EAAkB,GAAG,OAAO,CAAC,EAAU,OAAO,CAAC,cAAc,EAAC,CAAE,KAAK,GAA4B,IAA3B,EAAU,YAAY,EAAkB,GAA2B,EAAE,CAAC,EAAU,aAAY,CAAC,AACvS,EAmBA,IAOD,IAAe,IAAa,CAAC,CAAC,GAPlB,CAOE,KAPI,CAdjB,EAcoB,OAdX,AAAO,CAAM,CAAE,CAAM,CAAE,CAAO,CAAE,CAAU,EAC/C,IAAI,EAAS,CACT,KAAM,gBACN,SACA,CACJ,EAOA,OANI,KAAY,QAAoC,AAAtB,KAAD,MAAS,SAAS,OAA6C,IAA3B,EAAQ,cAAmB,AAAL,CAAc,GAAG,AACpG,EAAO,OAAO,CAAG,CAAA,OAEF,IAAf,IACA,EAAO,CADmB,WACP,CAAG,CAAA,EAEnB,CACX,EAOA,GAAW,EAAE,CALb,EAKgB,OALP,AAAG,CAAK,EAEb,OAAO,AADS,GACuB,WAAnB,EAAU,IAAI,EAAiB,GAAG,MAAM,CAAC,EAAU,MAAM,GAAK,GAAG,MAAM,CAAC,EAAU,MAAM,KAAK,IAAuB,IAAtB,EAAU,OAAO,EAC9H,MAAiC,IAAhC,EAAU,OAAO,CAAC,SAAS,EAAkB,GAAG,OAAO,CAAC,EAAU,OAAO,CAAC,UAAS,CAAC,KAAK,GAAsC,IAArC,EAAU,OAAO,CAAC,cAAc,EAAkB,GAAG,OAAO,CAAC,EAAU,OAAO,CAAC,eAAc,CAAC,CAAE,KAAK,GAA4B,IAA3B,EAAU,YAAY,EAAkB,GAA2B,EAAE,CAAC,EAAU,aAAY,CAAC,AACvS,EAkBA,CAdO,GAqBR,KAAe,EArBG,CAqBU,EAAC,CAAC,EAPlB,CAOE,KAPI,CAbjB,EAaoB,OAbX,AAAO,CAAG,CAAE,CAAO,CAAE,CAAU,EACpC,IAAI,EAAS,CACT,KAAM,SACN,KACJ,EAOA,YANgB,IAAZ,SAAgD,AAAvB,IAAC,EAAQ,SAAS,OAAgD,IAA9B,EAAQ,iBAAiB,AAAK,CAAS,GAAG,AACvG,EAAO,OAAO,CAAG,CAAA,OAEF,IAAf,IACA,EAAO,CADmB,WACP,CAAG,CAAA,EAEnB,CACX,EAOA,GAAW,EAAE,CALb,EAKgB,OALP,AAAG,CAAK,EAEb,OAAO,GAAa,AAAmB,aAAT,IAAI,EAAiB,GAAG,MAAM,CAAC,EAAU,GAAG,KAAK,IAAuB,IAAtB,EAAU,OAAO,EAC5F,MAAiC,IAAhC,EAAU,OAAO,CAAC,SAAS,EAAkB,GAAG,OAAO,CAAC,EAAU,OAAO,CAAC,UAAS,CAAC,KAAK,GAAyC,IAAxC,EAAU,OAAO,CAAC,iBAAiB,EAAkB,GAAG,OAAO,CAAC,EAAU,OAAO,CAAC,kBAAiB,CAAC,CAAE,KAAK,GAA4B,IAA3B,EAAU,YAAY,EAAkB,GAA2B,EAAE,CAAC,AAFlQ,EAE4Q,aAAY,CAC5S,AAD6S,EAmB7S,CACD,KAAkB,GAAgB,EAAC,CAAC,EADrB,EAAE,CAbhB,CAcgB,CADG,OAbV,AAAG,CAAK,EAEb,OAAO,SACoB,IAAvB,AAAC,EAAU,OAAO,OAAgD,IAA9B,EAAU,eAAe,AAAK,CAAS,GAC1E,AAA8B,EAA/B,SAAW,eAAe,EAAkB,AAHhC,EAG0C,eAAe,CAAC,KAAK,CAAC,AAAC,GACzE,AAAI,GAAG,MAAM,CAAC,EAAO,IAAI,EACd,CADiB,EACN,EAAE,CAAC,IAAW,GAAW,EAAE,CAAC,IAAW,GAAW,EAAE,CAAC,GAGhE,GAAiB,EAAE,CAAC,GAEnC,CACR,AADU,EAmTV,CARO,GAiBR,KAA2B,GAAyB,CAAC,CAAC,GAT9B,MAAM,AARA,CAK7B,EAGgC,IASP,GAZhB,AAAO,CAAG,EACf,MAAO,KAAE,CAAI,CACjB,EASA,GAAuB,EAAE,CAJzB,EAI4B,OAJnB,AAAG,CAAK,EAEb,OAAO,GAAG,OAAO,CAAC,IAAc,GAAG,MAAM,CAAC,AAD1B,EACoC,GAAG,CAC3D,EAiBA,CATO,GAkBR,KAAoC,GAAkC,EAAC,CAAC,EATvC,MAAM,CAHtC,EAGyC,MATH,CAM7B,AAAO,CAAG,CAAE,CAAO,EACxB,CAW8B,KAXvB,KAAE,UAAK,CAAQ,CAC1B,EASA,GAAgC,EAAE,CAJlC,EAIqC,OAJ5B,AAAG,CAAK,EAEb,OAAO,GAAG,OAAO,CAAC,IAAc,GAAG,MAAM,CADzB,AAC0B,EAAU,GAAG,GAAK,GAAG,OAAO,CAAC,EAAU,OAAO,CAC5F,EAiBA,CATO,GAkBR,KAA4C,GAA0C,EAAC,CAAC,EAT/C,MAAM,CAH9C,EAGiD,OAHxC,AAAO,CAAG,CAAE,CAAO,EACxB,EAP0C,IAOnC,GAW+B,EAX7B,UAAK,CAAQ,CAC1B,EASA,GAAwC,EAAE,CAJ1C,EAI6C,OAJpC,AAAG,CAAK,EAEb,OAAO,GAAG,OAAO,CAAC,IAAc,GAAG,MAAM,CAAC,EAAU,GAAG,IAA4B,CAAvB,MAAC,AAD7C,EACuD,OAAO,EAAa,GAAG,OAAO,CAAC,EAAU,QAAO,CAAC,AAC5H,EAmBA,IASD,KAAqB,GAAmB,EAAC,CAAC,EATxB,MAAM,CAHvB,AAYmB,EATO,OAHjB,AAAO,CAAG,CAAE,CAAU,CAAE,CAAO,CAAE,CAAI,EAC1C,MAAO,KAAE,aAAK,UAAY,OAAS,CAAK,CAC5C,EASA,GAAiB,EAAE,CAJnB,EAIsB,OAJb,AAAG,CAAK,EAEb,OAAO,GAAG,OAAO,CAAC,IAAc,GAAG,MAAM,CAAC,EAAU,GAAG,GAAK,GAAG,MAAM,CAAC,EAAU,UAAU,GAAK,GAAG,OAAO,CAAC,EAAU,OAAO,GAAK,GAAG,MAAM,CAAC,AAD1H,EACoI,IAAI,CAC5J,EAeA,CAJO,GAiBR,KAAe,EAjBG,CAiBU,EAAC,CAAC,EAblB,CAaE,QAbO,CAAG,YAIvB,GAAW,QAAQ,CAAG,WAQtB,GAAW,EAAE,CAJb,EAIgB,OAJP,AAAG,CAAK,EAEb,OAAO,IAAc,GAAW,SAAS,EADvB,AAC2B,IAAc,GAAW,QAAQ,AAClF,EAaD,AADC,MACiB,GAAgB,EAAC,CAAC,EADrB,EAAE,CAJhB,AAKgB,EADG,OAJV,AAAG,CAAK,EAEb,OAAO,GAAG,aAAa,CAAC,IAAU,GAAW,EAAE,CAD7B,AAC8B,EAAU,IAAI,GAAK,GAAG,MAAM,CAAC,EAAU,KAAK,CAChG,EAQA,CADO,GA0BR,KAAuB,GAAqB,EAAC,CAAC,EAzB1B,EADM,EACF,CAAG,EAC1B,EAwBqB,CAxBF,MAAM,CAAG,EAC5B,GAAmB,QAAQ,CAAG,EAC9B,GAAmB,WAAW,CAAG,EACjC,GAAmB,KAAK,CAAG,EAC3B,GAAmB,QAAQ,CAAG,EAC9B,GAAmB,KAAK,CAAG,EAC3B,GAAmB,SAAS,CAAG,EAC/B,GAAmB,MAAM,CAAG,EAC5B,GAAmB,QAAQ,CAAG,GAC9B,GAAmB,IAAI,CAAG,GAC1B,GAAmB,KAAK,CAAG,GAC3B,GAAmB,IAAI,CAAG,GAC1B,GAAmB,OAAO,CAAG,GAC7B,GAAmB,OAAO,CAAG,GAC7B,GAAmB,KAAK,CAAG,GAC3B,GAAmB,IAAI,CAAG,GAC1B,GAAmB,SAAS,CAAG,GAC/B,GAAmB,MAAM,CAAG,GAC5B,GAAmB,UAAU,CAAG,GAChC,GAAmB,QAAQ,CAAG,GAC9B,GAAmB,MAAM,CAAG,GAC5B,GAAmB,KAAK,CAAG,GAC3B,GAAmB,QAAQ,CAAG,GAC9B,GAAmB,aAAa,CAAG,GAWnC,CAJO,GAgBR,KAAqB,GAAmB,EAAC,CAAC,EAZxB,AAJM,OAgBJ,EAZO,CAAG,EAW7B,GAAiB,OAAO,CAAG,EAa3B,CACD,KAAsB,GAAoB,EAAC,CAAC,EADzB,QACE,EADQ,CAAG,EAe/B,CAPO,GAgBR,KAAsB,GAAoB,EAAC,CAAC,EATzB,CAPM,KAOA,CAHxB,CAYoB,CATO,OAHlB,AAAO,CAAO,CAAE,CAAM,CAAE,CAAO,EACpC,MAAO,SAAE,SAAS,UAAQ,CAAQ,CACtC,EASA,GAAkB,EAAE,CAJpB,EAIuB,OAJd,AAAG,CAAK,EAEb,OAAO,GAAa,GAAG,MAAM,CAAC,EAAU,OAAO,GAAK,GAAM,EAAE,CAD1C,AAC2C,EAAU,MAAM,GAAK,GAAM,EAAE,CAAC,EAAU,OAAO,CAChH,EAkBA,CARO,GAmBR,KAAmB,GAAiB,EAAC,CAnBf,AAmBgB,EAXtB,IAAI,CAWF,AAXK,EAUtB,GAAe,iBAAiB,CAAG,EASnC,AACD,MAA+B,GAA6B,EAAC,CAAC,EADlC,EAAE,CAL7B,EAKgC,OALvB,AAAG,CAAK,EAEb,CAIyB,MAJlB,IAAc,GAAG,MAAJ,AAAU,CAAC,EAAU,MAAM,QAA0B,IAArB,EAAU,MAAM,AAAK,CAAS,GAC7E,EAAD,CAAI,MAAM,CAAC,AAFG,EAEO,WAAW,QAA+B,IAA1B,EAAU,WAAW,AAAK,CAAS,AAChF,EAgBA,CACD,KAAmB,GAAiB,EAAC,CAAC,EADtB,KACE,CADI,CAHrB,EAGwB,OAHf,AAAO,CAAK,EACjB,MAAO,OAAE,CAAM,CACnB,EAkBA,CACD,KAAmB,GAAiB,EAAC,CAAC,EADtB,KACE,CADI,CAHrB,EAGwB,OAHf,AAAO,CAAK,CAAE,CAAY,EAC/B,MAAO,CAAE,MAAO,GAAgB,EAAE,CAAE,EAAZ,WAA0B,CAAC,CAAC,CAAa,CACrE,EAaA,CATO,GAkBR,IAAiB,IAAe,CAlBZ,CAkBa,CAAC,EATpB,GASE,UATW,CAH1B,EAG6B,OAHpB,AAAc,CAAS,EAC5B,OAAO,EAAU,OAAO,CAAC,wBAAyB,OACtD,EASA,AAV+D,GAUlD,EAAE,CAJf,EAIkB,OAJN,AAAH,CAAQ,EAEb,OAAO,GAAG,MAAM,CAAC,IAAe,GAAG,aAAa,CAAC,IAAc,GAAG,MAAM,CAAC,AADvD,EACiE,QAAQ,GAAK,GAAG,MAAM,CAAC,CAR+C,CAQrC,KAAK,CAC7H,EAcA,CACD,KAAU,GAAQ,CAAT,CAAU,CAAC,EADb,EAAE,CANR,EAMW,OANF,AAAG,CAAK,EAEb,MAAO,CAAC,CAAC,GAAa,GAAG,aAAa,CADtB,AACuB,KAAe,GAAc,EAAE,CAAC,EAAU,CAA5B,OAAoC,GACrF,GAAa,EAAE,CAAC,EAAU,QAAQ,GAClC,GAAG,UAAU,CAAC,EAAU,QAAQ,CAAE,GAAa,GAAE,CAAC,KAAK,GAAiB,IAAhB,EAAM,KAAK,EAAkB,GAAM,EAAE,CAAC,EAAM,MAAK,CAAC,AAClH,EAkBA,CACD,IAAyB,IAAuB,EAAC,CAAC,EAD5B,MAAM,CAH3B,EAG8B,EACP,KAJd,AAAO,CAAK,CAAE,CAAa,EAChC,OAAO,EAAgB,OAAE,gBAAO,CAAc,EAAI,OAAE,CAAM,CAC9D,EAsBA,AACD,MAAyB,GAAuB,EAAC,CAAC,EAD5B,MAAM,CAb3B,EAa8B,CACP,MAdd,AAAO,CAAK,CAAE,CAAa,CAAE,GAAG,CAAU,EAC/C,IAAI,EAAS,OAAE,CAAM,EAUrB,OATI,GAAG,OAAO,CAAC,KACX,EAAO,SADoB,IACP,CAAG,CAAA,EAEvB,GAAG,OAAO,CAAC,GACX,EAAO,QADiB,EACP,CAAG,EAGpB,EAAO,UAAU,CAAG,EAAE,CAEnB,CACX,EAWA,CAJO,GAaR,KAA0B,GAAwB,EAAC,CAAC,EAT7B,IAAI,CAJE,AAIC,EAI7B,GAAsB,EAKE,EALE,CAAG,EAI7B,GAAsB,KAAK,CAAG,EAoB9B,CACD,KAAsB,GAAoB,EAAC,CAAC,EADzB,MAAM,CAPxB,CAQoB,CADO,OAPlB,AAAO,CAAK,CAAE,CAAI,EACvB,IAAI,EAAS,OAAE,CAAM,EAIrB,OAHI,GAAG,MAAM,CAAC,KACV,EADiB,AACV,IAAI,CAAG,CAAA,EAEX,CACX,EAQA,IA0BD,KAAe,GAAa,CAAC,CAAC,GA1BlB,CA0BE,GA1BE,CAAG,EAClB,GAAW,MAAM,CAAG,EACpB,GAAW,SAAS,CAAG,EACvB,GAAW,OAAO,CAAG,EACrB,GAAW,KAAK,CAAG,EACnB,GAAW,MAAM,CAAG,EACpB,GAAW,QAAQ,CAAG,EACtB,GAAW,KAAK,CAAG,EACnB,GAAW,WAAW,CAAG,EACzB,GAAW,IAAI,CAAG,GAClB,GAAW,SAAS,CAAG,GACvB,GAAW,QAAQ,CAAG,GACtB,GAAW,QAAQ,CAAG,GACtB,GAAW,QAAQ,CAAG,GACtB,GAAW,MAAM,CAAG,GACpB,GAAW,MAAM,CAAG,GACpB,GAAW,OAAO,CAAG,GACrB,GAAW,KAAK,CAAG,GACnB,GAAW,MAAM,CAAG,GACpB,GAAW,GAAG,CAAG,GACjB,GAAW,IAAI,CAAG,GAClB,GAAW,UAAU,CAAG,GACxB,GAAW,MAAM,CAAG,GACpB,GAAW,KAAK,CAAG,GACnB,GAAW,QAAQ,CAAG,GACtB,GAAW,aAAa,CAAG,GAY3B,AACD,MAAc,GAAY,EAAC,CAAC,CAAf,CADF,UAAU,CAAG,EAwBvB,CACD,IAAsB,IAAoB,EAAC,CAAC,EADzB,MAAM,CAXxB,CAYoB,CADO,OAXlB,AAAO,CAAI,CAAE,CAAI,CAAE,CAAK,CAAE,CAAG,CAAE,CAAa,EACjD,IAAI,EAAS,MACT,OACA,EACA,SAAU,KAAE,QAAK,CAAM,CAC3B,EAIA,OAHI,IACA,EAAO,SADQ,IACK,CAAG,CAAA,EAEpB,CACX,EAmBA,CACD,KAAoB,GAAkB,EAAC,CAAC,EADvB,MAAM,AACJ,CANlB,EAKyB,OALhB,AAAO,CAAI,CAAE,CAAI,CAAE,CAAG,CAAE,CAAK,EAClC,YAAiB,IAAV,EACD,MAAE,OAAM,EAAM,SAAU,KAAE,EAAK,OAAM,CAAE,EACvC,MAAE,OAAM,EAAM,SAAU,KAAE,CAAI,CAAE,CAC1C,EA4BA,IAeD,KAAmB,GAAiB,EAAC,CAAC,EAftB,KAeE,CAfI,CAbrB,EAawB,OAbf,AAAO,CAAI,CAAE,CAAM,CAAE,CAAI,CAAE,CAAK,CAAE,CAAc,CAAE,CAAQ,EAC/D,IAAI,EAAS,MACT,SACA,OACA,QACA,iBACA,CACJ,EAIA,YAHiB,IAAb,IACA,EAAO,CADiB,OACT,CAAG,CAAA,EAEf,CACX,EAeA,GAAe,EAAE,CAVjB,EAUoB,OAVX,AAAG,CAAK,EAEb,OAAO,GACH,GAAG,MAAM,CAAC,EAAU,IAAI,GAAK,GAAG,MAAM,CAAC,EAAU,IAAI,GACrD,GAAM,EAAE,CAAC,EAAU,KAAK,GAAK,GAAM,EAAE,CAAC,EAAU,cAAc,KAC9D,IAAsB,IAArB,EAAU,MAAM,EAAkB,GAAG,MAAM,CAAC,EAAU,OAAM,CAAC,GAC7D,EAAD,GAA0B,MAAf,UAAU,EAAkB,GAAG,OAAO,CAAC,EAAU,WAAU,CAAC,KACvE,GAAwB,IAAvB,AANW,EAMD,QAAQ,EAAkB,MAAM,OAAO,CAAC,EAAU,SAAQ,CAAC,EACrE,CAAmB,EAApB,SAAW,IAAI,EAAkB,MAAM,OAAO,CAAC,EAAU,IAAI,CAAC,CACtE,EAWA,IAgED,KAAmB,GAAiB,EAAC,CAAC,EAhEtB,KAgEE,AAhEG,CAAG,GAIvB,GAAe,QAAQ,CAAG,WAI1B,GAAe,QAAQ,CAAG,WAY1B,GAAe,eAAe,CAAG,mBAWjC,GAAe,cAAc,CAAG,kBAahC,GAAe,eAAe,CAAG,mBAMjC,GAAe,MAAM,CAAG,SAIxB,GAAe,qBAAqB,CAAG,yBASvC,GAAe,YAAY,CAAG,gBAY9B,IAQD,KAA0B,GAAwB,CAAC,CAAC,GAR7B,OAAO,CAAG,EAOhC,EACwB,CADF,SAAS,CAAG,EAqBlC,CAdO,GAyBR,IAAsB,IAAoB,EAAC,CAAC,EAXzB,CAdM,KAcA,CAVxB,CAqBoB,CAXO,OAVlB,AAAO,CAAW,CAAE,CAAI,CAAE,CAAW,EAC1C,IAAI,EAAS,aAAE,CAAY,EAO3B,aANI,IACA,EAAO,GADE,CACE,CAAG,CAAA,QAEd,EAHsB,EAItB,EAAO,KAJwB,KAGf,CAHqB,AAInB,CAAG,CAAA,EAElB,CACX,EAWA,GAAkB,EAAE,AAfiB,CASrC,EAMuB,OANX,AAAH,CAAQ,EAEb,GAXiD,IAW1C,EAXgD,CAW7C,OAAO,CAAC,IAAc,GAAG,UAAU,CAD7B,AAC8B,EAAU,WAAW,CAAE,GAAW,EAAE,KAC3E,IAAoB,IAAnB,EAAU,IAAI,EAAkB,GAAG,UAAU,CAAC,EAAU,IAAI,CAAE,GAAG,MAAM,CAAC,KACzE,IAA2B,IAA1B,EAAU,WAAW,EAAkB,EAAU,WAAW,GAAK,GAAsB,OAAO,EAAI,EAAU,WAAW,GAAK,GAAsB,SAAA,AAAS,CACvK,EAuBA,CAnBO,GA+BR,KAAe,EA/BG,CA+BU,CAAC,CAAC,GAZlB,CAYE,KAZI,CAlBjB,EAkBoB,OAlBX,AAAO,CAAK,CAAE,CAAmB,CAAE,CAAI,EAC5C,IAAI,EAAS,OAAE,CAAM,EACjB,GAAY,EAchB,MAbI,AAA+B,UAAU,OAAlC,GACP,GAAY,EACZ,EAAO,IAAI,CAAG,GAET,GAAQ,EAAE,CAAC,GAChB,EAAO,OAAO,CAAG,EAGjB,EAAO,IAAI,CAAG,AAJwB,EAMtC,QAAsB,IAAT,IACb,EAAO,CAD0B,GACtB,CAAG,CAAA,EAEX,CACX,EAYA,GAAW,EAAE,CAVb,EAUgB,OAVP,AAAG,CAAK,EAEb,OAAO,GAAa,GAAG,MAAM,CAAC,EAAU,KAAK,KACzC,IAA2B,IAA1B,EAAU,WAAW,EAAkB,GAAG,UAAU,CAAC,EAAU,WAAW,CAAE,GAAW,GAAE,CAAC,KAC3F,GAAoB,IAAnB,EAAU,IAAI,EAAkB,GAAG,MAAM,CAAC,EAAU,KAAI,CAAC,KAC1D,GAAoB,IAAnB,EAAU,IAAI,OAAwC,IAAtB,EAAU,OAAO,AAAK,CAAS,KAChE,GAAuB,IAAtB,EAAU,OAAO,EAAkB,GAAQ,EAAE,CAAC,EAAU,QAAO,CAAC,KACjE,GAA2B,IAA1B,EAAU,WAAW,EAAkB,GAAG,OAAO,CAAC,EAAU,YAAW,CAAC,KACzE,GAAoB,IAAnB,EAAU,IAAI,EAAkB,GAAc,EAAE,CAAC,AAPtC,EAOgD,KAAI,CACxE,AADyE,EAoBzE,CAXO,GAoBR,KApBgB,AAoBH,GAAW,CAAC,CAAC,EAAd,CATF,MAAM,CAPf,EAOkB,OAPT,AAAO,CAAK,CAAE,CAAI,EACvB,IAAI,EAAS,CAAE,OAAM,EAIrB,OAHI,GAAG,OAAO,CAAC,KACX,EADkB,AACX,IAAI,CAAG,CAAA,EAEX,CACX,EASA,GAAS,EAAE,CAJX,EAIc,OAJL,AAAG,CAAK,EAEb,OAAO,GAAG,OAAO,CAAC,IAAc,GAAM,EAAE,CAAC,EAAU,KAAK,IAAM,CAAD,EAAI,SAAS,CAAC,EAAU,OAAO,GAAK,GAAQ,EAAE,CAD3F,AAC4F,EAAU,QAAO,CACjI,AADkI,EAgBlI,CAPO,GAgBR,IAAsB,IAAoB,EAAC,CAAC,EATzB,CAPM,KAOA,CAHxB,CAYoB,CATO,OAHlB,AAAO,CAAO,CAAE,CAAY,EACjC,MAAO,CAAE,uBAAS,CAAa,CACnC,EASA,GAAkB,EAAE,CAJpB,EAIuB,OAJX,AAAH,CAAQ,EAEb,OAAO,GAAG,OAAO,CAAC,IAAc,GAAG,QAAQ,CAAC,EAAU,OAAO,GAAK,GAAG,OAAO,CAAC,AAD7D,EACuE,YAAY,CACvG,EAeA,CAPO,GAgBR,KAAiB,GAAe,CAhBZ,AAgBa,CAAC,GATpB,GASE,GATI,CAHnB,EAGsB,OAHN,AAAP,CAAY,CAAE,CAAM,CAAE,CAAI,EAC/B,MAAO,OAAE,SAAO,OAAQ,CAAK,CACjC,EASA,GAAa,EAAE,CAJf,EAIkB,OAJT,AAAG,CAAK,EAEb,OAAO,GAAG,OAAO,CAAC,IAAc,GAAM,EAAE,CAAC,EAAU,KAAK,IAAM,CAAD,EAAI,SAAS,CAAC,AAD3D,EACqE,MAAM,GAAK,GAAG,MAAM,CAAC,EAAU,OAAM,CAAC,AAC/H,EAiBA,IAMD,KAAmB,GAAiB,CAAC,CAAC,GANtB,KAME,CANI,CAHrB,EAGwB,OAHf,AAAO,CAAK,CAAE,CAAM,EACzB,MAAO,OAAE,SAAO,CAAO,CAC3B,EAMA,GAAe,EAAE,CAJjB,EAIoB,OAJX,AAAG,CAAK,EAEb,OAAO,GAAG,aAAa,CAAC,IAAc,GAAM,EAAE,CAAC,EAAU,KAAK,KAAK,IAAsB,IAArB,EAAU,MAAM,EAAkB,GAAe,EAAE,CAAC,AADxG,EACkH,OAAM,CAAC,AAC7I,EAYA,CADO,GA+BR,KAAuB,GAAqB,EAAC,CAAC,EA9B1B,CAAD,CADO,OACM,AA8BV,CA9Ba,YAKlC,GAAmB,IAAO,CAAG,OAC7B,GADkB,AACC,KAAQ,CAAG,QAC9B,CADkB,EACC,IAAO,CAAG,OAC7B,GAAmB,AADD,SACa,CAAG,KAAhB,OAClB,GAAmB,MAAS,CAAG,QAAb,CAClB,GAAmB,aAAgB,CAAG,CAApB,eAClB,GAAmB,SAAY,CAAG,KAAhB,OAClB,GAAmB,QAAW,CAAG,MAAf,KAClB,GAAmB,QAAW,CAAG,MAAf,KAClB,GAAmB,UAAa,CAAG,IAAjB,SAClB,GAAmB,KAAQ,CAAG,QAC9B,CADkB,EACC,QAAW,CAAG,MAAf,KAClB,GAAmB,MAAS,CAAG,QAAb,CAClB,GAAmB,KAAQ,CAAG,QAC9B,CADkB,EACC,OAAU,CAAG,OAAd,GAClB,GAAmB,QAAW,CAAG,MAAf,KAClB,GAAmB,OAAU,CAAG,OAAd,GAClB,GAAmB,MAAS,CAAG,QAAb,CAClB,GAAmB,MAAS,CAAG,QAAb,CAClB,GAAmB,MAAS,CAAG,QAAb,CAClB,GAAmB,QAAW,CAAG,MAAf,KAIlB,GAAmB,SAAY,CAAG,KAAhB,OAWlB,CADO,GAWR,KAA2B,GAAyB,EAAC,CAAC,EAV9B,KAAD,CADO,KACQ,CAAG,CAUf,aATzB,GAAuB,UAAa,CAAG,QAAjB,KACtB,GAAuB,QAAW,CAAG,UAAf,CACtB,GAAuB,MAAS,CAAG,SACnC,GAAuB,AADD,UACc,CAAG,QAAjB,KACtB,GAAuB,QAAW,CAAG,UAAf,CACtB,GAAuB,KAAQ,CAAG,QAClC,GAAuB,EADD,UACgB,CAAG,MAAnB,SACtB,GAAuB,aAAgB,CAAG,KAApB,WACtB,GAAuB,cAAiB,CAAG,IAArB,aAYtB,CACD,KAAmB,GAAiB,CAAC,EAAC,EADtB,EAAE,CALjB,EAKoB,AACH,OANR,AAAG,CAAK,EAEb,OAAO,GAAG,aAAa,CAAC,UAAsC,IAAxB,AAAC,EAAU,QAAQ,EAAgD,UAA9B,OAAO,EAAU,QAAa,AAAL,CAAa,EAC7G,MAAM,OAAO,CAAC,EAAU,IAAI,IAAgC,CAA3B,GAAC,EAAU,IAAI,CAAC,MAAM,EAAuC,UAA7B,OAFnD,AAE0D,EAAU,IAAI,CAAC,EAAE,AAAK,CACtG,AAD8G,EAiB9G,IAMD,KAAoB,GAAkB,EAAC,CAAC,EANvB,MAAM,AAMJ,CATlB,EAGyB,OAHhB,AAAO,CAAK,CAAE,CAAI,EACvB,MAAO,OAAE,OAAO,CAAK,CACzB,EAMA,GAAgB,EAAE,CAJlB,EAIqB,OAJZ,AAAG,CAAK,EAEb,OAAO,SAAiD,GAAM,EAAzC,AAA2C,CAAC,EAAU,KAAK,GAAK,EAAnD,CAAsD,MAAM,CAD5E,AAC6E,EAAU,IAAI,AAA7D,CACpD,EAgBA,IAOD,KAA8B,GAA4B,CAAC,CAAC,GAPjC,MAAM,CAHhC,EAGmC,OAH1B,AAAO,AAUY,CAVP,CAAE,CAAY,CAAE,CAAmB,EACpD,MAAO,OAAE,eAAO,sBAAc,CAAoB,CACtD,EAOA,GAA0B,EAAE,CAL5B,EAK+B,OALnB,AAAH,CAAQ,EAEb,OAAO,SAAiD,GAAM,EAAzC,AAA2C,CAAC,EAAU,KAAK,GAAK,EAAnD,CAAsD,OAAO,CAAC,EAAU,GAA1D,gBAA6E,IACrH,CAAD,EAAI,MAAM,CAAC,AAFA,EAEU,YAAY,QAAgC,IAA3B,EAAU,YAAY,AAAK,CAAS,AACrF,EAgBA,CAPO,GAcR,KAAqC,GAAmC,CAAC,CAAC,GAPxC,MAAM,CAHvC,EAG0C,OAPH,AAI9B,AAAO,CAAK,CAAE,CAAU,EAC7B,EAS+B,IATxB,OAAE,EAAO,YAAW,CAC/B,EAOA,GAAiC,EAAE,CALnC,EAKsC,OAL7B,AAAG,CAAK,EAEb,OAAO,SAAiD,GAAM,EAAzC,AAA2C,CAAC,EAAU,KAAK,IACxE,CAAD,AAD2B,EACvB,MAAM,CAAC,EAAU,GADoB,OACV,QAA8B,IAFlD,AAEyB,EAAU,UAAU,AAAK,CAAS,AACjF,EAiBA,CAPO,GAgBR,KAAuB,GAAqB,EAAC,CAAC,EAT1B,EAPM,IAOA,CAHzB,EAG4B,AASP,OAZZ,AAAO,CAAO,CAAE,CAAe,EACpC,MAAO,SAAE,kBAAS,CAAgB,CACtC,EASA,GAAmB,EAAE,CAJrB,EAIwB,OAJf,AAAG,CAAK,EAEb,OAAO,GAAG,OAAO,CAAC,AADA,IACc,GAAM,EAAE,CAAC,EAAM,eAAe,CAClE,EAaA,CAJO,GAaR,KAAkB,GAAgB,EAbb,AAac,CAAC,EATrB,IASE,AATE,CAAG,EAIrB,GAAc,SAAS,CAAG,EAI1B,GAAc,EAAE,CAHhB,EAGmB,OAHV,AAAG,CAAK,EACb,OAAiB,IAAV,GAAyB,IAAV,CAC1B,EAQA,CAJO,GAaR,KAAuB,GAAqB,EAAC,CAAC,EAT1B,EAJM,IAIA,CAHzB,EAG4B,AASP,OAZL,AAAP,CAAY,EACjB,MAAO,OAAE,CAAM,CACnB,EASA,GAAmB,EAAE,CAPrB,EAOwB,OAPZ,AAAH,CAAQ,EAEb,OAAO,GAAG,aAAa,CAAC,UACM,IAAtB,AAAD,EAAW,OAAO,EAAkB,GAAG,MAAM,CAAC,EAAU,OAAO,GAAK,GAAc,EAAE,CAFzE,AAE0E,EAAU,QAAO,CAAC,KACvG,GAAwB,IAAvB,EAAU,QAAQ,EAAkB,GAAS,EAAE,CAAC,EAAU,SAAQ,CAAC,KACpE,GAAuB,IAAtB,EAAU,OAAO,EAAkB,GAAQ,EAAE,CAAC,EAAU,QAAO,CAAC,AAC5E,EAYA,IAYD,KAAc,GAAY,CAAC,CAAC,GAZjB,AAYE,MAZI,CAPhB,EAOmB,OAPV,AAAO,CAAQ,CAAE,CAAK,CAAE,CAAI,EACjC,IAAM,EAAS,UAAE,QAAU,CAAM,EAIjC,YAHa,IAAT,IACA,EAAO,CADa,GACT,CAAG,CAAA,EAEX,CACX,EAYA,GAAU,EAAE,CAVZ,EAUe,OAVN,AAAG,CAAK,EAEb,OAAO,GAAG,aAAa,CAAC,IAAc,GAAS,EAAE,CAAC,EAAU,QAAQ,IAC5D,CAAD,EAAI,MAAM,CAAC,EAAU,KAAK,GAAK,GAAG,UAAU,CAAC,EAAU,KAAK,CAAE,GAAmB,GAAE,CAAC,KACpF,GAAoB,IAAnB,EAAU,IAAI,EAAkB,GAAc,EAAE,CAAC,EAAU,KAAI,CAAC,OACxC,IAAxB,EAAU,SAAS,EAAmB,GAAG,UAAU,CAAC,EAAU,SAAS,CAAE,GAAS,EAAE,KACrF,IAAuB,IAAtB,EAAU,OAAO,EAAkB,GAAG,MAAM,CAAC,EAAU,OAAO,GAAK,GAAc,EAAE,CAAC,EAAU,QAAO,CAAC,KACvG,GAA2B,IAA1B,EAAU,WAAW,EAAkB,GAAG,OAAO,CAAC,EAAU,YAAW,CAAC,GAC7C,EAA5B,OAAC,EAAU,YAAY,EAAkB,GAAG,OAAO,CAAC,AAPzC,EAOmD,aAAY,CAAC,AACtF,EAQA,CACD,IAAgB,IAAc,EAAC,CAAC,EADnB,EACE,WADW,CAHzB,EAG4B,OAHnB,AAAc,CAAK,EACxB,MAAO,CAAE,KAAM,gBAAW,CAAM,CACpC,EAQA,CACD,KAAyB,GAAuB,EAAC,CAAC,EAD5B,MAAM,CAH3B,EAG8B,EACP,KAJd,AAAO,CAAU,CAAE,CAAU,CAAE,CAAK,CAAE,CAAO,EAClD,MAAO,YAAE,aAAY,QAAY,UAAO,CAAQ,CACpD,EAQA,CACD,KAAyB,GAAuB,EAAC,CAAC,EAD5B,MAAM,CAH3B,EAG8B,EACP,KAJd,AAAO,CAAK,EACjB,MAAO,OAAE,CAAM,CACnB,EAcA,CAJO,GASR,KAAgC,GAA8B,EAAC,CAAC,EALnC,OAAO,CAAG,EAItC,CARkC,EAQN,KACE,IADO,CAAG,EAOxC,CACD,KAA2B,GAAyB,EAAC,CAAC,EAD9B,MAAM,CAH7B,EAGgC,IACP,GAJhB,AAAO,CAAK,CAAE,CAAI,EACvB,MAAO,CAAE,aAAO,CAAK,CACzB,EAQA,CACD,KAA4B,GAA0B,EAAC,CAAC,EAD/B,MAAM,CAH9B,EAGiC,KACP,EAJjB,AAAO,CAAW,CAAE,CAAsB,EAC/C,MAAO,aAAE,yBAAa,CAAuB,CACjD,EASA,AACD,KAAoB,IAAkB,CAAC,EAAC,EADvB,EAAE,CAJlB,EAIqB,AACH,OALT,AAAG,CAAK,EAEb,OAAO,GAAG,aAAa,CAAC,IAAc,GAAI,EAAE,CAD1B,AAC2B,EAAU,GAAG,GAAK,GAAG,MAAM,CAAC,EAAU,IAAI,CAC3F,EAmBA,IAmED,KAAiB,GAAe,CAAC,CAAC,GAnEpB,GAmEE,GAnEI,CAHnB,EAGsB,OAHb,AAAO,CAAG,CAAE,CAAU,CAAE,CAAO,CAAE,CAAO,EAC7C,OAAO,IAAI,GAAiB,EAAK,EAAY,EAAS,EAC1D,EAUA,GAAa,EAAE,CALf,EAKkB,OALT,AAAG,CAAK,EAEb,SAAO,GAAG,OAAO,CAAC,IAAc,GAAG,MAAM,CAAC,EAAU,GAAG,IAAM,CAAD,EAAI,SAAS,CAAC,EAAU,UAAU,GAAK,GAAG,MAAM,CAAC,EAAU,WAAU,CAAC,EAAK,GAAG,QAAQ,CAAC,EAAU,SAAS,GAC/J,GAAG,IAAI,CAAC,EAAU,OAAO,GAAK,GAAG,IAAI,CAAC,AAF7B,EAEuC,UAAU,GAAK,GAAG,IAAI,CAAC,EAAU,SAAQ,CACpG,EA0BA,CA3BwG,EA2B3F,KA3BkG,KA2BxF,CAxBvB,EAwB0B,OAxBjB,AAAW,CAAQ,CAAE,CAAK,EAC/B,IAAI,EAAO,EAAS,OAAO,GACvB,EAuBR,AAvBsB,SAuBb,EAAU,CAAI,CAAE,CAAO,EAC5B,GAAI,EAAK,MAAM,EAAI,EAEf,CAFkB,MAEX,EAEX,IAAM,EAAK,EAAK,MAAM,CAAG,EAAK,EACxB,EAAO,EAAK,KAAK,CAAC,EAAG,GACrB,EAAQ,EAAK,KAAK,CAAC,GACzB,EAAU,EAAM,GAChB,EAAU,EAAO,GACjB,IAAI,EAAU,EACV,EAAW,EACX,EAAI,EACR,KAAO,EAAU,EAAK,MAAM,EAAI,EAAW,EAAM,MAAM,CAAE,CAEjD,AAAO,GADD,AACI,EADI,CAAI,CAAC,EAAQ,CAAE,CAAK,CAAC,EAAS,EAG5C,CAAI,CAAC,IAAI,CAAG,CAAI,CAAC,IAAU,CAI3B,CAAI,CAAC,IAAI,CAAG,CAAK,CAAC,IAAW,CAGrC,KAAO,EAAU,EAAK,MAAM,CAAE,CAC1B,CAAI,CAAC,IAAI,CAAG,CAAI,CAAC,IAAU,CAE/B,KAAO,EAAW,EAAM,MAAM,CAAE,CAC5B,CAAI,CAAC,IAAI,CAAG,CAAK,CAAC,IAAW,CAEjC,OAAO,CACX,EAtDgC,EAAO,CAAC,EAAG,KACnC,IAAI,EAAO,EAAE,KAAK,CAAC,KAAK,CAAC,IAAI,CAAG,EAAE,KAAK,CAAC,KAAK,CAAC,IAAI,QACrC,AAAb,GAAgB,CAAZ,EACO,EAAE,KAAK,CAAC,KAAK,CAAC,SAAS,CAAG,EAAE,KAAK,CAAC,KAAK,CAAC,SAAS,CAErD,CACX,GACI,EAAqB,EAAK,MAAM,CACpC,IAAK,IAAI,EAAI,EAAY,MAAM,CAAG,EAAG,GAAK,EAAG,IAAK,CAC9C,IAAI,EAAI,CAAW,CAAC,EAAE,CAClB,EAAc,EAAS,QAAQ,CAAC,EAAE,KAAK,CAAC,KAAK,EAC7C,EAAY,EAAS,QAAQ,CAAC,EAAE,KAAK,CAAC,GAAG,EAC7C,GAAI,GAAa,EACb,EAAO,EAAK,SAAS,CAAC,EAAG,EADQ,CACO,EAAE,OAAO,CAAG,EAAK,SAAS,CAAC,EAAW,EAAK,MAAM,OAGzF,MAAM,AAAI,MAAM,oBAEpB,EAAqB,CACzB,CACA,OAAO,CACX,CAsCJ,OAAM,GACF,YAAY,CAAG,CAAE,CAAU,CAAE,CAAO,CAAE,CAAO,CAAE,CAC3C,IAAI,CAAC,IAAI,CAAG,EACZ,IAAI,CAAC,WAAW,CAAG,EACnB,IAAI,CAAC,QAAQ,CAAG,EAChB,IAAI,CAAC,QAAQ,CAAG,EAChB,IAAI,CAAC,YAAY,MAAG,CACxB,CACA,IAAI,KAAM,CACN,OAAO,IAAI,CAAC,IAAI,AACpB,CACA,IAAI,YAAa,CACb,OAAO,IAAI,CAAC,WAAW,AAC3B,CACA,IAAI,SAAU,CACV,OAAO,IAAI,CAAC,QAAQ,AACxB,CACA,QAAQ,CAAK,CAAE,CACX,GAAI,EAAO,CACP,IAAI,EAAQ,IAAI,CAAC,QAAQ,CAAC,EAAM,KAAK,EACjC,EAAM,IAAI,CAAC,QAAQ,CAAC,EAAM,GAAG,EACjC,OAAO,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAO,EAC1C,CACA,OAAO,IAAI,CAAC,QAAQ,AACxB,CACA,OAAO,CAAK,CAAE,CAAO,CAAE,CACnB,IAAI,CAAC,QAAQ,CAAG,EAAM,IAAI,CAC1B,IAAI,CAAC,QAAQ,CAAG,EAChB,IAAI,CAAC,YAAY,MAAG,CACxB,CACA,gBAAiB,CACb,GAA0B,SAAtB,IAAI,CAAC,YAAY,CAAgB,CACjC,IAAI,EAAc,EAAE,CAChB,EAAO,IAAI,CAAC,QAAQ,CACpB,GAAc,EAClB,IAAK,IAAI,EAAI,EAAG,EAAI,EAAK,MAAM,CAAE,IAAK,CAC9B,IACA,EAAY,IAAI,CAAC,EADJ,CAEb,GAAc,GAElB,IAAI,EAAK,EAAK,MAAM,CAAC,GACrB,EAAsB,OAAP,GAAsB,OAAP,EACnB,OAAP,GAAe,EAAI,EAAI,EAAK,MAAM,EAA2B,MAAM,CAA7B,EAAK,MAAM,CAAC,EAAI,IACtD,GAER,CACI,GAAe,EAAK,MAAM,CAAG,GAC7B,AADgC,EACpB,IAAI,CAAC,EAAK,MAAM,EAEhC,IAAI,CAAC,YAAY,CAAG,CACxB,CACA,OAAO,IAAI,CAAC,YAAY,AAC5B,CACA,WAAW,CAAM,CAAE,CACf,EAAS,KAAK,GAAG,CAAC,KAAK,GAAG,CAAC,EAAQ,IAAI,CAAC,QAAQ,CAAC,MAAM,EAAG,GAC1D,IAAI,EAAc,IAAI,CAAC,cAAc,GACjC,EAAM,EAAG,EAAO,EAAY,MAAM,CACtC,GAAa,GAAG,CAAZ,EACA,OAAO,GAAS,MAAM,CAAC,EAAG,GAE9B,KAAO,EAAM,GAAM,CACf,IAAI,EAAM,KAAK,KAAK,CAAC,CAAC,EAAM,CAAA,CAAI,CAAI,GAChC,CAAW,CAAC,EAAI,CAAG,EACnB,EAAO,EAGP,EAJ2B,AAIrB,EAAM,CAEpB,CAGA,IAAI,EAAO,EAAM,EACjB,OAAO,GAAS,MAAM,CAAC,EAAM,EAAS,CAAW,CAAC,EAAK,CAC3D,CACA,SAAS,CAAQ,CAAE,CACf,IAAI,EAAc,IAAI,CAAC,cAAc,GACrC,GAAI,EAAS,IAAI,EAAI,EAAY,MAAM,CACnC,CADqC,MAC9B,IAAI,CAAC,QAAQ,CAAC,MAAM,CAE1B,GAAI,EAAS,IAAI,CAAG,EACrB,CADwB,MACjB,EAEX,IAAI,EAAa,CAAW,CAAC,EAAS,IAAI,CAAC,CACvC,EAAkB,EAAS,IAAI,CAAG,EAAI,EAAY,MAAM,CAAI,CAAW,CAAC,EAAS,IAAI,CAAG,EAAE,CAAG,IAAI,CAAC,QAAQ,CAAC,MAAM,CACrH,OAAO,KAAK,GAAG,CAAC,KAAK,GAAG,CAAC,EAAa,EAAS,SAAS,CAAE,GAAiB,EAC/E,CACA,IAAI,WAAY,CACZ,OAAO,IAAI,CAAC,cAAc,GAAG,MAAM,AACvC,CACJ,CAEW,EAAE,CAiDV,KAAO,CAAD,EAAM,CAAC,CAAC,EAhDP,EAAW,OAAO,SAAS,CAAC,QAAQ,CAI1C,GAAG,OAAO,CAHV,EAGa,OAHJ,AAAQ,CAAK,EAClB,OAAO,KAAiB,IAAV,CAClB,EAKA,GAAG,SAAS,CAHZ,EAGe,OAHN,AAAU,CAAK,EACpB,OAAO,KAAiB,IAAV,CAClB,EAKA,GAAG,OAAO,CAHV,EAGa,OAHI,AAAR,CAAa,EAClB,OAAiB,IAAV,IAA4B,IAAV,CAC7B,EAKA,GAAG,MAAM,CAHT,EAGY,OAHH,AAAO,CAAK,EACjB,MAAgC,oBAAzB,EAAS,IAAI,CAAC,EACzB,EAKA,GAAG,MAAM,CAHT,EAGY,OAHH,AAAO,CAAK,EACjB,MAAgC,oBAAzB,EAAS,IAAI,CAAC,EACzB,EAKA,GAAG,WAAW,CAHd,EAGiB,OAHI,AAAZ,CAAiB,CAAE,CAAG,CAAE,CAAG,EAChC,MAAgC,oBAAzB,EAAS,IAAI,CAAC,IAAgC,GAAO,GAAS,GAAS,CAClF,EAKA,GAAG,OAAO,CAHV,EAGa,OAHJ,AAAQ,CAAK,EAClB,MAAgC,oBAAzB,EAAS,IAAI,CAAC,IAAgC,CAAC,YAAc,GAAS,GAAS,UAC1F,EAKA,GAAG,QAAQ,CAHX,EAGc,OAHL,AAAS,CAAK,EACnB,MAAgC,oBAAzB,EAAS,IAAI,CAAC,IAAgC,GAAK,GAAS,GAAS,UAChF,EAKA,GAAG,IAAI,CAHP,EAGU,OAHD,AAAK,CAAK,EACf,MAAgC,sBAAzB,EAAS,IAAI,CAAC,EACzB,EAQA,GAAG,aAAa,CANhB,EAMmB,OANI,AAAd,CAAmB,EAIxB,OAAiB,OAAV,GAAmC,UAAjB,OAAO,CACpC,EAKA,GAAG,UAAU,CAHb,EAGgB,OAHP,AAAW,CAAK,CAAE,CAAK,EAC5B,OAAO,MAAM,OAAO,CAAC,IAAU,EAAM,KAAK,CAAC,EAC/C,0HgExpEwD,IAAI,CAAC,QAAQ,CAAC,I1PoChD,CAAA,qT0PhBiD,CAAC,MAAA,CAAA,EAAA,GAAA,EAAmC,CeqEC,QfrEQ,CAAE,CAAA,0KAY7E,4DAQI,EAAA,WAAA,CAAmB,EAAM,KAAK,CAAA,MAAO,CAAE,EAAa,GAAM,EAAD,AAAS,CAAR,QAAiB,EAAE,IAAI,CAAC,CAAC,+JAczE,CAAA,qOAwBvB,GAAA,4BAGX,CAAC,CnBwE6C,AlEvCJ,KAAA,IqFjC9B,GAAG,CAAC,GvC6DC,oGuClCtC,CUiPC,CO3NC,AEpCA,EAAA,QAAA,sCnBmB+C,QAAQ,CAAC,CAAC,gBAAnC,IAAA,CAAA,QAAA,EAAA,KAAA,EAAA,EAAe,KAAA,AAAK,CAAA,CAAgB,IAAI,CAAC,QAAQ,CAAC,AAAE,CAAD,MAAC,EAAA,IAAI,CAAC,SAAA,AAAS,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,IAAS,CAAC,EAAV,KAAA,+KAiBlD,IAAI,CAAC,MAAA,CAAQ,EjB6FE,CAAC,CiB7FC,CAAC,GAAG,CAAC,CAAC,EnH6DJ,CAAC,CkGgCO,AlGhCN,6HmH/CvB,8JAwB7B,OAAA,CAAA,uNAiBM,CAAA,kBAAA,AAAmB,C1P+CD,AyKWI,CAAA,KAAA,EAAA,EiF1DD,MAAA,AAAM,EAAA,EAAA,0FAQ3B,CAAA,iBAAA,AAAkB,EAAA,KAAA,EAAA,EAAE,GAAA,AAAG,EAAA,EAAA,EAAA,oFAcrB,MAAA,GAAgB,MAAA,CAAA,EAAA,gBAAkC,CAAA,EAAA,EAAM,UAPxC,qBAAW,wBAER,CAAE,CqBxBC,MrByBvB,CAAA,WAAA,CAAA,CAAiB,E7OsJE,IAAA,EAAA,KAAA,C6OtJuB,GAAG,CAAE,EAAU,GAAG,CAAA,IAAA,CAAQ,EAAW,C1DqDR,I0DrDa,CAAC,IAAI,CAAC,AAAE,CAAD,CAAY,KAAK,CAAC,AAAE,CAAD,CAAR,AAAmB,GAAG,CAAE,CAAC,EAAP,yEASlG,cACX,MACR,oFAO4B,CAAC,CAAA,IAAA,YACrB,OAAA,CAAA,EAAU,OAClB,MAAA,6BAII,CAAA,IAAA,CAAA,OAAA,CAAc,MAAM,CAAG,EAAA,gDAS1C,CmB9BC,AhQgLJ,GAAA,CAAA,MAAA,C6OlJiB,wBACQ,G7OmJD,CAAA,C6OnJO,CxOkFL,EpBgCM,SAAA,mC4P9Gd,CAAA,uFASH,CAAA,CAAA,CAAA,CAAA,GAAA,CAAA,CAAA,uBACG,CAAA,uBACsB,8BAIlB,MAAO,OACW,C1DsDlB,AzDgCJ,AkIkWI,IAAA,CAAA,MfxbgC,CAAC,AjF8D/B,CiFzDvB,MAAA,WAAA,sDAI2C,IAAI,CAAA,GAAI,CAAC,CtCKC,AsCLA,kEAH1C,CAAA,sBAYI,CU6PoB,CV7PX,EAAE,CAAC,CU8Pf,EAAE,EAAE,mFLzauD,C3C9DqB,AzMpBtC,AmMrBE,CiDuGsB,0OAgB5D,IzFvFgB,EAAA,CyFuFT,YAAY,EAAA,CAC/B,CzFxFiD,eAAA,EyFyFjD,CJrF2C,oBAAA,EIqFZ,MAAM,CAAC,0BAA0B,GAClE,8FAWY,CAAA,CAAA,mGAeH,CAAA,QAAA,CAAA,GAAA,CAAA,gZAwCM,EAAA,MAAA,CAAA,cAAA,yDAKX,EAAA,IAAA,CAAA,eAAA,CAAA,kBAC0B,WAAW,CAAA,GAAgB,EAAA,IAAS,CAAC,A/BnGA,AgBVE,CAAA,IAAA,Ce6GK,S/BnGS,CAAC,CAAC,MuBJ7E,CAAA,CQuGqF,CAAC,EAAM,EAAF,CAAQ,CAAF,CAAC,EAAK,CAAC,IAAI,CAAC,CAAC,CAAC,qCAE/G,KAAA,4DASE,GAAe,sCAIf,EAAA,EAAA,EAAiB,EjDrH4C,CAAC,CiDqHzC,CAAC,UAAtB,kEAMgC,CAAA,KAAA,CAAA,QAAe,CAAA,mCAEpD,EAAA,EAAA,IAAA,CAAA,IAAA,CAAA,QAAA,CAA0C,ChEvGC,A0C4EA,EAAA,CAAA,EAAA,IsB2Be,EAAI,IAAI,CAAA,QAAA,sDAET,EpF7GlB,AoF6G0B,IAAA,CAAA,CAAA,CAAO,CAAG,IpF7GhB,CAAC,CAAC,AwCqCoB,uC4C0EnD,OAAO,CAAA,CAAA,eACtC,WAAA,CAAA,cAAA,CAAA,EAAA,MAAA,sBACe,CAAA,KAAA,sLAaoC,EOlCK,SPmCzC,iCAEI,OACF,0IAkBiB,MAAA,aACf,6BAGQ,CI6DH,AJ7DI,A/O/B2B,gB+OgC3B,ChDrIC,AI2DK,KAAA,C4C0EE,IAAK,GAC5B,CAAA,CAAA,EAAA,sDAKY,EAAa,ChDnIC,AvH8E7B,KuKqDkC,YAGhC,CAAA,CAAA,CAAA,CAAA,8EAE2B,CAAC,GAAA,+BACI,CAAC,mBAC9B,CAAA,cAAA,CAAA,yBACiB,CAAA,aAAA,CAAA,EAAA,mCACM,CAAA,aAAc,CAAC,iCAGjB,GAAW,C/OnBX,CAAC,A+OmBgB,GAAD,EAAM,CAAC,AAAC,CAAA,GAAA,CAAM,SAAS,CAAC,OAAO,CAAC,EAAM,KAAK,CAAE,QAAQ,CAAC,QAChF,CtBpBC,A1CtFA,OAAA,CAAA,EAAA,OAAA,CgE0G6B,EAAgB,EAAU,UAAU,CAAC,AACnF,CADoF,EACpF,GAAyB,kBAEjB,UAAU,EACT,SAAA,CAAA,OAAA,CAAA,EAAA,GAAA,QAA0C,EAAA,qEAcrB,EvB9GE,AzCKA,AyCLC,CzCKA,AyCLA,UuB8Gc,CAAC,EAAA,AAA+B,QAAQ,EAAvC,OAAW,EAAM,SAAS,CvFvC5F,CAAC,AuFuC4G,CAAC,KAAK,CAAC,EAAM,GAAD,MAAU,CAAC,CAAC,SAGnH,CAAA,CAAkB,CAAE,CAAiB,CAAA,CAAA,CAA4B,CAAA,CAAA,OAE3E,IAAA,CAAK,WAAA,IAAA,8CAOV,IAAA,EAAA,IAAA,CAA2B,OAAA,CAAA,WAAmB,CAAA,EAAA,EAAA,oCACS,GAAG,CAAC,ChE3GC,8BgE4GX,EAAS,iCAImC,CjQUjD,iBiQT1B,YAAE,C9C/CC,AyC3DA,AYgFA,A5FTJ,A1KPJ,A+P0CiB,CAAA,CAAA,IAAA,CAAA,aAAuB,CAAC,C/OpBH,AoP0KI,WLpJ/C,CAAA,MAAA,CAAA,EAAmB,QAAQ,CAAE,CUoRC,AhG/TJ,CAAA,OAAA,CsF2CuB,EAAQ,EAAS,G9C/CJ,K8CgD/D,GAAA,CAAA,EAAA,KAMG,EAAA,IAAA,CAAe,OAAA,6BAEe,iCACa,CAAC,IACxC,EAAA,IAAA,CAAA,qBAAmC,CAAA,EAAS,8BAGxC,CAAC,IAAI,eAKL,CAAA,CAAA,KACb,IAAA,CAAA,WAAA,GAAA,4FAIoC,QAAQ,CAAC,A/OJtC,AwN3GsC,oCuBgHM,CAAA,WACnC,CK4JC,ArExQA,GAAA,CAAA,EAAA,QAAA,EgE8Gd,IAAA,CAAA,KAAA,CAAA,IAAe,uBACJ,CAAA,EAAA,QAAA,CAAkB,EAAA,OAAA,CAAA,EAAA,EAAA,QAAmC,EAAE,COuDC,CAAC,CAAC,EPvDE,CAAC,AAEnE,CAFoE,IAEpE,CAAA,sUAaY,SACT,SAAA,CAAU,OAAO,CAAA,EAAK,KAAA,CAAO,EAAA,QAAA,eAEf,IAAA,CAAA,aAAA,gBgBvJa,CAAC,AhBuJd,EgBvJc,KAAA,2CAI8B,IhBmJ5C,CgBnJwB,CAAC,EAAS,CpGkDZ,AoGlD+B,EAAE,CAAjB,AAAkB,CAAjB,GhBmJvC,sBgB7Ic,oCAEhB,GAAkB,IAPI,EAAS,MAAD,MAAa,CAAC,CAAC,wBhBuJvD,CAAwB,CAAA,2BACf,CAAA,GAAW,KAC5B,EAAA,GAAA,EAAyC,SAC1C,aAAA,CAAA,GAAA,CAAA,EAAA,CACD,WAAA,qBAC0C,EAAW,IpBzII,IAAA,4CoB+ItD,CAAgB,CAAA,CAAA,CAAA,CAAiC,CAAE,CAAA,CAAkB,CAAmB,CAAA,kCAGhE,+BACZ,cAAA,CAAA,EAAA,EAA6B,EAAS,E/OiCF,CAAC,CAAC,C+OjCK,AAI1D,CAJ2D,CAAC,gCAUzD,CAAA,EAAA,EAAY,iBAIX,AAAC,C/OqCe,A6LlDd,A7MYJ,KAAA,OAAA,C+PCiB,CAAA,CAAA,EAAY,GAAG,CIqNH,AJrNI,CIqNH,KnExOS,CAAC,CAAA,IxGWG,CAAC,AuKWlC,CvKXmC,AuKWnC,CvKXoC,CgFdJ,EuFyBhC,CAAA,EAEpB,wBAG0B,CAAA,CAAA,CAAwB,ChDhIjB,gBgDiIG,OAAO,C/OuCL,MAAA,C+OvCa,GAAA,KACzC,EAAW,CAAA,CAAA,EAAY,CAAC,AUuVA,KVtVb,WAAW,AACT,CADU,CAElB,CvB7GD,KuB6GO,CvB7GD,MAAA,CAAA,IuB6GsB,KAAK,CAAC,OAAO,CAAA,gBAAiB,CAAC,GAE1D,EAAA,CAAA,2BASf,+BAEmB,CvB9GC,A4BkRA,KAAA,mCL9Jb,IAAA,CAAA,OAAA,CAAA,gBAA6B,CAAC,CAUvC,MAAA,GAEF,0BAAA,CAAA,CAAA,WAMsC,yBAAyB,CAAC,iCAGlC,CAG7B,CAAA,WACqC,6BAA6B,CAAC,GAGpE,CKqJC,GLxJ0E,CAAC,CAAC,kBAGrD,CAAA,CAAA,kCAOqC,CAAA,yBAGvC,CAAA,CAAA,gCAOqC,CAAC,IAG/D,iBAEsD,kCAAkC,KAEhD,CpBvKR,AnEgHR,AgE5FU,CAAA,CAAA,MAAA,CuBmJsB,CAAA,CAKpD,CvBxJgD,QuByJhB,KAAK,CAC5B,IAAA,EAAe,KAAA,CAAQ,IACvB,EAAS,IAAA,CAAA,QAAA,CAAc,CUiTC,MVhTpB,CAAA,SAAA,EAAA,EAAA,IAAyB,CAAA,SAAA,CAAW,EAAG,EAAS,IAAI,CAAC,GpB5KG,GoB4KG,CpB5KE,CAAA,EoB4KG,CAAA,CAAA,CAChE,CAAA,C/OyCF,cAAA,EAAA,EAAA,I+OzCiC,CAAA,CAAA,CAAG,CAAC,mBACzB,EAAA,aAAA,EAA2B,EAAO,KAAK,CAAA,GAAA,CAAK,CAAC,gDAMpE,CAAA,8CAC8D,KAAK,CAAA,GAAA,CAAK,CAAC,CAUxE,MAAO,WAAA,wEAGmC,CUuSjB,AVvSkB,wBACG,CAAC,IvFtEpB,CAAC,CCkED,ADlEE,ChFmDC,auKoBP,gBACR,CAAG,CAAC,A1FlIP,AwCuGQ,CkD6BtB,QAAA,qBASM,CjQqCN,CAAA,yBiQnCmB,IAAI,CAAA,KAAA,CAAO,CtBtDC,EEpII,CAAC,IoB0LE,CAAC,EUqSG,CAAA,AVrSM,KAAM,EUqSE,OVrSO,CAAE,AjQwClD,CiQxCmD,CjQwCjD,AiQxCkD,OAC/D,C/DrCC,GAAA,C+DqCI,MAAM,CAAG,ClD7BC,CAAA,MkD6BY,C1FpIP,A0FoIQ,kCACQ,yBACb,CAAA,OAAA,CAAA,CAAA,QAClB,eAAA,CAAgB,KAAA,GACd,QACK,IAAA,CAAA,MAAA,sBACc,CAAA,gBAAA,CAAkB,YAC5B,IAAA,CAAK,CjCmBuB,aiCnBT,ClD9BC,OkDkCnB,CAAE,CAAA,CAAA,KACb,EAAA,IAAiB,CAAA,OAAA,CAAA,WAAA,CAAA,GAAA,EAAyC,IAAI,EAAG,IAAI,CAAC,mBAAmB,CAAC,GAAM,CAAF,CAAC,EAAK,CAAC,IAAI,CAAC,CAAC,CAAC,oBACrG,CAAA,GAAA,CAAA,EAAA,IAAA,CAAA,0BAEI,CAAA,CAAA,EAEV,yDAKc,CAAA,EAAA,sCAEJ,gCAIV,4BAC4B,GAC/B,GAAA,GACmB,UACT,CACN,IAAA,CAAA,cAAA,CAAA,IAGZ,CAAC,4CAGoB,CAAC,MAAA,CAAA,IAAW,CAAA,SAAU,CAAC,CtFU7B,AsFV8B,EjQwDE,oBiQpD9B,IAAA,CAAA,YAAiB,CAAA,MAAA,uBACb,EACV,CACX,CAAC,eAEc,CAAA,CAAA,8BACkB,iBACf,CAAG,CACrB,CAAC,UAEoB,CAAA,CAAsB,CAAA,CAAA,MAClC,OAAO,CAAA,WAAA,CAAA,EAAA,GACP,IAAI,CAAC,WAAW,KACjB,IAAA,CAAK,gBAAA,CAAA,wBAAkD,CAAC,ElD9BjD,GkD+BF,cAAA,CAAA,IAAA,CAAsB,OAAA,CAAA,EAEnC,C/D7BC,A+D6BA,WAEoC,CAAE,CAAA,CAAmB,CAAwB,CAAE,CAAU,CjQ0DvD,CiQzDnC,IAAI,CAAA,MAAA,CAAA,2BACoB,CAAC,EAAK,CU8RC,CpGjaL,E0FmIQ,A1FnIR,Y0FoIf,aAIN,IAAA,CAAA,WAAgB,8BAKzB,MAAM,CAAA,CAAA,KACG,IAAA,CAAK,WAAW,GAAI,CAAC,AACtB,CtFWL,GAAA,EAAA,IAAA,CsFXwB,YAAY,CAAC,WAAW,CAAA,GACvC,GAAA,GAAY,CAAC,A/P3Bd,G+P4BK,CAAA,YAAA,CAAc,GjQmED,GiQnEO,CAAA,EAEhC,CAAC,eAID,OAAQ,IAAI,CAAA,OAAgB,CAAC,EU2RP,AhGtQF,KsFrBgB,C1FpIhB,A0FoIiB,CvKXrB,AuKexB,IAAM,GAA+B,yCAEX,CU0RC,CAAC,sBVzRP,2BACS,GAO9B,OAAA,WAAA,iBAKyC,CAAA,CAAA,sDAG1B,IAAA,CACH,kBAHwB,AAGxB,GAHkC,iBAAkB,EAGpD,IACU,GAAqB,CUmRC,AjG/WN,AuF4FO,aAAc,EAAO,YAAY,CAAE,CAAC,CAC/D,IAAA,GAA4B,CAE1B,QAAS,EAAA,eAAsB,CAAC,A1F3IJ,A0F2IK,CAAA,IAAS,CAAC,CAAC,A1F3IJ,KAAA,G0F4I1C,GAAA,kCAMC,CAAA,eAAgB,CAAC,CK6IK,aL1IX,CAAA,CAAA,aACV,C1F9IL,CAAC,AwC4FM,CAAC,CAAA,CkDkDE,EAAM,EAC3B,ClDlDC,AkDkDA,wBAGQ,E/OoFJ,iBAAA,G+OjFL,EtF+BE,UAAA,CAAA,CsF/BuB,CAAoB,CpBhO9B,aoBiOC,OAAA,CAAA,EAAa,kBAGY,CAAA,CAAY,CAAA,QAC1C,IAAA,CAAA,OAAY,CAAC,EAAK,CAAF,CAAE,CACrB,KAAA,CAAO,YAIR,CAAA,CAAA,CAAA,CAAA,CACH,CpBlOC,GoBkOG,CAAA,EAAA,CAAA,EAAS,GAGjB,CpBnOC,CAAC,SAAA,CoBmOoB,CKwIP,CAAA,CAAA,MLvIN,MAAA,CAAO,EAAG,CAAA,WAGV,CAAA,CAAA,CAAA,CAAA,CACL,CvFxGH,GAAA,CuFwGQ,ClDlDC,GkDkDG,CAAA,EAAA,kBAGE,CAAA,CAAA,CAAA,CAAA,MACN,UAAA,CAAA,EAAgB,CvKRH,kBgJnpBoD,CAAA,CAA6B,mDAYnF,EAAA,EAAA,KAAA,EAAA,MAAA,CAAA,GAAA,MAAA,CAAkD,GAAQ,EAAA,GAAA,CAAA,8CAItE,QAAS,CRU2D,AQV1D,CACV,ARSqE,CAAE,A5IQF,QoJjB3D,EACV,E1B9BqF,M0B8B5E,CAAC,CxOQD,OwONT,EAAE,CAAE,CAAC,EACR,CAAC,mCAK2E,UA2LrF,qEA4C0C,CAAA,mBAElB,qCAAuC,EAAQ,ChJ+FT,A+CkCA,IiGjIc,CAAC,CAAC,YAEzD,MAAA,CAAA,CxO0FyD,MwO1FzD,CAAA,EAAA,EAA2B,EAChD,CAAC,A3BiGA,2C2BhTU,IAAA,EAAA,MAAA,CAAA,MAAA,CAAA,EAAA,iEA0K4D,CAAE,C3B+FxC,CAAA,E2B/F4D,QAAQ,OAW1F,GAAI,EkBkBA,AxO6FJ,CAAA,IAAA,EAAA,EAAA,IsN/GsD,CAAC,GAAG,CAAC,CAAE,CAAC,YAEvC,CAAA,GAAA,2BAEL,MAAA,CAAA,OAAA,CAAA,EAAA,GAAA,EAAiC,GAAA,CAAA,EAAA,EAAA,oBACR,EAAS,IAAI,CAAC,GAAA,EAAM,CAAC,MACvD,EAAA,OAAA,GACN,EAAe,GAAA,EAAA,EAAuB,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,6BACtB,EAAA,GxO+E8F,KwO9EhI,GAAI,GAAA,GAAA,OACK,EAAA,OAAA,YAC2B,KAAK,CAAC,AxOsFN,AyKKA,C+D3FO,EGzBE,gBH0BzB,CAAA,OAAA,CAAS,EAAK,CVuKC,AiDjLA,CvCUQ,CC0GC,QDxG9C,KACK,MAAU,CqCfC,wDrCTK,EAAE,mDACsC,EAAS,IAAI,CAAC,CAAN,C8BuKQ,CAAC,KAAA,iB9BrK5B,CAAA,GAAI,CAAC,CAAC,iBAClC,EAAY,QAAF,AAAU,CAAC,8DAEsB,GAAY,EAAS,IAAI,CAAC,CAAN,EAAS,CAAC,CAAC,CAAC,aAExD,GAkBlD,CAAC,uGA9LyB,EAAA,SAAA,CAAA,MAAA,CAAA,KAAuD,EAcvE,EADwC,AACxC,AAd6E,EAAA,SAAkB,C3BgF7C,A2BhF8C,AAchG,CAdiG,CAAC,CAclG,CAAA,GAAA,GAAA,EAAiD,KAAA,gDAIzC,EAAA,EAAA,UAAA,CAAA,EAAA,kBAEsB,EAAA,cApBqE,GAAG,CAAG,CAAD,EAAE,CAAE,CAAC,CAAC,sCACzC,EAAU,EAAU,IAAI,CAAC,CAAC,CAAC,oIAMvB,ChG+BxC,GgG/B4C,CAAC,QAAA,CAAA,CAAA,iCA8C/E,CAAA,CAAA,CAA8D,CxO2BpC,CAAC,+CwOzBmB,EAAE,OAE3C,EAAA,EAAA,gBAE6B,QAAA,CAAA,0GAcW,EAAA,GAAA,CAAA,AAAY,CV4HrD,AtDvEgD,wFgErJ7B,KA6GhC,SAAA,CAAA,CAAA,CAAA,KACkC,6BACnB,EAAA,EAAA,EAAA,QAAA,CAAiC,CAAC,AhJmEhB,CgJnEgB,MAEvC,EAAA,EAAA,4CAMkC,SAEJ,iBAEW,ChJuEH,A4HlDI,ApBqCN,CAAA,4FwCjDA,OAgCrB,EAAA,GAAuB,GA9BtC,GAAiC,EA8Ba,AA9Bb,EnE+CW,ImE/CD,CAAC,YAAA,CAAa,C8BmFe,CAAA,E9BnFA,E3BwFtB,C2BxFyB,CAAC,CAAA,EAAS,kFAMnE,EAAA,EAAA,yBACoB,MAAM,C8BoFI,A9FZL,AgExEE,qBAEH,CuB+GC,CAAA,6BvB7GQ,CAAC,EGvByC,MAAA,aHwBzC,CAAC,MAApC,CAAU,CAAG,EAAA,AAAI,CAAA,GGxB2D,qEHmCpD,eAAe,CAAC,GAAG,CAAC,EAAO,EAAO,EAAR,IAAc,CAAC,CAAC,CAAC,kBAC/D,CAAmB,CAAG,EAAG,AAAC,CAAA,CAAC,CAI3C,KAEuD,EjGyFF,CiGzFK,AhJoFV,SgJnFpD,SAEE,EAAI,CGxBC,KAAA,CAAA,WAAA,YHyBI,CAAC,eAAA,CAAgB,MAAA,CAAA,EAAA,EAAqB,CzBfC,CyBeG,CxO0ET,A+MzFU,KyBeK,CAAC,8BAKvE,MA1KiC,WA2KE,GAAA,CAAA,AAAI,GAAK,EAAA,EAAA,WACf,OAAA,CAAA,GAAA,EAAA,GA5KI,SiCobtB,GAAA,UAAA,GAAA,IjCnbyB,yCAEK,CAAA,EAAA,GAAA,sBAEG,QAAA,CAAA,CAAA,yBAAA,EAAA,EAAA,KAAmD,CAAA,CAAE,CAAC,CAAC,2BAExB,EAAQ,C9NMjB,C8NNyB,WAAW,CAAC,CAAC,KA5BzC,UAAA,gFAyEzC,KAAY,KACpB,EAAA,GAAA,EAAA,IAAA,SACiC,KAAK,CAAC,uCAExB,KAAA,KACf,EAAA,GAAA,EAAA,IAAA,OACuB,EAAA,KAAA,0BiC6I1B,GAAA,UAAA,GAAA,QjC1IG,EAAA,GAAA,EAAA,KAAA,0DAG0B,CAAA,GAAK,CAAA,IAAA,uBACM,CAAA,IAAJ,CAAI,CAAA,EAAA,CACxC,iBAAA,KAAA,iCA6GX,CpBoBC,QAAA,GAAA,CoBpBkD,+CA8CrC,CAAA,CAAA,CAAA,CAAA,CAA8D,CAAA,CAA0B,CxNkJ9D,EAAE,CgLvDO,CmE4NH,AnE5NG,CmE4NF,A3BtTrC,C2BsTsC,C3BtTtC,GAAgB,GAAA,sBAgBP,WAZD,EAAA,EAAU,EAAE,kCACsB,CAAC,EAAK,CAAF,AhJmGC,KgJjGhC,IAAA,EAAA,YACO,ChEuFP,AxKqBI,CAAA,sCwOrGd,+BAOU,CuB6GG,CvB7GC,C1OsKT,KAAA,C0OtKgB,IAAA,CAAA,EAAU,CAClC,IAAK,ChE2FH,AwBMI,GwCjGK,CxO4GH,CAAA,QwO3GF,C3BwGC,C2BxGM,CzBlBC,GAAA,EAAA,GAAA,KAAA,IyBoBf,GAAA,AAAoB,GAAG,C2B6UL,AxBzWI,EH4BtB,EG5BsB,6BHiDb,C3B+HC,EAAA,E2B/HY,CnE6BP,KmE7Ba,CAAC,CV0KmB,SU1KT,CAAC,C3B+HC,C2B/HI,S3B+HS,c2BjJvC,EAAI,EAAE,eAKC,CC0GC,KAAA,CAAA,YD1GkB,CAAC,EAAO,EAExC,CuB8GC,AKoKA,AvDrJA,G2B7HI,IAAM,EAAA,MAAA,CAAA,UAAA,CAAA,EAA2B,CAClC,EVuKqC,CAAC,CAAC,AUvKvC,IAAW,EAAA,UAET,IAAM,EAAA,wBAIC,C3B6HC,CbdG,AwC/GC,UAQP,QAAK,SACZ,QAAQ,aACP,EAAA,MAAA,CAAW,QAAA,CAAA,EAAc,ExC6GI,uBwC3GvB,EAAA,GAAa,aAK5C,CAAC,AAED,CALW,QAKX,GAAA,CAAA,CAAqC,C4B+RN,I3BlLJ,A2BkLI,I5B9Rd,AAMjB,SAAA,CAAA,CAAyC,CAAA,iBACV,AAChB,CxCkHqB,AwCnHJ,AhJ8IJ,CgJ7IL,IAAI,EAChB,GAAA,EAAA,SAAA,CAAA,GAAA,CAAA,UACI,EAAA,SAAA,CAAA,GAAA,CAAA,yBAG+B,CAAC,EAChB,EhE6Fd,AgE7FsB,KAAK,4BAEiB,GAAiB,EAAA,GAAS,CAAC,EGlBjE,EHmBc,QAAQ,CAAC,ChE6FL,CAAC,KgE7FW,CAAA,GACpB,EhJkJA,MgJlJQ,EAAE,CAAA,IAAA,CAAA,sDAOtB,CAAA,GAAA,CAAA,EAAc,CnEmCH,CAAC,CmElClB,EAEf,CAAC,CA5BgB,EAAiB,GACxB,EAAO,EAAI,MAAA,CAAA,OAAc,CAAA,8BACK,CGrBJ,A3CiIF,CAAA,aAAA,CwC5GyB,CAAC,CAAC,OAClD,CACX,CAAC,AA0BD,SAAS,CuBqKC,EAAA,CvBrK0B,CAAA,CAAA,MAC1B,EAAA,EAAA,MAAA,CAAmB,C4BmSU,CAAA,6B5BlSG,EAAA,aAAA,CAAmB,kFQ5VF,GAAS,2IAMW,GAAA,UAAuB,ChPSnF,AgPToF,6HAiBvD,8FAMmB,EAAA,GAAA,CAAA,GAAA,IAAA,CAAA,kBAAA,CAAA,IAAA,OACI,6BAIzD,EAAA,GAAA,gCACqC,Cf3BH,ASmDnB,AnJvBmB,AgJ4CI,ES7CQ,IAAI,CAAA,oBAAqB,CAAC,GAAA,gBAEvD,uFAQ2B,ElCxBE,KAAA,CkCwBQ,ET4CJ,MAAA,qEStCX,QAAQ,CAAA,IAAA,GAAO,qCAGL,CAAA,QAAS,CAAA,MAAA,2JAqBnB,MAAA,CAAA,KAAA,QAChC,CAAA,GAAM,EAAA,KAAA,EAAA,OAAA,mDAHoG,8BAMnD,EnC2EE,AlC9EjD,CkC8EkD,CAAC,ImC3EI,ErEHT,CAArC,IAAqC,EqEGS,CrEFvD,CqEEgE,CrEF9D,QqEEqD,MAAS,AAAe,CAAC,CAAC,CAAC,CAAC,EAArB,KAAA,GrEHhB,6CqEOpB,CAAC,EAAA,GAC1C,EAAA,qDAG4B,CAAA,EAAA,sBAGQ,CRJC,AiC0MA,AzBtMA,CRJC,CAAC,AhJoDV,CAAC,CmFjDT,iDqEQyC,CAAA,qCAEd,CAAC,CAAC,0CjCSpC,CAAA,CAAA,EAAI,EAAO,WAAW,EAAE,CAAA,EAAG,EAAA,WAAkB,EAAE,CAAA,CAAA,CAAG,CKsCW,ALtCR,AAAF,CAAC,EAAc,IACxF,EAD8F,CAAC,CAC3F,AAAL,CAAM,AADkF,EAChF,CAAC,CAAC,EiCViD,EAAA,KAAA,6BAKlC,MAAM,CAAA,CAAA,EAAA,SjCc9B,IAYwB,UAK1B,yBiC9B+B,IP6EqD,GO7EpC,CAAC,CsBqEuC,CAAC,CAAC,GxQuBA,S+MtBxD,KAAA,EAAA,EAAA,GmCrEtB,CQjCsB,AzDgCA,AcsEA,EAAA,AmCrEP,IjCYzB,CiCZ6B,CAAe,GAAG,CAAG,EAAQ,MAAM,CAAG,GAAG,CjCYrB,EiCZuB,EAAQ,KAAD,AAAM,CjCyBnF,AiCzBoF,EAAE,CAAC,OjCyBvF,SAZ0B,0BAeZ,EAAA,EAAA,MAAA,CAClB,EAAA,IAmIO,IAAA,OAAA,SAjIE,UACQ,GAAA,cAGqB,CvHuFX,sDuHjFY,CAAA,EAAA,GAAe,SACzC,EpCyCF,AoFoFkC,+ChDvHf,CAAA,EAAA,EAAA,4CAOL,gBAEyB,eACI,OAAO,CAAA,IAAM,CAAC,CAAC,C/LyGH,AiM3BI,EF9EM,EAE5C,6BAQJ,EAAA,OAAU,UACmB,CAAA,IAAM,CAAC,CAAC,CvHkGxB,AiLiXyB,A1DndE,CtCyFN,AsCzFO,AtCyFL,CsCzFQ,CtCyFN,AsCzFO,CAAC,CAAC,kBAMpC,EAAA,OAAA,CAAA,IAAA,GAAyB,EAAA,yFAWpB,uBAI3B,CKoCC,CsCRC,AYwJA,yDvD5KF,iCAEY,CAAA,iCAKM,wCAKP,CAAA,CAAA,EAAA,EAAa,EAAE,CAAC,GyBeG,IzBbnB,GAAA,SACK,EACL,GAAU,IAAY,KAAK,CAAC,AAC5B,IjN+J4B,MiN9J3B,CgEIC,AjRuKJ,wBiNxKwB,IACtB,KACJ,KAAA,WAES,WAEY,MAAM,CAAA,EAAM,EAAI,C1CuCL,uB0CpCpB,CAAM,CAAA,EAAK,CAAC,CAAA,UAEhB,IAAA,oBAIc,C7LuIL,A2PxIM,C9DCM,C/LmKL,A+KtIM,CAAC,A/KsIN,C+KtIO,GgB7BG,CAAA,EAAM,EAAI,GAAG,CAAC,CAAC,cAG5B,EAAO,OAAA,CAAQ,IAAK,CAAC,EAAI,CqDkSrD,ArDlSsD,CAAG,CAAC,CAAC,Af0GA,CezGzC,GAAA,IAAA,MAIhB,0DAUJ,EAAA,eAQT,EAA4B,CFyHC,IAAA,EE1QpC,gBAAA,CAAA,CAAA,EAAA,CAA2B,MAAA,CAAA,UiCdA,CAAC,EjDDE,6F4C9EP,sBAEH,IAAA,CAAA,GAAA,CAAA,YACkC,IAAI,CAAC,GAAG,CAAC,cACpD,EAAA,KAAA,EAAA,EAAA,QAAuB,CAAC,qBzBpDN,IAAA,CAAA,GAAA,0QAcqB,CAAC,qBAE3B,oByB2ZM,CACnB,EAAA,IAAA,EAAA,KAAA,EAAA,EAAW,IAAA,AAAI,EAAA,EAAI,EAAJ,MAAY,CAE3B,AAF4B,CAAb,KAEf,CAAA,CAFe,CAEf,IAFe,CAEK,CAAK,CAAA,EAAI,EAAK,CAAT,CAAQ,EzB9ZpB,AyB8ZyB,CAAC,CzB9Z1B,GyB8ZO,AAAK,EzB9ZZ,EAAA,EAAO,CyB8ZK,KAAA,KzB9ZM,mJAIC,WAAW,CAAA,0BAMzC,KAAA,GAAA,CAAA,CAAA,gBAEgB,sJAkBX,MAAA,2GAbiB,CAAA,EAAA,kDAuBP,uKAgBb,KAAK,4ImCrDjB,GAAA,OAAA,4UAiDiB,0BAIL,CAAA,kBxElGnB,MAAM,GACF,YAAY,CAAG,CAAE,CAAU,CAAE,CAAO,CAAE,CAAO,CAAE,CAC3C,IAAI,CAAC,IAAI,CAAG,EACZ,IAAI,CAAC,WAAW,CAAG,EACnB,IAAI,CAAC,QAAQ,CAAG,EAChB,IAAI,CAAC,QAAQ,CAAG,EAChB,IAAI,CAAC,YAAY,MAAG,CACxB,CACA,IAAI,KAAM,CACN,OAAO,IAAI,CAAC,IAChB,AADoB,CAEpB,IAAI,YAAa,CACb,OAAO,IAAI,CAAC,WAAW,AAC3B,CACA,IAAI,SAAU,CACV,OAAO,IAAI,CAAC,QAAQ,AACxB,CACA,QAAQ,CAAK,CAAE,CACX,GAAI,EAAO,CACP,IAAM,EAAQ,IAAI,CAAC,QAAQ,CAAC,EAAM,KAAK,EACjC,EAAM,IAAI,CAAC,QAAQ,CAAC,EAAM,GAAG,EACnC,OAAO,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAO,EAC1C,CACA,OAAO,IAAI,CAAC,QAChB,AADwB,CAExB,OAAO,CAAO,CAAE,CAAO,CAAE,CACrB,IAAK,IAAM,KAAU,EACjB,GAAI,GADsB,AACL,aAAa,CAAC,GAAS,CAExC,IAAM,EAAQ,GAAmB,EAAO,KAAK,EAEvC,EAAc,IAAI,CAAC,QAAQ,CAAC,EAAM,KAAK,EACvC,EAAY,IAAI,CAAC,QAAQ,CAAC,EAAM,GAAG,EACzC,IAAI,CAAC,QAAQ,CAAG,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAG,GAAe,EAAO,IAAI,CAAG,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAW,IAAI,CAAC,QAAQ,CAAC,MAAM,EAE/H,IAAM,EAAY,KAAK,GAAG,CAAC,EAAM,KAAK,CAAC,IAAI,CAAE,GACvC,EAAU,KAAK,GAAG,CAAC,EAAM,GAAG,CAAC,IAAI,CAAE,GACrC,EAAc,IAAI,CAAC,YAAY,CAC7B,EAAmB,GAAmB,EAAO,IAAI,EAAE,EAAO,GAChE,GAAI,EAAU,IAAc,EAAiB,MAAM,CAC/C,CADiD,GAC5C,IAAI,EAAI,EAAG,EAAM,EAAiB,MAAM,CAAE,EAAI,EAAK,IAAK,AACzD,CAAW,CAAC,EAAI,EAAY,EAAE,CAAG,CAAgB,CAAC,EAAE,MAIpD,EAAiB,MAAM,CAAG,IAC1B,EAAY,CADqB,KACf,CAAC,EAAY,EAAG,EAAU,KAAc,GAG1D,IAAI,CAAC,YAAY,CAAG,EAAc,EAAY,KAAK,CAAC,EAAG,EAAY,GAAG,MAAM,CAAC,EAAkB,EAAY,KAAK,CAAC,EAAU,IAGnI,IAAM,EAAO,EAAO,IAAI,CAAC,MAAM,CAAI,EAAD,CAAa,CAAA,CAAW,CAC1D,GAAa,GAAG,CAAZ,EACA,IAAK,IAAI,EAAI,EAAY,EAAI,EAAiB,MAAM,CAAE,EAAM,EAAY,MAAM,CAAE,EAAI,EAAK,IACrF,AAD0F,CAC/E,CAAC,EAAE,CAAG,CAAW,CAAC,EAAE,CAAG,CAG9C,MACK,GAAI,GAAiB,MAAM,CAAC,GAC7B,IAAI,CAAC,CADiC,OACzB,CAAG,EAAO,IAAI,CAC3B,IAAI,CAAC,YAAY,MAAG,OAGpB,MAAU,AAAJ,MAAU,iCAGxB,IAAI,CAAC,QAAQ,CAAG,CACpB,CACA,gBAAiB,CAIb,YAH0B,IAAtB,IAAI,CAAC,EAA4B,UAAhB,GACjB,IAAI,CAAC,YAAY,CAAG,GAAmB,IAAI,CAAC,QAAQ,EAAE,EAAA,EAEnD,IAAI,CAAC,YAAY,AAC5B,CACA,WAAW,CAAM,CAAE,CACf,EAAS,KAAK,GAAG,CAAC,KAAK,GAAG,CAAC,EAAQ,IAAI,CAAC,QAAQ,CAAC,MAAM,EAAG,GAC1D,IAAM,EAAc,IAAI,CAAC,cAAc,GACnC,EAAM,EAAG,EAAO,EAAY,MAAM,CACtC,GAAa,GAAG,CAAZ,EACA,MAAO,CAAE,KAAM,EAAG,UAAW,CAAO,EAExC,KAAO,EAAM,GAAM,CACf,IAAM,EAAM,KAAK,KAAK,CAAC,CAAC,EAAM,CAAA,CAAI,CAAI,EAClC,EAAW,CAAC,EAAI,CAAG,EACnB,EAAO,EAGP,EAAM,AAJqB,EAIf,CAEpB,CAGA,IAAM,EAAO,EAAM,EAEnB,OADA,EAAS,IAAI,CAAC,eAAe,CAAC,EAAQ,CAAW,CAAC,EAAK,EAChD,MAAE,EAAM,UAAW,EAAS,CAAW,CAAC,EAAK,AAAC,CACzD,CACA,SAAS,CAAQ,CAAE,CACf,IAAM,EAAc,IAAI,CAAC,cAAc,GACvC,GAAI,EAAS,IAAI,EAAI,EAAY,MAAM,CACnC,CADqC,MAC9B,IAAI,CAAC,QAAQ,CAAC,MAAM,CAE1B,GAAI,EAAS,IAAI,CAAG,EACrB,CADwB,MACjB,EAEX,IAAM,EAAa,CAAW,CAAC,EAAS,IAAI,CAAC,CAC7C,GAAI,EAAS,SAAS,EAAI,EACtB,CADyB,MAClB,EAEX,IAAM,EAAkB,EAAS,IAAI,CAAG,EAAI,EAAY,MAAM,CAAI,CAAW,CAAC,EAAS,IAAI,CAAG,EAAE,CAAG,IAAI,CAAC,QAAQ,CAAC,MAAM,CACjH,EAAS,KAAK,GAAG,CAAC,EAAa,EAAS,SAAS,CAAE,GACzD,OAAO,IAAI,CAAC,eAAe,CAAC,EAAQ,EACxC,CACA,gBAAgB,CAAM,CAAE,CAAU,CAAE,CAChC,KAAO,EAAS,GAAc,GAAM,IAAI,CAAC,QAAQ,CAAC,UAAU,CAAC,EAAS,IAAK,CACvE,IAEJ,OAAO,CACX,CACA,IAAI,WAAY,CACZ,OAAO,IAAI,CAAC,cAAc,GAAG,MACjC,AADuC,CAEvC,OAAO,cAAc,CAAK,CAAE,CAExB,OAAO,SACuB,AAA1B,KADiB,YACV,CADuB,CACb,IAAI,OAAqC,EADd,EACN,EAAU,KAAK,EACrD,MAA2B,IAA1B,EAAU,WAAW,EAAmD,UAAjC,OAH1B,AAGiC,EAAU,WAAgB,AAAL,CAAa,AACzF,CACA,OAAO,OAAO,CAAK,CAAE,CAEjB,OAAO,SACuB,KADT,KACjB,OAAO,CADuB,CACb,IAAI,OAAqC,EADd,EACN,EAAU,KAAK,OAA4C,IAFnF,AAEyD,EAAU,WAAW,AACpG,CACJ,CA+FA,SAAS,GAAmB,CAAI,CAAE,CAAa,CAAE,EAAa,CAAC,EAC3D,IAAM,EAAS,EAAgB,CAAC,EAAW,CAAG,EAAE,CAChD,IAAK,IAAI,EAAI,EAAG,EAAI,EAAK,MAAM,CAAE,IAAK,CAClC,IAAM,EAAK,EAAK,UAAU,CAAC,GACvB,GAAM,KACK,AADA,GACG,EAAV,GAA2C,EAAI,EAAI,EAAK,MAAM,EAA+B,GAAG,EAA9B,EAAK,CAAlC,SAA4C,CAAC,EAAI,IACtF,AADqH,IAGzH,CAH6H,CAGtH,IAAI,CAAC,EAAa,EAAI,GAErC,CACA,OAAO,CACX,CACA,SAAS,GAAM,CAAI,EACf,OAAO,AAAS,GAAG,KAA0C,GAAG,EAAZ,CACxD,CACA,SAAS,GAAmB,CAAK,EAC7B,AAH8C,EAAuC,EAG/E,EAAQ,EAAM,KAAK,CACnB,EAAM,EAAM,GAAG,QACrB,AAAI,EAAM,IAAI,CAAG,EAAI,IAAI,EAAK,EAAM,IAAI,GAAK,EAAI,IAAI,EAAI,EAAM,SAAS,CAAG,EAAI,SAAS,CAC7E,CADgF,AAC9E,MAAO,EAAK,IAAK,CAAM,EAE7B,CACX,CACA,SAAS,GAAkB,CAAQ,EAC/B,IAAM,EAAQ,GAAmB,EAAS,KAAK,SAC/C,AAAI,IAAU,EAAS,KAAK,CACjB,CADmB,AACjB,QAAS,EAAS,OAAO,OAAE,CAAM,EAEvC,CACX,CA/GI,CAZO,GA4DR,KAAiB,GAAe,CA5DZ,CA4Da,CAAC,EAhDpB,IAgDE,EAhDI,CAHnB,EAGsB,OAHN,AAAP,CAAU,CAAE,CAAU,CAAE,CAAO,CAAE,CAAO,EAC7C,OAAO,IAAI,GAAiB,EAAK,EAAY,EAAS,EAC1D,EAoBA,GAAa,MAAM,CATnB,EASsB,OATb,AAAO,CAAQ,CAAE,CAAO,CAAE,CAAO,EACtC,GAAI,aAAoB,GAEpB,OADA,EAAS,MAAM,CADuB,AACtB,EAAS,GAClB,CAGP,OAAM,AAAI,MAAM,uEAExB,EA6BA,GAAa,UAAU,CA3BvB,EA2B0B,OA3BjB,AAAW,CAAQ,CAAE,CAAK,EAC/B,IAAM,EAAO,EAAS,OAAO,GACvB,EAAc,AA2B5B,SAAS,EAAU,CAAI,CAAE,CAAO,EAC5B,GAAI,EAAK,MAAM,EAAI,EAEf,CAFkB,MAEX,EAEX,IAAM,EAAI,EAAM,MAAM,CAAG,EAAK,EACxB,EAAO,EAAK,KAAK,CAAC,EAAG,GACrB,EAAQ,EAAK,KAAK,CAAC,GACzB,EAAU,EAAM,GAChB,EAAU,EAAO,GACjB,IAAI,EAAU,EACV,EAAW,EACX,EAAI,EACR,KAAO,EAAU,EAAK,MAAM,EAAI,EAAW,EAAM,MAAM,CAAE,CAE1C,AAAP,GAAU,AADF,EAAQ,CAAI,CAAC,EAAQ,CAAE,CAAK,CAAC,EAAS,EAG9C,CAAI,CAAC,IAAI,CAAG,CAAI,CAAC,IAAU,CAI3B,CAAI,CAAC,IAAI,CAAG,CAAK,CAAC,IAAW,CAGrC,KAAO,EAAU,EAAK,MAAM,CAAE,CAC1B,CAAI,CAAC,IAAI,CAAG,CAAI,CAAC,IAAU,CAE/B,KAAO,EAAW,EAAM,MAAM,CAAE,CAC5B,CAAI,CAAC,IAAI,CAAG,CAAK,CAAC,IAAW,CAEjC,OAAO,CACX,EA1DsC,EAAM,GAAG,CAAC,IAAoB,CAAC,EAAG,KAC5D,IAAM,EAAO,EAAE,KAAK,CAAC,KAAK,CAAC,IAAI,CAAG,EAAE,KAAK,CAAC,KAAK,CAAC,IAAI,QACpD,AAAa,GAAG,CAAZ,EACO,EAAE,KAAK,CAAC,KAAK,CAAC,SAAS,CAAG,EAAE,KAAK,CAAC,KAAK,CAAC,SAAS,CAErD,CACX,GACI,EAAqB,EACnB,EAAQ,EAAE,CAChB,IAAK,IAAM,KAAK,EAAa,CACzB,IAAM,EAAc,EAAS,QAAQ,CAAC,EAAE,KAAK,CAAC,KAAK,EACnD,GAAI,EAAc,EACd,MAAM,AAAI,MAAM,MADkB,cAG7B,EAAc,GACnB,EAAM,IAAI,CAAC,EAAK,QADuB,CACd,CAAC,EAAoB,IAE9C,EAAE,OAAO,CAAC,MAAM,EAAE,AAClB,EAAM,IAAI,CAAC,EAAE,OAAO,EAExB,EAAqB,EAAS,QAAQ,CAAC,EAAE,KAAK,CAAC,GAAG,CACtD,CAEA,OADA,EAAM,IAAI,CAAC,EAAK,MAAM,CAAC,IAChB,EAAM,IAAI,CAAC,GACtB,uHhL1KyDA,ECbrD,CCPiB,CDQvB,AERoB,CHoB4CC,CGnBhE,IFOM,EACN,CGTuB,CAAA,CAAA,aJyBhBC,CEvBI,ADSZ,AGTS,CJuBoBC,CAAAA,CAAMC,CAAAA,EAMlC,GI5BK,CJuBL,IAIIC,EAJAC,CCfY,CAAA,GDgBZC,CIxBc,ADAlB,CHwBwB,EACpBC,EAAAA,CAAa,EACbC,EAAO,EAEFC,EAAI,EAAGA,CE3BG,EAAA,EF2BOC,IG3BrB,CDCA,CAAA,CAAA,EF0B+BD,EAAG,CACrC,GAAIA,CG5BW,CAAA,EH4BFC,MAAAA,CACXN,EAAOF,EAAKS,UAAAA,CAAWF,OACpB,CAAA,GAAa,KAATL,EACP,MAEAA,EAAO,EAAQ,CACjB,GAAa,KAATA,EAAmB,CACrB,GAAIG,IAAcE,EAAI,GAAc,IAATD,QAEpB,GAAID,IAAcE,EAAI,GAAc,IAATD,EAAY,CAC5C,GAAIH,EAAIK,MAAAA,CAAS,GAA2B,IAAtBJ,GAA8D,KAAnCD,EAAIM,UAAAA,CAAWN,EAAIK,MAAAA,CAAS,IAAsD,KAAnCL,EAAIM,UAAAA,CAAWN,EAAIK,MAAAA,CAAS,IAC1H,GAAIL,EAAIK,MAAAA,CAAS,EAAG,CAClB,IAAIE,EAAiBP,EAAIQ,WAAAA,CAAY,KACrC,GAAID,IAAmBP,EAAIK,MAAAA,CAAS,EAAG,CAAA,CACb,IAApBE,GACFP,CADEO,CACI,GACNN,GAAoB,CAAA,CAGpBA,EAAAA,CADAD,EAAMA,EAAIS,KAAAA,CAAM,EAAGF,EAAAA,CAAAA,CACKF,MAAAA,CAAS,EAAIL,EAAIQ,WAAAA,CAAY,KAEvDN,EAAYE,EACZD,EAAO,EACP,QACF,CACF,MAAO,GAAmB,IAAfH,EAAIK,MAAAA,EAA+B,IAAfL,EAAIK,MAAAA,CAAc,CAC/CL,EAAM,GACNC,EAAoB,EACpBC,EAAYE,EACZD,EAAO,EACP,UAGAL,GACEE,EADFF,CACMO,MAAAA,CAAS,EACfL,GAAO,MAEPA,EAAM,KACRC,GAAoB,CAAA,AAExB,MACMD,EAAIK,MAAAA,CAAS,EACfL,GAAO,IAAMH,EAAKY,KAAAA,CAAMP,EAAY,EAAGE,GAEvCJ,EAAMH,EAAKY,KAAAA,CAAMP,EAAY,EAAGE,GAClCH,EAAoBG,EAAIF,EAAY,EAEtCA,EAAYE,EACZD,EAAO,CACT,MAAoB,KAATJ,GAAAA,CAA+B,IAAVI,EAAAA,EAC5BA,EAEFA,EAAAA,CAAQ,CAEZ,CACA,OAAOH,CACT,CAcA,IAAIU,EAAQ,CAEVC,QAAS,WAKP,IAJA,IAKMd,EAHFe,EAFAC,EAAe,GACfC,EAAAA,CAAmB,EAGdV,EAAIW,UAAUV,MAAAA,CAAS,EAAGD,GAAAA,CAAM,GAAA,CAAMU,EAAkBV,IAAK,AAEhEA,GAAK,EACPP,EAAOkB,SAAAA,CAAUX,EAAAA,EAAAA,CAAAA,IAELY,IAARJ,GACFA,EADEA,CACIK,GAAAA,OAAAA,CAAQL,GAAAA,EAAAA,CAAAA,CAChBf,GAAOe,CAAAA,CAGTM,EAAWrB,GAGS,IAAhBA,EAAKQ,MAAAA,GAITQ,CAJSR,CAIMR,EAAO,IAAMgB,EAC5BC,EAA0C,KAAvBjB,EAAKS,UAAAA,CAAW,EAAA,CAAA,CASrC,OAFAO,EAAejB,EAAqBiB,EAAAA,CAAeC,GAE/CA,EACED,EAAaR,MAAAA,CAAS,EACjB,IAAMQ,EAEN,IACAA,EAAaR,MAAAA,CAAS,EACxBQ,EAEA,GAEX,EAEAM,UAAW,SAAmBtB,CAAAA,EAG5B,GAFAqB,EAAWrB,GAES,IAAhBA,EAAKQ,MAAAA,CAAc,MAAO,IAE9B,IAAIe,EAAoC,KAAvBvB,EAAKS,UAAAA,CAAW,GAC7Be,EAAyD,KAArCxB,EAAKS,UAAAA,CAAWT,EAAKQ,MAAAA,CAAS,GAQtD,OAHoB,IAAA,CAFpBR,EAAOD,EAAqBC,EAAAA,CAAOuB,EAAAA,CAAAA,CAE1Bf,MAAAA,EAAiBe,IAAYvB,CAAZuB,CAAmB,GAAA,CAAA,CACzCvB,EAAKQ,MAAAA,CAAS,GAAKgB,IAAmBxB,CAAnBwB,EAA2B,GAAA,CAAA,CAE9CD,EAAmB,IAAMvB,EACtBA,CACT,EAEAuB,WAAY,SAAoBvB,CAAAA,EAE9B,OADAqB,EAAWrB,GACJA,EAAKQ,MAAAA,CAAS,GAA4B,KAAvBR,EAAKS,UAAAA,CAAW,EAC5C,EAEAgB,KAAM,WACJ,GAAyB,GAArBP,UAAUV,MAAAA,CACZ,MAAO,IAET,IADA,IAAIkB,EACKnB,EAAI,EAAGA,EAAIW,UAAUV,MAAAA,CAAAA,EAAUD,EAAG,CACzC,IAAIoB,EAAMT,SAAAA,CAAUX,EAAAA,CACpBc,EAAWM,GACPA,EAAInB,MAAAA,CAAS,IAAA,CAAA,IACAW,IAAXO,EACFA,EAASC,EAETD,GAAU,KAAMC,CAAAA,AAEtB,CACA,OAAA,KAAeR,IAAXO,EACK,IACFb,EAAMS,SAAAA,CAAUI,EACzB,EAEAE,SAAU,SAAkBC,CAAAA,CAAMC,CAAAA,EAIhC,KAHWD,GACXR,EAAWS,GADXT,AAGIQ,IAASC,GAKb,CAHAD,EAAOhB,EAAMC,OAAAA,CAAQe,EAAAA,CAAAA,IACrBC,EADqBD,AAChBhB,EAAMC,OAAAA,CAAQgB,EAAAA,CAAAA,CAHF,EAKA,IALO,GAKA,AAIxB,IADA,IAAIC,EAAY,EACTA,EAAYF,EAAKrB,MAAAA,EACa,KAA/BqB,EAAKpB,UAAAA,CAAWsB,GAAAA,EADYA,GASlC,IALA,IAAIC,EAAUH,EAAKrB,MAAAA,CACfyB,EAAUD,EAAUD,EAGpBG,EAAU,EACPA,EAAUJ,EAAGtB,MAAAA,EACa,KAA3BsB,EAAGrB,UAAAA,CAAWyB,GAAAA,EADUA,GAW9B,IAPA,IACIC,EADQL,EAAGtB,MAAAA,CACK0B,EAGhB1B,EAASyB,EAAUE,EAAQF,EAAUE,EACrCC,EAAAA,CAAiB,EACjB7B,EAAI,EACDA,GAAKC,EAAAA,EAAUD,EAAG,CACvB,GAAIA,IAAMC,EAAQ,CAChB,GAAI2B,EAAQ3B,EAAQ,CAClB,GAAmC,KAA/BsB,EAAGrB,UAAAA,CAAWyB,EAAU3B,GAG1B,OAAOuB,EAAGlB,KAAAA,CAAMsB,EAAU3B,EAAI,GACzB,GAAU,IAANA,EAGT,OAAOuB,EAAGlB,KAAAA,CAAMsB,EAAU3B,EAE9B,MAAW0B,EAAUzB,IACoB,CADpBA,IACfqB,EAAKpB,UAAAA,CAAWsB,EAAYxB,GAG9B6B,EAAgB7B,EACD,IAANA,IAGT6B,CAHS7B,EAGO,CAAA,CAAA,CAGpB,KACF,CACA,IAAI8B,EAAWR,EAAKpB,UAAAA,CAAWsB,EAAYxB,GAE3C,GAAI8B,IADSP,EAAGrB,UAAAA,CAAWyB,EAAU3B,GAEnC,MACoB,KAAb8B,IACPD,CADOC,EACS9B,CAAAA,AACpB,CAEA,IAAI+B,EAAM,GAGV,IAAK/B,EAAIwB,EAAYK,EAAgB,EAAG7B,GAAKyB,EAAAA,EAAWzB,EAClDA,IAAMyB,GAAkC,KAAvBH,EAAKpB,UAAAA,CAAWF,KAChB,CADgBA,GAC/B+B,EAAI9B,MAAAA,CACN8B,GAAO,KAEPA,GAAO,KAAA,CAAA,CAMb,OAAIA,EAAI9B,MAAAA,CAAS,EACR8B,EAAMR,EAAGlB,KAAAA,CAAMsB,EAAUE,IAEhCF,CAFgCE,EAErBA,EACoB,KAA3BN,EAAGrB,UAAAA,CAAWyB,IAAAA,EACdA,EACGJ,EAAGlB,KAAAA,CAAMsB,EAAAA,CAAAA,AAEpB,EAEAK,UAAW,SAAmBvC,CAAAA,EAC5B,OAAOA,CACT,EAEAwC,QAAS,SAAiBxC,CAAAA,EAExB,GADAqB,EAAWrB,GACS,IAAhBA,EAAKQ,MAAAA,CAAc,MAAO,IAK9B,IAJA,IAAIN,EAAOF,EAAKS,UAAAA,CAAW,GACvBgC,EAAmB,KAATvC,EACVwC,EAAAA,CAAO,EACPC,EAAAA,CAAe,EACVpC,EAAIP,EAAKQ,MAAAA,CAAS,EAAGD,GAAK,EAAA,EAAKA,EAEtC,GAAa,MADbL,CACa,CADNF,EAAKS,UAAAA,CAAWF,EAAAA,CAAAA,EAEnB,CAFmBA,EAEnB,CAAKoC,EAAc,CACjBD,EAAMnC,EACN,MACF,MAGFoC,EAAAA,CAAe,EAInB,OAAA,CAAa,IAATD,EAAmBD,EAAU,IAAM,IACnCA,GAAmB,IAARC,EAAkB,KAC1B1C,EAAKY,KAAAA,CAAM,EAAG8B,EACvB,EAEAE,SAAU,SAAkB5C,CAAAA,CAAM6C,CAAAA,EAChC,GAAA,KAAY1B,IAAR0B,GAAoC,UAAA,OAARA,EAAkB,MAAM,AAAIC,UAAU,mCACtEzB,EAAWrB,GAEX,IAGIO,EAHAwC,EAAQ,EACRL,EAAAA,CAAO,EACPC,EAAAA,CAAe,EAGnB,GAAA,KAAYxB,IAAR0B,GAAqBA,EAAIrC,MAAAA,CAAS,GAAKqC,EAAIrC,MAAAA,EAAUR,EAAKQ,MAAAA,CAAQ,CACpE,GAAIqC,EAAIrC,MAAAA,GAAWR,EAAKQ,MAAAA,EAAUqC,IAAQ7C,EAAM,MAAO,GACvD,IAAIgD,EAASH,EAAIrC,MAAAA,CAAS,EACtByC,EAAAA,CAAoB,EACxB,IAAK1C,EAAIP,EAAKQ,MAAAA,CAAS,EAAGD,GAAK,EAAA,EAAKA,EAAG,CACrC,IAAIL,EAAOF,EAAKS,UAAAA,CAAWF,GAC3B,GAAa,KAATL,EAGA,CAHAA,GAGA,CAAKyC,EAAc,CACjBI,EAAQxC,EAAI,EACZ,MACF,MAAA,CAEwB,IAAtB0C,IAGFN,CAHEM,CAGFN,CAAe,EACfM,EAAmB1C,GAAI,CAAA,CAErByC,GAAU,GAER9C,EAFQ,GAEC2C,EAAIpC,UAAAA,CAAWuC,GAAAA,CACR,GAAA,EAAZA,IAGJN,CAHIM,EAGEzC,CAAAA,EAKRyC,EAAAA,AALQzC,CAKE,EACVmC,GAAMO,CAAAA,CAAAA,AAId,CAGA,OADIF,IAAUL,EAAKA,EAAMO,EAAAA,CAAmC,IAATP,IAAYA,CAAZA,CAAkB1C,EAAKQ,MAAAA,EACnER,EAAKY,KAAAA,CAAMmC,EAAOL,EAC3B,CACE,IAAKnC,EAAIP,EAAKQ,MAAAA,CAAS,EAAGD,GAAK,EAAA,EAAKA,EAClC,GAA2B,KAAvBP,EAAKS,UAAAA,CAAWF,IAAAA,AAGhB,GAAA,CAAKoC,EAAc,CACjBI,EAAQxC,EAAI,EACZ,MACF,MAAA,CACkB,IAATmC,IAGXC,CAHWD,CAGXC,CAAe,EACfD,EAAMnC,GAAI,CAAA,CAId,OAAA,CAAa,IAATmC,EAAmB,GAChB1C,EAAKY,KAAAA,CAAMmC,EAAOL,EAE7B,EAEAQ,QAAS,SAAiBlD,CAAAA,EACxBqB,EAAWrB,GAQX,IAPA,IAAImD,EAAAA,CAAY,EACZC,EAAY,EACZV,EAAAA,CAAO,EACPC,EAAAA,CAAe,EAGfU,EAAc,EACT9C,EAAIP,EAAKQ,MAAAA,CAAS,EAAGD,GAAK,EAAA,EAAKA,EAAG,CACzC,IAAIL,EAAOF,EAAKS,UAAAA,CAAWF,GAC3B,GAAa,KAATL,EAAAA,CASS,IAATwC,GAGFC,EAHED,CAGFC,CAAe,EACfD,EAAMnC,GAAI,CAAA,CAEC,KAATL,EAAAA,CAEkB,IAAdiD,EACFA,EAAW5C,EACY,IAAhB8C,IACPA,CADOA,EACO,CAAA,CAAA,CACK,IAAdF,IAGTE,CAHSF,CAGTE,EAAe,CAAA,MArBb,GAAA,CAAKV,EAAc,CACjBS,EAAY7C,EAAI,EAChB,KACF,CAoBN,CAEA,OAAA,CAAkB,IAAd4C,GAAAA,CAA4B,IAATT,GAEH,IAAhBW,GAEgB,IAAhBA,GAAqBF,IAAaT,EAAM,GAAKS,IAAaC,EAAY,EACjE,GAEFpD,EAAKY,KAAAA,CAAMuC,EAAUT,EAC9B,EAEAY,OAAQ,SAAgBC,CAAAA,MAlVpBE,EACAE,EAkVF,GAAmB,OAAfJ,GAA6C,UAAA,OAAfA,EAChC,MAAM,AAAIT,UAAU,mEAAA,OAA4ES,GAElG,OAvVJ,EAuVwBA,AAtVZA,EAAWE,GAAAA,EAAOF,AADbC,CAAAA,CACwBE,CADnBH,CAAAA,EACmBG,GAC5BH,EAAWI,IAAAA,EAAAA,CAASJ,EAAWK,IAAAA,EAAQ,EAAA,CAAA,EAAOL,EAAWV,AAAlB,GAAkBA,EAAO,EAAA,CAAA,CACtEY,EAGDA,IAAQF,EAAWG,IAAAA,CACdD,EAAME,EAERF,EA8UU,IA9UEE,EALVA,CAoVT,EAEAG,MAAO,SAAe9D,CAAAA,EACpBqB,EAAWrB,GAEX,IAAI+D,EAAM,CAAEL,KAAM,GAAID,IAAK,GAAIE,KAAM,GAAId,IAAK,GAAIe,KAAM,EAAA,EACxD,GAAoB,IAAhB5D,EAAKQ,MAAAA,CAAc,OAAOuD,EAC9B,IAEIhB,EAFA7C,EAAOF,EAAKS,UAAAA,CAAW,GACvBc,EAAsB,KAATrB,EAEbqB,GACFwC,CADExC,CACEmC,IAAAA,CAAO,IACXX,GAAQ,CAAA,CAERA,EAAQ,EAaV,IAXA,IAAII,EAAAA,CAAY,EACZC,EAAY,EACZV,EAAAA,CAAO,EACPC,EAAAA,CAAe,EACfpC,EAAIP,EAAKQ,MAAAA,CAAS,EAIlB6C,EAAc,EAGX9C,GAAKwC,EAAAA,EAASxC,EAEnB,GAAa,MADbL,CACa,CADNF,EAAKS,UAAAA,CAAWF,EAAAA,CAAAA,CAAAA,CAUV,IAATmC,IAGFC,CAHED,CAGFC,CAAe,EACfD,EAAMnC,GAAI,CAAA,CAEC,KAATL,EAAAA,CAEkB,IAAdiD,EAAiBA,EAAW5C,EAA2B,IAAhB8C,IAAmBA,CAAnBA,EAAiC,CAAA,CAAA,CACrD,IAAdF,IAGXE,CAHWF,CAGXE,EAAe,CAAA,MAlBb,GAAA,CAAKV,EAAc,CACjBS,EAAY7C,EAAI,EAChB,KACF,CAwCN,OAAA,CArBkB,IAAd4C,GAAAA,CAA4B,IAATT,GAEP,IAAhBW,GAEgB,IAAhBA,GAAqBF,IAAaT,EAAM,GAAKS,IAAaC,EAAY,EAAA,CACvD,IAATV,IACiCqB,CADjCrB,CACqCiB,IAAAA,CAAOI,EAAIH,IAAAA,CAAhC,IAAdR,GAAmB7B,EAAkCvB,EAAKY,KAAAA,CAAM,EAAG8B,GAAgC1C,EAAKY,KAAAA,CAAMwC,EAAWV,EAAAA,CAAAA,EAG7G,EAH6GA,EAG3HU,GAAmB7B,GACrBwC,CADqBxC,CACjBqC,IAAAA,CAAO5D,EAAKY,KAAAA,CAAM,EAAGuC,GACzBY,EAAIJ,IAAAA,CAAO3D,EAAKY,KAAAA,CAAM,EAAG8B,EAAAA,CAAAA,EAEzBqB,EAAIH,AAFqBlB,IAErBkB,CAAO5D,EAAKY,KAAAA,CAAMwC,EAAWD,GACjCY,EAAIJ,IAAAA,CAAO3D,EAAKY,KAAAA,CAAMwC,EAAWV,EAAAA,CAAAA,CAEnCqB,EAAIlB,GAAAA,CAAM7C,EAAKY,KAAAA,CAAMuC,EAAUT,EAAAA,CAAAA,CAG7BU,EAAY,EAAGW,EAAIN,GAAAA,CAAMzD,EAAKY,KAAAA,CAAM,EAAGwC,EAAY,GAAY7B,IAAYwC,CAAZxC,CAAgBkC,GAAAA,CAAM,GAAA,CAAA,CAElFM,CACT,EAEAP,IAAK,IACLQ,UAAW,IACXC,MAAO,KACPpD,MAAO,IAAA,EAGTA,EAAMA,KAAAA,CAAQA,EAEdqD,EAAOC,OAAAA,CAAUtD,C,C,EK/gBbuD,GAA2B,CAAC,EAGhC,SAASC,GAAoBC,CAAAA,EAE5B,IAAIC,EAAeH,EAAAA,CAAyBE,EAAAA,CAC5C,GAAA,KAAqBnD,IAAjBoD,EACH,OAAOA,EAAaJ,OAAAA,CAGrB,IAAID,EAASE,EAAAA,CAAyBE,EAAAA,CAAY,CAGjDH,QAAS,CAAC,CAAA,EAOX,OAHAK,EAAAA,CAAoBF,EAAAA,CAAUJ,EAAQA,EAAOC,OAAAA,CAASE,IAG/CH,EAAOC,OAAAA,AACf,CCrBAE,GAAoBI,CAAAA,CAAI,CAACN,EAASO,KACjC,IAAI,IAAIC,KAAOD,EACXL,GAAoBO,CAAAA,CAAEF,EAAYC,IAAAA,CAASN,GAAoBO,CAAAA,CAAET,EAASQ,IAC5EE,OAAOC,cAAAA,CAAeX,EAASQ,EAAK,CAAEI,WAAAA,CAAY,EAAMC,IAAKN,CAAAA,CAAWC,EAAAA,EAE1E,ECNDN,GAAoBO,CAAAA,CAAI,CAACK,EAAKC,IAAUL,OAAOM,SAAAA,CAAUC,cAAAA,CAAeC,IAAAA,CAAKJ,EAAKC,GCClFb,GAAoBiB,CAAAA,CAAAA,AAAKnB,IACH,IAAA,OAAXoB,QAA0BA,OAAOC,WAAAA,EAC1CX,OAAOC,cAAAA,CAAeX,EAASoB,OAAOC,WAAAA,CAAa,CAAEC,MAAO,QAAA,GAE7DZ,OAAOC,cAAAA,CAAeX,EAAS,aAAc,CAAEsB,MAAAA,CAAO,CAAA,EAAO,E,I,G,C,E,C,SCQnDC,G,G,C,C,I,G,C,C,G,C,I,I,E,M,I,C,GAEY,UAAA,OAAZtE,GAAAA,OAAAA,EACVsE,EAAiC,UAArBtE,GAAAA,OAAAA,CAAQuE,QAAAA,CACW,UAAA,OAAdC,WAAwB,CAEzCF,EAAYG,AADID,UAAUC,SAAAA,CACJC,OAAAA,CAAQ,YAAc,GCV7C,IAAMC,EAAiB,iBACjBC,EAAoB,MACpBC,EAAoB,QAE1B,SAASC,EAAanC,CAAAA,CAAUoC,CAAAA,EAG/B,GAAA,CAAKpC,EAAIqC,MAAAA,EAAUD,EAClB,MAAM,AAAIE,MAAM,CAAA,wDAAA,EAA2DtC,EAAIuC,SAAAA,CAAAA,UAAAA,EAAsBvC,EAAI/D,IAAAA,CAAAA,WAAAA,EAAkB+D,EAAIwC,KAAAA,CAAAA,cAAAA,EAAsBxC,EAAIyC,QAAAA,CAAAA,EAAAA,CAAAA,EAK1J,GAAIzC,EAAIqC,MAAAA,EAAAA,CAAWL,EAAeU,IAAAA,CAAK1C,EAAIqC,MAAAA,EAC1C,MAAM,AAAIC,MAAM,mDAQjB,GAAItC,EAAI/D,IAAAA,EACP,GAAI+D,EAAIuC,SAAAA,CACP,CADOA,GACP,CAAKN,EAAkBS,IAAAA,CAAK1C,EAAI/D,IAAAA,EAC/B,MAAUqG,AAAJ,MAAU,2IAAA,MAGjB,GAAIJ,EAAkBQ,IAAAA,CAAK1C,EAAI/D,IAAAA,EAC9B,MAAUqG,AAAJ,MAAU,4HAAA,CAIpB,CAkCA,IAEMO,EAFAF,AAEU,8DAkBT,OAAMG,EAEZ,OAAA,KAAOC,CAAMC,CAAAA,CAAAA,CACZ,OAAIA,aAAiBF,GAAAA,CAAAA,CAGhBE,GAGoC,UAAA,OAArBA,EAAOT,SAAAA,EACU,UAAA,OAApBS,EAAOP,QAAAA,EACS,UAAA,OAAhBO,EAAO/G,IAAAA,EACU,UAAA,OAAjB+G,EAAOR,KAAAA,EACW,UAAA,OAAlBQ,EAAOX,MAAAA,EACW,UAAA,OAAlBW,EAAOC,MAAAA,EACS,YAAA,OAAhBD,EAAOE,IAAAA,EACa,YAAA,OAApBF,EAAOG,QACzB,AADyBA,CAOhBd,MAAAA,CAMAE,SAAAA,CAKAtG,IAAAA,AAKAuG,MAAAA,AAKAC,SAeT,aAAsBW,CAAAA,CAAsCb,CAAAA,CAAoBtG,CAAAA,CAAeuG,CAAAA,CAAgBC,CAAAA,CAAmBL,EAAAA,CAAmB,CAAA,CAAA,CAExH,UAAA,OAAjBgB,GACVC,CADUD,GACVC,CAAKhB,MAAAA,CAASe,EAAaf,MAAAA,IAAUM,CACrCU,IAAAA,CAAKd,SAAAA,CAAYa,EAAab,SAAAA,IAAaI,CAC3CU,IAAAA,CAAKpH,IAAAA,CAAOmH,EAAanH,IAAAA,IAAQ0G,CACjCU,IAAAA,CAAKb,KAAAA,CAAQY,EAAaZ,KAAAA,IAASG,CACnCU,IAAAA,CAAKZ,QAAAA,CAAWW,EAAaX,QAAAA,IAAYE,CAAAA,EAKzCU,EALyCV,EAKzCU,CAAKhB,MAAAA,CAvHR,SAAoBA,CAAAA,CAAgBD,CAAAA,EACnC,OAAKC,GAAWD,EAGTC,EAFC,MAGT,CAkHiBiB,CAAWF,EAAchB,GACvCiB,IAAAA,CAAKd,SAAAA,CAAYA,KAAaI,CAC9BU,IAAAA,CAAKpH,IAAAA,CAjHR,SAA8BoG,CAAAA,CAAgBpG,CAAAA,EAM7C,OAAQoG,GACP,IAAK,QACL,IAAK,OACL,IAAK,OACCpG,QAEMA,CAAAA,CAAK,EAAA,GACfA,EADsB2G,AACfA,KADeA,AACN3G,CAAAA,CAFhBA,IAAO2G,CAAAA,CAMV,OAAO3G,CACR,CA+FesH,CAAqBF,IAAAA,CAAKhB,MAAAA,CAAQpG,KAAQ0G,EACtDU,IAAAA,CAAKb,KAAAA,CAAQA,KAASG,CACtBU,IAAAA,CAAKZ,QAAAA,CAAWA,KAAYE,CAE5BR,EAAakB,IAAAA,CAAMjB,EAAAA,CAAAA,AAErB,CA4BA,IAAA,MAAIa,EAAAA,CAIH,OAAOO,EAAYH,IAAAA,CAAAA,CAAM,EAC1B,CAIA,KAAKI,CAAAA,CAAAA,CAEJ,GAAA,CAAKA,EACJ,OAAOJ,IAAAA,CAGR,GAAA,CAAI,OAAEhB,CAAAA,CAAM,UAAEE,CAAAA,CAAS,KAAEtG,CAAAA,CAAI,MAAEuG,CAAAA,CAAK,SAAEC,CAAAA,CAAAA,CAAagB,EA2BnD,OAAA,KA1BerG,IAAXiF,EACHA,EAASgB,IAAAA,CAAKhB,MAAAA,CACO,OAAXA,GACVA,EADUA,GACDM,CAAAA,CAAAA,KAEQvF,IAAdmF,EACHA,EAAYc,IAAAA,CAAKd,SAAAA,CACO,OAAdA,IACVA,CADUA,GACEI,CAAAA,CAAAA,KAEAvF,IAATnB,EACHA,EAAOoH,IAAAA,CAAKpH,IAAAA,CACO,OAATA,GACVA,EADUA,GACH0G,CAAAA,CAAAA,KAEMvF,IAAVoF,EACHA,EAAQa,IAAAA,CAAKb,KAAAA,CACO,OAAVA,IACVA,CADUA,GACFG,CAAAA,CAAAA,KAEQvF,IAAbqF,EACHA,EAAWY,IAAAA,CAAKZ,QAAAA,CACO,OAAbA,GACVA,EADUA,GACCE,CAAAA,CAGRN,IAAWgB,IAAAA,CAAKhB,MAAAA,EAChBE,IAAcc,IAAAA,CAAKd,SAAAA,EACnBtG,IAASoH,IAAAA,CAAKpH,IAAAA,EACduG,IAAUa,IAAAA,CAAKb,KAAAA,EACfC,IAAaY,IAAAA,CAAKZ,QAAAA,CAEdY,IAAAA,CAGD,IAAIK,EAAIrB,EAAQE,EAAWtG,EAAMuG,EAAOC,EAChD,CAUA,OAAA,KAAO1C,CAAM2B,CAAAA,CAAeU,EAAAA,CAAmB,CAAA,CAAA,CAC9C,IAAMuB,EAAQd,EAAQe,IAAAA,CAAKlC,GAC3B,OAAKiC,EAGE,IAAID,EACVC,CAAAA,CAAM,EAAA,EAnMM,EAmMAhB,CACZkB,CAnMGjB,CAmMWe,CAAAA,CAAM,EAAA,IAAMhB,EAC1BkB,EAAcF,CAAAA,CAAM,EAAA,IAAMhB,EAC1BkB,EAAcF,CAAAA,CAAM,EAAA,IAAMhB,EAC1BkB,EAAcF,CAAAA,CAAM,EAAA,IAAMhB,EAC1BP,GARO,IAAIsB,EAAIf,GAAQA,GAAQA,GAAQA,GAAQA,GAUjD,CAuBA,OAAA,IAAOmB,CAAK7H,CAAAA,CAAAA,CAEX,IAAIsG,IAAYI,CAWhB,GANIhB,IACH1F,CADG0F,CACI1F,EAAK8H,OAAAA,CAAQ,OAAOnB,GAAAA,CAAAA,CAKxB3G,OAAAA,CAAK,EAAA,EAAiBA,GAAV2G,IAAU3G,CAAK,EAAA,CAAe,CAC7C,GADqC2G,CAC/BoB,EAAM/H,EAAK8F,OAAAA,CAAQa,IAAQ,GAAA,CACpB,IAAToB,GACHzB,CADGyB,CACS/H,EAAKgI,SAAAA,CAAU,GAC3BhI,EAjPW,GAiPJ2G,CAAAA,EAEPL,EAFOK,AAEK3G,EAAKgI,SAAAA,CAAU,EAAGD,GAC9B/H,EAAOA,EAAKgI,SAAAA,CAAUD,OAAQpB,CAAAA,A,CAIhC,OAAO,IAAIc,EAAI,OAAQnB,EAAWtG,GAAM0G,GAAQA,EACjD,CAEA,OAAA,IAAO7E,CAAKoG,CAAAA,CAAAA,CACX,IAAMC,EAAS,IAAIT,EAClBQ,EAAW7B,MAAAA,CACX6B,EAAW3B,SAAAA,CACX2B,EAAWjI,IAAAA,CACXiI,EAAW1B,KAAAA,CACX0B,EAAWzB,QAAAA,EAGZ,OADAN,EAAagC,EAAAA,CAAQ,GACdA,CACR,CAeA,QAAAhB,CAASiB,EAAAA,CAAwB,CAAA,CAAA,CAChC,OAAOC,EAAahB,IAAAA,CAAMe,EAC3B,CAEA,MAAAE,EAAAA,CACC,OAAOjB,IAAAA,AACR,CAMA,OAAA,MAAOkB,CAAOC,CAAAA,CAAAA,CACb,GAAKA,EAEE,CAAA,GAAIA,aAAgB1B,EAC1B,OAAO0B,CACD,EACN,IAAML,EAAS,IAAIT,EAAIc,GAGvB,OAFAL,EAAOM,UAAAA,CAAwBD,EAAME,QAAAA,CACrCP,EAAOQ,OAAAA,CAAqBH,EAAMI,IAAAA,GAASC,EAA4BL,EAAMvB,MAAAA,CAAS,KAC/EkB,C,C,CAPP,OAAYK,CASd,CAAA,CAkBD,IAAMK,EAAiBlD,EAAY,EAAA,KAAIvE,CAGvC,OAAMsG,UAAYZ,EAEjB2B,WAA4B,IAAA,CAC5BE,QAAyB,IAAA,AAEzB,KAAA,MAAa1B,EAAAA,CAIZ,OAHKI,IAAAA,CAAKsB,OAAAA,GACTtB,CADSsB,GACTtB,CAAKsB,OAAAA,CAAUnB,EAAYH,IAAAA,CAAAA,CAAM,EAAA,CAAA,CAE3BA,IAAAA,CAAKsB,OACb,CAES,QAAAxB,CAASiB,EAAAA,CAAwB,CAAA,CAAA,CACzC,OAAKA,EAOGC,EAAahB,IAAAA,CAAAA,CAAM,IANrBA,CAMqB,GANrBA,CAAKoB,UAAAA,GACTpB,CADSoB,GACTpB,CAAKoB,UAAAA,CAAaJ,EAAahB,IAAAA,CAAAA,CAAM,EAAA,CAAA,CAE/BA,IAAAA,CAAKoB,UAAAA,CAKd,CAES,MAAAH,EAAAA,CACR,IAAMlI,EAAgB,CACrB0I,KAAM,CAAA,EA0BP,OAvBIzB,IAAAA,CAAKsB,OAAAA,EACRvI,EADQuI,CACJ1B,MAAAA,CAASI,IAAAA,CAAKsB,OAAAA,CAClBvI,EAAIwI,IAAAA,EAAOC,CAAAA,CAERxB,IAAAA,CAAKoB,UAAAA,GACRrI,CADQqI,CACJC,QAAAA,CAAWrB,IAAAA,CAAKoB,UAAAA,EAGjBpB,IAAAA,CAAKpH,IAAAA,GACRG,CADQH,CACJA,IAAAA,CAAOoH,IAAAA,CAAKpH,IAAAA,EAEboH,IAAAA,CAAKhB,MAAAA,GACRjG,CADQiG,CACJA,MAAAA,CAASgB,IAAAA,CAAKhB,MAAAA,EAEfgB,IAAAA,CAAKd,SAAAA,GACRnG,CADQmG,CACJA,SAAAA,CAAYc,IAAAA,CAAKd,SAAAA,EAElBc,IAAAA,CAAKb,KAAAA,GACRpG,CADQoG,CACJA,KAAAA,CAAQa,IAAAA,CAAKb,KAAAA,EAEda,IAAAA,CAAKZ,QAAAA,GACRrG,CADQqG,CACJA,QAAAA,CAAWY,IAAAA,CAAKZ,QAAAA,EAEdrG,CACR,CAAA,CAID,IAAM2I,EAAwC,CAC7C,GAAkB,MAClB,GAAkB,MAClB,GAAyB,MACzB,GAAiB,MACjB,GAA8B,MAC9B,GAA+B,MAC/B,GAAmB,MAEnB,GAA4B,MAC5B,GAAuB,MACvB,GAAsB,MACtB,GAAwB,MACxB,GAAsB,MACtB,GAAuB,MACvB,GAAqB,MACrB,GAAiB,MACjB,GAAkB,MAClB,GAAsB,MACtB,GAAmB,MAEnB,GAAkB,KAAA,EAGnB,SAASC,EAAuBC,CAAAA,CAAsBC,CAAAA,CAAiBC,CAAAA,EACtE,IAAI/I,EACAgJ,EAAAA,CAAmB,EAEvB,IAAK,IAAIC,EAAM,EAAGA,EAAMJ,EAAaxI,MAAAA,CAAQ4I,IAAO,CACnD,IAAMlJ,EAAO8I,EAAavI,UAAAA,CAAW2I,GAGrC,GACElJ,GAAQ,IAAcA,GAAQ,KAC3BA,GAAQ,IAAcA,GAAQ,IAC9BA,GAAQ,IAAmBA,GAAQ,IAC3B,KAATA,GACS,KAATA,GACS,KAATA,GACS,MAATA,GACC+I,GAAmB,KAAT/I,GACVgJ,GAAwB,KAAThJ,GACfgJ,GAAwB,KAAThJ,GACfgJ,GAAwB,KAAThJ,EAAAA,CAGM,IAArBiJ,IACHhJ,CADGgJ,EACIE,mBAAmBL,EAAahB,SAAAA,CAAUmB,EAAiBC,IAClED,EAAAA,EAAmB,CAAA,CAAA,KAGRhI,IAARhB,IACHA,CADGA,EACI6I,EAAaM,MAAAA,CAAOF,EAAAA,CAAAA,KAGtB,CAAA,KAEMjI,IAARhB,IACHA,CADGA,CACG6I,EAAaO,MAAAA,CAAO,EAAGH,EAAAA,CAAAA,CAI9B,IAAMI,EAAUV,CAAAA,CAAY5I,EAAAA,MACZiB,IAAZqI,GAAAA,CAAAA,AAGsB,IAArBL,IACHhJ,CADGgJ,EACIE,mBAAmBL,EAAahB,SAAAA,CAAUmB,EAAiBC,IAClED,EAAAA,EAAmB,CAAA,CAIpBhJ,IAAOqJ,CAAAA,CAAAA,CAEwB,IAArBL,IAEVA,CAFUA,EAEQC,CAAAA,A,C,CASrB,OAAA,CAJyB,IAArBD,IACHhJ,CADGgJ,EACIE,mBAAmBL,EAAahB,SAAAA,CAAUmB,GAAAA,CAAAA,CAAAA,KAGnChI,IAARhB,EAAoBA,EAAM6I,CAClC,CAEA,SAASS,EAA0BzJ,CAAAA,EAClC,IAAIG,EACJ,IAAK,IAAIiJ,EAAM,EAAGA,EAAMpJ,EAAKQ,MAAAA,CAAQ4I,IAAO,CAC3C,IAAMlJ,EAAOF,EAAKS,UAAAA,CAAW2I,EAChB,MAATlJ,GAAmC,KAATA,GAAAA,CAAAA,IACjBiB,IAARhB,IACHA,CADGA,CACGH,EAAKuJ,MAAAA,CAAO,EAAGH,EAAAA,CAAAA,CAEtBjJ,GAAO2I,CAAAA,CAAY5I,EAAAA,EAAAA,KAEPiB,IAARhB,IACHA,CADGA,EACIH,CAAAA,CAAKoJ,EAAAA,C,CAIf,OAAA,KAAejI,IAARhB,EAAoBA,EAAMH,CAClC,CAKO,SAASuH,EAAYmC,CAAAA,CAAUC,CAAAA,EAErC,IAAIlE,EAsBJ,OAnBCA,EAFGiE,EAAIpD,SAAAA,EAAaoD,EAAI1J,IAAAA,CAAKQ,MAAAA,CAAS,GAAoB,SAAfkJ,EAAItD,MAAAA,CAEvC,CAAA,EAAA,EAAKsD,EAAIpD,SAAAA,CAAAA,EAAYoD,EAAI1J,IAAAA,CAAAA,CAAAA,CAEN,KAA3B0J,EAAI1J,IAAAA,CAAKS,UAAAA,CAAW,KAChBiJ,CADgB,CACZ1J,IAAAA,CAAKS,UAAAA,CAAW,IAAM,IAAwC,IAA1BiJ,EAAI1J,IAAAA,CAAKS,UAAAA,CAAW,IAAoBiJ,EAAI1J,IAAAA,CAAKS,UAAAA,CAAW,IAAM,IAAwC,KAA1BiJ,EAAI1J,IAAAA,CAAKS,UAAAA,CAAW,EAAM,CAAA,EACxH,KAA3BiJ,EAAI1J,IAAAA,CAAKS,UAAAA,CAAW,GAElBkJ,EAIID,EAAI1J,IAAAA,CAAKuJ,MAAAA,CAAO,GAFhBG,EAAI1J,IAAAA,CAAK,EAAA,CAAG4J,WAAAA,GAAgBF,EAAI1J,IAAAA,CAAKuJ,MAAAA,CAAO,GAM7CG,EAAI1J,IAAAA,CAET0F,IACHD,CADGC,CACKD,EAAMqC,OAAAA,CAAQ,MAAO,KAAA,CAAA,CAEvBrC,CACR,CAKA,SAAS2C,EAAasB,CAAAA,CAAUvB,CAAAA,EAE/B,IAAM0B,EAAW1B,EAEdsB,EADAV,EAGC5I,EAAM,GAAA,CACN,OAAEiG,CAAAA,CAAM,UAAEE,CAAAA,CAAS,KAAEtG,CAAAA,CAAI,MAAEuG,CAAAA,CAAK,SAAEC,CAAAA,CAAAA,CAAakD,EASnD,GARItD,IACHjG,CADGiG,EACIA,EACPjG,GAAO,GAAA,CAAA,CAAA,CAEJmG,GAAwB,SAAXF,CAAAA,IAChBjG,CADgBiG,IACTO,EACPxG,MAAOwG,CAAAA,CAEJL,EAAW,CACd,IAAIyB,EAAMzB,EAAUR,OAAAA,CAAQ,KAC5B,GAAA,CAAa,IAATiC,EAAY,CAEf,IAAM+B,EAAWxD,EAAUiD,MAAAA,CAAO,EAAGxB,GACrCzB,EAAYA,EAAUiD,MAAAA,CAAOxB,EAAM,GACR,CACd,KADbA,CACIA,CADE+B,EAASnJ,WAAAA,CAAY,IAAA,EAE1BR,GAAO0J,EAAQC,EAAAA,CAAU,EAAA,CAAO,IAGhC3J,CAHgC,EAGzB0J,EAAQC,EAASP,MAAAA,CAAO,EAAGxB,GAAAA,CAAM,EAAA,CAAO,GAC/C5H,GAAO,IACPA,GAAO0J,EAAQC,EAASP,MAAAA,CAAOxB,EAAM,GAAA,CAAI,EAAA,CAAO,EAAA,CAAA,CAEjD5H,GAAO,G,CAGoB,CACf,KADb4H,CACIA,CADEzB,CADNA,EAAYA,EAAUsD,WAAAA,EAAAA,EACNjJ,WAAAA,CAAY,IAAA,EAE3BR,GAAO0J,EAAQvD,EAAAA,CAAW,EAAA,CAAO,GAGjCnG,EAHiC,EAG1B0J,EAAQvD,EAAUiD,MAAAA,CAAO,EAAGxB,GAAAA,CAAM,EAAA,CAAO,GAChD5H,GAAOmG,EAAUiD,MAAAA,CAAOxB,EAAAA,CAAAA,A,CAG1B,GAAI/H,EAAM,CAET,GAAIA,EAAKQ,MAAAA,EAAU,GAA4B,KAAvBR,EAAKS,UAAAA,CAAW,IAAgD,KAAvBT,EAAKS,UAAAA,CAAW,GAAuB,CACvG,IAAMP,EAAOF,EAAKS,UAAAA,CAAW,GACzBP,GAAQ,IAAcA,GAAQ,KACjCF,CADiC,CAC1B,CAAA,CAAA,EAAI+J,OAAOC,YAAAA,CAAa9J,EAAO,IAAA,CAAA,EAAOF,EAAKuJ,MAAAA,CAAO,GAAA,CAAA,C,MAEpD,GAAIvJ,EAAKQ,MAAAA,EAAU,GAA4B,KAAvBR,EAAKS,UAAAA,CAAW,GAAuB,CACrE,IAAMP,EAAOF,EAAKS,UAAAA,CAAW,GACzBP,GAAQ,IAAcA,GAAQ,KACjCF,CADiC,CAC1B,CAAA,EAAG+J,OAAOC,YAAAA,CAAa9J,EAAO,IAAA,CAAA,EAAOF,EAAKuJ,MAAAA,CAAO,GAAA,CAAA,C,CAI1DpJ,GAAO0J,EAAQ7J,EAAAA,CAAM,EAAA,CAAM,E,CAU5B,OARIuG,IACHpG,CADGoG,EACI,IACPpG,GAAO0J,EAAQtD,EAAAA,CAAO,EAAA,CAAO,EAAA,CAAA,CAE1BC,IACHrG,CADGqG,EACI,IACPrG,GAAQgI,EAAgE3B,EAAjDuC,EAAuBvC,EAAAA,CAAU,EAAA,CAAO,EAAA,CAAA,CAEzDrG,CACR,CAgBA,IAAMiK,EAAiB,8BAEvB,SAASxC,EAAcsC,CAAAA,EACtB,OAAKA,EAAIxC,KAAAA,CAAM0C,GAGRF,EAAIpC,OAAAA,CAAQsC,EAAAA,AAAiB1C,GAAUuC,CAlB/C,SAASA,EAA2BC,CAAAA,EACnC,GAAA,CACC,OAAOC,mBAAmBD,E,CACzB,KAAA,CACD,OAAIA,EAAI1J,MAAAA,CAAS,EACT0J,EAAIX,MAAAA,CAAO,EAAG,GAAKU,EAA2BC,EAAIX,MAAAA,CAAO,IAEzDW,C,EAGV,EAQ0ExC,IAFjEwC,CAGT,C,MC9pBiBK,E,E,G,KAHjB,IAAMF,EAAY,EAAA,KAAA,EAAkB,CAkBhB,EAjBdC,AAEWC,CAAAA,CAAAA,IAAAA,CAAAA,CAAK,EAAA,CAAA,EAeFC,QAAAA,CAAhB,SAAyBd,CAAAA,CAAAA,GAAae,CAAAA,EAClC,OAAOf,EAAIzC,IAAAA,CAAK,CAAEjH,KAAMqK,EAAU5I,IAAAA,CAAKiI,EAAI1J,IAAAA,IAASyK,EAAAA,EACxD,EAgBgB,EAAAC,WAAAA,CAAhB,SAA4BhB,CAAAA,CAAAA,GAAae,CAAAA,EACrC,IAAIzK,EAAO0J,EAAI1J,IAAAA,CACX2K,EAAAA,CAAa,QACb3K,CAAAA,CAAK,EAAA,GACLA,EAAOsK,AADKA,IACGtK,CADHsK,CAEZK,EAAAA,EAAa,CAAA,CAEjB,IAAI3J,EAAeqJ,EAAUvJ,OAAAA,CAAQd,KAASyK,GAI9C,OAHIE,SAAc3J,CAAAA,CAAa,EAAA,EAAOsJ,CAAUZ,EAAVY,AAAchE,SAAAA,EAChDtF,EADgDsF,CACjCtF,EAAagH,SAAAA,CAAU,EAAA,CAAA,CAEnC0B,EAAIzC,IAAAA,CAAK,CAAEjH,KAAMgB,CAAAA,EAC5B,EAUgB,EAAAwB,OAAAA,CAAhB,SAAwBkH,CAAAA,EACpB,GAAwB,IAApBA,EAAI1J,IAAAA,CAAKQ,MAAAA,EA1DP,MA0DuBkJ,EAAI1J,IAAAA,CAC7B,IADsCsK,GAC/BZ,EAEX,IAAI1J,EAAOqK,EAAU7H,OAAAA,CAAQkH,EAAI1J,IAAAA,EAIjC,OAHoB,IAAhBA,EAAKQ,MAAAA,EAAuC,KAAvBR,EAAKS,UAAAA,CAAW,KACrCT,CADqC,CAC9B,EAAA,CAAA,CAEJ0J,EAAIzC,IAAAA,CAAK,CAAEjH,KAAAA,CAAAA,EACtB,EAUgB,EAAA4C,QAAAA,CAAhB,SAAyB8G,CAAAA,EACrB,OAAOW,EAAUzH,QAAAA,CAAS8G,EAAI1J,IAAAA,CAClC,EAUgB,EAAAkD,OAAAA,CAAhB,SAAwBwG,CAAAA,EACpB,OAAOW,EAAUnH,OAAAA,CAAQwG,EAAI1J,IAAAA,CACjC,E,C,G,E,C,C,I,E,O,E,C,C,E,K8PjDQ,KAAA,GAAA,CAAA,CAAA,wVAsHiD,uDACU,CAAC,8DAIrC,kBAAA,CAAA,QAAA,CAA4B,uDAM0B,CAAA,CAAyC,qFAGxE,CMrDF,+GNiEjB,C3F7EpB,AmCLkB,AyByDA,CzBzDA,cwDsFc,CAAA,CAAA,CAAA,2EAMjC,EAAA,IAAA,CAAA,KAAA,CAAA,EAAA,EAA0C,ChG1BJ,AtKrCJ,gFsQmEX,EAAA,MAAA,cAA8B,C9KxBP,CAAA,a8KwBwB,EAAE,CAAE,CAAC,MOpGM,CPqGhF,IAAA,CAAA,qBAAA,CAAA,EAA2C,UAG9B,IAAA,CAAK,KAAA,CAAA,EAAA,EAAsB,OAAO,EAAE,C9FhCR,A8FgCU,C9FhCR,wC8FiCE,UAI5C,YAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,4BAEF,EAAA,MAAA,IAAwB,CAAC,CpP9CP,AyPvBwB,SAAA,CAAA,EAAA,ELqEW,gDACO,kCAEhB,CxCmBF,CwCnBU,OAAO,GAAI,uCACtB,EAAA,2BAeiC,CrDRpD,CAAA,CqDQgE,CAA2B,CS9F1E,AxIyEJ,A+HqBgF,C/HrB9E,A+HqB2F,CAAA,cAG3H,oCAGoB,YACf,EAAA,yDAIwC,CAAC,C7BcC,C6BdI,qDAK9C,EAAA,4DAOb,eAG+B,CAAA,CAAA,CAAA,CAAA,qCAEF,CAAC,CtPgBL,CwJnCO,G8FmBG,CAAC,M9FnBM,EAAA,A8FmBE,EAAA,KAAA,EAAA,EAAE,IAAI,CAAC,CnDlC+C,OAAA,8BmDmClE,EAAA,KAAA,EAAA,EAAE,GAAG,CAAC,EAAS,E5FG0C,C4FHvC,CAAC,EAAL,EpPrCuC,IoPqC1B,EAAE,CAAC,CAAC,EACzD,EAAA,EAAA,OAAA,GAAA,MAA8C,CxC+DA,GwC/DI,CAAC,kBAAkB,CAAC,QAAA,CAAS,EAAA,GAAA,8CAMpF,OACW,eAIY,GlD3DG,CAAA,CAAA,wBkD2D0B,CAAC,C9KTH,CAAC,A3EsFZ,GyP7E0B,CAAE,wGAajB,EpPrCF,CoPqCK,CAAA,EAAA,iCACI,cAElC,MAAA,4BAKT,eAAA,CAAA,WAAA,CAAA,6BACoB,CAAI,EAAM,EACxD,0BAGqB,IAAA,CAAA,eAAA,CAAA,WAAA,CAAA,SACK,CAAA,WAAA,CAAa,KAAK,CAAA,EAAU,8CAIrB,eAAA,OAEtB,mBAC6B,MAAM,CAClC,EAAI,CAAD,OAAS,EAAE,CAAE,EAAgB,WAAW,CAAC,CAAb,EAAgB,AAAE,CAAD,eAAiB,CAAC,UAAU,CAAE,CAAC,OAAE,EAAA,EAAI,AAAI,EAAJ,AAAM,CAC9F,EADwF,AACvF,QADmF,IAAI,KAAA,KAAA,uBA+E9B,2CAGf,CAAC,M/H3EF,CAAC,e+H2EuB,CAAC,G9BnKG,oB8BoK3C,eAAe,kBAIxC,EAAA,IAAA,CAAA,WAAA,CAAA,MAA8B,8BAIP,CAAA,QAAA,2BACL,SACf,MAAA,CAAA,yBAAA,EAAA,EAA+C,qBAAA,CAAuB,CAAC,CAAC,yDAMpD,UACvB,IAAA,CAAA,WAAA,CAAA,GAAA,CAAA,mHAQ8C,EAAK,CAAF,OACnD,CZxJS,UAAA,CAAA,4CYgKC,CAAA,sBAAA,CAAwB,UAAU,CAAC,EAAM,EAAF,AAAO,C9BvKF,A8BuKA,EAAqB,IAAA,CAAA,SACnE,WAAA,CAAY,yCAIuB,CAAC,CtQ9FL,CwKJH,Q8FkGkB,CAAC,EAAM,GAAG,ApPzDF,6BoP6DvE,CAAC,ApPxDF,CpBsBG,oDwQqC0C,0CAIV,EAAE,CAAC,A/HtDM,mB+HuDH,GAAA,CAAI,8CAEW,CAAC,GAAG,AAAE,C7BlED,A6BkEA,SAAW,CAAC,C7BlEC,CAAC,CAAC,G6BkEG,CAAC,qBAEtC,OAAA,8BAEtB,WAAW,MAAG,GAEtB,kBAGY,CAAA,OACD,EAAA,QAAA,SACK,CAAA,WAAA,CAAA,GAAA,CAAA,UACnB,YAAY,GACqB,OAAA,wBACV,CAAA,2HnD/XH,IAAA,EAAA,MAAA,CAAA,SAAA,CAAgC,gBAAA,qKAMP,CAAA,KAAM,yGAUnD,EAAA,IAAA,CAAA,6DAMY,gBAAA,CAAA,OACK,gBAAA,GAAA,WAAA,CAAA,EAAA,WAAA,EAAyD,CAAC,AiCvCA,C7JCvE,S4HwC+B,CAAC,WAAA,CAAA,kBACb,C7CpBhB,CAAA,IAAA,C6CoBmC,E7CnB5B,A7EEN,M0HiBe,UAAqC,CAAA,EAAU,C4BOrE,iG5BAwE,QAAQ,CAAA,EAAA,CAAI,CAAE,kBAC7D,EAAA,OAAA,EAAA,EAAyB,E6BhC4B,CAAC,CAAC,CAAC,EAAA,6C7BmC1E,QAAA,CAAS,gDAAA,EAAmD,EAAI,CAAD,OAAS,CAAA,GAAA,EAAM,EAAY,CAAE,EAC/F,CAAC,MAD4F,8KAqBzD,SAAA,CAAA,QAAA,eACtC,EAAA,EAAA,IAAmB,CAAC,kBAAkB,CAAC,sCAOxC,EAAA,mDAKqB,IAAA,aAEJ,CAAA,IAAA,uBACiB,IAAI,CAAA,gBAAiB,sCP1DlD,iBAAA,EAAA,IAAA,EAAA,UAAA,OAAA,EAAA,IAAA,CO0DkD,KAE3C,EAAA,EAAA,WAA+B,CAAC,IAAI,CAAC,gBAAA,oBAC/B,EAAA,EACD,OsB4C2E,CAAC,CAAC,StB5C3D,CAAC,WAAE,EAAW,OAAF,EAAW,CAAE,IAAI,OAAE,CAAQ,CAAE,CAAE,IAAI,CAAR,AAAS,gBAAgB,CAAC,CAAC,qDAI3D,SAAS,CAAC,AnMmCJ,EmMlC1B,CsD0IC,CAAA,atD1ImB,CAAA,aAAc,UAAW,YAAc,6BACX,cAAA,EAAgB,CAAC,qDAI7C,C1CsB4B,I0CtBvB,C3Hc/C,A2HdgD,qBiBvDuH,CAAC,CAAC,kBjByDzJ,I0D9DuD,KrGgEK,C2CFlD,CAAC,IAAA,CAAA,IAAA,eACT,IAAA,GAAA,wDAC6C,EAAO,IxC/BpD,AwC+BmD,UAAe,CAAC,SxC9BnE,EAAE,GwC8B+E,CAAC,GAAK,CAAD,AAAC,CAAA,CAAI,EAAQ,MAAA,IAAA,EAAa,EAAO,EAAA,CAAI,CAAC,CAAL,AAAM,2HAQ1G,CgDuGH,GAAA,CAAA,IAAA,CAAA,KAAA,yFhD7FL,MAEzB,EAAA,IAAA,CAAA,WAAA,CAAA,sBAEyB,MAAO,CnBMC,A2CnEA,AxB6DU,CAAE,6CAMhB,CAAC,EAAA,gFAIqC,SAAS,CAAC,MnM6CxD,EAAA,CAAA,EAAA,CAAA,CAAA,oBmM5CS,CpB7BJ,AgB9BA,MAAA,EAAA,EI2De,MuD9CgC,AvD8C1B,CAAC,SAC/C,sCAEI,C4DtDiC,CAAC,CpGiCD,AAAE,CAAD,AwCsBrC,CrNuEoC,A6K7FE,C7K6FO,MqNvEpC,CAAA,gDAAA,EAAmD,CzCiC/B,CACtC,AyClC6E,SAAS,CAAC,QAAQ,CAAA,GAAA,EAAM,EAAY,CAAE,EAC7G,OAD2G,8BAQzF,IAAI,2CAEiB,EAAgB,CjMDL,UiMCgB,CAAC,CAAC,c3CWc,4B2CPtD,CAAA,EAAK,WAAA,CAAY,KAAA,CAAO,CnBYG,A8BiFH,CtD5EJ,A2CjBoB,IAAI,CAAC,CAAC,4CAMpC,EAAA,SAAA,WACjB,CAAA,GAAA,cAA+B,EAAE,CAAC,C3H0BnD,W2HzBI,CAAA,6EAAA,EAAgF,EAAS,GAAG,CAAA,EAAA,CAAI,CAAC,CAAC,gFAI5G,GwBjEmC,SxBkE7B,CAAA,+BAAA,EAAkC,EAAa,QAAA,EAAW,EAAQ,KAAD,IAAU,CAAC,QAAQ,CAAA,EAAA,CAAI,CACjG,iBAAiB,EAAA,GACnB,+GyCxOO,IAAA,CAAA,GAAA,CAAA,CAAA,iMxK0Cf,KAAA,EwKjC+B,CAAC,CAAE,E1O4C0B,C0O5C7B,CAAC,CxKiChC,GwKjC0C,E9PqEmB,C8PrEjB,C9PsE3C,A8PtE2C,C9PsE1C,A8PtE2C,mHAMW,EAAA,MAAA,CAAW,CxC2CC,AwC3CA,CxC2CC,AwC3CA,AR0BA,gVVsBzB,cAAA,8BAK5B,EAAA,AC4IZ,SAAA,CAAyC,6BAIpC,IAAA,CAAA,MAAA,CAAA,EAAA,EAAA,SAAA,EAAA,KAAA,EAAA,EAA+B,OAAA,AAAO,GAAE,CAAC,IACtC,EAAA,GAAA,EAAwC,aAAa,CAAE,gCAOrE,CHyBC,AGzBA,CDxJiB,gCAG6C,EAAA,OAAA,CAAA,8HAQE,GAAA,EAAK,CtBVC,AqD6BA,A/BnBA,mJASmB,EAAQ,CAAC,CAAC,kFAUxF,EjE3BF,QAAA,CiE2BqB,oCAC6B,CAAA,kBACzC,EAAA,EAAsB,QAAA,SAAtB,+HAauC,CAAA,EAAA,IAAA,CAAA,WAA6B,CAAC,cAAc,CAAC,UAAU,CAAC,CAAC,CAAC,aACnF,eAC2B,GAAA,MAAe,CAAC,EAAI,SAAA,CAAW,EAAQ,KAAD,MAAY,EAAC,CAAC,CAAC,kIAUzD,CAAA,4EAM/B,EAAA,uFczHwB,oHA6B3B,2QAuCc,GAAA,CAAA,uBAEC,CAAA,IAAA,gDAWZ,GAAA,IAAA,CAAA,gBAEA,EAAA,kBAQR,CAAA,CAAA,CAAA,aACA,GAAA,CAAA,GAAA,CAAA,MAAc,MACV,GAAA,CAAA,GAAA,IAAA,IAAA,iCAIN,IAAA,UAM8C,CAAA,yBAEjD,EAAA,OAAA,CAAA,GAAA,EAAA,EAAyC,CxOyGoB,CwOzGf,AxOyGqB,CwOzGvB,AxOyGwB,GwOzGlB,2CAQnC,C/EmFL,A5JmDE,AuPuII,EAAA,QZ7QU,0BAOZ,CAAA,GAAA,CAAA,OAAA,IACb,OAAA,CAAA,CAAA,CAAA,EAAA,EAAA,GAAA,EAAgC,GAAA,CAAA,GAAa,KAAsB,CAAC,+BAO9C,6CAOU,uDAYvC,MAAA,0BAMc,GAAG,CAAC,IAAA,gCAJF,8CAYN,IAAA,CAAA,GAAA,CAAA,EAAA,oBAMC,KAAA,+BAIO,CAAA,iBACP,GAAA,CAAA,EAAA,GACT,IAAA,CAAA,OAAA,CAAA,GAAA,CAAA,EAAA,YAIA,CAAA,CAAA,qEAQS,CAAA,mBACiB,CAAC,EiBkXE,mBjBjXJ,EACrB,IAAA,CAAA,GAAQ,CAAA,MAAA,CAAA,sToBrHoI,CAAE,EAAA,GAAA,iBAAkD,CAAA,IAAA,CAAA,oFAMjK,2EAYlB,IAAI,CAAA,YAAA,CAAA,iBAA+B,CAAC,C1PST,AuOaU,CAAC,AxC6BA,E2DnDU,C3DmDC,CAAC,mD2D/CY,CAAC,IAAA,CAAA,KAC1E,EAAA,EAAA,WAAA,CAAA,KAAA,8DAK+B,mGAenB,CAAA,EAAA,IAAA,CAAA,YAAA,CAAA,iBAA+C,CAAC,EAAM,C3D8CxB,AtCxES,CiG0Ba,AAAQ,gHdrFvD,KAAA,EAAA,EAAA,SAAA,MAAA,AAAwB,GAAA,gLAaf,IAAA,CAAA,WAAgB,C7CsEkB,C6CtEhB,GAAA,EAAU,WAAW,C7CsEkB,C6CtEhB,EAAA,IAAA,CAAA,QAAA,CAAA,IAAA,CAAA,GAAA,EAAA,IAAA,GAChC,wDAKJ,CAAA,kTAwBoB,CrFUD,AkGVE,CbAC,A5OuBV,AyPvBU,CAAA,mEbMjC,CAAA,UAAA,CAAA,wCAMK,CAAA,QAAA,CAAA,MAAA,4CAEc,CAAA,UAAA,CAAA,cAAA,GAAA,8aY9D7B,CAAA,8QA2BN,CAAA,KAAA,yFAWO,EAAA,GAAuB,KAAK,CAAC,CAAC,+HAUV,EAAA,+FAU9B,GAAI,EAAA,wBAEU,EAAA,wFAcnB,CAAA,CAAA,gEAIY,CAAC,MAAA,CAAA,yHAWD,CAAA,GAAA,CAAK,EAAA,4DA+DV,SAAS,CAAC,IAAA,CAAA,EAAA,SAAA,CAAA,eAAA,CAA8C,YAAA,CAAA,EAAoB,G/FkC7B,A+FlCgC,EAAE,+CAG1C,CAAA,eAAA,CAAiB,C5C0JlB,A5MvGe,C4MuGd,A5MvGe,CAAC,KAAA,CAAA,CAAA,EwPnDqB,K5QgIhF,CgO2BiB,CACV,A4C5JgF,A5QgIvF,MAAA,CAAA,G4Q/H2B,+BAKd,CAAA,IAAA,CAAA,EAAA,SAA8B,CAAC,eAAe,CAAA,QAAS,CAAC,oFvBlK3B,6LAI0B,6IAY7C,MAAA,CAAA,6BAEA,CAAC,UAAU,CAAA,SAAU,CAAA,EAAA,IAAU,CAAE,M7EGnB,2S6EyBQ,CAAA,EAAA,+EAWF,IAAM,IAAI,GAAS,IAAA,CAAA,YAAiB,CAAC,GZyCG,CAAC,CAAC,CAAC,KYzCK,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC,6DlCK1C,mIAM+B,CAAC,CAAC,KnNNhG,yBmNiB8B,CAAA,SAAA,CAAA,gBAAA,uBACR,SAAA,CAAA,cAAA,+BACQ,CAAA,YAAA,qDACsB,CGxDC,AhIGF,A6HqDE,+BAI1B,CAAA,6BACM,CAAC,sBAC2B,CAAA,EAAA,EAAA,UACpB,IAAA,EAAA,EAAA,EAAgD,GAAmB,0EAI3E,EAAS,KAAK,CAAC,qDAM6B,CAAA,wDAChD,CAAA,uDAMwC,CAAA,SAAA,CAAU,CAAA,aAAA,CAAA,CAAA,CAAA,kJAuBvD,OAAA,EAAA,EAAW,6BAA6B,yEAdjB,CcAC,Af/DA,EC+DI,YAEL,GAAA,CAFqB,AAEhB,CAFiB,ID/DI,YCmE3B,uEAKT,+CAUO,yDAES,uCACrB,EAAS,K3C3BQ,MAAA,A2C2BG,CAAA,EAAE,CAAC,kEAEI,GAAG,CAAC,QAAQ,EAAA,CAAE,CAAC,mBAI3E,EAAA,OAAA,MAAA,CAAA,CAAA,EAAiB,EAAA,yBACK,EAAA,QAAA,AAAc,EAAA,KAAA,EAAA,EAAE,CtCtEzB,EAAE,CsCsE2B,eAG1C,C+BhEqD,C/BgE9C,A+BhE+C,ClCVC,AkCUA,AhDyCa,CcnDJ,CdmDM,AcnDL,EdmDO,EAAA,MAAA,CAAA,CAAA,EAAA,EAAA,YiBwBpD,CAAA,eAAA,CAAA,UAAA,CAAA,sDAKjB,CwBiB0C,AtB7CA,CAAA,sGFuClC,KAAA,yCAI6C,EAAA,SAAa,CAAC,CAAC,YACK,CAAA,wBAE9D,MAAA,CAAA,GAAA,CAAA,EAAA,UAA6B,CAAC,EqDSK,CrDTF,GAAA,OAAA,CAAA,qBACO,E0BhHN,AxBiFQ,MF+BM,Q0B9G/D,EAAA,M1B8GiE,C0B5FC,CAAC,CAAC,A1B4FA,C0B5GtB,A1B4GuB,CqDPnB,AhGvBtB,AzJ8BrC,MAAA,CAAA,CAAA,IoMA+E,GAAG,CAAC,yCAW9C,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAA0H,CwBgBtF,uBxBf7B,CF9FC,A0DgRA,MxDlLM,CAAC,IAAI,EAAG,qBAC5B,YACY,MAAM,CkDsFH,AUlLI,IAAA,S5D6Ff,EAAM,CACvB,GAAA,UAAkC,CjB3BC,AiB2BA,CjB3BC,qBiB4BmB,EAAM,EAAF,AAAW,CmBrFV,EnBsFzD,EAAA,oBACsC,EGpDsE,EHoDvD,EAAA,EAAoB,kBAG9C,C4D1FD,AzDwCA,AHkDE,C4D1FD,G5D2Fb,CAAC,eAAe,CAAC,EAAM,EAAF,AAAgB,EAAM,EAAF,AAAQ,OAAO,CAAC,CAAC,oBAE9B,CakDI,CAAA,eb9C/C,CAAA,yBADF,qCAMwB,CAAA,CAAA,CAAoB,CAAA,CAAA,CAAA,CAAiD,CAA+B,CAAA,C8C4CvF,M9C3CvC,EAAA,QAAA,+CAGwB,EAAU,IAAA,CAAA,EAAA,YAA0B,OACxD,CJaC,A7M/BV,AoN9BU,mBHkDO,CAAA,YAAA,CAAA,OAAqB,CAAC,EAAA,kEAY9B,EAAW,EAAE,AjBToC,EAAE,EAAE,IiBSrD,CkDiJiB,AMiII,CAAC,ANjIJ,CxB1OK,A5C6BA,A0CsFA,+JxBR8B,CAAA,QAC1D,qCAGL,OAAA,0CAIsB,gBAAA,CAAA,WAAA,CAAA,SAElB,MAAA,oCAAA,4BAE6B,WAEW,EAAI,CjBJE,AxGsBT,QAAA,CAAA,EyHlBoB,CwBiCC,CsCnHU,AtCmHT,CAAC,AsCnHS,C9DkFM,GAAI,KAAK,CAAC,EAAI,CAAD,QAAU,CAAC,CAAC,CAAE,aAAa,CAAC,CAAC,CAAC,WACxF,CAAC,C5ClDP,U4CkDkB,CAAC,G5ClDL,M4CoD1C,MAAA,oCAAA,WAEsB,MAAM,C8DlFC,AhEEA,AgEFA,G9DkFK,mBACP,CAAC,KAAK,CAAC,AAEtC,IAAA,EAAa,IAAA,CAAA,cAAmB,CAAA,UAAW,CAAC,EAAS,CwDoYN,CAAQ,SxDpYS,CAAC,IwDoYI,CxDpYC,CAAE,EAAI,CAAD,MwDoYQ,ExDpYE,CAAC,EAAgB,CAAC,CAAC,CAAC,CAAC,AwDoYA,EAAZ,uDxD/XpF,oBAKrB,4JoDrQsC,KpCjCsD,IoCiC7C,CAAC,CrQI/B,YqQJ4C,CAAC,oCAIjB,gGAGK,EAAA,uDAAA,EAAA,EAAA,UAA4E,CAAA,EAAA,CAAI,CAAC,CAAC,S/FN9D,CAAC,CAAC,iB+FQ9B,sCAEG,CAAA,GACN,oUAcO,GAAA,CAAA,EAAA,CAAQ,CAAA,KAAA,EAAA,EAAE,UAAU,wMAW6B,EAAA,gBAAA,EAAsB,EAAU,EAAA,CAAI,CAAC,CAAC,WAE5G,MAAA,CAAA,6DAAA,EAAsE,EAAG,EAAA,CAAI,0GAgB9E,CAAA,IAAA,CAAA,aAAA,CAAA,MAAA,MtCDR,IAAA,CAAA,GAAA,CAAA,CAAA,CAAA,wKA+BD,CAAA,CAAA,EAAA,IAAA,CAAA,EAAA,MAAA,CAAA,IACJ,aAAA,4HAKA,GAAI,MAAA,OAAA,gEAGmD,0GAOX,EAAW,8HAYtB,EAAA,IAAU,CAAA,EAAA,EAAA,EAAwB,GAAc,sCAAuC,CKpFC,CLoFO,CKpFC,EAAE,CLoFC,CAAC,CAAC,eKpFe,WLwFhC,CgCwC/D,AhCxC4E,CAAA,yFAQlG,KAAA,UACpB,KAAA,CAAA,EAAA,KAAe,C4ChEC,ADlBA,A3CkFA,0BAEkB,EAAI,OAAO,CAAE,AAAD,CAAC,MAAQ,2GAOvC,oBAGN,CAAA,UAAA,CAAA,cAA0B,CAAA,MAAQ,CAAC,AdJA,CAAC,CAAC,uDcU3B,CAAA,IAAA,MAAA,CAAA,IAAA,CAAA,OAAA,CAAA,GAAA,CAAA,gDAGoB,EAAA,QAAc,EAAC,6CAqBhB,EAAA,IAAA,CAAA,mBACrC,CAAC,IAAA,CAAA,IAAS,CAAC,wBAAA,CAAA,EAAsC,oDAAqD,OAAO,CAAC,CAAC,CAAC,+EAoB7E,EAAA,uDAAoE,OAAO,CAAC,CAAC,CAAC,mBAGpG,CAAA,CAAA,CAAoD,CAAA,CAAkB,CAAA,cACvF,EAAA,EAAkB,EAAA,sCACW,IAAA,CAAK,EAAA,EAAA,EAAA,EAAuC,GAAc,EAAgB,EAAQ,IAAF,A/NhCjF,CAAC,CAC1C,CAAC,C+N+BmI,CAAC,CAAnB,AAAoB,wPX9LzB,CAAC,E2C8DlB,CAAC,C3C9DqB,C2Bb5G,Ad3BuE,Ac2BvE,sE3BmBuC,QAAA,CAAA,+FAEiB,CAAA,MAAA,CAAA,EAAA,CAAC,CAAC,IvBtCvC,EAAA,KAAA,EAAA,EuBsC6C,IAAA,AAAI,IAAK,GAAkB,WAAW,CAAA,CAAC,CAAb,CAAe,CAAC,2DAKvE,EAAA,IAAA,CAAA,2CAA8B,IAAA,AAAI,IAAK,GAAkB,YAAY,CAAA,CAAb,AAAc,EAAE,CAAC,mEAKxD,gBAAK,CAAA,MAAA,CAAA,EAAA,EAAA,IAAA,EAAA,KAAA,EAAA,EAAQ,IAAA,AAAI,IAAK,GAAkB,YAAY,CAAA,CAAb,AAAc,EAAE,CAAC,iCAOjF,CAAA,WAAA,CAAA,EAAA,KAA8B,CgCnBC,AhCmBC,EAAS,oIAaI,CAA2B,CsBQvD,AHqBA,8DnB5BM,EAAY,C3HwB7C,C3FwCO,SAAA,AsNhEiD,EAAA,KAAA,EAAA,EAAE,WAAA,AAAW,E3H2BrE,E2H3ByE,EAAJ,AAAM,CAAuB,CAAC,MAA9B,I3H2BrE,gB2HzBqB,C3H6BD,A0J1CQ,C1J0CR,EAAA,6F2HpBE,uBACuB,MAAA,CAAS,2BAuKhF,SAAA,CAAA,oCAG4B,GAAA,WAA6B,CAAC,CAAC,qBAE9C,KAAA,GAAA,aAAA,sCAE2C,CAAC,CqDgbC,ArDhbA,CqDgbC,CAAC,kCrD9aJ,CAAC,CAAC,OpM8FH,OoM5F3C,MAAA,gCAA4C,EoBpBrB,oEpBnJ0E,CAAA,mEAM7D,wBAIlC,IAAA,EAAA,EAAA,aAAqE,kDAOhB,CAAC,AHkDnD,iDGvDwD,C1CqCtB,SAAA,EAAA,S0CrCiD,CAAE,gBACpD,GmBgCG,anBvBV,CWwDC,IXxDI,CjMWP,AiMXQ,0BAIJ,iDAGQ,C3C6CP,AuBfE,WoB9BiB,CAAC,4DAQZ,CAAA,CAAA,CAAA,CAAA,CAAA,gBACnB,UAAA,CAAA,SACE,KAAK,MAClB,KACR,EAAA,kEAK0B,YAAA,2BACc,KAAK,UACjC,EAAa,QAAA,iEAIa,EAAa,CzCNL,MyCMY,CAAE,IAAI,CAAC,CAAC,CAAC,2CAKqB,CAAC,IAAI,CAAA,eAEpB,EAAA,YAC9D,IAAA,CAAA,YAAA,CAAA,EAAA,EAAA,uBAGd,iBAAiB,CAAA,EAAA,EAAoB,E3C4CL,A3KiDK,mCsN5FD,EAAA,mCACA,EAAA,gCAK4B,CqD0QrC,AjLtOL,C4HpCwE,CAAA,EAAA,GAAA,iBAAiC,CAAA,IAAK,CAAA,eAEpI,SADc,CAAA,OWoD8F,WXpD9F,AACe,CADK,AACJ,AqBuEA,YrBxEI,mBAGnC,EAAA,EAAA,EAAA,MAAA,CAAA,EAAgC,EAAA,UAAA,EAAA,EAAA,EAAwB,CAAE,+BAIoC,CAAA,EAAgB,GAAA,iBAAiB,CAAC,IAAI,CAAA,OACxI,QAAA,GAAA,CAAA,GAAA,GAAgC,GAAA,CAAI,MAAA,0BACd,OACL,CAAA,kBAAA,CAAoB,CgDuO/B,ArEpPgC,QAAA,CAAA,EqBac,KAAA,CAAA,EAAe,C5H8CH,CAAC,Q4H9CY,CAAC,CAAC,OAEvE,EAAA,EAAA,EAAA,8BAKgC,CAAA,CAAA,CAAA,CAA0D,CAAA,EAAA,GAAA,iBAAiC,CAAC,IAAI,C2C2FzD,oB3C1F/E,IAAkB,CAAA,gBACc,CAAC,CADf,CAAoB,CpN+BT,CAAC,AmNTU,SCtBS,CAAC,A5H+C3B,AwGXyB,AtL5BF,M0MN1C,GAAA,wBAC+B,EAAA,UAAA,AAAkB,EAAA,EAAI,EAAA,CAAI,CkDwDsC,CAAC,oElD/BnG,EAAA,KAAA,EAGA,iBAAA,EAAA,QAAA,MACuB,EAAA,IAAA,CAAU,E5HwDJ,MAAA,CAAA,EAAA,Q4HxD2B,CAAE,EAAA,KAAU,CAAC,CAAC,AqB2EA,UrB1EpC,CAAC,EqDyWA,mE9BpasD,aAC3F,OAAA,GAAA,SAAqB,4BAGgB,aAAA,CAAc,KAAK,GAAK,C7OgJpE,M6OhJ2E,EAAE,CAAC,aAG3C,QAAQ,WAG1C,IAEM,GADI,EAAA,IAAA,EAAA,EACJ,IAAA,CAAa,wBAEO,GAAK,OACM,CvB4CG,CzCUV,WgEtDoB,CAAC,AFwHA,EExHI,EAAU,aAAa,CAAC,KAAK,GAAA,SAAc,CAAC,UHwB9C,gBGjBnC,CAAA,AACrB,CwBuQD,ArQrHA,AsNrGE,CqDwXC,AH/OA,K3BtLK,KAnCyC,ExBiE9B,EnNSoB,I2O1EmB,EAAI,KAAA,EAAJ,EAAM,EAAF,GxBkEG,CwBlEP,CAAa,CAAC,CAAC,CAAX,EACxC,GADwC,GACnD,EADmD,IACnD,6CAIoC,MAAM,CAAA,MAI7C,CAAA,CAAA,EAAA,kBvB+D8C,EAAA,OAAY,CAAA,EAAO,MAAK,CAAC,CAAC,UAE/E,CqB4EqD,AzNJJ,A+LzGI,C0B6GA,EAAA,IrB5EhC,CAAA,QAAA,AAAS,CH6CmD,AwB+BA,CrB5ElD,AH6CmD,GGtC3E,EAAQ,IAND,CAAC,AyD1CA,AT6RU,AhD7OL,QAPpB,GH6C4C,A5ClDhB,C4CkDiB,CF9EC,AE8EA,0BGzCzB,CAAC,6GAzBW,CrBdC,iBAAA,MqBepB,EAAA,IAAA,sBACgB,CpBwCH,4DoBLM,C2CyFC,A/DlDA,AxGuBR,CwGvBQ,AxGuBT,AuK2BU,CvK3BT,c4H5DjB,oIASiD,QAmB7C,IAAA,CAAA,GAAA,CAAA,CAAA,8CAEa,CP0EM,+BOzEN,C/CJF,2NsFxPgC,4CAI5B,GAAY,CvKelB,ClEC8D,CpBiCzD,C8LpDd,A+DG+B,4BACd,CAAA,OAAA,CAAA,EAAA,gGAG6B,kCAGvB,EAAA,EAAoB,EAAkB,ElKSpD,KkKToD,EAAA,EIqFpC,EJrFwC,CAAC,YAAY,CAAC,WAAW,CAAC,EAAI,CAAC,CAAA,EAAI,EAAK,EAAD,MAAS,CAAC,CAAA,CAAC,oPA2DxC,CAAA,kBAGzE,KAAA,iBAD2B,KAAA,+BAGW,EAAA,IAAyB,OAAA,CAAA,AAAQ,C3B9BC,+B2BgCjC,CAAA,uFAWvB,SAAA,CAAU,QAAA,mWP5FwB,CAAC,A1OUJ,CAAC,A0OVI,kOAaZ,CAAA,yIAWe,4BAElB,EAAA,0BACW,EAAA,OACkB,CAAA,EAAA,2BAC3C,CAAC,qNSwBY,4FAQxB,MAAA,CAAA,EAAA,EAAA,YAAA,CAAA,SAAA,AAA6B,EAAA,KAAA,EAAA,EAAA,aAAA,AAAe,GAAA,GAAA,EAAI,KAAK,CAAT,AAAU,OAAV,KAAA,sEASjB,CTlDC,ASkDA,yBAGjB,CAAC,GAAA,IAAA,CAAA,aAAA,CAAA,EAAgC,gBAAA,CAAA,UAAA,oCAOpC,IAAA,CAAA,eAAA,CAAqB,C/O3EH,EAAA,C+O2EO,GAAA,CAAA,GAAY,CAAA,GAAA,2BAEvB,gBAAgB,CAAC,UAAU,iGAMb,CAAA,CAAQ,ClFxDR,AoD8EQ,C8BtBI,CAAC,CAAC,mHAkBvB,mFAED,CAAA,0GAcd,CAAA,CAAA,CAAA,sNP/I1B,IAAA,CAAA,GAAA,CAAA,CAAA,CAAA,iQbqHgB,CAAA,IAAA,qHAKkC,+DACY,CACvE,IAAA,CAAA,aAAA,CAAA,EAAA,SAAA,CAAA,aAAA,2CACmD,sFAI8E,CAAA,wBAC/F,CE/GC,AF+GA,gDAEe,EAAE,+CACqB,mHAKd,CAAC,qBACd,CAAA,GAAI,CAAC,KACZ,MAAA,CAAA,EAAA,MAAA,EAAA,KAAA,EAAA,EAAY,MAAA,AAAM,EAAA,IAAlB,CAAkB,EAAA,EAAE,K5BdH,W4BcmB,C5BdN,A4BcO,C5BdN,I4BelC,iBAGE,EAAA,UAAA,CAAmB,UAAA,EAAA,EAAc,GAAA,GAAA,AAA8C,uBAC5B,CAAC,CtB/CzB,AsB+C0B,CtB/CzB,AsB+C0B,AO/EA,C7BgCzB,AsB+C0B,AO/EA,CP+EC,4BAE3D,CAAA,GAAA,CAAA,EAAU,iEAIV,EAAQ,KAAD,KAAW,EAAA,YACrB,CAAU,EACb,+BAIsB,iBAAA,+FAUV,EAAA,GAAA,EAAQ,EAAA,+EAI4B,CAAA,ChJRnE,sHgJaoC,4FAKkB,CAAC,C3B3FC,CAAC,CtEsC9B,6CiG0D6B,OAAS,WAAa,EtB5ClE,qDsB8CmB,CAAA,0BAEd,EAAA,QAAA,qBAGkB,CAAA,GAAU,GAAG,CAAA,AAAC,CLhGC,AjNuCO,EiNvCP,EKgGU,KtB7CK,GsB6CG,EAAE,CAAC,CAAC,KAAK,EAAE,0DAElC,KAAA,IAAA,CAAA,YAAA,CAAA,EAA8B,IAAA,OAAA,CAAA,sDAEV,CAAA,MAAO,CAAC,EjJjCxD,qBiJmCF,GAAA,CAAA,EAAA,KAAA,CAAA,GAAA,cAAA,iDAIM,mBAKzB,EAAA,IAAuB,CAAA,aAAA,CAAA,IAAA,CAAA,gBACJ,CAAA,GAAI,CAAA,MAAA,CAAA,iBAGjB,EAAA,KAAA,CAAA,GAAA,MAAA,EAAA,CAAA,CAAA,MAAA,CAAA,EAAA,IAAA,CAAA,UAAA,CAAA,GAAA,CAAA,EAAA,GAAA,CAAA,QAAA,GAAA,EAAA,KAAA,EAAA,EAE6C,MO7EF,GAAA,AP6EW,CAAA,CAAA,uBAIxD,CAAA,cAAA,CAAA,EAAA,IAAsC,CAAA,kBAAmB,CAAE,WAAW,CAAC,CAAC,kBAI5E,QAAA,GAAA,CAAA,IAAA,CAAA,eAAA,CAAA,GAAoC,CAAA,AAAC,CXSsB,AqCyDzB,E1BlEe,EAAS,EAAS,OAAO,CAAC,CAAC,CAAC,CAAC,gEAe1C,CAAC,eAAA,CAAgB,CAAA,CAAA,EAAe,EAAG,CAAC,qBAI/C,eAAA,CAAA,CAAA,CAA0B,EAAM,EAAG,CAAC,WAK1D,CAAA,CAAA,EAAA,CAAA,CAA0B,CAAA,EAAA,CAAA,CAAW,CAAC,CzCzCC,AyCyCQ,CAAC,EVhBE,CUgBM,CAAS,CAAA,EAAM,CAAC,CAAC,SsC3GxC,kBtCkHF,CAAA,2CACP,C6BfO,AvErEE,AqBaF,CAAA,KAAA,EAAA,EqBuEL,GAAG,CAAC,EAAI,CAAD,GAAI,CAAC,CAAC,CAAC,aAML,CAAA,CAAA,CAAA,mCAEM,WAAL,CAAiB,CAAC,CAIxD,IAAI,CAAA,MsBgBgE,MtBhBhE,CAAA,UAAA,CAAyB,EAAU,4EAMxB,CAAA,eAAA,CAAiB,CzOxCb,AsK8DY,MmEtBQ,CAAC,kDAgBnC,CD5FT,cAAA,CAAA,CC4FsD,CAAA,CAAA,CAAA,CAAA,mDAGrB,GAAA,MAAA,CAAsB,EAAA,GACtD,IAAI,CAAA,sBAAuB,CAAC,MAAM,CAAC,EAAK,CAAF,UAAa,CAAC,CACvD,CAAC,kCAE8D,CAAE,EAAA,AAAa,GAAG,AAC9E,CAD+E,CvNtBrE,EuNuBN,CAAC,YAAY,CAAC,aAAa,CAAC,EAAK,CAAF,UAAa,CAAC,CACpD,CAAC,CAES,aAAA,CAAA,EAAA,GAAA,cAAA,CAAA,EAAoE,E5BLd,CAAC,G4BKmB,GAAG,CzO5BpB,CACnE,AyO2BwF,C5BJrE,A7MvBlB,qCyO4B4D,E6BXK,AAAC,C7BWH,A6BXG,E7BWC,CAAC,CAAC,UAAU,CAAC,gBAAgB,CAAC,4BAChD,EDhGtB,gBCgGwC,CAAC,EAAK,gCAGvC,GAAA,MAAA,CAAA,EAAA,AAAmC,wBAC/B,WAAW,CAAC,EAAI,GAAA,EAAK,CvNX3B,CAAC,AlBdsB,A+PyCM,QtBhBQ,CAAA,MAAO,CAC5D,AAD6D,IAC7D,CAAA,AsBekE,EtBflE,kCAGgC,iBAAiB,CAAE,EAAA,AAAa,GAAG,AAAG,CAAF,GAC9E,CAAC,YAAY,CAAC,gBAAgB,CAAC,EAAK,CAAF,UAAa,CAAC,CACvD,CAAC,QAE4C,CvNPE,GuNOE,CAAA,cAAA,CAAA,4CACV,GAAA,SAAuB,CAAE,CxBjCC,CAAC,AAAC,AwBiCU,CxBjCV,EwBiCa,AAC7E,CAD8E,GAC1E,CAAC,QAAQ,CAAC,EAAK,CAAF,MAIQ,IAJK,CAAC,CAClC,CAAC,yBAI2C,CAAA,QAAS,EAAE,CAAC,AhE3BlD,CgE2BmD,iBAEhC,CAAA,yBAYrB,IAAA,KAAA,EAAA,yEAOQ,UAAA,CAAA,GAAA,CAAA,EAAA,sBAED,EACA,OAAA,MAAA,EAAA,KAAA,EAAQ,EAAO,MAAM,UAgBrB,cAAA,CAAA,CAA4C,CAAA,CAAA,CAAA,CACxD,CElIsD,AFkIQ,CAAA,CElIN,CAAC,CAAC,kBFoInC,2DAIT,CAAA,mBAAA,CAAA,EAA+B,EAAa,CDxGC,CAAC,AAAX,CAAY,IC8GvD,EAAA,EAAA,MAAA,CAAA,AAAmC,GAAG,AD1GA,AC0GC,CAAA,CAAA,KAAA,GAAiB,CX6DC,UW7DU,CAAC,CAAC,CAChE,gBAAA,CAAiB,EAAA,EAA8B,oBACzC,CAAG,oDAIK,GAAA,CAAA,EAAA,aACA,uCACwB,EhEXJ,CAAC,qBgEeyB,CoC5HrC,A/Q+KJ,mC2OlDH,CAAA,GAAA,CAAA,EAAA,MACT,MAAA,CAAA,gCACa,CAAA,MAAO,CAAC,EAAa,EErII,G3OwHd,AuIoCA,CAAC,AvIpCA,CAAC,C2OxHO,SF2IvB,CAAA,CAAA,CAAA,CAAA,0BAGlB,gBAIV,EAAgB,GAAA,MAAL,AjJJyC,CAAC,CAC1D,OiJGK,EAAiC,CAAC,IAAA,AAAI,EAAC,gBAAvC,SjJJmC,MiJMQ,WAAW,CAAC,SACnC,EAAA,KAAA,CAAA,SACL,QAAA,OAAA,CAAA,eAGN,YAAA,EAAgB,CvNYD,SuNXL,OAAA,CAAA,KAAA,8BAC6B,ChE+BD,AgE/BE,AzOEN,CAAC,WyODnB,CAAC,IAEnB,IAAI,QAAA,CAAA,EAAkB,eACG,CAAC,YAAA,CAAa,EAAO,E2BqKC,C3BrKE,mBAE/B,OAAA,GACb,EAAK,CAAC,A2BqKI,M3BpKO,IAAA,CAAK,SjJoBO,OiJpBS,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC,eAChD,EAAU,GAAG,CAAC,AAC1B,CAD2B,KAEvB,CADG,CACH,KAAA,SAG8B,uBAAuB,CAAC,GAAG,EAAE,AAC/D,EAAA,OAAuB,EAAE,ChEyCH,AzJsBJ,AyN/DQ,SACF,0CAM+C,C2ByKrC,ADyEZ,A1BlPmD,CAAA,CAAA,cjJ0B9E,IAAA,CAAA,sBiJzB0C,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CACpB,aAGvB,EAAA,EAAA,SACD,EAAK,CAAC,CpE9ET,AoG2aQ,AjCxcA,EC8GgB,CXgEC,AsC8GlB,C3B9KJ,uCAO8C,CAAA,CAAsB,CAA8B,CAAA,IACtF,CAAC,CpE/EP,IoE+EL,CjJ6B6C,CiL+T3C,AjL/T4C,CAAC,AuKc5C,GAAA,StBrCN,0BAA2B,CAAC,EAFG,CAAC,EjEjBL,CiEiBQ,AjEjBP,CiEiBQ,AjEjBP,KiEiBY,CAAC,CAAC,CACjB,SAE3B,CzCHC,EAAA,+ByCaU,CAAA,CAAA,QACd,CAAQ,IAAA,CAAA,eAAoB,CAAA,GAAW,EjJiCJ,EAAE,CAAC,KiJjCW,AAC5D,CAD6D,AAC5D,AAMS,CAPoD,EhEgDN,CAAC,CAAC,CgEzC1C,SAAA,CAAkC,C2BkL1B,A3BlL4B,CzNuFhC,AwNxMc,AxNwMd,AhBvEA,CgBuEA,ayNtFE,IAAI,CAAC,eAAe,CAAC,CXoEC,CUpLC,SCgHS,CAAC,CXoEC,CWpEQ,GAAG,CAAC,CAAC,IDhHI,MCgHM,CAAC,CDhHC,gBCgHgB,CAAC,AACxF,EAAoB,EDhHE,AxOkIN,EyOlBQ,CAAA,eAAA,CAAiB,GAAU,ADhHY,CAAC,CAAC,GxOmIxC,KAAA,CyOlBzB,EAAuC,ODhHO,GCgHpC,OAAA,EAAwC,OAAoB,EACtE,EAAA,KAD+E,CAAC,AAChF,EAA8B,gBAAA,CAAiB,EAAU,EAAS,CgC2VN,8BhCzVzC,IAAA,IAAA,uBAMnB,EAAA,IAAA,CAAA,UAAA,CAAA,GAAA,CAAA,EAAA,GAAA,CAAyC,C5BwBC,CAAC,CpCiCL,KgEzDW,wBAEvC,EAAZ,GAAM,MAAM,CAAK,EAAA,CAAE,EAAC,oBACE,EAAO,IEvIO,CFuIP,EAAP,EAAS,KAAF,IAAP,CAAS,AAAU,EAAA,EAAI,EAAJ,CAAuB,GAAG,CAAtC,AAAuC,GAA3B,EAAZ,KAAY,CAAsB,IAAtB,UACR,GACvB,MAAA,CAAA,gBAAuB,CAAA,IAAK,IAAA,6BAEF,ChE2DC,AgE3DA,KAAiB,CAAC,AAG/D,CsBwDC,AtBxDA,AzCkBA,gByChByB,CAAA,CAAA,gBACf,MAAA,CAAA,EAAA,MAAA,CAAA,EAAA,IAAA,CAAA,UAAA,CAAA,GAAA,CAAA,EAAA,GAAgC,CAAA,QAAS,GAAE,EAAA,KAAA,EAAA,EAAG,OAAA,AAAO,EAAA,EAAI,CAAA,CAAJ,AAAM,CAAC,CAG1E,MAHmE,OAAA,KAAA,2KF3Zb,+JASkB,CDxEP,CAAA,UCwE0B,GAAK,IhJ/ChF,SgJ+C6F,ChJ9ChG,AgJ8CiG,sCASxE,WAAA,CAAA,IAAA,mBAEC,MAAA,CAAA,GAAc,CAAA,GAAA,EAAc,CzNpElD,EAAA,CAAA,GAAA,sHyN+E2C,EAAA,2BACrB,IAAA,CAAA,WAAgB,CAAC,GAAA,CAAA,EAAA,EAAA,EAAY,EAAA,AAAE,C7N5C9D,A6N4C+D,C7N5C9D,O6N6CoC,GAAA,IAAA,CAAA,aAAuB,CAAC,SAAS,CAAC,CAAC,CAAC,IAAI,CAAE,0CAJxC,EAAE,CAAC,E9D3B3B,CqC1CmE,ArC2CxF,K8DmCgB,CAAA,8JAOoE,CAAA,uCAC9B,CAAA,EAAA,GAAA,sDACwB,CAAC,EAAU,WAAW,CAAC,CAAC,uHAMf,CAAA,0CACvB,GAAA,kDACY,CAAA,kBAAmB,CAAA,EAAW,WAAW,CAAC,CAAC,oBAC7E,QAAA,GAAA,mDAIe,GAAG,CAAC,QAAA,mCAIZ,EAAA,GAAe,CAAC,EAAA,SAAA,CAAA,QAAsB,sKkBzFvB,wGAEI,2GASxD,IAAA,CAAA,OAAA,8KAU+D,EAAA,EAAI,EAAE,CAAE,EAAM,CAAA,CAAC,CAAC,AAAH,CAAC,CAAA,iDAGF,IAAA,CAAA,wFAKjC,mBAAA,CAAqB,SAO1D,eAAe,CAAA,CAAA,wCAC6B,GAAA,EAAA,gBAAA,CAAwB,cAAA,iLAa1D,GAAK,IAAA,CAAA,aAAA,CAAA,yCACwB,ElBKA,EAAA,gBkBHxC,CAAA,OAAA,+HA0B2I,CAAA,+HAGnF,CAAC,AdvEA,CAAC,A3CqEpC,A+DkEN,8BN9DkC,GAAG,C9EhDnB,A8EgDqB,EAAgB,G9EhDjB,CAAC,CAAC,I8EgDwB,CAAC,CAAC,gCAEpC,mBAAmB,CAAA,EAAO,GAAG,CAAC,CAAC,qBAUb,CsB9D1C,AtB8D4C,CAAA,CAAA,UACvD,QAAA,CAAA,EAAe,GAAA,kBACjB,yDAI2B,wCAEV,EAAA,GAAS,C1DrCC,AtBqDd,ADhBM,AiFAQ,A5CgCA,+EmB9MmC,CHHvB,A7BqClD,CAAA,CAAA,CAAA,CAAA,2CgCjCwD,CAAC,EAAU,EAAa,ChOoChF,CgBWmB,AgN/CqE,EAAM,ChNgD9G,AAAM,CgNhDgG,ASGA,ATHM,CSGL,ETHT,CAAsB,CAAC,CAAC,chNgDvF,CAAC,0DgN5CwC,CAAC,qMA2CL,CmBTC,yHnBaH,MAAA,CAAA,GAAA,yEAEH,yFAGL,uLAaL,CvIS9B,A0HkBqB,Ca3BW,oBACpC,IAAA,CAAA,YAAA,EAAA,iBAAmC,AAAnC,EAAmC,KAAA,EAAA,EAAA,IAAA,CAAA,EAAG,IAAI,CAAC,6DAMU,ElB/BE,AyBqEA,CAAC,AzBrEA,GAAA,CAAA,EkB+BgB,GClCC,EAAA,EDkCM,C2B8BC,G3B9BG,EAAE,CAAC,AAAE,CAAD,GtDP/E,CAAA,MsDO2F,CAAC,qEAkB5D,gBAAiB,C3DPL,sB2Dc7D,gBAAA,KAd8D,IAc9D,EAdmD,MAAA,EAAW,SAAe,AAc7E,CzIdM,CAAA,CAAA,CAAA,CyIAyF,CAAC,CAAC,CAc3D,CAAA,GAA6B,sDnByCpD,KAAA,CAAA,mHA2K1B,SAAA,GAAA,CAAA,CAAA,CAAA,MACU,EAAA,EAAa,SAAA,CAAU,GAAA,KAAA,CAAA,+BAMjC,CAAC,aAqD4C,iBACd,EAAA,KAAA,CAAA,aAGI,SACA,kBAAW,AAAe,C4DqWC,CAAC,EhC5VE,CAAC,A5BTA,CAAE,A4BSD,C5BTE,GAAvB,IAAU,eACtC,eASmB,CAAC,AtEiCF,AoG9JI,G9BoHtB,SAQc,CAAA,EAAA,KAAA,CAAe,uCANR,KAAA,CAAA,eAEV,EAAO,CbLC,CAAA,AxGGH,AiJYI,C5BVI,CpCUL,AvJWI,CAAC,IAAA,CAAA,E2LrBkB,GpCUH,CAAC,CAAA,CoCVQ,KAAK,CAAE,EAAU,KAAK,CAAC,CAAP,EAAU,CAAC,CAAC,CAAC,AAY/F,CgElHC,QAAA,GAAA,ChEkH2C,CAAA,CAAA,mBACA,KAAA,GAAQ,YACnB,CAAC,SAAA,CAAU,CAAC,CAAC,WACV,CAAA,EAAA,KAAA,CAAA,WAC5B,EAAA,KAAA,EAAA,EAAW,IAAA,AAAI,IAAK,GAApB,GAA0B,WAEhB,EAAA,GAAA,UACC,IAAA,GAAA,EAEH,CEpH2B,AjNwLV,GiNxLU,GFoHT,CAAC,CrHWyB,CqHXjB,CrHWmB,AqHXjB,ErHWmB,AqHXX,KAAK,EAAA,EAAA,GAEpC,MAAM,CAAC,EAAS,KAAK,CAAC,KAAK,CAAE,EAAQ,KAAD,AAAM,CAAC,GAAG,CAAC,CACxD,CAAC,SAEI,EAAA,GAAA,iBAEF,EAAA,EAAA,EAGA,GAAM,EAAD,ArHW4C,CAAC,CAAC,CAAC,CqHXxC,CAAC,EAAS,KAAK,CAAN,AAAO,KAAK,CAAE,EAAQ,KAAD,AAAM,CAAC,GAAG,CAAC,CACxD,CAAC,sBAIC,IAAI,GAAA,EAAA,IAAuB,GAAc,EAAA,CAAI,GAAQ,CrHqBD,CqHrBS,CsDoOT,A3K/ME,E2K+MM,AnP1KA,CmP0KC,AnP1KA,C6L1DK,AsDoOJ,AnP1KA,C6L1DK,CAAC,UAItC,ErCdpB,CiEeS,AjEfR,OqCeA,MAAA,CAAA,EAAA,KAAA,GAAA,iBACS,OAAA,CAAS,EAAM,CbCd,AmEwOqC,ItDzOlB,WAqB9C,GAAA,CAAA,eAEM,GAAiB,iBAEf,KACL,KAAA,iBAGK,CAAA,IAAA,CAAA,CAAA,KAAA,CAAA,CAAA,CAAA,gDAImB,gBAIX,CAAmC,CAAA,CAAgB,yBACtC,AAAkB,GkDEf,GvKOmB,EAAE,AqHTE,SAAnB,MrHSI,AqHTE,GAQpC,CrHC+C,MqHRhD,EAAA,UAAA,OAAA,EAAuC,C2B/HC,E3B+HY,GAAU,EAAO,CAAX,CAAC,CAAC,CAAC,AAAO,EAAO,CAAC,SAEnE,OAAA,CAAA,KAAA,EAAe,EkDSG,CAAA,AlDTM,CAAC,CAAC,AAE9B,E/MiDsB,K+MjDtB,CAAA,IAAA,EAAA,EAAA,KAAA,CAAgC,CAAC,CAAC,MAE1C,CAAC,gBAU4B,C2BpIf,A3BoIiB,CAAY,C8BvJtB,M9BwJnB,QAAQ,CAAA,YACH,CAAG,CACjB,CAAC,AkDqBA,OlDnBM,CAAY,CAAA,uBACO,GAAA,IAAA,CAAA,GAAa,CrCzCL,A4FoMU,AvD3JJ,CAAC,IAAI,GAAA,6CAIV,CAAA,GAAA,EAAA,IAAA,GAAA,wDAI6B,CAAC,CACjE,+CAIuC,CAAE,ArHQP,CAAE,AqHRM,G/M+DH,Y+M7D3B,EAAA,EAAA,QAAA,YAEM,EAAA,EAAA,QAAuB,EAAE,CAAC,SACD,WAG1B,CrHUD,GqHVK,CxCtGP,EwCyGd,WAAW,C2BzIC,AGpBE,CAAA,2B9B+JgB,CAAA,QAAA,IACD,2BACS,CAAC,E2BzIE,CC+GC,AD/GA,CC+GC,AX0EA,CAAE,CAAA,CjBhDC,CAAC,CrC3CP,AqC2CQ,G8B9JG,e9BgKP,GAChC,GAAS,CiBiDC,EAAA,GjBjDqB,WAG1B,IAAI,8BAU6C,CAAA,CAAc,CAAA,UACnE,CrCjDN,CAAA,MqCkDE,OAAO,CAAA,OACP,MAAM,CpCiCD,AoCjCI,CxCzGL,KwC0GL,CAAC,KAAA,CAAA,aAIL,C/M2ED,A0K7HF,G1K6HE,EAAA,CAAA,CAAA,EAAA,IAAA,C+M3EqB,CiB6CC,GAAA,CAAA,CjB7CK,CAAC,AACrB,C7MNY,AyKqCI,CoC/BhB,CpC+BkB,GoC/BlB,CAAA,OAAsB,CAAA,QAAS,C/M2ED,C+M3EG,CAAC,OACJ,CxCzGH,AwCyGI,EAAE,CAAC,ExCzGF,ArKoGE,CAAC,AqKpGF,UwCyGtB,OAAA,CAAQ,CbXC,A3B9FJ,C2B8FI,IAAA,MaYZ,CkD0BS,CAAA,CAAA,ElD1BD,CrCnDL,C4F2MyC,CAAA,AvDxJ3B,MACf,OAAA,CAAQ,OAAO,CAAC,MAAA,CAAS,CAAC,EAAE,CAAC,E7MLN,G6MMzB;AAAA,EAAS,ErClDJ,CAAA,OqCoDV,MAAA,MAEM,EAAA,CAAA,CAAA,cAMR,CAAA,CAAA,gBACA,MAAA,CAAA,EAAA,MAAA,CAAA,QAAA,ExCnGsB,AI2II,CgGsRX,IhGtRW,EoCxC1B,EAAS,KAAF,IAAP,AAAS,AAAS,EpCwCQ,AoCxCR,IAAA,CAAA,EAAA,EAAA,GAAA,CAAA,CAAA,EAAG,GAAH,EAAO,CAAC,CAAA,CAAR,CAAY,GAAJ,CAAQ,CAAC,MAAT,OAAA,IAA0B,CAA1B,AAA2B,OAAO,CAAC,CAAC,YAG/C,CAA4B,CAAA,8BACX,CAAC,CiB8DC,ArDvBR,iBoCtChB,OA6BzB,CkDqCC,AtFqBA,QoC1DQ,CAA2B,CAAA,CAAA,CAAA,CAA8C,CrChDzC,CAAC,4BqCiDX,AAAQ,gBAAsB,CpCiED,QoCjEP,EAAgB,CAAb,AAAc,IACxD,EAAA,EAAA,OAAuB,CAAC,CpCoED,CAAC,CoCpEG,ApCoEF,CoCpEG,CAAC,AAC/B,EAAA,SACW,KACL,CrC9CP,CqC8CsB,GAAe,EpCyEA,AoCzES,KAAK,AACxC,CADyC,CAAC,AAC1C,SAAA,CAAA,gBACiB,CAAC,CAAC,ApC0EF,CAAA,EoCzE/B,QAMO,gBAL4B,YAAA,AAA2B,SAA3B,EAAkB,C4DiUC,G5DjUG,AAAK,GAAS,CAAC,uBAInD,MAAA,CAAA,EAAA,EAAQ,UAAA,AAAU,EAAA,IAAA,CAAA,EAAA,EAAA,IAAA,CAAA,EAAG,EAAS,C8B3KjB,CAAC,A9B2KuB,CAAC,CAAA,EAAI,GAAJ,MAM1D,AAAkB,CAAe,CANyB,AAMzB,CAAiB,KAN6B,AAOhF,CAP2D,AAO1D,KAP0D,cAQxC,aACI,CrChDT,CqCgDgB,CAAA,CAAG,SAC7B,UAGZ,CAAC,CAbwF,EAAS,EAE9F,CAAC,AAEL,CAAC,CA7C4C,AAyCmD,EAAS,CAAC,CAzCzD,AAyC0D,CAzC1D,IAAK,CAAE,EAAS,I/MwFE,I+MxFF,EAAW,CAAA,CAAE,CAAC,CAAC,CAAR,EACjD,eADiD,EACjD,GADiD,MAEjD,kBAIX,EAAA,KAAA,EAAA,EAAS,GAAA,AAAG,IAAK,UAAY,OAAA,EAAO,KAAA,EAAP,EAAS,CAAF,EAAE,AAAG,EAAL,IAAP,GAAiB,IAAV,IAE7B,CAF6B,AAAmB,EAAE,CAAC,EAAtB,CAE7B,EAAA,KAAA,EAAA,EAAA,GAAY,AAAZ,C8B1KuD,G9B0KtC,QAAQ,CAAC,YAE1B,C8B1KA,AnE0HR,CAAA,KAAA,EqCgDQ,EAAS,EpCyCkC,CoCzClC,AAAG,GpC0CV,CoC1Ce,SpC2Cd,SoC1CD,KAAA,CAAK,AkDiCA,OlD/BP,CAAA,EAAG,EAAA,CAAA,EAAA,IAAA,CAAe,IAAA,CAAA,EAAO,C8B3KC,CyB+UK,AzB/UJ,CyB+UI,QvDnKN,CAAC,A7MQY,E6MRV,qBAAf,CAAA,MAAA,GACb,CAAA,EAAG,EAAI,CrChDN,EAAA,EAAA,EAAA,CqCgDqB,CpC8CX,AsFZY,AlDlCA,AAC3B,CkDiC4B,GlDjCpB,CAAC,OAAA,CAAQ,CrC/CT,MAAA,CAAA,MqC+CuB,CAAG,CAAC,EAAE,CAAC,CrC/CT,SqCgDlB;AAAA,EAAA,EAAA,CAAA,OAET,MAAA,EAEE,AAFM,CAEN,CAAA,EAAA,EAAQ,CAAA,CAAA,IAK1B,AA8BD,MAAM,gBAI8B,C7MwBtB,A6MxBwB,CAAA,CAAA,aAClB,CAAA,OACP,KAAA,CAAA,aAIL,IAAA,EAAA,OACK,IAAA,EAAQ,CAAC,AuD0LA,CL1IC,ElDhDK,IAAI,CAAC,M7MyBI,CAAA,C6MzBI,MAAA,CAAQ,IAAK,CpCmFN,AoCnFO,UACxB,CAAC,OAAO,CAAC,CAAC,A7MyBV,CAAA,G6MxBN,E4D4TE,EAAA,C5D5TG,OAAO,CAAC,CAAC,CAAG,CAAC,CAAC,IACxB,EuD0LE,AvD1LK,QAAQ,QACN,KAAA,CAAM,C4D4TC,IAAA,C5D5TK,E7MyBV,CoQiKa,CAAA,CAAA,EvD1LW,GpCyF9C,EoCzFmD,CAAC,KAAK,CAAC,IAAI,EAAE,CAAC,kBAOtE,CbYC,UaZU,CAA4B,CAAA,OACxB,EAAE,CAAC,0BACkB,CAAC,MAAM,CAAE,CAAC,EAAE,CAAE,CAAC,IACrC,EAAA,IAAA,CAAA,OAAA,CAAA,EAAA,GACO,IAAI,CAAA,OAAA,CAAS,CAAC,A4D2TA,CzE9SE,CAAA,CAAA,MaZd,UAAA,CAAA,yBACqB,EAAM,G7MiCT,C6MjCS,CAAM,CAAC,G7MiCL,EAAA,C6MjCW,IAAI,EAAE,C7MiCN,A6MjCO,C7MiCN,CAAC,C6MhC7C,IAAA,CAEhB,CAAC,UAGR,MAEK,CrH4CD,EqHxCD,YAAA,CAAwB,CAAE,CAAA,CAAA,MACjB,IAAA,CAAA,sCAKO,IAAI,yBAGL,CAAC,C4DsTC,CAAC,EAAA,E5DjTtB,SAAS,GAAa,CAAY,I4DoTJ,K5DnTtB,EAAA,QAAa,CAAA,MACN,CADc,IAGd,MAEf,0EiClpBkE,ChCnBC,AgCmBA,oDACE,2DAIb,2BjCkG9C,EAAA,uEAQA,EAAA,EAAA,KAAA,iCAGS,EAAY,IAAI,CAAA,EAAA,IAAY,EAAQ,QAAS,KAAA,EAAT,EAAW,IAAI,CAAC,EAAI,YAAX,oBAvC9B,kEA+OlC,CgErHC,QAAA,CAAA,kBhEsHS,EAAA,GAAA,MAAA,CAA0C,EAAQ,Gd9FP,Kc8Fe,CAAC,IAAA,CAAM,EAAQ,KAAD,GAAS,CAAC,SAAS,CAAC,CAAC,GACjF,YAAA,CAAA,MAAA,0CAGiB,MAC5B,EAAQ,KAAA,CAAA,EAAA,MAAA,CAAA,MAA6B,EAAA,yBAYtC,CiBgEC,CAAA,EAAA,MAAA,CAAA,EjBhE6B,KAAK,CAAA,OACzC,AsDsKD,AtDtKU,CsDsKV,MtDtK0B,CsDsK1B,EtDtKU,IAAA,yCAEsD,CAAC,K2B/FG,qB3BwGL,+BAEZ,CAAC,CAAC,CyDyEC,qDzDrEjB,CAAC,yBARzC,C6C9EC,Af5CA,A9B0HA,IArB0D,CAAC,EAAS,MAAA,CAAS,CAAC,CAAC,CAAC,CACrE,AADsE,SAC7D,AACI,CAAA,2BAGP,CAAQ,CAAA,EAAA,EAAA,KAAA,EAAA,EAAK,KAAK,CAAC,KAAK,AAAL,ErHVqE,EqHU5D,EAAJ,AAChC,EAAA,MADgC,AAChC,CAAA,EADiD,AACjD,CADkD,GAAlB,EAChC,CrHXgG,AqHWhG,EAAA,CAAA,CAAA,EAAwB,MAAM,CAAG,EAAA,AAAE,EAAA,KAAA,EAAA,EAAE,KAAK,CAAC,GAAA,EAAG,EAAI,EAAJ,AACpD,CuD0KC,A7HvKF,AuF6DE,CnD9HC,AmD8HA,KjBhEK,CAD6C,GAAiB,AAC1D,CAD2D,EAC3D,CADyC,CACd,GAAM,CADQ,KACR,CAAO,EAAO,Cd7FC,Ec8F/D,AADiE,CAAC,AACjE,CADkE,CAAC,8DrHVkD,CACrG,CAAC,mCqHhLE,EAAA,EAAA,KAAA,CAAA,MAAA,CAA0B,IAAA,qEAMT,KAAA,CAAA,8CACgB,CAAC,IAAI,wBAEL,CAAC,C6D5FC,6C7D+FP,IAAI,CAAC,2EAMN,IAAA,CAAK,oBAEf,CAAA,EAAA,EAAA,KAAA,CAAA,KAKP,mBADG,8BA2I7B,CtETD,A+H4EE,EAAA,GzDnEY,AAAkB,iBAAlB,EAAA,KAAkB,UACd,KAAA,EA5IY,IACH,YAEU,0BAGE,MAAM,CAAA,EAAA,mDAIR,EAAA,8BAKtB,EAAA,GAAoB,IAAA,CAAA,uBAGA,CAAA,EAAA,oCAEsC,EAAQ,EAAU,CdrEC,EzB6DjF,CACL,EAAA,+CuCW+B,EAAA,uEAQO,IAAI,CAAC,CblCC,AxBKN,CAAA,QqC6BkB,CAAC,WACvC,IAAA,cAgByD,CbvCnC,AhLqCV,C6LEqE,UACzE,oCAGc,iBACF,EAAA,EAAA,MAAA,8BAG1B,QACF,GAAA,MAAA,CAAA,EAAA,sCAKD,EAAA,EAAA,KAAA,0EAKqC,SAC5B,GAAA,MAAA,CAAA,GAAA,MACY,CAAC,C6C3EiB,A3DDA,Cc4EN,ErCxBY,GqCyBvC,GAAS,KAAD,CAAO,CAAC,EAAW,EAAa,KAAf,GAAY,MAAiB,CAAC,CAC1D,UAIY,CAAC,CAAC,AkErGA,AhFuBC,CAAA,8CckFb,GAAA,MAAA,CAAA,GAAA,MACY,CAAC,EAAA,EAAuB,C7MjCK,A+P2DY,CAAC,AlD1BT,GAChD,GAAS,MAAM,CAAC,EAAW,EAAY,EOlE2B,APkElB,COlEmB,CAAC,APkEZ,CAA/B,CAAoB,CAAT,EAAmB,CAAO,CAAG,cAAc,CAAC,CACnF,CAEmB,CACR,YAAA,CAAA,wBAEQ,CAAC,CAAA,+CAKb,CdjFiB,EAAA,MAAA,CciFD,EAAW,EAAY,EAAS,ClC9DtB,E+FlCyC,A7DiGnE,GAAA,MAAe,CAAC,ElC9DjB,AkC8D4B,ClC7D5C,CAAC,AkC6DuD,EAAS,EAAM,CAA7B,CAAoB,CAAT,AAAiB,GAAO,CAAG,cAAc,CAAC,CACjF,QAIK,wBAEC,GAAA,MAAA,CAAA,GACM,MAAA,CAAO,EAAW,CrHXlB,CqHW8B,EAAS,E2BxF0B,C3ByF1E,CAD6C,A2BxFwB,AAAO,EAAE,A3ByFrE,KAAD,CAAO,CAAC,CAD8C,CAAC,AACpC,EAAY,EAAS,GAAvB,CAAoB,CAAT,SAA0B,CAAC,CAClE,6BAME,MAAA,CAAA,WAEP,KAAA,0CAGmB,CAAC,CI1BiB,AwDsTA,CAAC,A5D5RP,CkDoBQ,AAAS,ClDpBL,EOtEkB,CAAA,GPuEhD,MAAM,CAAC,EAAW,EAAY,EAAiB,EAAW,CAA1C,EAAW,GAAqC,CAAC,CAC7E,AADqE,EAAb,SAOzE,CAAC,AkEhHA,ANgZA,C5D1X0B,EAAwC,EAAM,ClCnElC,CkCmE+C,CtEvBd,CsEuBiC,AtEvBhC,6BsEgCjD,GAAA,AAAwC,SAAS,CAAjD,AAAkD,CAAvC,CAAA,EAAA,MAAA,CAAiB,EAAA,CAAA,IAAA,QACzB,CAAA,EAAA,8HiCxM2C,6CAGd,CAAA,EAAA,qCAO4B,CAAA,sDACxB,CAAC,EAAM,EAAA,EAAA,EAAS,IAAI,CAAC,qBAAqB,CAAC,EAAM,EAAF,EAAM,CAAC,CAAC,iBAC/D,4CAEV,WAAW,CAAA,KAAA,CAAA,KAAA,CAAa,I5BPI,CAAC,I4BOI,CAAA,sBACvB,CAAA,sBAAoC,CAAE,iCACtC,2IAoBA,CAAA,GAAA,EAAA,IAAY,GAAA,gFAW/B,YAAA,CAAA,WAAA,GAAA,IAA+B,CAAA,GAAA,EAAQ,CpEuDH,CAChE,AoCvEqE,EAAA,GgCeO,IAAI,CAAC,+I+B8ChF,SAAA,CAAA,CAAwD,CAAsB,EAChF,CpGkFD,AqDmCE,EAAA,EAAA,K+CpHS,EAAA,UA8F+B,CAAE,EAAA,CAAA,CAAa,OACjD,EAAK,SAAA,EAAA,8BAEkB,CAAA,OAAA,CAAS,2CAIjB,CAAA,EAAA,MAAA,cAO1B,CAAC,CA5Ga,EAAA,CAAA,GACN,GAAA,GAAA,EAAA,EAAA,eAAuD,sBAMlB,CrGsEE,AwBND,Q6EhEQ,CAAA,GAAM,CAAA,EAAA,MAAS,yBACjB,gBACP,CAAC,EAAA,MACZ,EAAA,6C/ElH8B,EAAE,AiE0FsB,CjE1FtB,qBAAA,CAAA,EAAA,KAAA,EAAA,EAAyB,IAAI,CAAC,sTuDCrF,IAAA,GAAA,uBAAA,6JrC+BoG,CgBA7C,AvIRN,GuHQuD,CAAA,qGAS3F,OAAA,gTAkB4D,2CAGxB,IAAM,EAAO,Ce+DC,yBf5DtD,MAA2B,UAEX,CAAA,KAAA,yGAWG,uRjB9CmD,CAAC,CAAC,CAAC,IAAC,iBAG7D,YAAA,CAAA,GAAA,CAAA,AAAiB,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,EAAW,GAAA,CAAG,GzBVtC,KyBU+C,EAAE,OAAA,gCAClC,EAAA,KAAA,CAAc,IAAA,CAAK,uBAAA,CAAwB,CzBL/D,CAAA,KAAA,kLyByBN,8DAOqB,CAAA,GAAA,CAAA,+GAGoB,mEAEQ,CCYC,CAAA,uBDVP,CAAC,A2CeA,0E3CPzB,SACF,CAAA,IAAA,CAAA,gBAAA,CAAA,EAAA,sIAU2B,uDAQqB,CAAA,yCAG1D,QAAA,wBACqB,CAAC,GAAA,CAAA,EAAA,SAAsB,6HAWL,EAAK,aAAa,CAAC,CAAC,AqCrBA,0CrCwBnC,CAAA,EAAA,OAAa,CAAC,AzBwDF,QyBtDtC,OAAA,CAAA,EAAA,OAAsB,CAAA,GAAA,CAAA,AAAK,GAAA,IAAA,CAAA,gBAAA,CAA+B,EAAO,CcqEJ,EdrEE,GAClD,6BACc,IAAI,CAAC,I+B0FI,CwCnBI,AxCmBH,CAAA,G/BzF5B,EAAK,MAAA,CACtB,EAAA,MAAA,CAAA,EAAA,MAAA,wFAG6B,GAAA,CAAA,IAAA,qBACE,GAAA,CAAA,SAAa,aAKY,CAAA,eAEtD,EAAA,IAAA,CAAA,sBAAqC,CAAA,SAC3C,aAAA,+DAImC,2BAE/B,aAAA,EAAA,YAAiC,CoE6JH,0DpEvJlC,CgEuGC,AKwIA,ApPxKJ,KAAA,EAAA,IAAA,c+KrEG,IAAK,IAAA,KAAA,GAAA,4BAIY,SACF,KAAW,EAAA,EAAA,QAAuB,CAAC,CAAE,CyCVC,AxO0CR,A+LhCQ,4BAElB,MACW,QAAkB,EAE7C,CzBkGL,WAAA,QyBjGQ,iBACY,CvG4DP,AtE1BA,A8KaQ,AmE2IN,4BpEzLY,CAAC,C+BgIC,CAAA,O/B9H1B,IACO,CAAC,EAAA,SACL,CAAA,kDAUY,CAAuB,CqE0P1B,SrEzPL,QAAQ,CAAC,C4C7BC,AvB2CA,ErBdE,CAAC,aAOnB,EAAA,KANV,KAAA,CAAA,EAAA,KAAkB,mBACA,CyDjBC,CAAC,AxOsGV,AAAC,C+P3GU,AvBKA,A1BsJA,AnDrHD,A3JqET,cAAA,qB+KpFO,CAAA,EAAA,kBAA0B,GAC3C,QAAA,KACG,QAAQ,CAAA,EAAA,QAAA,CAAoB,GAAG,CAAC,EAAA,SAAa,CAAC,CAAC,AAEzC,OAAA,OAAwB,CAAC,0CAItB,CAAC,GAAA,CACd,IAAA,EAAA,EAAyB,SAEd,MADJ,CAAA,EAAA,CAAA,EACI,GACH,EAAA,GACA,EAAA,EADiB,EACjB,CAAA,IAAa,CAAA,SAAU,CAAC,CyCLC,AvBiEA,CuBjEC,AvBiEA,CAAC,ClB5DC,CAAC,C8E5BC,aAAA,C9E4Bc,EAAM,G0CuFG,AzO3BR,A+L5De,C0CuFC,Y1CtFnC,OACb,CAAA,gBAAA,CAAkB,CtB+DD,A+DnEE,CzCIK,CtB+DL,CsB/DG,A/L6DR,A+L7DmB,EAAM,OAAO,CAAC,CAAC,CAAC,M/L8DjD,CAC5B,CAAC,O+LzDa,CAAC,EAAA,CAAA,IAAA,CAAA,SAAsB,CAAA,IAAA,CAAM,cAAA,CAAe,EAAO,C7KmFV,E6KnFoB,CuEoF1D,EvEnFH,Cc+FD,CAAA,Kd9FE,EAAA,CADmB,AACnB,CADoB,AqBmBF,A1C6DJ,AoDuEI,G/BtJlB,CAAA,gBAAA,CAA8B,C2DMC,CAAA,E3DNe,EAAM,GACrD,KAAA,IAAA,MACC,CADoB,CACpB,AADqB,CkBiED,AlBhEZ,CkBgEa,AlBhEb,sBAMC,CAAE,CAAA,CAAA,CAE3B,C/KiGH,AyNGI,AvNVJ,kB6K3FkB,CAAG,E/KkGrB,mB+K9F0B,CAAA,CAAA,CAA6B,CAAE,CAAA,CAAc,CAAA,CAAA,kCACnC,CAAC,EAAA,EAAA,EAAA,QAA4B,CAAC,GAAG,CAAC,EAAU,OAAD,CAAS,CAAE,CAAE,EAAU,QAAQ,CAAC,CAAC,sBAG1C,CAAA,KAC7D,EAAA,EAAqB,QAAA,CAAA,GAAA,CAAa,gFAEc,CjM4HD,CiM5HS,CjM4HP,aiM5HoB,CAAC,CAAC,wBAEpC,CAAC,EAAA,OAAA,oBAElB,EAAA,OAAe,CAAA,0BACK,CAAA,EAAA,EAAA,OACzB,OAAA,CAAQ,IAAA,CAAA,+BAMF,CAAY,CAAA,CACrC,IAAA,EAAkB,IAAA,CAAA,YAAiB,CAAA,EAAS,CoEgQH,QpEhQY,SAQ/C,IAAA,GAPA,EAAA,MAAA,KAQF,KAAA,wBAN+B,CAAC,UAC9B,EAAA,WAAiC,OAa3B,MAAM,QAZa,WACb,EAAA,SAAA,GAed,0BAM2B,CAAA,YACpB,CAAA,KAAA,CAAA,UAAA,CAAA,EAAuB,2BAI9B,CAAA,KAAO,GAG2B,CgEmGE,AhEnGD,EAAE,KAAjC,CAAC,CxDyGH,AzIwCE,kBiMjJoB,CAAA,IAAK,CqEmQK,+BrElQJ,GAE3B,IAAI,CAAA,mBAAoB,CAAA,GAAA,CAAK,sBAGF,CAAA,QACD,GAAQ,CAAC,AoEmSJ,AxBzUI,AoCmBA,KhFmBjC,mBAAA,CAAoB,IAAI,MACzB,CAAC,yBAAA,4BAEgC,MAAM,CAAC,CtB0FvC,kCsBrFL,CgFrBC,ChFqBI,MACJ,IAAA,KAAA,GAA2B,CgB7BC,GAAA,CAAA,OhB6BW,CAAC,eACrC,mCAC6B,C/KsIL,A+LnKM,A0B6HA,AoC9HA,C9E8BQ,EAAE,AgB7BA,sPAtKlD,SAAA,CAAA,yFAQ6B,OAAA,CAAA,wCmDtG6D,WAC1E,CAAC,EAAA,IAAA,iDpDyBsC,oMoC5CnD,EAAA,IAAA,wBAAqC,oHpCkDG,mHAK0C,0CACI,oFAK9B,yFAKV,4BACY,4CAGM,4KA8BtC,GAAc,CuCfL,GvCeS,CuCfL,EAAA,6BvCgBqB,uBAC1B,GAAA,2BACI,GAAwB,GG0EjD,0CHzEiD,CAAA,4DAEU,IAGlF,CAAC,A+DlBA,AJ0MA,wBrClQwJ,C5F2B9E,CDGlE,ACHkE,CAAA,C4F3BgI,CAAuB,eAErM,MAA2B,IAAkB,EAAS,EAAS,EAAQ,CAAC,EAAX,EAAS,EAAQ,CAAC,GAAQ,CAAA,CAAE,CAAJ,AAAkB,CAAC,uFA7BpH,KAAA,GAAA,CAAA,CAAA,CAAA,qNA8DoB,EAAA,EAAA,GAAA,uCAGsB,EAAA,EAAW,EAAQ,GAAA,GAAA,OAA2B,wBAAwB,CAAA,EAAM,EAAI,CLoFD,8DKlFpF,GAAQ,CAAC,eASzD,GAT2E,AAS3E,IpNgEyE,CACxE,CAAC,eoNnDgB,CAAA,CAAA,CAAA,CAAA,CAAA,CAAgE,CAAA,sCAEhD,KAClB,MAAA,mFAA0F,CAAC,KAAK,CAAE,CAAG,CAAC,EAAK,CAAC,CAAF,AAAG,CAAC,mBAGlH,MAAA,gCAAA,OAAmD,GAAQ,sHAGlE,GAAA,KAAA,EAAA,QACwE,CAAA,EAAA,EACxE,CAAA,EAAM,CvN0GM,mCuNxGuC,GAAY,CpC2DC,EoC3DO,EAAO,KzDiBf,CAAC,CAAC,CyDjBqB,CAAC,CAAC,6DAMxF,CAAC,wEAgByB,CAAC,EAAI,WACH,AAAW,UAAA,AAA0B,CnBqFC,SmBrF3B,OAAA,GAAwD,QAAQ,EAAE,AAA5B,CAA6B,GnBqFzB,GmBrFG,GACrE,CAAA,EAAA,AnBoF2E,AmBrFA,CAC3E,AnBoF4E,CAAC,EmBpF9D,EAAA,QAEP,UAKvB,+DRxHa,4L/BlBK,0FAQV,IAAA,IAAA,oCAIT,EAAA,GAAA,GAAA,IAAA,YAKsB,YACxB,qBAEkB,CAAA,QAAA,CAAA,QAUN,EAAA,UAAA,CAAA,cAAkC,CAAC,WAAW,CAAC,UAC/D,EAAS,MAAA,CAAA,SAAgB,CAAA,sBAAuB,CAAC,SAAS,CAAA,EAAU,GAAG,AAAC,KAAA,CAAA,CAAA,SAAA,EAAkB,MAAA,CAAA,EAAA,EAAQ,IpGgClF,AoGhCsF,EAAA,EAAI,SAAS,CAAA,QAAA,CAAU,CAAC,CAAC,CAAC,EnMhDpI,IAAI,GAAY,OAAO,cAAc,CACjC,GAAS,CAAC,EAAQ,IAAU,GAAU,EAAQ,OAAQ,CAAE,QAAO,cAAc,CAAK,GAIlF,GAAY,YACZ,GAAe,eACnB,SAAS,GAAe,CAAI,EAC1B,OAAO,GAAW,UAAU,CAAC,EAAM,GACrC,CACA,GAAO,GAAgB,kBACvB,IAAI,GAAO,OACP,GAAS,SACb,SAAS,GAAS,CAAI,EACpB,OAAO,GAAW,UAAU,CAAC,EAAM,GACrC,CACA,GAAO,GAAU,YACjB,IAAI,GAAW,WACX,GAAgB,gBAChB,GAAoB,oBACpB,GAAS,SACb,SAAS,GAAS,CAAI,EACpB,OAAO,GAAW,UAAU,CAAC,EAAM,GACrC,CACA,GAAO,GAAU,YACjB,IAAI,GAAQ,QACR,GAAO,OACP,GAAQ,QACR,GAAW,WACf,SAAS,GAAW,CAAI,EACtB,OAAO,GAAW,UAAU,CAAC,EAAM,GACrC,CACA,GAAO,GAAY,cACnB,IAAI,GAAQ,QACR,GAAO,OACX,SAAS,GAAO,CAAI,EAClB,OAAO,GAAW,UAAU,CAAC,EAAM,GACrC,CACA,GAAO,GAAQ,UACf,IAAI,GAAO,OACP,GAAW,WACX,GAAQ,QACZ,SAAS,GAAQ,CAAI,EACnB,OAAO,GAAW,UAAU,CAAC,EAAM,GACrC,CACA,GAAO,GAAS,WAChB,IAAI,GAAS,SACT,GAAS,SACb,SAAS,GAAS,CAAI,EACpB,OAAO,GAAW,UAAU,CAAC,EAAM,GACrC,CACA,GAAO,GAAU,YACjB,IAAI,GAAc,cAClB,SAAS,GAAc,CAAI,EACzB,OAAO,GAAW,UAAU,CAAC,EAAM,GACrC,CAGA,SAAS,GAAM,CAAI,EACjB,OAAO,GAAW,UAAU,CAAC,MAAM,EACrC,CAJA,GAAO,GAAe,iBAKtB,GAAO,GAAO,SACd,IAAI,GAAa,aACjB,SAAS,GAAa,CAAI,EACxB,OAAO,GAAW,UAAU,CAAC,EAAM,GACrC,CACA,GAAO,GAAc,gBACrB,IAAI,GAAQ,QACR,GAAU,UACV,GAAU,UACd,SAAS,GAAU,CAAI,EACrB,OAAO,GAAW,UAAU,CAAC,EAAM,GACrC,CACA,GAAO,GAAW,aAClB,IAAI,GAAa,aACb,GAAY,YACZ,GAAO,OACP,GAAU,UACV,GAAuB,cAAc,EACvC,MAAO,CACL,GAAO,IAAI,CAAE,uBACf,CAAC,AACD,aAAc,CACZ,MAAO,CAAC,GAAc,GAAM,GAAQ,GAAU,GAAe,GAAmB,GAAQ,GAAO,GAAW,GAAM,GAAO,GAAU,GAAO,GAAM,GAAM,GAAU,GAAM,GAAO,GAAQ,GAAQ,SAAkB,GAAY,GAAO,GAAS,GAAS,GAAW,GAAS,GAAW,AACnR,CACA,iBAAiB,CAAO,CAAE,CAAS,CAAE,CACnC,OAAQ,GACN,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACH,OAAO,IAAI,CAAC,SAAS,CAAC,GAAW,EAEnC,MAAK,GACH,OAAO,IAAI,CAAC,SAAS,CAAC,GAAU,EAElC,MAAK,GACL,KAAK,GACH,OAAO,IAAI,CAAC,SAAS,CAAC,GAAM,EAE9B,SACE,OAAO,CAEX,CACF,CACA,iBAAiB,CAAO,CAAE,CACxB,IAAM,EAAc,CAAA,EAAG,EAAQ,SAAS,CAAC,KAAK,CAAC,CAAC,EAAE,EAAQ,QAAQ,CAAA,CAAE,CACpE,GACO,eADC,EAEJ,OAAO,EAGP,OAAM,AAAI,MAAM,CAAA,EAAG,EAAY,6BAA6B,CAAC,CAGnE,CACA,gBAAgB,CAAI,CAAE,CACpB,OAAQ,GACN,KAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,QAAS,aAAc,EAAE,AAAC,EAClC,CAAE,KAAM,SAAU,aAAc,EAAE,AAAC,EACnC,CAAE,KAAM,YAAa,aAAc,EAAE,AAAC,EACtC,CAAE,KAAM,WAAY,aAAc,EAAE,AAAC,EACrC,CAAE,KAAM,OAAQ,EACjB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,OAAQ,EAChB,CAAE,KAAM,MAAO,EAChB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,MAAO,EACf,CAAE,KAAM,OAAQ,EACjB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,QAAS,EAClB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,IAAK,EACb,CAAE,KAAM,QAAS,EACjB,CAAE,KAAM,OAAQ,aAAc,EAAG,AAAD,EACjC,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,WAAY,EACpB,CAAE,KAAM,WAAY,EACrB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,IAAK,EACb,CAAE,KAAM,SAAU,EAClB,CAAE,KAAM,OAAQ,aAAc,EAAE,AAAC,EACjC,CAAE,KAAM,MAAO,EAChB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,UAAW,aAAc,EAAE,AAAC,EACpC,CAAE,KAAM,OAAQ,EAChB,CAAE,KAAM,MAAO,EAChB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,QAAS,EACjB,CAAE,KAAM,WAAY,cAAc,CAAM,EACxC,CAAE,KAAM,OAAQ,EAChB,CAAE,KAAM,UAAW,cAAc,CAAM,EACvC,CAAE,KAAM,QAAS,EACjB,CAAE,KAAM,WAAY,cAAc,CAAM,EACxC,CAAE,KAAM,OAAQ,EAChB,CAAE,KAAM,UAAW,cAAc,CAAM,EACvC,CAAE,KAAM,OAAQ,EACjB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,MAAO,EACf,CAAE,KAAM,OAAQ,EACjB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,aAAc,aAAc,EAAE,AAAC,EACvC,CAAE,KAAM,OAAQ,EACjB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,MAAO,EACf,CAAE,KAAM,IAAK,EACb,CAAE,KAAM,IAAK,EACb,CAAE,KAAM,OAAQ,EACjB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,OAAQ,EACjB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,eAAgB,EACxB,CAAE,KAAM,MAAO,EAChB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,IAAK,EACb,CAAE,KAAM,IAAK,EACd,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,QAAS,EACjB,CAAE,KAAM,IAAK,EACb,CAAE,KAAM,OAAQ,aAAc,EAAE,AAAC,EACjC,CAAE,KAAM,MAAO,EAChB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,MAAO,EACf,CAAE,KAAM,QAAS,cAAc,CAAM,EACtC,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,SAAU,aAAc,EAAE,AAAC,EACnC,CAAE,KAAM,OAAQ,EAEpB,AADG,CAGL,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,MAAO,EACf,CAAE,KAAM,KAAM,EACd,CAAE,KAAM,OAAQ,EAChB,CAAE,KAAM,OAAQ,EACjB,AACH,CAEF,KAAK,MACH,MAAO,CACL,MAAM,KACN,WAAY,CACV,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,WAAY,aAAc,EAAE,AAAC,EACrC,CAAE,KAAM,WAAY,cAAc,CAAM,EACxC,CAAE,KAAM,OAAQ,EACjB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,OAAQ,EAChB,CAAE,KAAM,OAAQ,EACjB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,OAAQ,aAAc,EAAE,AAAC,EACjC,CAAE,KAAM,SAAU,aAAc,EAAE,AAAC,EACnC,CAAE,KAAM,UAAW,aAAc,EAAG,AAAD,EACnC,CAAE,KAAM,OAAQ,EACjB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,MAAO,EACf,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,IAAK,EACb,CAAE,KAAM,IAAK,EACb,CAAE,KAAM,OAAQ,EACjB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,OAAQ,EAChB,CAAE,KAAM,cAAe,aAAc,EAAG,AAAD,EACxC,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,QAAS,EACjB,CAAE,KAAM,MAAO,EAChB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,UAAW,EACnB,CAAE,KAAM,KAAM,EACd,CAAE,KAAM,aAAc,aAAc,EAAG,AAAD,EACtC,CAAE,KAAM,OAAQ,EACjB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,eAAgB,EACxB,CAAE,KAAM,MAAO,EACf,CAAE,KAAM,OAAQ,EACjB,AACH,CAEF,MAAK,GACH,MAAO,CACL,KAAM,GACN,WAAY,CACV,CAAE,KAAM,eAAgB,EACxB,CAAE,KAAM,MAAO,EAChB,AACH,CAEF,SACE,MAAO,CACL,KAAM,EACN,WAAY,EAAE,AAChB,CAEJ,CACF,CACF,EACI,GAAa,IAAI,GAKjB,GAA8B,GAAO,IAAM,IAA7B,CAAmD,GAAoB,GAAoB,CAAC,KAA/E,IAAqC,gjJAAmmJ,EAAC,CAAC,CAAG,eAExqJ,GAAgC,GAAO,IAAM,KAAwB,CAArD,EAA2E,GAAoB,CAAC,OAAnF,IAAuC,unLAA8qL,EAAC,CAAC,CAAG,iBAEvvL,GAA6B,GAAO,IAAM,GAA7B,EAAkD,GAAmB,GAAoB,CAAC,IAA7E,IAAoC,+3LAAg7L,CAAC,CAAC,EAAG,cAEn/L,GAAsC,GAAO,IAAM,KAA8B,GAA4B,GAAoB,CAAC,AAA5G,aAAa,IAA6C,q1WAAw5W,EAAC,CAAC,CAAG,uBAE7+W,GAAkC,GAAO,IAAM,KAA0B,GAAvD,AAA+E,GAAoB,CAAC,SAAvF,IAAyC,gqVAA2tV,EAAC,CAAC,CAAG,mBAExyV,GAA+B,GAAO,IAAM,KAA7B,AAAoD,GAAqB,GAAoB,CAAC,MAAjF,IAAsC,2qXAAguX,EAAC,CAAC,CAAG,gBAEvyX,GAAiC,GAAO,IAAM,KAAyB,EAAtD,CAA6E,GAAoB,CAAC,QAArF,IAAwC,y5RAAk9R,EAAC,CAAC,CAAG,kBAG7hS,GAAuB,CACzB,WAAY,OACZ,eAAgB,CAAC,OAAQ,WAAW,CACpC,iBAAiB,EACjB,KAAM,YACR,EACI,GAAyB,CAC3B,WAAY,SACZ,eAAgB,CAAC,OAAQ,WAAW,CACpC,iBAAiB,EACjB,KAAM,YACR,EACI,GAAsB,CACxB,WAAY,MACZ,eAAgB,CAAC,OAAQ,WAAW,CACpC,iBAAiB,EACjB,KAAM,YACR,EACI,GAA+B,CACjC,WAAY,eACZ,eAAgB,CAAC,OAAQ,WAAW,CACpC,iBAAiB,EACjB,KAAM,YACR,EACI,GAA2B,CAC7B,WAAY,WACZ,eAAgB,CAAC,OAAQ,WAAW,CACpC,iBAAiB,EACjB,KAAM,YACR,EACI,GAAwB,CAC1B,WAAY,QACZ,eAAgB,CAAC,OAAQ,WAAW,CACpC,iBAAiB,EACjB,KAAM,YACR,EACI,GAA0B,CAC5B,WAAY,UACZ,eAAgB,CAAC,OAAQ,WAAW,CACpC,iBAAiB,EACjB,KAAM,YACR,EACI,GAA+B,CACjC,cAA+B,CAAhB,EAAuB,IAAM,IAAI,GAAwB,AAA5C,gBAC9B,EACI,GAAsB,CACxB,QAAyB,CAAhB,EAAuB,IAAM,KAAe,EAA/B,SACtB,iBAAkC,CAAhB,EAAuB,IAAM,GAAsB,IAAtC,gBAC/B,OAAQ,CAAC,CACX,EACI,GAAwB,CAC1B,QAAyB,CAAhB,EAAuB,IAAM,KAAiB,EAAjC,SACtB,iBAAkC,CAAhB,EAAuB,IAAM,GAAwB,IAAxC,gBAC/B,OAAQ,CAAC,CACX,EACI,GAAqB,CACvB,QAAyB,CAAhB,EAAuB,IAAM,KAAc,EAA9B,SACtB,iBAAkC,CAAhB,EAAuB,IAAM,GAAqB,IAArC,gBAC/B,OAAQ,CAAC,CACX,EACI,GAA8B,CAChC,QAAyB,CAAhB,EAAuB,IAAM,KAAuB,EAAvC,SACtB,iBAAkC,CAAhB,EAAuB,IAAM,GAA8B,IAA9C,gBAC/B,OAAQ,CAAC,CACX,EACI,GAA0B,CAC5B,QAAyB,CAAhB,EAAuB,IAAM,KAAmB,EAAnC,SACtB,iBAAkC,CAAhB,EAAuB,IAAM,GAA0B,IAA1C,gBAC/B,OAAQ,CAAC,CACX,EACI,GAAuB,CACzB,QAAyB,CAAhB,EAAuB,IAAM,KAAgB,EAAhC,SACtB,iBAAkC,CAAhB,EAAuB,IAAM,GAAuB,IAAvC,gBAC/B,OAAQ,CAAC,CACX,EACI,GAAyB,CAC3B,QAAyB,CAAhB,EAAuB,IAAM,KAAkB,EAAlC,SACtB,iBAAkC,CAAhB,EAAuB,IAAM,GAAyB,IAAzC,gBAC/B,OAAQ,CAAC,CACX,EAWI,GAAe,CACjB,UAN4B,CAMjB,4CACX,UAN4B,CAMjB,2BACX,MANe,CAMR,sBACT,EACI,GAAgC,cAAc,GAChD,MAAO,CACL,GAAO,IAAI,CAAE,gCACf,CAAC,AACD,aAAa,CAAI,CAAE,CAAK,CAAE,CAAO,CAAE,CACjC,IAAI,EAAQ,IAAI,CAAC,kBAAkB,CAAC,EAAM,EAAO,SAIjD,CAHc,KAAK,GAAG,CAAlB,IACF,EAAQ,IAAI,CAAC,kBAAkB,CAAC,EAAM,EAAO,EAAA,EAEjC,KAAK,GAAG,CAAlB,GACK,KAAK,CAAC,aAAa,EAAM,EAAO,GAElC,CACT,CACA,mBAAmB,CAAI,CAAE,CAAK,CAAE,CAAQ,CAAE,CACxC,IAAM,EAAQ,EAAY,CAAC,EAAK,IAAI,CAAC,CACrC,GAAc,KAAK,GAAG,CAAlB,EACF,OAAO,AAET,IAAM,CAFQ,CAEA,EAAM,IAAI,CAAC,GACzB,GAAc,MAAM,CAAhB,GAGJ,GAAiB,KAAK,GAAG,CAArB,CAAK,CAAC,EAAE,CACV,OAAO,CAAK,CAAC,EAAE,CAAC,IAAI,GAAG,OAAO,CAAC,cAAe,KAEhD,GAAI,AAAa,KAAK,GAAG,EAAhB,CAAC,EAAE,CACV,OAAO,CAAK,CAAC,EAAE,CAAC,OAAO,CAAC,SAAU,IAAI,OAAO,CAAC,SAAU,IAAI,OAAO,CAAC,cAAe,KAAK,OAAO,CAAC,eAAgB,MAGpH,CACF,EACI,GAAuB,cAAc,GACvC,MAAO,CACL,GAAO,IAAI,CAAE,uBACf,CAAC,AACD,mBAAmB,CAAK,CAAE,CAAM,CAAE,CAAQ,CAAE,CAE5C,CACF,EAII,GAA8B,cAAc,GAC9C,MAAO,CACL,GAAO,IAAI,CAAE,8BACf,CACA,AADC,YACW,CAAQ,CAAE,CACpB,KAAK,GACL,IAAI,CAAC,QAAQ,CAAG,IAAI,IAAI,EAC1B,CACA,mBAAmB,CAAK,CAAE,CAAc,CAAE,CAAO,CAAE,CACjD,IAAM,EAAa,KAAK,CAAC,mBAAmB,EAAO,EAAgB,GAMnE,OALA,EAAW,OAAO,CAAC,AAAC,IACd,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,EAAU,IAAI,GAA2B,KAAK,GAAG,CAA9B,EAAU,OAAO,GACxD,EAAU,OAAO,CAAG,AAAI,OAAO,EAAU,OAAO,CAAC,QAAQ,GAAK,qBAAA,CAElE,GACO,CACT,CACF,EACI,GAAqB,cAAc,GACrC,MAAO,CACL,GAAO,IAAI,CAAE,qBACf,CAAC,AACH,ycAjiBU","ignoreList":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343]}